<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>haoran&#39;s blog</title>
  
  <subtitle>Talk is cheap. Show me the code</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://javassun.github.io/"/>
  <updated>2020-05-18T07:46:30.881Z</updated>
  <id>http://javassun.github.io/</id>
  
  <author>
    <name>Allen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>8-如何设计一个消息队列</title>
    <link href="http://javassun.github.io/2020/04/11/8-%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    <id>http://javassun.github.io/2020/04/11/8-%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</id>
    <published>2020-04-11T11:44:16.000Z</published>
    <updated>2020-05-18T07:46:30.881Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-面试官心里分析"><a href="#1-面试官心里分析" class="headerlink" title="1. 面试官心里分析"></a>1. 面试官心里分析</h2><p>如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路</p><p>其实聊到这个问题，一般面试官要考察两块：</p><ul><li><p>你有没有对某一个消息队列做过较为深入的原理的了解，或者从整体了解把握住一个mq的架构原理</p></li><li><p>看看你的设计能力，给你一个常见的系统，就是消息队列系统，看看你能不能从全局把握一下整体架构设计，给出一些关键点出来</p></li></ul><p>说实话，遇到类似此类问题，大部分人基本都会蒙，因为平时从来没有思考过类似的问题，大多数人就是平时埋头用，从来不去思考背后的一些东西。类似的问题，如果让你来设计一个spring框架你会怎么做？如果让你来设计一个dubbo框架你会怎么做？如果让你来设计一个mybatis框架你会怎么做？</p><a id="more"></a><h2 id="2-面试题剖析"><a href="#2-面试题剖析" class="headerlink" title="2. 面试题剖析"></a>2. 面试题剖析</h2><p>其实回答这类问题，说白了，起码不求你看过那技术的源码，起码你大概知道那个技术的基本原理，核心组成部分，基本架构构成，然后参照一些开源的技术把一个系统设计出来的思路说一下就好。</p><p>比如说这个消息队列系统，我们来从以下几个角度来考虑一下</p><h3 id="1-支持可伸缩性"><a href="#1-支持可伸缩性" class="headerlink" title="1 支持可伸缩性"></a>1 支持可伸缩性</h3><p>首先这个mq得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下kafka的设计理念，broker -&gt; topic -&gt; partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？</p><h3 id="2-落地磁盘"><a href="#2-落地磁盘" class="headerlink" title="2 落地磁盘"></a>2 落地磁盘</h3><p>其次你得考虑一下这个mq的数据要不要落地磁盘吧？那肯定要了，落磁盘，才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是kafka的思路。</p><h3 id="3-可用性"><a href="#3-可用性" class="headerlink" title="3 可用性"></a>3 可用性</h3><p>其次你考虑一下你的mq的可用性啊？这个事儿，具体参考我们之前可用性那个环节讲解的kafka的高可用保障机制。多副本 -&gt; leader &amp; follower -&gt; broker挂了重新选举leader即可对外服务。</p><h3 id="4-支持数据0丢失"><a href="#4-支持数据0丢失" class="headerlink" title="4 支持数据0丢失"></a>4 支持数据0丢失</h3><p>能不能支持数据0丢失啊？可以的，参考我们之前说的那个kafka数据零丢失方案</p><p>其实一个mq肯定是很复杂的，面试官问你这个问题，其实是个开放题，他就是看看你有没有从架构角度整体构思和设计的思维以及能力。确实这个问题可以刷掉一大批人，因为大部分人平时不思考这些东西。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>一般而言，如果一个面试官水平还算不错，会沿着从浅入深的环节深入挖一个点。比如一些大牛面试官，其实按照这个思路可以一直问下去，除了这里的7个问题之外，甚至能挑着你熟悉的一个mq一直问到源码级别非常底层。还可能会结合项目来仔细问，可能会先让你给我详细说说你的业务细节，然后将你的业务跟这些mq的问题场景结合起来，看看你每个细节是怎么处理的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-面试官心里分析&quot;&gt;&lt;a href=&quot;#1-面试官心里分析&quot; class=&quot;headerlink&quot; title=&quot;1. 面试官心里分析&quot;&gt;&lt;/a&gt;1. 面试官心里分析&lt;/h2&gt;&lt;p&gt;如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路&lt;/p&gt;
&lt;p&gt;其实聊到这个问题，一般面试官要考察两块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;你有没有对某一个消息队列做过较为深入的原理的了解，或者从整体了解把握住一个mq的架构原理&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;看看你的设计能力，给你一个常见的系统，就是消息队列系统，看看你能不能从全局把握一下整体架构设计，给出一些关键点出来&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;说实话，遇到类似此类问题，大部分人基本都会蒙，因为平时从来没有思考过类似的问题，大多数人就是平时埋头用，从来不去思考背后的一些东西。类似的问题，如果让你来设计一个spring框架你会怎么做？如果让你来设计一个dubbo框架你会怎么做？如果让你来设计一个mybatis框架你会怎么做？&lt;/p&gt;
    
    </summary>
    
    
      <category term="MQ" scheme="http://JavaSsun.github.io/categories/MQ/"/>
    
      <category term="面试" scheme="http://JavaSsun.github.io/categories/MQ/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/categories/MQ/%E9%9D%A2%E8%AF%95/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="面试" scheme="http://JavaSsun.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
      <category term="MQ" scheme="http://JavaSsun.github.io/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>45-自增ID用完怎么办</title>
    <link href="http://javassun.github.io/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/"/>
    <id>http://javassun.github.io/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/</id>
    <published>2020-03-11T13:18:38.000Z</published>
    <updated>2020-05-20T20:17:41.473Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>MySQL里有很多自增的id，每个自增id都是定义了初始值，然后不停地往上加步长。虽然自然数是没有上限的，但是在计算机里，只要定义了表示这个数的字节长度，那它就有上限。比如，无符号整型(unsigned int)是4个字节，上限就是2<sup>32</sup>-1。</p><p>既然自增id有上限，就有可能被用完。但是，自增id用完了会怎么样呢？</p><p>今天这篇文章，我们就来看看MySQL里面的几种自增id，一起分析一下它们的值达到上限以后，会出现什么情况。</p><a id="more"></a><h2 id="1-表定义自增值id"><a href="#1-表定义自增值id" class="headerlink" title="1. 表定义自增值id"></a>1. 表定义自增值id</h2><p>说到自增id，你第一个想到的应该就是表结构定义里的自增字段，也就是在 <strong>第39篇文章</strong> 中和你介绍过的自增主键id。</p><p>表定义的自增值达到上限后的逻辑是：再申请下一个id时，得到的值保持不变。</p><p>我们可以通过下面这个语句序列验证一下：</p><p><img src="/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/8542df98-a3c7-45c2-aca1-e971baf20d6d.png" alt></p><p>可以看到，第一个insert语句插入数据成功后，这个表的AUTO_INCREMENT没有改变（还是4294967295），就导致了第二个insert语句又拿到相同的自增id值，再试图执行插入语句，报主键冲突错误。</p><p>2<sup>32</sup>-1（4294967295）不是一个特别大的数，对于一个频繁插入删除数据的表来说，是可能会被用完的。因此在建表的时候你需要考察你的表是否有可能达到这个上限，如果有可能，就应该创建成8个字节的bigint unsigned。</p><h2 id="2-InnoDB系统自增row-id"><a href="#2-InnoDB系统自增row-id" class="headerlink" title="2. InnoDB系统自增row_id"></a>2. InnoDB系统自增row_id</h2><p>如果你创建的InnoDB表没有指定主键，那么InnoDB会给你创建一个不可见的，长度为6个字节的row_id。InnoDB维护了一个全局的dict_sys.row_id值，所有无主键的InnoDB表，每插入一行数据，都将当前的dict_sys.row_id值作为要插入数据的row_id，然后把dict_sys.row_id的值加1。</p><p>实际上，在代码实现时row_id是一个长度为8字节的无符号长整型(bigint unsigned)。但是，InnoDB在设计时，给row_id留的只是6个字节的长度，这样写到数据表中时只放了最后6个字节，所以row_id能写到数据表中的值，就有两个特征：</p><ol><li><p>row_id写入表中的值范围，是从0到2<sup>48</sup>-1；</p></li><li><p>当dict_sys.row_id=2<sup>48</sup>时，如果再有插入数据的行为要来申请row_id，拿到以后再取最后6个字节的话就是0。</p></li></ol><p>也就是说，写入表的row_id是从0开始到2<sup>48</sup>-1。达到上限后，下一个值就是0，然后继续循环。</p><p>当然，2<sup>48</sup>-1这个值本身已经很大了，但是如果一个MySQL实例跑得足够久的话，还是可能达到这个上限的。在InnoDB逻辑里，申请到row_id=N后，就将这行数据写入表中；如果表中已经存在row_id=N的行，新写入的行就会覆盖原有的行。</p><p>要验证这个结论的话，你可以通过gdb修改系统的自增row_id来实现。注意，用gdb改变量这个操作是为了便于我们复现问题，只能在测试环境使用。</p><p><img src="/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/f0b4de21-192a-4098-9b54-9974638b56db.jpg" alt></p><p>可以看到，在我用gdb将dict_sys.row_id设置为2<sup>48</sup>之后，再插入的a=2的行会出现在表t的第一行，因为这个值的row_id=0。之后再插入的a=3的行，由于row_id=1，就覆盖了之前a=1的行，因为a=1这一行的row_id也是1。</p><p>从这个角度看，我们还是应该在InnoDB表中主动创建自增主键。因为，表自增id到达上限后，再插入数据时报主键冲突错误，是更能被接受的。</p><p>毕竟覆盖数据，就意味着数据丢失，影响的是数据可靠性；报主键冲突，是插入失败，影响的是可用性。而一般情况下，可靠性优先于可用性。</p><h2 id="3-Xid"><a href="#3-Xid" class="headerlink" title="3. Xid"></a>3. Xid</h2><p>在 <strong>第15篇文章《答疑文章（一）：日志和索引相关问题》</strong> 中，我和你介绍redo log和binlog相配合的时候，提到了它们有一个共同的字段叫作Xid。它在MySQL中是用来对应事务的。</p><p>那么，Xid在MySQL内部是怎么生成的呢？</p><p>MySQL内部维护了一个全局变量global_query_id，每次执行语句的时候将它赋值给Query_id，然后给这个变量加1。如果当前语句是这个事务执行的第一条语句，那么MySQL还会同时把Query_id赋值给这个事务的Xid。</p><p>而global_query_id是一个纯内存变量，重启之后就清零了。所以你就知道了，在同一个数据库实例中，不同事务的Xid也是有可能相同的。</p><p>但是MySQL重启之后会重新生成新的binlog文件，这就保证了，同一个binlog文件里，Xid一定是惟一的。</p><p>虽然MySQL重启不会导致同一个binlog里面出现两个相同的Xid，但是如果global_query_id达到上限后，就会继续从0开始计数。从理论上讲，还是就会出现同一个binlog里面出现相同Xid的场景。</p><p>因为global_query_id定义的长度是8个字节，这个自增值的上限是2<sup>64</sup>-1，要出现这种情况，必须是下面这样的过程：</p><ol><li><p>执行一个事务，假设Xid是A；</p></li><li><p>接下来执行2<sup>64</sup>次查询语句，让global_query_id回到A；</p></li><li><p>再启动一个事务，这个事务的Xid也是A。</p></li></ol><p>不过，2<sup>64</sup>这个值太大了，大到你可以认为这个可能性只会存在于理论上。</p><h2 id="4-Innodb-trx-id"><a href="#4-Innodb-trx-id" class="headerlink" title="4. Innodb trx_id"></a>4. Innodb trx_id</h2><p>Xid和InnoDB的trx_id是两个容易混淆的概念。</p><p>Xid是由server层维护的。InnoDB内部使用Xid，就是为了能够在InnoDB事务和server之间做关联。但是，InnoDB自己的trx_id，是另外维护的。</p><p>其实，你应该非常熟悉这个trx_id。它就是在我们在 <strong>第8篇文章《事务到底是隔离的还是不隔离的？》</strong> 中讲事务可见性时，用到的事务id（transaction id）。</p><p>InnoDB内部维护了一个max_trx_id全局变量，每次需要申请一个新的trx_id时，就获得max_trx_id的当前值，然后并将max_trx_id加1。</p><p>InnoDB数据可见性的核心思想是：每一行数据都记录了更新它的trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的trx_id做对比。</p><p>对于正在执行的事务，你可以从information_schema.innodb_trx表中看到事务的trx_id。</p><p>我在上一篇文章的末尾留给你的思考题，就是关于从innodb_trx表里面查到的trx_id的。现在，我们一起来看一个事务现场：</p><p><img src="/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/d63c1cc4-7682-4787-a428-44dd3e0e6a26.png" alt></p><p>session B里，我从innodb_trx表里查出的这两个字段，第二个字段trx_mysql_thread_id就是线程id。显示线程id，是为了说明这两次查询看到的事务对应的线程id都是5，也就是session A所在的线程。</p><p>可以看到，T2时刻显示的trx_id是一个很大的数；T4时刻显示的trx_id是1289，看上去是一个比较正常的数字。这是什么原因呢？</p><p>实际上，在T1时刻，session A还没有涉及到更新，是一个只读事务。而对于只读事务，InnoDB并不会分配trx_id。也就是说：</p><ol><li><p>在T1时刻，trx_id的值其实就是0。而这个很大的数，只是显示用的。一会儿我会再和你说说这个数据的生成逻辑。</p></li><li><p>直到session A 在T3时刻执行insert语句的时候，InnoDB才真正分配了trx_id。所以，T4时刻，session B查到的这个trx_id的值就是1289。</p></li></ol><p>需要注意的是，除了显而易见的修改类语句外，如果在select 语句后面加上for update，这个事务也不是只读事务。</p><p>有同学提出，实验的时候发现不止加1。这是因为：</p><ol><li><p>update 和 delete语句除了事务本身，还涉及到标记删除旧数据，也就是要把数据放到purge队列里等待后续物理删除，这个操作也会把max_trx_id+1， 因此在一个事务中至少加2；</p></li><li><p>InnoDB的后台操作，比如表的索引信息统计这类操作，也是会启动内部事务的，因此你可能看到，trx_id值并不是按照加1递增的。</p></li></ol><p>那么，<strong>T2时刻查到的这个很大的数字是怎么来的呢？</strong></p><p>其实，这个数字是每次查询的时候由系统临时计算出来的。它的算法是：把当前事务的trx变量的指针地址转成整数，再加上2<sup>48</sup>。使用这个算法，就可以保证以下两点：</p><ol><li><p>因为同一个只读事务在执行期间，它的指针地址是不会变的，所以不论是在 innodb_trx还是在innodb_locks表里，同一个只读事务查出来的trx_id就会是一样的。</p></li><li><p>如果有并行的多个只读事务，每个事务的trx变量的指针地址肯定不同。这样，不同的并发只读事务，查出来的trx_id就是不同的。</p></li></ol><p>那么，<strong>为什么还要再加上2<sup>48</sup>呢？</strong></p><p>在显示值里面加上2<sup>48</sup>，目的是要保证只读事务显示的trx_id值比较大，正常情况下就会区别于读写事务的id。但是，trx_id跟row_id的逻辑类似，定义长度也是8个字节。因此，在理论上还是可能出现一个读写事务与一个只读事务显示的trx_id相同的情况。不过这个概率很低，并且也没有什么实质危害，可以不管它。</p><p>另一个问题是，<strong>只读事务不分配trx_id，有什么好处呢？</strong></p><ul><li><p>一个好处是，这样做可以减小事务视图里面活跃事务数组的大小。因为当前正在运行的只读事务，是不影响数据的可见性判断的。所以，在创建事务的一致性视图时，InnoDB就只需要拷贝读写事务的trx_id。</p></li><li><p>另一个好处是，可以减少trx_id的申请次数。在InnoDB里，即使你只是执行一个普通的select语句，在执行过程中，也是要对应一个只读事务的。所以只读事务优化后，普通的查询语句不需要申请trx_id，就大大减少了并发事务申请trx_id的锁冲突。</p></li></ul><p>由于只读事务不分配trx_id，一个自然而然的结果就是trx_id的增加速度变慢了。</p><p>但是，max_trx_id会持久化存储，重启也不会重置为0，那么从理论上讲，只要一个MySQL服务跑得足够久，就可能出现max_trx_id达到2<sup>48</sup>-1的上限，然后从0开始的情况。</p><p>当达到这个状态后，MySQL就会持续出现一个脏读的bug，我们来复现一下这个bug。</p><p>首先我们需要把当前的max_trx_id先修改成2<sup>48</sup>-1。注意：这个case里使用的是可重复读隔离级别。具体的操作流程如下：</p><p><img src="/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/b4980826-15ef-4e17-bed7-bf65a9e7ce5c.png" alt></p><p>由于我们已经把系统的max_trx_id设置成了2<sup>48</sup>-1，所以在session A启动的事务TA的低水位就是2<sup>48</sup>-1。</p><p>在T2时刻，session B执行第一条update语句的事务id就是2<sup>48</sup>-1，而第二条update语句的事务id就是0了，这条update语句执行后生成的数据版本上的trx_id就是0。</p><p>在T3时刻，session A执行select语句的时候，判断可见性发现，c=3这个数据版本的trx_id，小于事务TA的低水位，因此认为这个数据可见。</p><p>但，这个是脏读。</p><p>由于低水位值会持续增加，而事务id从0开始计数，就导致了系统在这个时刻之后，所有的查询都会出现脏读的。</p><p>并且，MySQL重启时max_trx_id也不会清0，也就是说重启MySQL，这个bug仍然存在。</p><p>那么，<strong>这个bug也是只存在于理论上吗？</strong></p><p>假设一个MySQL实例的TPS是每秒50万，持续这个压力的话，在17.8年后，就会出现这个情况。如果TPS更高，这个年限自然也就更短了。但是，从MySQL的真正开始流行到现在，恐怕都还没有实例跑到过这个上限。不过，这个bug是只要MySQL实例服务时间够长，就会必然出现的。</p><p>当然，这个例子更现实的意义是，可以加深我们对低水位和数据可见性的理解。你也可以借此机会再回顾下 <strong>第8篇文章</strong> 中的相关内容。</p><h2 id="5-thread-id"><a href="#5-thread-id" class="headerlink" title="5. thread_id"></a>5. thread_id</h2><p>接下来，我们再看看线程id（thread_id）。其实，线程id才是MySQL中最常见的一种自增id。平时我们在查各种现场的时候，show processlist里面的第一列，就是thread_id。</p><p>thread_id的逻辑很好理解：系统保存了一个全局变量thread_id_counter，每新建一个连接，就将thread_id_counter赋值给这个新连接的线程变量。</p><p>thread_id_counter定义的大小是4个字节，因此达到2<sup>32</sup>-1后，它就会重置为0，然后继续增加。但是，你不会在show processlist里看到两个相同的thread_id。</p><p>这，是因为MySQL设计了一个唯一数组的逻辑，给新线程分配thread_id的时候，逻辑代码是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">do &#123; </span><br><span class="line">    new_id&#x3D; thread_id_counter++; </span><br><span class="line">&#125; while (!thread_ids.insert_unique(new_id).second);</span><br></pre></td></tr></table></figure><p>这个代码逻辑简单而且实现优雅，相信你一看就能明白。</p><h2 id="6-小结"><a href="#6-小结" class="headerlink" title="6. 小结"></a>6. 小结</h2><p>今天这篇文章，介绍了MySQL不同的自增id达到上限以后的行为。数据库系统作为一个可能需要7*24小时全年无休的服务，考虑这些边界是非常有必要的。</p><p>每种自增id有各自的应用场景，在达到上限后的表现也不同：</p><ol><li><p>表的自增id达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。</p></li><li><p>row_id达到上限后，则会归0再重新递增，如果出现相同的row_id，后写的数据会覆盖之前的数据。</p></li><li><p>Xid只需要不在同一个binlog文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。</p></li><li><p>InnoDB的max_trx_id 递增值每次MySQL重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的bug，好在留给我们的时间还很充裕。</p></li><li><p>thread_id是我们使用中最常见的，而且也是处理得最好的一个自增id逻辑了。</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;MySQL里有很多自增的id，每个自增id都是定义了初始值，然后不停地往上加步长。虽然自然数是没有上限的，但是在计算机里，只要定义了表示这个数的字节长度，那它就有上限。比如，无符号整型(unsigned int)是4个字节，上限就是2&lt;sup&gt;32&lt;/sup&gt;-1。&lt;/p&gt;
&lt;p&gt;既然自增id有上限，就有可能被用完。但是，自增id用完了会怎么样呢？&lt;/p&gt;
&lt;p&gt;今天这篇文章，我们就来看看MySQL里面的几种自增id，一起分析一下它们的值达到上限以后，会出现什么情况。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>44-一些常见问题</title>
    <link href="http://javassun.github.io/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>http://javassun.github.io/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</id>
    <published>2020-03-09T13:11:38.000Z</published>
    <updated>2020-05-20T20:15:46.633Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="1-join的用法"><a href="#1-join的用法" class="headerlink" title="1. join的用法"></a>1. join的用法</h2><p>在 <strong>第35篇文章《join语句怎么优化？》</strong> 中，在介绍join执行顺序的时候，用的都是straight_join。有人在文后提出了两个问题：</p><ol><li><p>如果用left join的话，左边的表一定是驱动表吗？</p></li><li><p>如果两个表的join包含多个条件的等值匹配，是都要写到on里面呢，还是只把一个条件写到on里面，其他条件写到where部分？</p></li></ol><p>为了同时回答这两个问题，我来构造两个表a和b：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table a(f1 int, f2 int, index(f1))engine&#x3D;innodb; </span><br><span class="line">create table b(f1 int, f2 int)engine&#x3D;innodb; </span><br><span class="line">insert into a values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6); </span><br><span class="line">insert into b values(3,3),(4,4),(5,5),(6,6),(7,7),(8,8);</span><br></pre></td></tr></table></figure><a id="more"></a><p>表a和b都有两个字段f1和f2，不同的是表a的字段f1上有索引。然后，我往两个表中都插入了6条记录，其中在表a和b中同时存在的数据有4行。</p><p>第二个问题，其实就是下面这两种写法的区别：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from a left join b on(a.f1&#x3D;b.f1) and (a.f2&#x3D;b.f2); &#x2F;*Q1*&#x2F; </span><br><span class="line">select * from a left join b on(a.f1&#x3D;b.f1) where (a.f2&#x3D;b.f2);&#x2F;*Q2*&#x2F;</span><br></pre></td></tr></table></figure><p>把这两条语句分别记为Q1和Q2。</p><p>首先，需要说明的是，这两个left join语句的语义逻辑并不相同。我们先来看一下它们的执行结果。</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/f37a2a42-2bf1-49ae-8e77-2a62c3592330.jpg" alt></p><p>可以看到：</p><ul><li>语句Q1返回的数据集是6行，表a中即使没有满足匹配条件的记录，查询结果中也会返回一行，并将表b的各个字段值填成NULL。</li><li>语句Q2返回的是4行。从逻辑上可以这么理解，最后的两行，由于表b中没有匹配的字段，结果集里面b.f2的值是空，不满足where 部分的条件判断，因此不能作为结果集的一部分。</li></ul><p>接下来，我们看看实际执行这两条语句时，MySQL是怎么做的。</p><p>我们先一起看看语句Q1的explain结果：</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/f813e7c6-2c38-4057-99e9-596ff144fdf6.jpg" alt></p><p>可以看到，这个结果符合我们的预期：</p><ul><li>驱动表是表a，被驱动表是表b；</li><li>由于表b的f1字段上没有索引，所以使用的是Block Nexted Loop Join（简称BNL） 算法。</li></ul><p>看到BNL算法，你就应该知道这条语句的执行流程其实是这样的：</p><ol><li><p>把表a的内容读入join_buffer 中。因为是select * ，所以字段f1和f2都被放入join_buffer了。</p></li><li><p>顺序扫描表b，对于每一行数据，判断join条件（也就是a.f1=b.f1 and a.f2=b.f2)是否满足，满足条件的记录, 作为结果集的一行返回。如果语句中有where子句，需要先判断where部分满足条件后，再返回。</p></li><li><p>表b扫描完成后，对于没有被匹配的表a的行（在这个例子中就是(1,1)、(2,2)这两行），把剩余字段补上NULL，再放入结果集中。</p></li></ol><p>对应的流程图如下：</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/798a8f15-e542-41d4-a36f-f79d50154e6a.jpg" alt></p><p>可以看到，这条语句确实是以表a为驱动表，而且从执行效果看，也和使用straight_join是一样的。</p><p>你可能会想，语句Q2的查询结果里面少了最后两行数据，是不是就是把上面流程中的步骤3去掉呢？我们还是先看一下语句Q2的expain结果吧。</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/7c1c19f0-19c9-4cec-a936-ef1a3061a7a2.jpg" alt></p><p>可以看到，这条语句是以表b为驱动表的。而如果一条join语句的Extra字段什么都没写的话，就表示使用的是Index Nested-Loop Join（简称NLJ）算法。</p><p>因此，语句Q2的执行流程是这样的：顺序扫描表b，每一行用b.f1到表a中去查，匹配到记录后判断a.f2=b.f2是否满足，满足条件的话就作为结果集的一部分返回。</p><p>那么，<strong>为什么语句Q1和Q2这两个查询的执行流程会差距这么大呢？</strong>其实，这是因为优化器基于Q2这个查询的语义做了优化。</p><p>为了理解这个问题，我需要再和你交代一个背景知识点：在MySQL里，NULL跟任何值执行等值判断和不等值判断的结果，都是NULL。这里包括， select NULL = NULL 的结果，也是返回NULL。</p><p>因此，语句Q2里面where a.f2=b.f2就表示，查询结果里面不会包含b.f2是NULL的行，这样这个left join的语义就是“找到这两个表里面，f1、f2对应相同的行。对于表a中存在，而表b中匹配不到的行，就放弃”。</p><p>这样，这条语句虽然用的是left join，但是语义跟join是一致的。</p><p>因此，优化器就把这条语句的left join改写成了join，然后因为表a的f1上有索引，就把表b作为驱动表，这样就可以用上NLJ 算法。在执行explain之后，你再执行show warnings，就能看到这个改写的结果，如图5所示。</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/b930959e-05ce-4f47-9d0d-26b6319203a9.jpg" alt></p><p>这个例子说明，即使我们在SQL语句中写成left join，执行过程还是有可能不是从左到右连接的。也就是说，<strong>使用left join时，左边的表不一定是驱动表。</strong></p><p>这样看来，<strong>如果需要left join的语义，就不能把被驱动表的字段放在where条件里面做等值判断或不等值判断，必须都写在on里面。</strong>那如果是join语句呢？</p><p>这时候，我们再看看这两条语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from a join b on(a.f1&#x3D;b.f1) and (a.f2&#x3D;b.f2); &#x2F;*Q3*&#x2F; </span><br><span class="line">select * from a join b on(a.f1&#x3D;b.f1) where (a.f2&#x3D;b.f2);&#x2F;*Q4*&#x2F;</span><br></pre></td></tr></table></figure><p>我们再使用一次看explain 和 show warnings的方法，看看优化器是怎么做的。</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/61ea5c57-d580-42d6-a23d-eb243cae0bc8.jpg" alt></p><p>可以看到，这两条语句都被改写成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from a join b where (a.f1&#x3D;b.f1) and (a.f2&#x3D;b.f2);</span><br></pre></td></tr></table></figure><p>执行计划自然也是一模一样的。</p><p>也就是说，在这种情况下，join将判断条件是否全部放在on部分就没有区别了。</p><h2 id="2-Simple-Nested-Loop-Join-的性能问题"><a href="#2-Simple-Nested-Loop-Join-的性能问题" class="headerlink" title="2. Simple Nested Loop Join 的性能问题"></a>2. Simple Nested Loop Join 的性能问题</h2><p>我们知道，join语句使用不同的算法，对语句的性能影响会很大。</p><p>虽然BNL算法和Simple Nested Loop Join 算法都是要判断M*N次（M和N分别是join的两个表的行数），但是Simple Nested Loop Join 算法的每轮判断都要走全表扫描，因此性能上BNL算法执行起来会快很多。</p><p>为了便于说明，我还是先为你简单描述一下这两个算法。</p><p>BNL算法的执行逻辑是：</p><ol><li><p>首先，将驱动表的数据全部读入内存join_buffer中，这里join_buffer是无序数组；</p></li><li><p>然后，顺序遍历被驱动表的所有行，每一行数据都跟join_buffer中的数据进行匹配，匹配成功则作为结果集的一部分返回。</p></li></ol><p>Simple Nested Loop Join算法的执行逻辑是：顺序取出驱动表中的每一行数据，到被驱动表去做全表扫描匹配，匹配成功则作为结果集的一部分返回。</p><p>有人提出问题，Simple Nested Loop Join算法，其实也是把数据读到内存里，然后按照匹配条件进行判断，为什么性能差距会这么大呢？</p><p>解释这个问题，需要用到MySQL中索引结构和Buffer Pool的相关知识点：</p><ol><li><p>在对被驱动表做全表扫描的时候，如果数据没有在Buffer Pool中，就需要等待这部分数据从磁盘读入；<br>从磁盘读入数据到内存中，会影响正常业务的Buffer Pool命中率，而且这个算法天然会对被驱动表的数据做多次访问，更容易将这些数据页放到Buffer Pool的头部（请参考 <strong>第35篇文章</strong> 中的相关内容)；</p></li><li><p>即使被驱动表数据都在内存中，每次查找“下一个记录的操作”，都是类似指针操作。而join_buffer中是数组，遍历的成本更低。</p></li></ol><p>所以说，BNL算法的性能会更好。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-join的用法&quot;&gt;&lt;a href=&quot;#1-join的用法&quot; class=&quot;headerlink&quot; title=&quot;1. join的用法&quot;&gt;&lt;/a&gt;1. join的用法&lt;/h2&gt;&lt;p&gt;在 &lt;strong&gt;第35篇文章《join语句怎么优化？》&lt;/strong&gt; 中，在介绍join执行顺序的时候，用的都是straight_join。有人在文后提出了两个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;如果用left join的话，左边的表一定是驱动表吗？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;如果两个表的join包含多个条件的等值匹配，是都要写到on里面呢，还是只把一个条件写到on里面，其他条件写到where部分？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了同时回答这两个问题，我来构造两个表a和b：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;create table a(f1 int, f2 int, index(f1))engine&amp;#x3D;innodb; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;create table b(f1 int, f2 int)engine&amp;#x3D;innodb; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;insert into a values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6); &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;insert into b values(3,3),(4,4),(5,5),(6,6),(7,7),(8,8);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>43-要不要使用分区表</title>
    <link href="http://javassun.github.io/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/"/>
    <id>http://javassun.github.io/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/</id>
    <published>2020-03-08T12:31:38.000Z</published>
    <updated>2020-05-20T20:13:58.934Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>经常被问到这样一个问题：分区表有什么问题，为什么公司规范不让使用分区表呢？今天，我们就来聊聊分区表的使用行为，然后再一起回答这个问题。</p><a id="more"></a><h2 id="1-分区表是什么？"><a href="#1-分区表是什么？" class="headerlink" title="1. 分区表是什么？"></a>1. 分区表是什么？</h2><p>为了说明分区表的组织形式，我先创建一个表t：</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/b28f3457-d137-4aa8-90e5-f9a014513aca.png" alt></p><p>在表t中初始化插入了两行记录，按照定义的分区规则，这两行记录分别落在p_2018和p_2019这两个分区上。</p><p>可以看到，这个表包含了一个.frm文件和4个.ibd文件，每个分区对应一个.ibd文件。也就是说：</p><ul><li>对于引擎层来说，这是4个表；</li><li>对于Server层来说，这是1个表。</li></ul><p>你可能会觉得这两句都是废话。其实不然，这两句话非常重要，可以帮我们理解分区表的执行逻辑。</p><h2 id="2-分区表的引擎层行为"><a href="#2-分区表的引擎层行为" class="headerlink" title="2. 分区表的引擎层行为"></a>2. 分区表的引擎层行为</h2><p>先给你举个在分区表加间隙锁的例子，目的是说明对于InnoDB来说，这是4个表。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/886be770-3ff5-4252-b5a6-34828df80510.png" alt></p><p>这里顺便复习一下，在 <strong>第21篇文章</strong> 和你介绍的间隙锁加锁规则。</p><p>我们初始化表t的时候，只插入了两行数据， ftime的值分别是，‘2017-4-1’ 和’2018-4-1’ 。session A的select语句对索引ftime上这两个记录之间的间隙加了锁。如果是一个普通表的话，那么T1时刻，在表t的ftime索引上，间隙和加锁状态应该是图3这样的。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/9c5904d4-c2d7-4875-8ec7-8d975bccb1bb.jpg" alt></p><p>也就是说，‘2017-4-1’ 和’2018-4-1’ 这两个记录之间的间隙是会被锁住的。那么，sesion B的两条插入语句应该都要进入锁等待状态。</p><p>但是，从上面的实验效果可以看出，session B的第一个insert语句是可以执行成功的。这是因为，对于引擎来说，p_2018和p_2019是两个不同的表，也就是说2017-4-1的下一个记录并不是2018-4-1，而是p_2018分区的supremum。所以T1时刻，在表t的ftime索引上，间隙和加锁的状态其实是图4这样的：</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/8eb98e23-1f11-45ac-b693-58f53e1d568a.jpg" alt></p><p>由于分区表的规则，session A的select语句其实只操作了分区p_2018，因此加锁范围就是图4中深绿色的部分。</p><p>所以，session B要写入一行ftime是2018-2-1的时候是可以成功的，而要写入2017-12-1这个记录，就要等session A的间隙锁。</p><p>图5就是这时候的show engine innodb status的部分结果。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/749ad5db-1704-418f-b648-1bd44002566b.jpg" alt></p><p>看完InnoDB引擎的例子，我们再来一个MyISAM分区表的例子。</p><p>我首先用alter table t engine=myisam，把表t改成MyISAM表；然后，我再用下面这个例子说明，对于MyISAM引擎来说，这是4个表。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/6fb65701-4e3d-4dbc-bce1-763ffe81d042.png" alt></p><p>在session A里面，我用sleep(100)将这条语句的执行时间设置为100秒。由于MyISAM引擎只支持表锁，所以这条update语句会锁住整个表t上的读。</p><p>但我们看到的结果是，session B的第一条查询语句是可以正常执行的，第二条语句才进入锁等待状态。</p><p>这正是因为MyISAM的表锁是在引擎层实现的，session A加的表锁，其实是锁在分区p_2018上。因此，只会堵住在这个分区上执行的查询，落到其他分区的查询是不受影响的。</p><p>看到这里，你可能会说，分区表看来还不错嘛，为什么不让用呢？我们使用分区表的一个重要原因就是单表过大。那么，如果不使用分区表的话，我们就是要使用手动分表的方式。</p><p>接下来，我们一起看看手动分表和分区表有什么区别。</p><p>比如，按照年份来划分，我们就分别创建普通表t_2017、t_2018、t_2019等等。手工分表的逻辑，也是找到需要更新的所有分表，然后依次执行更新。在性能上，这和分区表并没有实质的差别。</p><p>分区表和手工分表，一个是由server层来决定使用哪个分区，一个是由应用层代码来决定使用哪个分表。因此，从引擎层看，这两种方式也是没有差别的。</p><p>其实这两个方案的区别，主要是在server层上。从server层看，我们就不得不提到分区表一个被广为诟病的问题：打开表的行为。</p><h2 id="3-分区策略"><a href="#3-分区策略" class="headerlink" title="3. 分区策略"></a>3. 分区策略</h2><p>每当第一次访问一个分区表的时候，MySQL需要把所有的分区都访问一遍。<strong>一个典型的报错情况</strong>是这样的：如果一个分区表的分区很多，比如超过了1000个，而MySQL启动的时候，open_files_limit参数使用的是默认值1024，那么就会在访问这个表的时候，由于需要打开所有的文件，导致打开表文件的个数超过了上限而报错。</p><p>下图就是我创建的一个包含了很多分区的表t_myisam，执行一条插入语句后报错的情况。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/58f26ec6-fae9-4dbd-a120-0070e8c41e6f.jpg" alt></p><p>可以看到，这条insert语句，明显只需要访问一个分区，但语句却无法执行。</p><p>这时，你一定从表名猜到了，这个表我用的是MyISAM引擎。是的，因为使用InnoDB引擎的话，并不会出现这个问题。</p><p>MyISAM分区表使用的分区策略，我们称为<strong>通用分区策略</strong>（generic partitioning），每次访问分区都由server层控制。通用分区策略，是MySQL一开始支持分区表的时候就存在的代码，在文件管理、表管理的实现上很粗糙，因此有比较严重的性能问题。</p><p>从MySQL 5.7.9开始，InnoDB引擎引入了<strong>本地分区策略</strong>（native partitioning）。这个策略是在InnoDB内部自己管理打开分区的行为。</p><p>MySQL从5.7.17开始，将MyISAM分区表标记为即将弃用(deprecated)，意思是“从这个版本开始不建议这么使用，请使用替代方案。在将来的版本中会废弃这个功能”。</p><p>从MySQL 8.0版本开始，就不允许创建MyISAM分区表了，只允许创建已经实现了本地分区策略的引擎。目前来看，只有InnoDB和NDB这两个引擎支持了本地分区策略。</p><p>接下来，我们再看一下分区表在server层的行为。</p><h2 id="4-分区表的server层行为"><a href="#4-分区表的server层行为" class="headerlink" title="4. 分区表的server层行为"></a>4. 分区表的server层行为</h2><p>如果从server层看的话，一个分区表就只是一个表。</p><p>这句话是什么意思呢？接下来，我就用下面这个例子来和你说明。如图8和图9所示，分别是这个例子的操作序列和执行结果图。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/2c1e24c9-f714-49e0-9e62-7e9a52fa0010.jpg" alt></p><p>可以看到，虽然session B只需要操作p_2107这个分区，但是由于session A持有整个表t的MDL锁，就导致了session B的alter语句被堵住。</p><p>这也是DBA同学经常说的，分区表，在做DDL的时候，影响会更大。如果你使用的是普通分表，那么当你在truncate一个分表的时候，肯定不会跟另外一个分表上的查询语句，出现MDL锁冲突。</p><p>到这里我们小结一下：</p><ol><li><p>MySQL在第一次打开分区表的时候，需要访问所有的分区；</p></li><li><p>在server层，认为这是同一张表，因此所有分区共用同一个MDL锁；</p></li><li><p>在引擎层，认为这是不同的表，因此MDL锁之后的执行过程，会根据分区表规则，只访问必要的分区。</p></li></ol><p>而关于“必要的分区”的判断，就是根据SQL语句中的where条件，结合分区规则来实现的。比如我们上面的例子中，where ftime=‘2018-4-1’，根据分区规则year函数算出来的值是2018，那么就会落在p_2019这个分区。</p><p>但是，如果这个where 条件改成 where ftime&gt;=‘2018-4-1’，虽然查询结果相同，但是这时候根据where条件，就要访问p_2019和p_others这两个分区。</p><p>如果查询语句的where条件中没有分区key，那就只能访问所有分区了。当然，这并不是分区表的问题。即使是使用业务分表的方式，where条件中没有使用分表的key，也必须访问所有的分表。</p><p>我们已经理解了分区表的概念，那么什么场景下适合使用分区表呢？</p><h2 id="5-分区表的应用场景"><a href="#5-分区表的应用场景" class="headerlink" title="5. 分区表的应用场景"></a>5. 分区表的应用场景</h2><p>分区表的一个显而易见的优势是对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁。还有，分区表可以很方便的清理历史数据。</p><p>如果一项业务跑的时间足够长，往往就会有根据时间删除历史数据的需求。这时候，按照时间分区的分区表，就可以直接通过alter table t drop partition …这个语法删掉分区，从而删掉过期的历史数据。</p><p>这个alter table t drop partition …操作是直接删除分区文件，效果跟drop普通表类似。与使用delete语句删除数据相比，优势是速度快、对系统影响小。</p><h2 id="6-小结"><a href="#6-小结" class="headerlink" title="6. 小结"></a>6. 小结</h2><p>这篇文章，主要介绍的是server层和引擎层对分区表的处理方式。希望通过这些介绍，你能够对是否选择使用分区表，有更清晰的想法。</p><p>需要注意的是，我是以范围分区（range）为例和你介绍的。实际上，MySQL还支持hash分区、list分区等分区方法。你可以在需要用到的时候，再翻翻 <a href="https://dev.mysql.com/doc/refman/8.0/en/partitioning-types.html" target="_blank" rel="noopener">手册</a>。</p><p>实际使用时，分区表跟用户分表比起来，有两个绕不开的问题：一个是第一次访问的时候需要访问所有分区，另一个是共用MDL锁。</p><p>因此，如果要使用分区表，就不要创建太多的分区。我见过一个用户做了按天分区策略，然后预先创建了10年的分区。这种情况下，访问分区表的性能自然是不好的。这里有两个问题需要注意：</p><ol><li><p>分区并不是越细越好。实际上，单表或者单分区的数据一千万行，只要没有特别大的索引，对于现在的硬件能力来说都已经是小表了。</p></li><li><p>分区也不要提前预留太多，在使用之前预先创建即可。比如，如果是按月分区，每年年底时再把下一年度的12个新分区创建上即可。对于没有数据的历史分区，要及时的drop掉。</p></li></ol><p>至于分区表的其他问题，比如查询需要跨多个分区取数据，查询性能就会比较慢，基本上就不是分区表本身的问题，而是数据量的问题或者说是使用方式的问题了。</p><p>当然，如果你的团队已经维护了成熟的分库分表中间件，用业务分表，对业务开发同学没有额外的复杂性，对DBA也更直观，自然是更好的。</p><h2 id="7-思考"><a href="#7-思考" class="headerlink" title="7. 思考"></a>7. 思考</h2><p>我们举例的表中没有用到自增主键，假设现在要创建一个自增字段id。MySQL要求分区表中的主键必须包含分区字段。如果要在表t的基础上做修改，你会怎么定义这个表的主键呢？为什么这么定义呢？</p><p>即 怎么给分区表t创建自增主键。由于MySQL要求主键包含所有的分区字段，所以肯定是要创建联合主键的。</p><p><strong>回答：</strong></p><p>这时候就有两种可选：一种是(ftime, id)，另一种是(id, ftime)。</p><p>如果从利用率上来看，应该使用(ftime, id)这种模式。因为用ftime做分区key，说明大多数语句都是包含ftime的，使用这种模式，可以利用前缀索引的规则，减少一个索引。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/a356d81c-9939-4171-aca2-d4bcc26ef25a.png" alt></p><p>当然，建议是你要尽量使用InnoDB引擎。InnoDB表要求至少有一个索引，以自增字段作为第一个字段，所以需要加一个id的单独索引。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/b1dbaf86-ec67-4126-b30a-1c0fcd39299f.png" alt></p><p>当然把字段反过来，创建成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PRIMARY KEY (&#96;id&#96;,&#96;ftime&#96;), </span><br><span class="line">KEY &#96;id&#96; (&#96;ftime&#96;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;经常被问到这样一个问题：分区表有什么问题，为什么公司规范不让使用分区表呢？今天，我们就来聊聊分区表的使用行为，然后再一起回答这个问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>42-grant之后要跟着flush privileges吗</title>
    <link href="http://javassun.github.io/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/"/>
    <id>http://javassun.github.io/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/</id>
    <published>2020-03-07T12:31:38.000Z</published>
    <updated>2020-05-20T20:12:09.913Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在MySQL里面，grant语句是用来给用户赋权的。不知道你有没有见过一些操作文档里面提到，grant之后要马上跟着执行一个flush privileges命令，才能使赋权语句生效。我最开始使用MySQL的时候，就是照着一个操作文档的说明按照这个顺序操作的。</p><p>那么，grant之后真的需要执行flush privileges吗？如果没有执行这个flush命令的话，赋权语句真的不能生效吗？</p><p>接下来，就先和你介绍一下grant语句和flush privileges语句分别做了什么事情，然后再一起来分析这个问题。</p><a id="more"></a><p>为了便于说明，先创建一个用户：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create user &#39;ua&#39;@&#39;%&#39; identified by &#39;pa&#39;;</span><br></pre></td></tr></table></figure><p>这条语句的逻辑是创建一个用户’ua’@’%’，密码是pa。注意，在MySQL里面，用户名(user)+地址(host)才表示一个用户，因此 ua@ip1 和 ua@ip2代表的是两个不同的用户。</p><p>这条命令做了两个动作：</p><ol><li><p>磁盘上，往mysql.user表里插入一行，由于没有指定权限，所以这行数据上所有表示权限的字段的值都是N；</p></li><li><p>内存里，往数组acl_users里插入一个acl_user对象，这个对象的access字段值为0。</p></li></ol><p>图1就是这个时刻用户ua在user表中的状态。</p><p><img src="/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/f72e1569-15c5-42d5-b401-bb8b702e5283.jpg" alt></p><p>在MySQL中，用户权限是有不同的范围的。接下来，就按照用户权限范围从大到小的顺序依次和你说明。</p><h2 id="1-全局权限"><a href="#1-全局权限" class="headerlink" title="1. 全局权限"></a>1. 全局权限</h2><p>全局权限，作用于整个MySQL实例，这些权限信息保存在mysql库的user表里。如果我要给用户ua赋一个最高权限的话，语句是这么写的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant all privileges on *.* to &#39;ua&#39;@&#39;%&#39; with grant option;</span><br></pre></td></tr></table></figure><p>这个grant命令做了两个动作：</p><ol><li><p>磁盘上，将mysql.user表里，用户’ua’@’%’这一行的所有表示权限的字段的值都修改为‘Y’；</p></li><li><p>内存里，从数组acl_users中找到这个用户对应的对象，将access值（权限位）修改为二进制的“全1”。</p></li></ol><p>在这个grant命令执行完成后，如果有新的客户端使用用户名ua登录成功，MySQL会为新连接维护一个线程对象，然后从acl_users数组里查到这个用户的权限，并将权限值拷贝到这个线程对象中。之后在这个连接中执行的语句，所有关于全局权限的判断，都直接使用线程对象内部保存的权限位。</p><p>基于上面的分析我们可以知道：</p><ol><li><p>grant 命令对于全局权限，同时更新了磁盘和内存。命令完成后即时生效，接下来新创建的连接会使用新的权限。</p></li><li><p>对于一个已经存在的连接，它的全局权限不受grant命令的影响。</p></li></ol><p>需要说明的是，<strong>一般在生产环境上要合理控制用户权限的范围</strong>。我们上面用到的这个grant语句就是一个典型的错误示范。如果一个用户有所有权限，一般就不应该设置为所有IP地址都可以访问。</p><p>如果要回收上面的grant语句赋予的权限，你可以使用下面这条命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">revoke all privileges on *.* from &#39;ua&#39;@&#39;%&#39;;</span><br></pre></td></tr></table></figure><p>这条revoke命令的用法与grant类似，做了如下两个动作：</p><ol><li><p>磁盘上，将mysql.user表里，用户’ua’@’%’这一行的所有表示权限的字段的值都修改为“N”；</p></li><li><p>内存里，从数组acl_users中找到这个用户对应的对象，将access的值修改为0。</p></li></ol><h2 id="2-db权限"><a href="#2-db权限" class="headerlink" title="2. db权限"></a>2. db权限</h2><p>除了全局权限，MySQL也支持库级别的权限定义。如果要让用户ua拥有库db1的所有权限，可以执行下面这条命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant all privileges on db1.* to &#39;ua&#39;@&#39;%&#39; with grant option;</span><br></pre></td></tr></table></figure><p>基于库的权限记录保存在mysql.db表中，在内存里则保存在数组acl_dbs中。这条grant命令做了如下两个动作：</p><ol><li><p>磁盘上，往mysql.db表中插入了一行记录，所有权限位字段设置为“Y”；</p></li><li><p>内存里，增加一个对象到数组acl_dbs中，这个对象的权限位为“全1”。</p></li></ol><p>图2就是这个时刻用户ua在db表中的状态。</p><p><img src="/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/4a4625a0-3508-47a4-9c5f-1fef791d2463.jpg" alt></p><p>每次需要判断一个用户对一个数据库读写权限的时候，都需要遍历一次acl_dbs数组，根据user、host和db找到匹配的对象，然后根据对象的权限位来判断。</p><p>也就是说，grant修改db权限的时候，是同时对磁盘和内存生效的。</p><p>grant操作对于已经存在的连接的影响，在全局权限和基于db的权限效果是不同的。接下来，我们做一个对照试验来分别看一下。</p><p><img src="/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/c24d86be-45f6-4476-b3d2-4e7a1a106b80.jpg" alt></p><p>需要说明的是，图中set global sync_binlog这个操作是需要super权限的。</p><p>可以看到，虽然用户ua的super权限在T3时刻已经通过revoke语句回收了，但是在T4时刻执行set global的时候，权限验证还是通过了。这是因为super是全局权限，这个权限信息在线程对象中，而revoke操作影响不到这个线程对象。</p><p>而在T5时刻去掉ua对db1库的所有权限后，在T6时刻session B再操作db1库的表，就会报错“权限不足”。这是因为acl_dbs是一个全局数组，所有线程判断db权限都用这个数组，这样revoke操作马上就会影响到session B。</p><p>这里在代码实现上有一个特别的逻辑，如果当前会话已经处于某一个db里面，之前use这个库的时候拿到的库权限会保存在会话变量中。</p><p>你可以看到在T6时刻，session C和session B对表t的操作逻辑是一样的。但是session B报错，而session C可以执行成功。这是因为session C在T2 时刻执行的use db1，拿到了这个库的权限，在切换出db1库之前，session C对这个库就一直有权限。</p><h2 id="3-表权限和列权限"><a href="#3-表权限和列权限" class="headerlink" title="3. 表权限和列权限"></a>3. 表权限和列权限</h2><p>除了db级别的权限外，MySQL支持更细粒度的表权限和列权限。其中，表权限定义存放在表mysql.tables_priv中，列权限定义存放在表mysql.columns_priv中。这两类权限，组合起来存放在内存的hash结构column_priv_hash中。</p><p>这两类权限的赋权命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create table db1.t1(id int, a int); </span><br><span class="line"></span><br><span class="line">grant all privileges on db1.t1 to &#39;ua&#39;@&#39;%&#39; with grant option; </span><br><span class="line"></span><br><span class="line">GRANT SELECT(id), INSERT (id,a) ON mydb.mytbl TO &#39;ua&#39;@&#39;%&#39; with grant option;</span><br></pre></td></tr></table></figure><p>跟db权限类似，这两个权限每次grant的时候都会修改数据表，也会同步修改内存中的hash结构。因此，对这两类权限的操作，也会马上影响到已经存在的连接。</p><p>看到这里，你一定会问，看来grant语句都是即时生效的，那这么看应该就不需要执行flush privileges语句了呀。</p><p>答案也确实是这样的。</p><p>flush privileges命令会清空acl_users数组，然后从mysql.user表中读取数据重新加载，重新构造一个acl_users数组。也就是说，以数据表中的数据为准，会将全局权限内存数组重新加载一遍。</p><p>同样地，对于db权限、表权限和列权限，MySQL也做了这样的处理。</p><p>也就是说，如果内存的权限数据和磁盘数据表相同的话，不需要执行flush privileges。而如果我们都是用grant/revoke语句来执行的话，内存和数据表本来就是保持同步更新的。</p><p><strong>因此，正常情况下，grant命令之后，没有必要跟着执行flush privileges命令。</strong></p><h2 id="4-flush-privileges使用场景"><a href="#4-flush-privileges使用场景" class="headerlink" title="4. flush privileges使用场景"></a>4. flush privileges使用场景</h2><p>那么，flush privileges是在什么时候使用呢？显然，当数据表中的权限数据跟内存中的权限数据不一致的时候，flush privileges语句可以用来重建内存数据，达到一致状态。</p><p>这种不一致往往是由不规范的操作导致的，比如直接用DML语句操作系统权限表。我们来看一下下面这个场景：</p><p><img src="/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/36990de3-5724-4922-b7a7-b0129ed7bfdc.png" alt></p><p>可以看到，T3时刻虽然已经用delete语句删除了用户ua，但是在T4时刻，仍然可以用ua连接成功。原因就是，这时候内存中acl_users数组中还有这个用户，因此系统判断时认为用户还正常存在。</p><p>在T5时刻执行过flush命令后，内存更新，T6时刻再要用ua来登录的话，就会报错“无法访问”了。</p><p>直接操作系统表是不规范的操作，这个不一致状态也会导致一些更“诡异”的现象发生。比如，前面这个通过delete语句删除用户的例子，就会出现下面的情况：</p><p><img src="/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/e61445ea-4fe8-4fcc-9966-315258c8f83a.png" alt></p><p>可以看到，由于在T3时刻直接删除了数据表的记录，而内存的数据还存在。这就导致了：</p><ol><li><p>T4时刻给用户ua赋权限失败，因为mysql.user表中找不到这行记录；</p></li><li><p>而T5时刻要重新创建这个用户也不行，因为在做内存判断的时候，会认为这个用户还存在。</p></li></ol><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>今天这篇文章，介绍了MySQL用户权限在数据表和内存中的存在形式，以及grant和revoke命令的执行逻辑。</p><p>grant语句会同时修改数据表和内存，判断权限的时候使用的是内存数据。因此，规范地使用grant和revoke语句，是不需要随后加上flush privileges语句的。</p><p>flush privileges语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下再使用。而这种不一致往往是由于直接用DML语句操作系统权限表导致的，所以我们尽量不要使用这类语句。</p><p>另外，在使用grant语句赋权时，你可能还会看到这样的写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant super on *.* to &#39;ua&#39;@&#39;%&#39; identified by &#39;pa&#39;;</span><br></pre></td></tr></table></figure><p>这条命令加了identified by ‘密码’， 语句的逻辑里面除了赋权外，还包含了：</p><ol><li><p>如果用户’ua’@’%’不存在，就创建这个用户，密码是pa；</p></li><li><p>如果用户ua已经存在，就将密码修改成pa。</p></li></ol><p>这也是一种不建议的写法，因为这种写法很容易就会不慎把密码给改了。</p><p>“grant之后随手加flush privileges”，我自己是这么使用了两三年之后，在看代码的时候才发现其实并不需要这样做。</p><h2 id="6-技巧"><a href="#6-技巧" class="headerlink" title="6. 技巧"></a>6. 技巧</h2><p>在grant的时候是支持通配符的：”_”表示一个任意字符，“%”表示任意字符串。这个技巧在一个分库分表方案里面，同一个分库上有多个db的时候，是挺方便的。不过我个人认为，权限赋值的时候，控制的精确性还是要优先考虑的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在MySQL里面，grant语句是用来给用户赋权的。不知道你有没有见过一些操作文档里面提到，grant之后要马上跟着执行一个flush privileges命令，才能使赋权语句生效。我最开始使用MySQL的时候，就是照着一个操作文档的说明按照这个顺序操作的。&lt;/p&gt;
&lt;p&gt;那么，grant之后真的需要执行flush privileges吗？如果没有执行这个flush命令的话，赋权语句真的不能生效吗？&lt;/p&gt;
&lt;p&gt;接下来，就先和你介绍一下grant语句和flush privileges语句分别做了什么事情，然后再一起来分析这个问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>41-如何最快的复制一张表</title>
    <link href="http://javassun.github.io/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/"/>
    <id>http://javassun.github.io/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/</id>
    <published>2020-03-06T11:30:38.000Z</published>
    <updated>2020-05-20T20:10:11.566Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在上一篇文章最后，给你留下的问题是怎么在两张表中拷贝数据。如果可以控制对源表的扫描行数和加锁范围很小的话，我们简单地使用insert … select 语句即可实现。</p><p>当然，为了避免对源表加读锁，更稳妥的方案是先将数据写到外部文本文件，然后再写回目标表。这时，有两种常用的方法。接下来的内容，会和你详细展开一下这两种方法。</p><p>为了便于说明，我还是先创建一个表db1.t，并插入1000行数据，同时创建一个相同结构的表db2.t。</p><a id="more"></a><p><img src="/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/e547ee45-f447-4575-888d-36caac547487.png" alt></p><p>假设，我们要把db1.t里面a&gt;900的数据行导出来，插入到db2.t中。</p><h2 id="1-mysqldump方法"><a href="#1-mysqldump方法" class="headerlink" title="1. mysqldump方法"></a>1. mysqldump方法</h2><p>一种方法是，使用mysqldump命令将数据导出成一组INSERT语句。你可以使用下面的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -h$host -P$port -u$user --add-locks&#x3D;0 --no-create-info --single-transaction --set-gtid-purged&#x3D;OFF db1 t --where&#x3D;&quot;a&gt;900&quot; --result-file&#x3D;&#x2F;client_tmp&#x2F;t.sql</span><br></pre></td></tr></table></figure><p>把结果输出到临时文件。</p><p>这条命令中，主要参数含义如下：</p><ol><li><p>–single-transaction的作用是，在导出数据的时候不需要对表db1.t加表锁，而是使用START TRANSACTION WITH CONSISTENT SNAPSHOT的方法；</p></li><li><p>–add-locks设置为0，表示在输出的文件结果里，不增加” LOCK TABLES <code>t</code> WRITE;” ；</p></li><li><p>–no-create-info的意思是，不需要导出表结构；</p></li><li><p>–set-gtid-purged=off表示的是，不输出跟GTID相关的信息；</p></li><li><p>–result-file指定了输出文件的路径，其中client表示生成的文件是在客户端机器上的。</p></li></ol><p>通过这条mysqldump命令生成的t.sql文件中就包含了如图1所示的INSERT语句。</p><p><img src="/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/02e8acc5-628d-49bd-a9e7-66792537cb23.jpg" alt></p><p>可以看到，一条INSERT语句里面会包含多个value对，这是为了后续用这个文件来写入数据的时候，执行速度可以更快。</p><p>如果你希望生成的文件中一条INSERT语句只插入一行数据的话，可以在执行mysqldump命令时，加上参数–skip-extended-insert。</p><p>然后，你可以通过下面这条命令，将这些INSERT语句放到db2库里去执行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h127.0.0.1 -P13000 -uroot db2 -e &quot;source &#x2F;client_tmp&#x2F;t.sql&quot;</span><br></pre></td></tr></table></figure><p>需要说明的是，source并不是一条SQL语句，而是一个客户端命令。mysql客户端执行这个命令的流程是这样的：</p><ol><li><p>打开文件，默认以分号为结尾读取一条条的SQL语句；</p></li><li><p>将SQL语句发送到服务端执行。</p></li></ol><p>也就是说，服务端执行的并不是这个“source t.sql”语句，而是INSERT语句。所以，不论是在慢查询日志（slow log），还是在binlog，记录的都是这些要被真正执行的INSERT语句。</p><h2 id="2-导出CSV文件"><a href="#2-导出CSV文件" class="headerlink" title="2. 导出CSV文件"></a>2. 导出CSV文件</h2><p>另一种方法是直接将结果导出成.csv文件。MySQL提供了下面的语法，用来将查询结果导出到服务端本地目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from db1.t where a&gt;900 into outfile &#39;&#x2F;server_tmp&#x2F;t.csv&#39;;</span><br></pre></td></tr></table></figure><p>我们在使用这条语句时，需要注意如下几点。</p><ol><li><p>这条语句会将结果保存在服务端。如果你执行命令的客户端和MySQL服务端不在同一个机器上，客户端机器的临时目录下是不会生成t.csv文件的。</p></li><li><p>into outfile指定了文件的生成位置（/server_tmp/），这个位置必须受参数secure_file_priv的限制。参数secure_file_priv的可选值和作用分别是：</p><ul><li>如果设置为empty，表示不限制文件生成的位置，这是不安全的设置；</li><li>如果设置为一个表示路径的字符串，就要求生成的文件只能放在这个指定的目录，或者它的子目录；</li><li>如果设置为NULL，就表示禁止在这个MySQL实例上执行select … into outfile 操作。</li></ul></li><li><p>这条命令不会帮你覆盖文件，因此你需要确保/server_tmp/t.csv这个文件不存在，否则执行语句时就会因为有同名文件的存在而报错。</p></li><li><p>这条命令生成的文本文件中，原则上一个数据行对应文本文件的一行。但是，如果字段中包含换行符，在生成的文本中也会有换行符。不过类似换行符、制表符这类符号，前面都会跟上“\”这个转义符，这样就可以跟字段之间、数据行之间的分隔符区分开。</p></li></ol><p>得到.csv导出文件后，你就可以用下面的load data命令将数据导入到目标表db2.t中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data infile &#39;&#x2F;server_tmp&#x2F;t.csv&#39; into table db2.t;</span><br></pre></td></tr></table></figure><p>这条语句的执行流程如下所示。</p><ol><li><p>打开文件/server_tmp/t.csv，以制表符(\t)作为字段间的分隔符，以换行符（\n）作为记录之间的分隔符，进行数据读取；</p></li><li><p>启动事务。</p></li><li><p>判断每一行的字段数与表db2.t是否相同：</p><ul><li>若不相同，则直接报错，事务回滚；</li><li>若相同，则构造成一行，调用InnoDB引擎接口，写入到表中。</li></ul></li><li><p>重复步骤3，直到/server_tmp/t.csv整个文件读入完成，提交事务。</p></li></ol><p>你可能有一个疑问，<strong>如果binlog_format=statement，这个load语句记录到binlog里以后，怎么在备库重放呢？</strong></p><p>由于/server_tmp/t.csv文件只保存在主库所在的主机上，如果只是把这条语句原文写到binlog中，在备库执行的时候，备库的本地机器上没有这个文件，就会导致主备同步停止。</p><p>所以，这条语句执行的完整流程，其实是下面这样的。</p><ol><li><p>主库执行完成后，将/server_tmp/t.csv文件的内容直接写到binlog文件中。</p></li><li><p>往binlog文件中写入语句load data local infile ‘/tmp/SQL_LOAD_MB-1-0’ INTO TABLE <code>db2</code>.<code>t</code>。</p></li><li><p>把这个binlog日志传到备库。</p></li><li><p>备库的apply线程在执行这个事务日志时：<br>a. 先将binlog中t.csv文件的内容读出来，写入到本地临时目录/tmp/SQL_LOAD_MB-1-0 中；<br>b. 再执行load data语句，往备库的db2.t表中插入跟主库相同的数据。</p></li></ol><p>执行流程如图2所示：</p><p><img src="/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/a054cd4e-3760-4da5-9a5e-745186004290.jpg" alt></p><p>注意，这里备库执行的load data语句里面，多了一个“local”。它的意思是“将执行这条命令的客户端所在机器的本地文件/tmp/SQL_LOAD_MB-1-0的内容，加载到目标表db2.t中”。</p><p>也就是说，<strong>load data命令有两种用法</strong>：</p><ol><li><p>不加“local”，是读取服务端的文件，这个文件必须在secure_file_priv指定的目录或子目录下；</p></li><li><p>加上“local”，读取的是客户端的文件，只要mysql客户端有访问这个文件的权限即可。这时候，MySQL客户端会先把本地文件传给服务端，然后执行上述的load data流程。</p></li></ol><p>另外需要注意的是，<strong>select …into outfile方法不会生成表结构文件</strong>, 所以我们导数据时还需要单独的命令得到表结构定义。mysqldump提供了一个–tab参数，可以同时导出表结构定义文件和csv数据文件。这条命令的使用方法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -h$host -P$port -u$user ---single-transaction --set-gtid-purged&#x3D;OFF db1 t --where&#x3D;&quot;a&gt;900&quot; --tab&#x3D;$secure_file_priv</span><br></pre></td></tr></table></figure><p>这条命令会在$secure_file_priv定义的目录下，创建一个t.sql文件保存建表语句，同时创建一个t.txt文件保存CSV数据。</p><h2 id="3-物理拷贝方法"><a href="#3-物理拷贝方法" class="headerlink" title="3. 物理拷贝方法"></a>3. 物理拷贝方法</h2><p>前面我们提到的mysqldump方法和导出CSV文件的方法，都是逻辑导数据的方法，也就是将数据从表db1.t中读出来，生成文本，然后再写入目标表db2.t中。</p><p>你可能会问，有物理导数据的方法吗？比如，直接把db1.t表的.frm文件和.ibd文件拷贝到db2目录下，是否可行呢？</p><p>答案是不行的。</p><p>因为，一个InnoDB表，除了包含这两个物理文件外，还需要在数据字典中注册。直接拷贝这两个文件的话，因为数据字典中没有db2.t这个表，系统是不会识别和接受它们的。</p><p>不过，在MySQL 5.6版本引入了<strong>可传输表空间</strong>(transportable tablespace)的方法，可以通过导出+导入表空间的方式，实现物理拷贝表的功能。</p><p>假设我们现在的目标是在db1库下，复制一个跟表t相同的表r，具体的执行步骤如下：</p><ol><li><p>执行 create table r like t，创建一个相同表结构的空表；</p></li><li><p>执行alter table r discard tablespace，这时候r.ibd文件会被删除；</p></li><li><p>执行flush table t for export，这时候db1目录下会生成一个t.cfg文件；</p></li><li><p>在db1目录下执行cp t.cfg r.cfg; cp t.ibd r.ibd；这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL进程要有读写权限）；</p></li><li><p>执行unlock tables，这时候t.cfg文件会被删除；</p></li><li><p>执行alter table r import tablespace，将这个r.ibd文件作为表r的新的表空间，由于这个文件的数据内容和t.ibd是相同的，所以表r中就有了和表t相同的数据。</p></li></ol><p>至此，拷贝表数据的操作就完成了。这个流程的执行过程图如下：</p><p><img src="/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/007f0a52-cad6-4c3f-b6ae-199bbbf0be40.jpg" alt></p><p>关于拷贝表的这个流程，有以下几个注意点：</p><ol><li><p>在第3步执行完flsuh table命令之后，db1.t整个表处于只读状态，直到执行unlock tables命令后才释放读锁；</p></li><li><p>在执行import tablespace的时候，为了让文件里的表空间id和数据字典中的一致，会修改r.ibd的表空间id。而这个表空间id存在于每一个数据页中。因此，如果是一个很大的文件（比如TB级别），每个数据页都需要修改，所以你会看到这个import语句的执行是需要一些时间的。当然，如果是相比于逻辑导入的方法，import语句的耗时是非常短的。</p></li></ol><h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a>4. 小结</h2><p>今天这篇文章，介绍了三种将一个表的数据导入到另外一个表中的方法。</p><p>我们来对比一下这三种方法的优缺点。</p><ol><li><p>物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：</p><ul><li>必须是全表拷贝，不能只拷贝部分数据；</li><li>需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；</li><li>由于是通过拷贝物理文件实现的，源表和目标表都是使用InnoDB引擎时才能使用。</li></ul></li><li><p>用mysqldump生成包含INSERT语句文件的方法，可以在where参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用join这种比较复杂的where条件写法。</p></li><li><p>用select … into outfile的方法是最灵活的，支持所有的SQL写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。</p></li></ol><p>后两种方式都是逻辑备份方式，是可以跨引擎使用的。</p><h2 id="5-思考"><a href="#5-思考" class="headerlink" title="5. 思考"></a>5. 思考</h2><p>我们前面介绍binlog_format=statement的时候，binlog记录的load data命令是带local的。既然这条命令是发送到备库去执行的，那么备库执行的时候也是本地执行，为什么需要这个local呢？如果写到binlog中的命令不带local，又会出现什么问题呢？</p><p><strong>回答：</strong></p><p>这样做的一个原因是，为了确保备库应用binlog正常。因为备库可能配置了secure_file_priv=null，所以如果不用local的话，可能会导入失败，造成主备同步延迟。</p><p>另一种应用场景是使用mysqlbinlog工具解析binlog文件，并应用到目标库的情况。你可以使用下面这条命令 ：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqlbinlog $binlog_file | mysql -h$host -P$port -u$user -p$pwd</span><br></pre></td></tr></table></figure><p>把日志直接解析出来发给目标库执行。增加local，就能让这个方法支持非本地的$host。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在上一篇文章最后，给你留下的问题是怎么在两张表中拷贝数据。如果可以控制对源表的扫描行数和加锁范围很小的话，我们简单地使用insert … select 语句即可实现。&lt;/p&gt;
&lt;p&gt;当然，为了避免对源表加读锁，更稳妥的方案是先将数据写到外部文本文件，然后再写回目标表。这时，有两种常用的方法。接下来的内容，会和你详细展开一下这两种方法。&lt;/p&gt;
&lt;p&gt;为了便于说明，我还是先创建一个表db1.t，并插入1000行数据，同时创建一个相同结构的表db2.t。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>40-insert语句的锁为什么这么多</title>
    <link href="http://javassun.github.io/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/"/>
    <id>http://javassun.github.io/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/</id>
    <published>2020-03-04T11:25:38.000Z</published>
    <updated>2020-05-20T20:07:28.741Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在上一篇文章中，提到MySQL对自增主键锁做了优化，尽量在申请到自增id以后，就释放自增锁。</p><p>因此，insert语句是一个很轻量的操作。不过，这个结论对于“普通的insert语句”才有效。也就是说，还有些insert语句是属于“特殊情况”的，在执行过程中需要给其他资源加锁，或者无法在申请到自增id以后就立马释放自增锁。</p><p>那么，今天这篇文章，我们就一起来聊聊这个话题。</p><a id="more"></a><h2 id="1-insert-…-select-语句"><a href="#1-insert-…-select-语句" class="headerlink" title="1. insert … select 语句"></a>1. insert … select 语句</h2><p>我们先从昨天的问题说起吧。表t和t2的表结构、初始化数据语句如下，今天的例子我们还是针对这两个表展开。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/84586a3d-0459-4a83-8c0a-ba8acc4096e6.png" alt></p><p>现在，我们一起来看看为什么在可重复读隔离级别下，binlog_format=statement时执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t2(c,d) select c,d from t;</span><br></pre></td></tr></table></figure><p>这个语句时，需要对表t的所有行和间隙加锁呢？</p><p>其实，这个问题我们需要考虑的还是日志和数据的一致性。我们看下这个执行序列：</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/e725474a-33e2-44eb-bf69-7935a8844323.png" alt></p><p>实际的执行效果是，如果session B先执行，由于这个语句对表t主键索引加了(-∞,1]这个next-key lock，会在语句执行完成后，才允许session A的insert语句执行。</p><p>但如果没有锁的话，就可能出现session B的insert语句先执行，但是后写入binlog的情况。于是，在binlog_format=statement的情况下，binlog里面就记录了这样的语句序列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(-1,-1,-1); </span><br><span class="line">insert into t2(c,d) select c,d from t;</span><br></pre></td></tr></table></figure><p>这个语句到了备库执行，就会把id=-1这一行也写到表t2中，出现主备不一致。</p><h2 id="2-insert-循环写入"><a href="#2-insert-循环写入" class="headerlink" title="2. insert 循环写入"></a>2. insert 循环写入</h2><p>当然了，执行insert … select 的时候，对目标表也不是锁全表，而是只锁住需要访问的资源。</p><p>如果现在有这么一个需求：要往表t2中插入一行数据，这一行的c值是表t中c值的最大值加1。</p><p>此时，我们可以这么写这条SQL语句 ：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t2(c,d) (select c+1, d from t force index(c) order by c desc limit 1);</span><br></pre></td></tr></table></figure><p>这个语句的加锁范围，就是表t索引c上的(3,4]和(4,supremum]这两个next-key lock，以及主键索引上id=4这一行。</p><p>它的执行流程也比较简单，从表t中按照索引c倒序，扫描第一行，拿到结果写入到表t2中。</p><p>因此整条语句的扫描行数是1。</p><p>这个语句执行的慢查询日志（slow log），如下图所示：</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/c20204d1-ffaf-4362-aac5-6d560bce29de.jpg" alt></p><p>通过这个慢查询日志，我们看到Rows_examined=1，正好验证了执行这条语句的扫描行数为1。</p><p>那么，如果我们是要把这样的一行数据插入到表t中的话：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t(c,d) (select c+1, d from t force index(c) order by c desc limit 1);</span><br></pre></td></tr></table></figure><p>语句的执行流程是怎样的？扫描行数又是多少呢？</p><p>这时候，我们再看慢查询日志就会发现不对了。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/495f0386-cc12-4cfd-a044-64535607038d.png" alt></p><p>可以看到，这时候的Rows_examined的值是5。</p><p>我在前面的文章中提到过，希望你都能够学会用explain的结果来“脑补”整条语句的执行过程。今天，我们就来一起试试。</p><p>如图4所示就是这条语句的explain结果。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/3192619c-cecd-471d-9991-4289b49ea5aa.jpg" alt></p><p>从Extra字段可以看到“Using temporary”字样，表示这个语句用到了临时表。也就是说，执行过程中，需要把表t的内容读出来，写入临时表。</p><p>图中rows显示的是1，我们不妨先对这个语句的执行流程做一个猜测：如果说是把子查询的结果读出来（扫描1行），写入临时表，然后再从临时表读出来（扫描1行），写回表t中。那么，这个语句的扫描行数就应该是2，而不是5。</p><p>所以，这个猜测不对。实际上，Explain结果里的rows=1是因为受到了limit 1 的影响。</p><p>从另一个角度考虑的话，我们可以看看InnoDB扫描了多少行。如图5所示，是在执行这个语句前后查看Innodb_rows_read的结果。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/f1d53f89-8766-44a8-a1bc-95ba4a6582f9.jpg" alt></p><p>可以看到，这个语句执行前后，Innodb_rows_read的值增加了4。因为默认临时表是使用Memory引擎的，所以这4行查的都是表t，也就是说对表t做了全表扫描。</p><p>这样，我们就把整个执行过程理清楚了：</p><ol><li><p>创建临时表，表里有两个字段c和d。</p></li><li><p>按照索引c扫描表t，依次取c=4、3、2、1，然后回表，读到c和d的值写入临时表。这时，Rows_examined=4。</p></li><li><p>由于语义里面有limit 1，所以只取了临时表的第一行，再插入到表t中。这时，Rows_examined的值加1，变成了5。</p></li></ol><p>也就是说，这个语句会导致在表t上做全表扫描，并且会给索引c上的所有间隙都加上共享的next-key lock。所以，这个语句执行期间，其他事务不能在这个表上插入数据。</p><p>至于这个语句的执行为什么需要临时表，原因是这类一边遍历数据，一边更新数据的情况，如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录，新插入的记录如果参与计算逻辑，就跟语义不符。</p><p>由于实现上这个语句没有在子查询中就直接使用limit 1，从而导致了这个语句的执行需要遍历整个表t。它的优化方法也比较简单，就是用前面介绍的方法，先insert into到临时表temp_t，这样就只需要扫描一行；然后再从表temp_t里面取出这行数据插入表t1。</p><p>当然，由于这个语句涉及的数据量很小，你可以考虑使用内存临时表来做这个优化。使用内存临时表优化时，语句序列的写法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create temporary table temp_t(c int,d int) engine&#x3D;memory; </span><br><span class="line">insert into temp_t (select c+1, d from t force index(c) order by c desc limit 1); </span><br><span class="line">insert into t select * from temp_t; </span><br><span class="line">drop table temp_t;</span><br></pre></td></tr></table></figure><h2 id="3-insert-唯一键冲突"><a href="#3-insert-唯一键冲突" class="headerlink" title="3. insert 唯一键冲突"></a>3. insert 唯一键冲突</h2><p>前面的两个例子是使用insert … select的情况，接下来我要介绍的这个例子就是最常见的insert语句出现唯一键冲突的情况。</p><p>对于有唯一键的表，插入数据时出现唯一键冲突也是常见的情况了。我先给你举一个简单的唯一键冲突的例子。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/52f29765-b6c9-4e00-bbfd-1f6d3bb7b712.png" alt></p><p>这个例子也是在可重复读（repeatable read）隔离级别下执行的。可以看到，session B要执行的insert语句进入了锁等待状态。</p><p>也就是说，session A执行的insert语句，发生唯一键冲突的时候，并不只是简单地报错返回，还在冲突的索引上加了锁。我们前面说过，一个next-key lock就是由它右边界的值定义的。这时候，session A持有索引c上的(5,10]共享next-key lock（读锁）。</p><p>至于为什么要加这个读锁，其实我也没有找到合理的解释。从作用上来看，这样做可以避免这一行被别的事务删掉。</p><p>这里<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html" target="_blank" rel="noopener">官方文档</a>有一个描述错误，认为如果冲突的是主键索引，就加记录锁，唯一索引才加next-key lock。但实际上，这两类索引冲突加的都是next-key lock。(已由官方矫正)</p><p>这里，分享一个经典的死锁场景</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/71e2714d-a949-40b4-b6d6-9a7cf1990900.png" alt></p><p>在session A执行rollback语句回滚的时候，session C几乎同时发现死锁并返回。</p><p>这个死锁产生的逻辑是这样的：</p><ol><li><p>在T1时刻，启动session A，并执行insert语句，此时在索引c的c=5上加了记录锁。注意，这个索引是唯一索引，因此退化为记录锁（如果你的印象模糊了，可以回顾下<a href="https://time.geekbang.org/column/article/75659" target="_blank" rel="noopener">第21篇文章</a>介绍的加锁规则）。</p></li><li><p>在T2时刻，session B要执行相同的insert语句，发现了唯一键冲突，加上读锁；同样地，session C也在索引c上，c=5这一个记录上，加了读锁。</p></li><li><p>T3时刻，session A回滚。这时候，session B和session C都试图继续执行插入操作，都要加上写锁。两个session都要等待对方的行锁，所以就出现了死锁。</p></li></ol><p>这个流程的状态变化图如下所示。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/0bb154f1-15f2-4fe0-bfc9-d67c345aff04.jpg" alt></p><h2 id="4-insert-into-…-on-duplicate-key-update"><a href="#4-insert-into-…-on-duplicate-key-update" class="headerlink" title="4. insert into … on duplicate key update"></a>4. insert into … on duplicate key update</h2><p>上面这个例子是主键冲突后直接报错，如果是改写成</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(11,10,10) on duplicate key update d&#x3D;100;</span><br></pre></td></tr></table></figure><p>的话，就会给索引c上(5,10] 加一个排他的next-key lock（写锁）。</p><p><strong>insert into … on duplicate key update 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。</strong></p><p>注意，如果有多个列违反了唯一性约束，就会按照索引的顺序，修改跟第一个索引冲突的行。</p><p>现在表t里面已经有了(1,1,1)和(2,2,2)这两行，我们再来看看下面这个语句执行的效果：</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/2b618770-d89c-435a-84af-2fba062aed59.jpg" alt></p><p>可以看到，主键id是先判断的，MySQL认为这个语句跟id=2这一行冲突，所以修改的是id=2的行。</p><p>需要注意的是，执行这条语句的affected rows返回的是2，很容易造成误解。实际上，真正更新的只有一行，只是在代码实现上，insert和update都认为自己成功了，update计数加了1， insert计数也加了1。</p><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>今天这篇文章，介绍了几种特殊情况下的insert语句。</p><p>insert … select 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下，这个语句会给select的表里扫描到的记录和间隙加读锁。</p><p>而如果insert和select的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。</p><p>insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的next-key lock(S锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。</p><h2 id="6-思考"><a href="#6-思考" class="headerlink" title="6. 思考"></a>6. 思考</h2><p>你平时在两个表之间拷贝数据用的是什么方法，有什么注意事项吗？在你的应用场景里，这个方法，相较于其他方法的优势是什么呢？</p><p><strong>见第41篇文章</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在上一篇文章中，提到MySQL对自增主键锁做了优化，尽量在申请到自增id以后，就释放自增锁。&lt;/p&gt;
&lt;p&gt;因此，insert语句是一个很轻量的操作。不过，这个结论对于“普通的insert语句”才有效。也就是说，还有些insert语句是属于“特殊情况”的，在执行过程中需要给其他资源加锁，或者无法在申请到自增id以后就立马释放自增锁。&lt;/p&gt;
&lt;p&gt;那么，今天这篇文章，我们就一起来聊聊这个话题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>39-自增主键为什么不是连续的</title>
    <link href="http://javassun.github.io/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/"/>
    <id>http://javassun.github.io/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/</id>
    <published>2020-03-03T11:20:38.000Z</published>
    <updated>2020-05-20T20:04:56.819Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 <strong>第4篇文章</strong> 中，我们提到过自增主键，由于自增主键可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑。</p><p>之前见过有的业务设计依赖于自增主键的连续性，也就是说，这个设计假设自增主键是连续的。但实际上，这样的假设是错的，因为自增主键不能保证连续递增。</p><p>今天这篇文章，我们就来说说这个问题，看看什么情况下自增主键会出现 “空洞”？</p><a id="more"></a><p>为了便于说明，我们创建一个表t，其中id是自增主键字段、c是唯一索引。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;t&#96; (</span><br><span class="line">&#96;id&#96; int(11) NOT NULL AUTO_INCREMENT, </span><br><span class="line">&#96;c&#96; int(11) DEFAULT NULL, </span><br><span class="line">&#96;d&#96; int(11) DEFAULT NULL, </span><br><span class="line"> PRIMARY KEY (&#96;id&#96;), </span><br><span class="line"> UNIQUE KEY &#96;c&#96; (&#96;c&#96;) </span><br><span class="line">) ENGINE&#x3D;InnoDB;</span><br></pre></td></tr></table></figure><h2 id="1-自增值保存在哪儿？"><a href="#1-自增值保存在哪儿？" class="headerlink" title="1. 自增值保存在哪儿？"></a>1. 自增值保存在哪儿？</h2><p>在这个空表t里面执行insert into t values(null, 1, 1);插入一行数据，再执行show create table命令，就可以看到如下图所示的结果：</p><p><img src="/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/b6d9b4ae-a205-4a0f-ad5b-5319114c8970.jpg" alt></p><p>可以看到，表定义里面出现了一个AUTO_INCREMENT=2，表示下一次插入数据时，如果需要自动生成自增值，会生成id=2。</p><p>其实，这个输出结果容易引起这样的误解：自增值是保存在表结构定义里的。实际上，<strong>表的结构定义存放在后缀名为.frm的文件中，但是并不会保存自增值。</strong></p><p>不同的引擎对于自增值的保存策略不同。</p><ul><li><p>MyISAM引擎的自增值保存在数据文件中。</p></li><li><p>InnoDB引擎的自增值，其实是保存在了内存里，并且到了MySQL 8.0版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为MySQL重启前的值”，具体情况是：</p><ul><li><p>在MySQL 5.7及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值max(id)，然后将max(id)+1作为这个表当前的自增值。</p><p>举例来说，如果一个表当前数据行里最大的id是10，AUTO_INCREMENT=11。这时候，我们删除id=10的行，AUTO_INCREMENT还是11。但如果马上重启实例，重启后这个表的AUTO_INCREMENT就会变成10。<br>也就是说，MySQL重启可能会修改一个表的AUTO_INCREMENT的值。</p></li><li><p>在MySQL 8.0版本，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启之前的值。</p></li></ul></li></ul><p>理解了MySQL对自增值的保存策略以后，我们再看看自增值修改机制。</p><h2 id="2-自增值修改机制"><a href="#2-自增值修改机制" class="headerlink" title="2. 自增值修改机制"></a>2. 自增值修改机制</h2><p>在MySQL里面，如果字段id被定义为AUTO_INCREMENT，在插入一行数据的时候，自增值的行为如下：</p><ol><li><p>如果插入数据时id字段指定为0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT值填到自增字段；</p></li><li><p>如果插入数据时id字段指定了具体的值，就直接使用语句里指定的值。</p></li></ol><p>根据要插入的值和当前自增值的大小关系，自增值的变更结果也会有所不同。假设，某次要插入的值是X，当前的自增值是Y。</p><ol><li><p>如果X&lt;Y，那么这个表的自增值不变；</p></li><li><p>如果X≥Y，就需要把当前自增值修改为新的自增值。</p></li></ol><p><strong>新的自增值生成算法是</strong>：从auto_increment_offset开始，以auto_increment_increment为步长，持续叠加，直到找到第一个大于X的值，作为新的自增值。</p><p>其中，auto_increment_offset 和 auto_increment_increment是两个系统参数，分别用来表示自增的初始值和步长，默认值都是1。</p><blockquote><p>备注：在一些场景下，使用的就不全是默认值。比如，双M的主备结构里要求双写的时候，我们就可能会设置成auto_increment_increment=2，让一个库的自增id都是奇数，另一个库的自增id都是偶数，避免两个库生成的主键发生冲突。</p></blockquote><p>当auto_increment_offset和auto_increment_increment都是1的时候，新的自增值生成逻辑很简单，就是：</p><ol><li><p>如果准备插入的值&gt;=当前自增值，新的自增值就是“准备插入的值+1”；</p></li><li><p>否则，自增值不变。</p></li></ol><p>这就引入了我们文章开头提到的问题，在这两个参数都设置为1的时候，自增主键id却不能保证是连续的，这是什么原因呢？</p><h2 id="3-自增值的修改时机"><a href="#3-自增值的修改时机" class="headerlink" title="3. 自增值的修改时机"></a>3. 自增值的修改时机</h2><p>要回答这个问题，我们就要看一下自增值的修改时机。</p><p>假设，表t里面已经有了(1,1,1)这条记录，这时我再执行一条插入数据命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(null, 1, 1);</span><br></pre></td></tr></table></figure><p>这个语句的执行流程就是：</p><ol><li><p>执行器调用InnoDB引擎接口写入一行，传入的这一行的值是(0,1,1);</p></li><li><p>InnoDB发现用户没有指定自增id的值，获取表t当前的自增值2；</p></li><li><p>将传入的行的值改成(2,1,1);</p></li><li><p>将表的自增值改成3；</p></li><li><p>继续执行插入数据操作，由于已经存在c=1的记录，所以报Duplicate key error，语句返回。</p></li></ol><p>对应的执行流程图如下：</p><p><img src="/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/585d91a6-baee-4b35-999d-8a8add53b6f4.jpg" alt></p><p>可以看到，这个表的自增值改成3，是在真正执行插入数据的操作之前。这个语句真正执行的时候，因为碰到唯一键c冲突，所以id=2这一行并没有插入成功，但也没有将自增值再改回去。</p><p>所以，在这之后，再插入新的数据行时，拿到的自增id就是3。也就是说，出现了自增主键不连续的情况。</p><p>如图3所示就是完整的演示结果。</p><p><img src="/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/13954a15-61cf-42c9-b5cf-a535ad2f5099.jpg" alt></p><p>可以看到，这个操作序列复现了一个自增主键id不连续的现场(没有id=2的行）。可见，<strong>唯一键冲突是导致自增主键id不连续的第一种原因。</strong></p><p>同样地，事务<strong>回滚也会产生类似的现象，这就是第二种原因。</strong></p><p>下面这个语句序列就可以构造不连续的自增id，你可以自己验证一下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(null,1,1); </span><br><span class="line">begin; </span><br><span class="line">insert into t values(null,2,2); </span><br><span class="line">rollback; </span><br><span class="line">insert into t values(null,2,2); </span><br><span class="line">&#x2F;&#x2F;插入的行是(3,2,2)</span><br></pre></td></tr></table></figure><p>你可能会问，为什么在出现唯一键冲突或者回滚的时候，MySQL没有把表t的自增值改回去呢？如果把表t的当前自增值从3改回2，再插入新数据的时候，不就可以生成id=2的一行数据了吗？</p><p>其实，MySQL这么设计是为了提升性能。接下来，我就跟你分析一下这个设计思路，看看<strong>自增值为什么不能回退。</strong></p><p>假设有两个并行执行的事务，在申请自增值的时候，为了避免两个事务申请到相同的自增id，肯定要加锁，然后顺序申请。</p><ol><li><p>假设事务A申请到了id=2， 事务B申请到id=3，那么这时候表t的自增值是4，之后继续执行。</p></li><li><p>事务B正确提交了，但事务A出现了唯一键冲突。</p></li><li><p>如果允许事务A把自增id回退，也就是把表t的当前自增值改回2，那么就会出现这样的情况：表里面已经有id=3的行，而当前的自增id值是2。</p></li><li><p>接下来，继续执行的其他事务就会申请到id=2，然后再申请到id=3。这时，就会出现插入语句报错“主键冲突”。</p></li></ol><p>而为了解决这个主键冲突，有两种方法：</p><ol><li><p>每次申请id之前，先判断表里面是否已经存在这个id。如果存在，就跳过这个id。但是，这个方法的成本很高。因为，本来申请id是一个很快的操作，现在还要再去主键索引树上判断id是否存在。</p></li><li><p>把自增id的锁范围扩大，必须等到一个事务执行完成并提交，下一个事务才能再申请自增id。这个方法的问题，就是锁的粒度太大，系统并发能力大大下降。</p></li></ol><p>可见，这两个方法都会导致性能问题。造成这些麻烦的罪魁祸首，就是我们假设的这个“允许自增id回退”的前提导致的。</p><p>因此，InnoDB放弃了这个设计，语句执行失败也不回退自增id。也正是因为这样，所以才只保证了自增id是递增的，但不保证是连续的。</p><h2 id="4-自增锁的优化"><a href="#4-自增锁的优化" class="headerlink" title="4. 自增锁的优化"></a>4. 自增锁的优化</h2><p>可以看到，自增id锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请。其实，在MySQL 5.1版本之前，并不是这样的。</p><p>接下来，我会先给你介绍下自增锁设计的历史，这样有助于你分析接下来的一个问题。</p><p>在MySQL 5.0版本的时候，自增锁的范围是语句级别。也就是说，如果一个语句申请了一个表自增锁，这个锁会等语句执行结束以后才释放。显然，这样设计会影响并发度。</p><p>MySQL 5.1.22版本引入了一个新策略，新增参数innodb_autoinc_lock_mode，默认值是1。</p><ol><li><p>这个参数的值被设置为0时，表示采用之前MySQL 5.0版本的策略，即语句执行结束后才释放锁；</p></li><li><p>这个参数的值被设置为1时：</p><ul><li>普通insert语句，自增锁在申请之后就马上释放；</li><li>类似insert … select这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；</li></ul></li><li><p>这个参数的值被设置为2时，所有的申请自增主键的动作都是申请后就释放锁。</p></li></ol><p>你一定有两个疑问：<strong>为什么默认设置下，insert … select 要使用语句级的锁？为什么这个参数的默认值不是2？</strong></p><p>答案是，这么设计还是为了数据的一致性。</p><p>我们一起来看一下这个场景：</p><p><img src="/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/41f9fd86-2d31-4731-9c11-1c3355780fc9.png" alt></p><p>在这个例子里，我往表t1中插入了4行数据，然后创建了一个相同结构的表t2，然后两个session同时执行向表t2中插入数据的操作。</p><p>你可以设想一下，如果session B是申请了自增值以后马上就释放自增锁，那么就可能出现这样的情况：</p><ul><li>session B先插入了两个记录，(1,1,1)、(2,2,2)；</li><li>然后，session A来申请自增id得到id=3，插入了（3,5,5)；</li><li>之后，session B继续执行，插入两条记录(4,3,3)、 (5,4,4)。</li></ul><p>你可能会说，这也没关系吧，毕竟session B的语义本身就没有要求表t2的所有行的数据都跟session A相同。</p><p>是的，从数据逻辑上看是对的。但是，如果我们现在的binlog_format=statement，你可以设想下，binlog会怎么记录呢？</p><p>由于两个session是同时执行插入数据命令的，所以binlog里面对表t2的更新日志只有两种情况：要么先记session A的，要么先记session B的。</p><p>但不论是哪一种，这个binlog拿去从库执行，或者用来恢复临时实例，备库和临时实例里面，session B这个语句执行出来，生成的结果里面，id都是连续的。这时，这个库就发生了数据不一致。</p><p>你可以分析一下，出现这个问题的原因是什么？</p><p>其实，这是因为原库session B的insert语句，生成的id不连续。这个不连续的id，用statement格式的binlog来串行执行，是执行不出来的。</p><p>而要解决这个问题，有两种思路：</p><ol><li><p>一种思路是，让原库的批量插入数据语句，固定生成连续的id值。所以，自增锁直到语句执行结束才释放，就是为了达到这个目的。</p></li><li><p>另一种思路是，在binlog里面把插入数据的操作都如实记录进来，到备库执行的时候，不再依赖于自增主键去生成。这种情况，其实就是innodb_autoinc_lock_mode设置为2，同时binlog_format设置为row。</p></li></ol><p>因此，<strong>在生产上，尤其是有insert … select这种批量插入数据的场景时，从并发插入数据性能的角度考虑，我建议你这样设置：innodb_autoinc_lock_mode=2 ，并且 binlog_format=row</strong>.这样做，既能提升并发性，又不会出现数据一致性问题。</p><p>需要注意的是，我这里说的<strong>批量插入数据，包含的语句类型是insert … select、replace … select和load data语句。</strong></p><p>但是，在普通的insert语句里面包含多个value值的情况下，即使innodb_autoinc_lock_mode设置为1，也不会等语句执行完成才释放锁。因为这类语句在申请自增id的时候，是可以精确计算出需要多少个id的，然后一次性申请，申请完成后锁就可以释放了。</p><p>也就是说，批量插入数据的语句，之所以需要这么设置，是因为“不知道要预先申请多少个id”。</p><p>既然预先不知道要申请多少个自增id，那么一种直接的想法就是需要一个时申请一个。但如果一个select … insert语句要插入10万行数据，按照这个逻辑的话就要申请10万次。显然，这种申请自增id的策略，在大批量插入数据的情况下，不但速度慢，还会影响并发插入的性能。</p><p>因此，对于批量插入数据的语句，MySQL有一个批量申请自增id的策略：</p><ol><li><p>语句执行过程中，第一次申请自增id，会分配1个；</p></li><li><p>1个用完以后，这个语句第二次申请自增id，会分配2个；</p></li><li><p>2个用完以后，还是这个语句，第三次申请自增id，会分配4个；</p></li><li><p>依此类推，同一个语句去申请自增id，每次申请到的自增id个数都是上一次的两倍。</p></li></ol><p>举个例子，我们一起看看下面的这个语句序列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(null, 1,1);</span><br><span class="line">insert into t values(null, 2,2); </span><br><span class="line">insert into t values(null, 3,3); </span><br><span class="line">insert into t values(null, 4,4); </span><br><span class="line">create table t2 like t; </span><br><span class="line">insert into t2(c,d) select c,d from t; </span><br><span class="line">insert into t2 values(null, 5,5);</span><br></pre></td></tr></table></figure><p>insert…select，实际上往表t2中插入了4行数据。但是，这四行数据是分三次申请的自增id，第一次申请到了id=1，第二次被分配了id=2和id=3， 第三次被分配到id=4到id=7。</p><p>由于这条语句实际只用上了4个id，所以id=5到id=7就被浪费掉了。之后，再执行insert into t2 values(null, 5,5)，实际上插入的数据就是（8,5,5)。</p><p><strong>这是主键id出现自增id不连续的第三种原因。</strong></p><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>今天，我们从“自增主键为什么会出现不连续的值”这个问题开始，首先讨论了自增值的存储。</p><p>在MyISAM引擎里面，自增值是被写在数据文件上的。而在InnoDB中，自增值是被记录在内存的。MySQL直到8.0版本，才给InnoDB表的自增值加上了持久化的能力，确保重启前后一个表的自增值不变。</p><p>然后，分享了在一个语句执行过程中，自增值改变的时机，分析了为什么MySQL在事务回滚的时候不能回收自增id。</p><p>MySQL 5.1.22版本开始引入的参数innodb_autoinc_lock_mode，控制了自增值申请时的锁范围。从并发性能的角度考虑，建议将其设置为2，同时将binlog_format设置为row。在前面的文章中其实多次提到，binlog_format设置为row，是很有必要的。今天的例子给这个结论多了一个理由。</p><h2 id="6-思考"><a href="#6-思考" class="headerlink" title="6. 思考"></a>6. 思考</h2><p>在最后一个例子中，执行  <code>insert into t2(c,d) select c,d from t;</code> 这个语句的时候，如果隔离级别是可重复读（repeatable read），binlog_format=statement。这个语句会对表t的所有记录和间隙加锁。</p><p>你觉得为什么需要这么做呢？</p><p><strong>回答：见第40篇文章</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在 &lt;strong&gt;第4篇文章&lt;/strong&gt; 中，我们提到过自增主键，由于自增主键可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑。&lt;/p&gt;
&lt;p&gt;之前见过有的业务设计依赖于自增主键的连续性，也就是说，这个设计假设自增主键是连续的。但实际上，这样的假设是错的，因为自增主键不能保证连续递增。&lt;/p&gt;
&lt;p&gt;今天这篇文章，我们就来说说这个问题，看看什么情况下自增主键会出现 “空洞”？&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>38-都说InnoDB好_那还要不要使用Memory引擎</title>
    <link href="http://javassun.github.io/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/"/>
    <id>http://javassun.github.io/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/</id>
    <published>2020-03-02T10:30:38.000Z</published>
    <updated>2020-05-20T20:03:08.638Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在上一篇文章末尾留给你的问题是：两个group by 语句都用了order by null，为什么使用内存临时表得到的语句结果里，0这个值在最后一行；而使用磁盘临时表得到的结果里，0这个值在第一行？</p><p>今天我们就来看看，出现这个问题的原因吧。</p><a id="more"></a><h2 id="1-内存表的数据组织结构"><a href="#1-内存表的数据组织结构" class="headerlink" title="1. 内存表的数据组织结构"></a>1. 内存表的数据组织结构</h2><p>为了便于分析，我来把这个问题简化一下，假设有以下的两张表t1 和 t2，其中表t1使用Memory 引擎， 表t2使用InnoDB引擎。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table t1(id int primary key, c int) engine&#x3D;Memory; </span><br><span class="line">create table t2(id int primary key, c int) engine&#x3D;innodb; </span><br><span class="line">insert into t1 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0); </span><br><span class="line">insert into t2 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);</span><br></pre></td></tr></table></figure><p>然后，分别执行 <code>select * from t1</code>和<code>select * from t2</code>。</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/8a7b006c-41cb-474f-91c0-380a7bf01061.jpg" alt></p><p>可以看到，内存表t1的返回结果里面0在最后一行，而InnoDB表t2的返回结果里0在第一行。</p><p>出现这个区别的原因，要从这两个引擎的主键索引的组织方式说起。</p><p>表t2用的是InnoDB引擎，它的主键索引id的组织方式，你已经很熟悉了：InnoDB表的数据就放在主键索引树上，主键索引是B+树。所以表t2的数据组织方式如下图所示：</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/5f62bf38-caf1-4b43-9ea5-98c47f00de26.jpg" alt></p><p>主键索引上的值是有序存储的。在执行select *的时候，就会按照叶子节点从左到右扫描，所以得到的结果里，0就出现在第一行。</p><p>与InnoDB引擎不同，Memory引擎的数据和索引是分开的。我们来看一下表t1中的数据内容。</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/5b8ea2fe-feb6-4a69-91ae-98ad9f3b6af9.jpg" alt></p><p>可以看到，内存表的数据部分以数组的方式单独存放，而主键id索引里，存的是每个数据的位置。主键id是hash索引，可以看到索引上的key并不是有序的。</p><p>在内存表t1中，当我执行select *的时候，走的是全表扫描，也就是顺序扫描这个数组。因此，0就是最后一个被读到，并放入结果集的数据。</p><p>可见，InnoDB和Memory引擎的数据组织方式是不同的：</p><ul><li>InnoDB引擎把数据放在主键索引上，其他索引上保存的是主键id。这种方式，我们称之为<strong>索引组织表</strong>（Index Organizied Table）。</li><li>而Memory引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为<strong>堆组织表</strong>（Heap Organizied Table）。</li></ul><p>从中我们可以看出，这两个引擎的一些典型不同：</p><ol><li><p>InnoDB表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；</p></li><li><p>当数据文件有空洞的时候，InnoDB表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；</p></li><li><p>数据位置发生变化的时候，InnoDB表只需要修改主键索引，而内存表需要修改所有索引；</p></li><li><p>InnoDB表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。</p></li><li><p>InnoDB支持变长数据类型，不同记录的长度可能不同；内存表不支持Blob 和 Text字段，并且即使定义了varchar(N)，实际也当作char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。</p></li></ol><p>由于内存表的这些特性，每个数据行被删除以后，空出的这个位置都可以被接下来要插入的数据复用。比如，如果要在表t1中执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">delete from t1 where id&#x3D;5; </span><br><span class="line">insert into t1 values(10,10); </span><br><span class="line">select * from t1;</span><br></pre></td></tr></table></figure><p>就会看到返回结果里，id=10这一行出现在id=4之后，也就是原来id=5这行数据的位置。</p><p>需要指出的是，表t1的这个主键索引是哈希索引，因此如果执行范围查询，比如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from t1 where id&lt;5;</span><br></pre></td></tr></table></figure><p>是用不上主键索引的，需要走全表扫描。你可以借此再回顾下 *<em>第4篇文章 *</em>的内容。那如果要让内存表支持范围扫描，应该怎么办呢 ？</p><h2 id="2-hash索引和B-Tree索引"><a href="#2-hash索引和B-Tree索引" class="headerlink" title="2. hash索引和B-Tree索引"></a>2. hash索引和B-Tree索引</h2><p>实际上，内存表也是支B-Tree索引的。在id列上创建一个B-Tree索引，SQL语句可以这么写：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t1 add index a_btree_index using btree (id);</span><br></pre></td></tr></table></figure><p>这时，表t1的数据组织形式就变成了这样：</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/d67a12f1-9745-4e66-a93b-ca579205ec89.jpg" alt></p><p>新增的这个B-Tree索引你看着就眼熟了，这跟InnoDB的b+树索引组织形式类似。</p><p>作为对比，你可以看一下这下面这两个语句的输出：</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/b1c2d64c-ef06-4d09-a7cc-f31e9de8d6f4.png" alt></p><p>可以看到，执行select * from t1 where id&lt;5的时候，优化器会选择B-Tree索引，所以返回结果是0到4。 使用force index强行使用主键id这个索引，id=0这一行就在结果集的最末尾了。</p><p>其实，一般在我们的印象中，内存表的优势是速度快，其中的一个原因就是Memory引擎支持hash索引。当然，更重要的原因是，内存表的所有数据都保存在内存，而内存的读写速度总是比磁盘快。</p><p>但是，接下来要跟你说明，为什么我不建议你在生产环境上使用内存表。这里的原因主要包括两个方面：</p><ol><li><p>锁粒度问题；</p></li><li><p>数据持久化问题。</p></li></ol><h2 id="3-内存表的锁"><a href="#3-内存表的锁" class="headerlink" title="3. 内存表的锁"></a>3. 内存表的锁</h2><p>我们先来说说内存表的锁粒度问题。</p><p>内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作。</p><p>需要注意的是，这里的表锁跟之前我们介绍过的MDL锁不同，但都是表级的锁。接下来，我通过下面这个场景，跟你模拟一下内存表的表级锁。</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/6c4b9af9-26ee-4776-b5a9-f2f231f10b45.png" alt></p><p>在这个执行序列里，session A的update语句要执行50秒，在这个语句执行期间session B的查询会进入锁等待状态。session C的show processlist 结果输出如下：</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/847e10df-561a-4793-91d7-83f675acb085.png" alt></p><p>跟行锁比起来，表锁对并发访问的支持不够好。所以，内存表的锁粒度问题，决定了它在处理并发事务的时候，性能也不会太好。</p><h2 id="4-数据持久性问题"><a href="#4-数据持久性问题" class="headerlink" title="4. 数据持久性问题"></a>4. 数据持久性问题</h2><p>接下来，我们再看看数据持久性的问题。</p><p>数据放在内存中，是内存表的优势，但也是一个劣势。因为，数据库重启的时候，所有的内存表都会被清空。</p><p>你可能会说，如果数据库异常重启，内存表被清空也就清空了，不会有什么问题啊。但是，在高可用架构下，内存表的这个特点简直可以当做bug来看待了。为什么这么说呢？</p><p><strong>我们先看看M-S架构下，使用内存表存在的问题。</strong></p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/db5b7b2f-1f3f-46a7-a413-d08e5f4b4e45.jpg" alt></p><p>我们来看一下下面这个时序：</p><ol><li><p>业务正常访问主库；</p></li><li><p>备库硬件升级，备库重启，内存表t1内容被清空；</p></li><li><p>备库重启后，客户端发送一条update语句，修改表t1的数据行，这时备库应用线程就会报错“找不到要更新的行”。</p></li></ol><p>这样就会导致主备同步停止。当然，如果这时候发生主备切换的话，客户端会看到，表t1的数据“丢失”了。</p><p>在图8中这种有proxy的架构里，大家默认主备切换的逻辑是由数据库系统自己维护的。这样对客户端来说，就是“网络断开，重连之后，发现内存表数据丢失了”。</p><p>你可能说这还好啊，毕竟主备发生切换，连接会断开，业务端能够感知到异常。</p><p>但是，接下来内存表的这个特性就会让使用现象显得更“诡异”了。由于MySQL知道重启之后，内存表的数据会丢失。所以，担心主库重启之后，出现主备不一致，MySQL在实现上做了这样一件事儿：在数据库重启之后，往binlog里面写入一行DELETE FROM t1。</p><p><strong>如果你使用是如图9所示的双M结构的话：</strong></p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/bf5e6a65-c33e-4ed4-841d-9cc1a4f2ba4c.jpg" alt></p><p>在备库重启的时候，备库binlog里的delete语句就会传到主库，然后把主库内存表的内容删除。这样你在使用的时候就会发现，主库的内存表数据突然被清空了。</p><p>基于上面的分析，你可以看到，内存表并不适合在生产环境上作为普通数据表使用。</p><p>有同学会说，但是内存表执行速度快呀。这个问题，其实你可以这么分析：</p><ol><li><p>如果你的表更新量大，那么并发度是一个很重要的参考指标，InnoDB支持行锁，并发度比内存表好；</p></li><li><p>能放到内存表的数据量都不大。如果你考虑的是读的性能，一个读QPS很高并且数据量不大的表，即使是使用InnoDB，数据也是都会缓存在InnoDB Buffer Pool里的。因此，使用InnoDB表的读性能也不会差。</p></li></ol><p>所以，<strong>建议你把普通内存表都用InnoDB表来代替。</strong>但是，有一个场景却是例外的。</p><p>这个场景就是，我们在第35和36篇说到的用户临时表。在数据量可控，不会耗费过多内存的情况下，你可以考虑使用内存表。</p><p>内存临时表刚好可以无视内存表的两个不足，主要是下面的三个原因：</p><ol><li><p>临时表不会被其他线程访问，没有并发性的问题；</p></li><li><p>临时表重启后也是需要删除的，清空数据这个问题不存在；</p></li><li><p>备库的临时表也不会影响主库的用户线程。</p></li></ol><p>现在，我们回过头再看一下第35篇join语句优化的例子，当时我建议的是创建一个InnoDB临时表，使用的语句序列是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create temporary table temp_t(id int primary key, a int, b int, index(b))engine&#x3D;innodb; </span><br><span class="line">insert into temp_t select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000; </span><br><span class="line">select * from t1 join temp_t on (t1.b&#x3D;temp_t.b);</span><br></pre></td></tr></table></figure><p>了解了内存表的特性，你就知道了， 其实这里使用内存临时表的效果更好，原因有三个：</p><ol><li><p>相比于InnoDB表，使用内存表不需要写磁盘，往表temp_t的写数据的速度更快；</p></li><li><p>索引b使用hash索引，查找的速度比B-Tree索引快；</p></li><li><p>临时表数据只有2000行，占用的内存有限。</p></li></ol><p>因此，你可以对 <strong>第35篇文章</strong> 的语句序列做一个改写，将临时表t1改成内存临时表，并且在字段b上创建一个hash索引。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create temporary table temp_t(id int primary key, a int, b int, index (b))engine&#x3D;memory; </span><br><span class="line">insert into temp_t select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000; </span><br><span class="line">select * from t1 join temp_t on (t1.b&#x3D;temp_t.b);</span><br></pre></td></tr></table></figure><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/2897310d-b2b2-4fe3-a67d-901ccab9c3c5.jpg" alt></p><p>可以看到，不论是导入数据的时间，还是执行join的时间，使用内存临时表的速度都比使用InnoDB临时表要更快一些。</p><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>今天这篇文章，从“要不要使用内存表”这个问题展开，介绍了Memory引擎的几个特性。</p><p>可以看到，由于重启会丢数据，如果一个备库重启，会导致主备同步线程停止；如果主库跟这个备库是双M架构，还可能导致主库的内存表数据被删掉。</p><p>因此，在生产上，我不建议你使用普通内存表。</p><p>如果你是DBA，可以在建表的审核系统中增加这类规则，要求业务改用InnoDB表。我们在文中也分析了，其实InnoDB表性能还不错，而且数据安全也有保障。而内存表由于不支持行锁，更新语句会阻塞查询，性能也未必就如想象中那么好。</p><p>基于内存表的特性，我们还分析了它的一个适用场景，就是内存临时表。内存表支持hash索引，这个特性利用起来，对复杂查询的加速效果还是很不错的。</p><h2 id="6-思考"><a href="#6-思考" class="headerlink" title="6. 思考"></a>6. 思考</h2><p>假设你刚刚接手的一个数据库上，真的发现了一个内存表。备库重启之后肯定是会导致备库的内存表数据被清空，进而导致主备同步停止。这时，最好的做法是将它修改成InnoDB引擎表。</p><p>假设当时的业务场景暂时不允许你修改引擎，你可以加上什么自动化逻辑，来避免主备同步停止呢？</p><p>即 如果你维护的MySQL系统里有内存表，怎么避免内存表突然丢数据，然后导致主备同步停止的情况。</p><p><strong>回答：</strong><br>我们假设的是主库暂时不能修改引擎，那么就把备库的内存表引擎先都改成InnoDB。对于每个内存表，执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set sql_log_bin&#x3D;off;</span><br><span class="line">alter table tbl_name engine&#x3D;innodb;</span><br></pre></td></tr></table></figure><p>这样就能避免备库重启的时候，数据丢失的问题。</p><p>由于主库重启后，会往binlog里面写“delete from tbl_name”，这个命令传到备库，备库的同名的表数据也会被清空。</p><p>因此，就不会出现主备同步停止的问题。</p><p>如果由于主库异常重启，触发了HA，这时候我们之前修改过引擎的备库变成了主库。而原来的主库变成了新备库，在新备库上把所有的内存表（这时候表里没数据）都改成InnoDB表。</p><p>所以，如果我们不能直接修改主库上的表引擎，可以配置一个自动巡检的工具，在备库上发现内存表就把引擎改了。</p><p>同时，跟业务开发同学约定好建表规则，避免创建新的内存表。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在上一篇文章末尾留给你的问题是：两个group by 语句都用了order by null，为什么使用内存临时表得到的语句结果里，0这个值在最后一行；而使用磁盘临时表得到的结果里，0这个值在第一行？&lt;/p&gt;
&lt;p&gt;今天我们就来看看，出现这个问题的原因吧。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>37-什么时候会使用内部临时表</title>
    <link href="http://javassun.github.io/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/"/>
    <id>http://javassun.github.io/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/</id>
    <published>2020-03-01T07:40:38.000Z</published>
    <updated>2020-05-20T19:58:14.021Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 <strong>第16**</strong> 和 <strong>第34</strong> 篇文章中，分别介绍了sort buffer、内存临时表和join buffer。这三个数据结构都是用来存放语句执行过程中的中间数据，以辅助SQL语句的执行的。其中，我们在排序的时候用到了sort buffer，在使用join语句的时候用到了join buffer。</p><p>然后，你可能会有这样的疑问，MySQL什么时候会使用内部临时表呢？</p><p>今天这篇文章，先给你举两个需要用到内部临时表的例子，来看看内部临时表是怎么工作的。然后，我们再来分析，什么情况下会使用内部临时表。</p><a id="more"></a><h2 id="1-union-执行流程"><a href="#1-union-执行流程" class="headerlink" title="1. union 执行流程"></a>1. union 执行流程</h2><p>为了便于量化分析，我用下面的表t1来举例。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/cb5eac58-76b4-4b8a-b490-126289198b65.png" alt></p><p>然后，我们执行下面这条语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(select 1000 as f) union (select id from t1 order by id desc limit 2);</span><br></pre></td></tr></table></figure><p>这条语句用到了union，它的语义是，取这两个子查询结果的并集。并集的意思就是这两个集合加起来，重复的行只保留一行。</p><p>下图是这个语句的explain结果。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/fec2ea93-ef01-455e-b6c0-a7cd18551677.jpg" alt></p><p>可以看到：</p><ul><li>第二行的key=PRIMARY，说明第二个子句用到了索引id。</li><li>第三行的Extra字段，表示在对子查询的结果集做union的时候，使用了临时表(Using temporary)。</li></ul><p>这个语句的执行流程是这样的：</p><ol><li><p>创建一个内存临时表，这个临时表只有一个整型字段f，并且f是主键字段。</p></li><li><p>执行第一个子查询，得到1000这个值，并存入临时表中。</p></li><li><p>执行第二个子查询：</p><ul><li>拿到第一行id=1000，试图插入临时表中。但由于1000这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行；</li><li>取到第二行id=999，插入临时表成功。</li></ul></li><li><p>从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是1000和999。</p></li></ol><p>这个过程的流程图如下所示：</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/c2fb9818-3a4c-4eb6-abfd-f58da74c1ae2.jpg" alt></p><p>可以看到，这里的内存临时表起到了暂存数据的作用，而且计算过程还用上了临时表主键id的唯一性约束，实现了union的语义。</p><p>顺便提一下，如果把上面这个语句中的union改成union all的话，就没有了“去重”的语义。这样执行的时候，就依次执行子查询，得到的结果直接作为结果集的一部分，发给客户端。因此也就不需要临时表了。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/04f6723d-ff50-4447-bf20-ced938b562ab.png" alt></p><p>可以看到，第二行的Extra字段显示的是Using index，表示只使用了覆盖索引，没有用临时表了。</p><h2 id="2-group-by-执行流程"><a href="#2-group-by-执行流程" class="headerlink" title="2. group by 执行流程"></a>2. group by 执行流程</h2><p>另外一个常见的使用临时表的例子是group by，我们来看一下这个语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id%10 as m, count(*) as c from t1 group by m;</span><br></pre></td></tr></table></figure><p>这个语句的逻辑是把表t1里的数据，按照 id%10 进行分组统计，并按照m的结果排序后输出。它的explain结果如下：</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/ae4c74ca-9826-4f2e-a396-0d79c32cc706.png" alt></p><p>在Extra字段里面，我们可以看到三个信息：</p><ul><li>Using index，表示这个语句使用了覆盖索引，选择了索引a，不需要回表；</li><li>Using temporary，表示使用了临时表；</li><li>Using filesort，表示需要排序。</li></ul><p>这个语句的执行流程是这样的：</p><ol><li><p>创建内存临时表，表里有两个字段m和c，主键是m；</p></li><li><p>扫描表t1的索引a，依次取出叶子节点上的id值，计算id%10的结果，记为x；</p><ul><li>如果临时表中没有主键为x的行，就插入一个记录(x,1);</li><li>如果表中有主键为x的行，就将x这一行的c值加1；</li></ul></li><li><p>遍历完成后，再根据字段m做排序，得到结果集返回给客户端。</p></li></ol><p>这个流程的执行图如下：</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/388f7d5b-3593-4b43-bc9b-56c2919f309b.jpg" alt></p><p>图中最后一步，对内存临时表的排序，在 <strong>第17篇文章</strong> 中已经有过介绍，我把图贴过来，方便你回顾。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/dd8daed5-cf18-4096-8c33-3488ed6e0b95.jpg" alt></p><p>其中，临时表的排序过程就是图6中虚线框内的过程。</p><p>接下来，我们再看一下这条语句的执行结果：</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/cc7dd5c3-c25a-4f07-ae1a-dcf2252ef2f5.png" alt></p><p>如果你的需求并不需要对结果进行排序，那你可以在SQL语句末尾增加order by null，也就是改成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id%10 as m, count(*) as c from t1 group by m order by null;</span><br></pre></td></tr></table></figure><p>这样就跳过了最后排序的阶段，直接从临时表中取数据返回。返回的结果如图8所示。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/3084be14-5fb0-47c0-a8d3-c754ae1e340d.png" alt></p><p>由于表t1中的id值是从1开始的，因此返回的结果集中第一行是id=1；扫描到id=10的时候才插入m=0这一行，因此结果集里最后一行才是m=0。</p><p>这个例子里由于临时表只有10行，内存可以放得下，因此全程只使用了内存临时表。但是，内存临时表的大小是有限制的，参数tmp_table_size就是控制这个内存大小的，默认是16M。</p><p>如果我执行下面这个语句序列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set tmp_table_size&#x3D;1024; </span><br><span class="line">select id%100 as m, count(*) as c from t1 group by m order by null limit 10;</span><br></pre></td></tr></table></figure><p>把内存临时表的大小限制为最大1024字节，并把语句改成id % 100，这样返回结果里有100行数据。但是，这时的内存临时表大小不够存下这100行数据，也就是说，执行过程中会发现内存临时表大小到达了上限（1024字节）。</p><p>那么，这时候就会把内存临时表转成磁盘临时表，磁盘临时表默认使用的引擎是InnoDB。 这时，返回的结果如图9所示。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/127a16ea-dded-4f41-bed8-26731140f612.png" alt></p><p>如果这个表t1的数据量很大，很可能这个查询需要的磁盘临时表就会占用大量的磁盘空间。</p><h2 id="3-group-by-优化方法-–索引"><a href="#3-group-by-优化方法-–索引" class="headerlink" title="3. group by 优化方法 –索引"></a>3. group by 优化方法 –索引</h2><p>可以看到，不论是使用内存临时表还是磁盘临时表，group by逻辑都需要构造一个带唯一索引的表，执行代价都是比较高的。如果表的数据量比较大，上面这个group by语句执行起来就会很慢，我们有什么优化的方法呢？</p><p>要解决group by语句的优化问题，你可以先想一下这个问题：执行group by语句为什么需要临时表？</p><p>group by的语义逻辑，是统计不同的值出现的个数。但是，由于每一行的id%100的结果是无序的，所以我们就需要有一个临时表，来记录并统计结果。</p><p>那么，如果扫描过程中可以保证出现的数据是有序的，是不是就简单了呢？</p><p>假设，现在有一个类似图10的这么一个数据结构，我们来看看group by可以怎么做。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/8b971fe1-2c3b-400c-b8a8-009db9660dc1.jpg" alt></p><p>可以看到，如果可以确保输入的数据是有序的，那么计算group by的时候，就只需要从左到右，顺序扫描，依次累加。也就是下面这个过程：</p><ul><li>当碰到第一个1的时候，已经知道累积了X个0，结果集里的第一行就是(0,X);</li><li>当碰到第一个2的时候，已经知道累积了Y个1，结果集里的第一行就是(1,Y);</li></ul><p>按照这个逻辑执行的话，扫描到整个输入的数据结束，就可以拿到group by的结果，不需要临时表，也不需要再额外排序。</p><p>你一定想到了，InnoDB的索引，就可以满足这个输入有序的条件。</p><p>在MySQL 5.7版本支持了generated column机制，用来实现列数据的关联更新。你可以用下面的方法创建一个列z，然后在z列上创建一个索引（如果是MySQL 5.6及之前的版本，你也可以创建普通列和索引，来解决这个问题）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t1 add column z int generated always as(id % 100), add index(z);</span><br></pre></td></tr></table></figure><p>这样，索引z上的数据就是类似图10这样有序的了。上面的group by语句就可以改成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select z, count(*) as c from t1 group by z;</span><br></pre></td></tr></table></figure><p>优化后的group by语句的explain结果，如下图所示：</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/23fd349e-4e82-48c7-8da8-2d48057d16fa.png" alt></p><p>从Extra字段可以看到，这个语句的执行不再需要临时表，也不需要排序了。</p><h2 id="4-group-by优化方法-–直接排序"><a href="#4-group-by优化方法-–直接排序" class="headerlink" title="4. group by优化方法 –直接排序"></a>4. group by优化方法 –直接排序</h2><p>所以，如果可以通过加索引来完成group by逻辑就再好不过了。但是，如果碰上不适合创建索引的场景，我们还是要老老实实做排序的。那么，这时候的group by要怎么优化呢？</p><p>如果我们明明知道，一个group by语句中需要放到临时表上的数据量特别大，却还是要按照“先放到内存临时表，插入一部分数据后，发现内存临时表不够用了再转成磁盘临时表”，看上去就有点儿傻。</p><p>那么，我们就会想了，MySQL有没有让我们直接走磁盘临时表的方法呢？</p><p>答案是，有的。</p><p>在group by语句中加入SQL_BIG_RESULT这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。</p><p>MySQL的优化器一看，磁盘临时表是B+树存储，存储效率不如数组来得高。所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。</p><p>因此，下面这个语句</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;</span><br></pre></td></tr></table></figure><p>的执行流程就是这样的：</p><ol><li><p>初始化sort_buffer，确定放入一个整型字段，记为m；</p></li><li><p>扫描表t1的索引a，依次取出里面的id值, 将 id%100的值存入sort_buffer中；</p></li><li><p>扫描完成后，对sort_buffer的字段m做排序（如果sort_buffer内存不够用，就会利用磁盘临时文件辅助排序）；</p></li><li><p>排序完成后，就得到了一个有序数组。</p></li></ol><p>根据有序数组，得到数组里面的不同值，以及每个值的出现次数。这一步的逻辑，你已经从前面的图10中了解过了。</p><p>下面两张图分别是执行流程图和执行explain命令得到的结果。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/71233a5f-536a-4096-b315-b489c69206d1.jpg" alt></p><p>从Extra字段可以看到，这个语句的执行没有再使用临时表，而是直接用了排序算法。</p><p>基于上面的union、union all和group by语句的执行过程的分析，我们来回答文章开头的问题：MySQL什么时候会使用内部临时表？</p><ol><li><p>如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；</p></li><li><p>join_buffer是无序数组，sort_buffer是有序数组，临时表是二维表结构；</p></li><li><p>如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union需要用到唯一索引约束， group by还需要用到另外一个字段来存累积计数。</p></li></ol><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>通过今天这篇文章，重点讲了group by的几种实现算法，从中可以总结一些使用的指导原则：</p><ol><li><p>如果对group by语句的结果没有排序要求，要在语句后面加 order by null；</p></li><li><p>尽量让group by过程用上表的索引，确认方法是explain结果里没有Using temporary 和 Using filesort；</p></li><li><p>如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大tmp_table_size参数，来避免用到磁盘临时表；</p></li><li><p>如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法得到group by的结果。</p></li></ol><h2 id="6-思考"><a href="#6-思考" class="headerlink" title="6. 思考"></a>6. 思考</h2><p>文章中图8和图9都是order by null，为什么图8的返回结果里面，0是在结果集的最后一行，而图9的结果里面，0是在结果集的第一行？</p><p><strong>回答：见第38篇文章</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在 &lt;strong&gt;第16**&lt;/strong&gt; 和 &lt;strong&gt;第34&lt;/strong&gt; 篇文章中，分别介绍了sort buffer、内存临时表和join buffer。这三个数据结构都是用来存放语句执行过程中的中间数据，以辅助SQL语句的执行的。其中，我们在排序的时候用到了sort buffer，在使用join语句的时候用到了join buffer。&lt;/p&gt;
&lt;p&gt;然后，你可能会有这样的疑问，MySQL什么时候会使用内部临时表呢？&lt;/p&gt;
&lt;p&gt;今天这篇文章，先给你举两个需要用到内部临时表的例子，来看看内部临时表是怎么工作的。然后，我们再来分析，什么情况下会使用内部临时表。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ详解</title>
    <link href="http://javassun.github.io/2020/02/25/RabbitMQ%E8%AF%A6%E8%A7%A3/"/>
    <id>http://javassun.github.io/2020/02/25/RabbitMQ%E8%AF%A6%E8%A7%A3/</id>
    <published>2020-02-25T12:22:31.000Z</published>
    <updated>2020-05-06T06:33:23.548Z</updated>
    
    <content type="html"><![CDATA[<p>转载<a href="http://www.ityouknow.com/springboot/2016/11/30/spring-boot-rabbitMQ.html" target="_blank" rel="noopener">纯洁的微笑</a></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>RabbitMQ 即一个消息队列，主要是用来实现应用程序的异步和解耦，同时也能起到消息缓冲，消息分发的作用。消息中间件在互联网公司的使用中越来越多，消息中间件最主要的作用是解耦，中间件最标准的用法是生产者生产消息传送到队列，消费者从队列中拿取消息并处理，生产者不用关心是谁来消费，消费者不用关心谁在生产消息，从而达到解耦的目的。在分布式的系统中，消息队列也会被用在很多其它的方面，比如：分布式事务的支持，RPC 的调用等等。</p><h2 id="RabbitMQ-介绍"><a href="#RabbitMQ-介绍" class="headerlink" title="RabbitMQ 介绍"></a>RabbitMQ 介绍</h2><p>RabbitMQ 是实现 AMQP（高级消息队列协议）的消息中间件的一种，最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 RabbitMQ 主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。</p><p>AMQP，即 Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP 的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。</p><p>RabbitMQ 是一个开源的 AMQP 实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等，支持 AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。</p><a id="more"></a><h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h3><p>通常我们谈到队列服务, 会有三个概念： 发消息者、队列、收消息者，RabbitMQ 在这个基本概念之上, 多做了一层抽象, 在发消息者和 队列之间, 加入了交换器 (Exchange). 这样发消息者和队列就没有直接联系, 转而变成发消息者把消息给交换器, 交换器根据调度策略再把消息再给队列。</p><p><img src="/2020/02/25/RabbitMQ%E8%AF%A6%E8%A7%A3/RabbitMQ01.png" alt></p><ul><li>左侧 P 代表 生产者，也就是往 RabbitMQ 发消息的程序。</li><li>中间即是 RabbitMQ，其中包括了 交换机 和 队列。</li><li>右侧 C 代表 消费者，也就是从 RabbitMQ 拿消息的程序。</li></ul><p>那么，其中比较重要的概念有 4 个，分别为：虚拟主机，交换机，队列，和绑定。</p><ul><li>虚拟主机：一个虚拟主机持有一组交换机、队列和绑定。为什么需要多个虚拟主机呢？很简单， RabbitMQ 当中，<em>用户只能在虚拟主机的粒度进行权限控制。</em> 因此，如果需要禁止A组访问B组的交换机/队列/绑定，必须为A和B分别创建一个虚拟主机。每一个 RabbitMQ 服务器都有一个默认的虚拟主机“/”。</li><li>交换机：<em>Exchange 用于转发消息，但是它不会做存储</em> ，如果没有 Queue bind 到 Exchange 的话，它会直接丢弃掉 Producer 发送过来的消息。 这里有一个比较重要的概念：<strong>路由键</strong> 。消息到交换机的时候，交互机会转发到对应的队列中，那么究竟转发到哪个队列，就要根据该路由键。</li><li>绑定：也就是交换机需要和队列相绑定，这其中如上图所示，是多对多的关系</li></ul><h3 id="交换机-Exchange"><a href="#交换机-Exchange" class="headerlink" title="交换机(Exchange)"></a>交换机(Exchange)</h3><p>交换机的功能主要是接收消息并且转发到绑定的队列，交换机不存储消息，在启用ack模式后，交换机找不到队列会返回错误。交换机有四种类型：Direct, topic, Headers and Fanout</p><ul><li>Direct：direct 类型的行为是”先匹配, 再投送”. 即在绑定时设定一个 <strong>routing_key</strong>, 消息的<strong>routing_key</strong> 匹配时, 才会被交换器投送到绑定的队列中去.</li><li>Topic：按规则转发消息（最灵活）</li><li>Headers：设置 header attribute 参数类型的交换机</li><li>Fanout：转发消息到所有绑定队列</li></ul><p><strong>Direct Exchange</strong></p><p>Direct Exchange 是 RabbitMQ 默认的交换机模式，也是最简单的模式，根据key全文匹配去寻找队列。</p><p><img src="/2020/02/25/RabbitMQ%E8%AF%A6%E8%A7%A3/rabbitMq_direct.png" alt></p><p>第一个 X - Q1 就有一个 binding key，名字为 orange； X - Q2 就有 2 个 binding key，名字为 black 和 green。<em>当消息中的 路由键 和 这个 binding key 对应上的时候，那么就知道了该消息去到哪一个队列中。</em></p><p>Ps：为什么 X 到 Q2 要有 black，green，2个 binding key呢，一个不就行了吗？ - 这个主要是因为可能又有 Q3，而Q3只接受 black 的信息，而Q2不仅接受black 的信息，还接受 green 的信息。</p><p><strong>Topic Exchange</strong></p><p>Topic Exchange 转发消息主要是根据通配符。_ 在这种交换机下，队列和交换机的绑定会定义一种路由模式，那么，通配符就要在这种路由模式和路由键之间匹配后交换机才能转发消息。</p><p>在这种交换机模式下：</p><ul><li>路由键必须是一串字符，用句号（<code>.</code>） 隔开，比如说 agreements.us，或者 agreements.eu.stockholm 等。</li><li>路由模式必须包含一个 星号（<code>*</code>），主要用于匹配路由键指定位置的一个单词，比如说，一个路由模式是这样子：agreements..b.*，那么就只能匹配路由键是这样子的：第一个单词是 agreements，第四个单词是 b。 井号（#）就表示相当于一个或者多个单词，例如一个匹配模式是 agreements.eu.berlin.#，那么，以agreements.eu.berlin 开头的路由键都是可以的。</li></ul><p>具体代码发送的时候还是一样，第一个参数表示交换机，第二个参数表示 routing key，第三个参数即消息。如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">abbitTemplate.convertAndSend(&quot;testTopicExchange&quot;,&quot;key1.a.c.key2&quot;, &quot; this is  RabbitMQ!&quot;);</span><br></pre></td></tr></table></figure><p>topic 和 direct 类似, 只是匹配上支持了”模式”, 在”点分”的 routing_key 形式中, 可以使用两个通配符:</p><ul><li><code>*</code>表示一个词.</li><li><code>#</code>表示零个或多个词.</li></ul><p><strong>Headers Exchange</strong></p><p>headers 也是根据规则匹配, 相较于 direct 和 topic 固定地使用 routing_key , headers 则是一个自定义匹配规则的类型. 在队列与交换器绑定时, 会设定一组键值对规则, 消息中也包括一组键值对( headers 属性), 当这些键值对有一对, 或全部匹配时, 消息被投送到对应队列.</p><p><strong>Fanout Exchange</strong></p><p>Fanout Exchange 消息广播的模式，不管路由键或者是路由模式，_会把消息发给绑定给它的全部队列_，如果配置了 routing_key 会被忽略。</p><h2 id="Spring-Boot-集成-RabbitMQ"><a href="#Spring-Boot-集成-RabbitMQ" class="headerlink" title="Spring Boot 集成 RabbitMQ"></a>Spring Boot 集成 RabbitMQ</h2><p>Spring Boot 集成 RabbitMQ 非常简单，如果只是简单的使用配置非常少，Spring Boot 提供了<code>spring-boot-starter-amqp</code> 项目对消息各种支持。</p><h3 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h3><p>1、配置 Pom 包，主要是添加 <code>spring-boot-starter-amqp</code> 的支持</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-amqp&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><p>2、配置文件</p><p>配置 RabbitMQ 的安装地址、端口以及账户信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spring.application.name&#x3D;Spring-boot-rabbitmq</span><br><span class="line"></span><br><span class="line">spring.rabbitmq.host&#x3D;192.168.0.86</span><br><span class="line">spring.rabbitmq.port&#x3D;5672</span><br><span class="line">spring.rabbitmq.username&#x3D;admin</span><br><span class="line">spring.rabbitmq.password&#x3D;123456</span><br></pre></td></tr></table></figure><p>3、队列配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class RabbitConfig &#123;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public Queue Queue() &#123;</span><br><span class="line">        return new Queue(&quot;hello&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4、发送者</p><p>rabbitTemplate 是 Spring Boot 提供的默认实现</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@component</span><br><span class="line">public class HelloSender &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private AmqpTemplate rabbitTemplate;</span><br><span class="line"></span><br><span class="line">    public void send() &#123;</span><br><span class="line">        String context &#x3D; &quot;hello &quot; + new Date();</span><br><span class="line">        System.out.println(&quot;Sender : &quot; + context);</span><br><span class="line">        this.rabbitTemplate.convertAndSend(&quot;hello&quot;, context);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>5、接收者</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">@RabbitListener(queues &#x3D; &quot;hello&quot;)</span><br><span class="line">public class HelloReceiver &#123;</span><br><span class="line"></span><br><span class="line">    @RabbitHandler</span><br><span class="line">    public void process(String hello) &#123;</span><br><span class="line">        System.out.println(&quot;Receiver  : &quot; + hello);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>6、测试</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@RunWith(SpringRunner.class)</span><br><span class="line">@SpringBootTest</span><br><span class="line">public class RabbitMqHelloTest &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private HelloSender helloSender;</span><br><span class="line"></span><br><span class="line">    @Test</span><br><span class="line">    public void hello() throws Exception &#123;</span><br><span class="line">        helloSender.send();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>注意，发送者和接收者的 queue name 必须一致，不然不能接收</p></blockquote><h3 id="多对多使用"><a href="#多对多使用" class="headerlink" title="多对多使用"></a>多对多使用</h3><p>一个发送者，N 个接收者或者 N 个发送者和 N 个接收者会出现什么情况呢？</p><p><strong>一对多发送</strong></p><p>对上面的代码进行了小改造，接收端注册了两个 Receiver,Receiver1 和 Receiver2，发送端加入参数计数，接收端打印接收到的参数，下面是测试代码，发送一百条消息，来观察两个接收端的执行效果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void oneToMany() throws Exception &#123;</span><br><span class="line">    for (int i&#x3D;0;i&lt;100;i++)&#123;</span><br><span class="line">        neoSender.send(i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Receiver 1: Spring boot neo queue ****** 11</span><br><span class="line">Receiver 2: Spring boot neo queue ****** 12</span><br><span class="line">Receiver 2: Spring boot neo queue ****** 14</span><br><span class="line">Receiver 1: Spring boot neo queue ****** 13</span><br><span class="line">Receiver 2: Spring boot neo queue ****** 15</span><br><span class="line">Receiver 1: Spring boot neo queue ****** 16</span><br><span class="line">Receiver 1: Spring boot neo queue ****** 18</span><br><span class="line">Receiver 2: Spring boot neo queue ****** 17</span><br><span class="line">Receiver 2: Spring boot neo queue ****** 19</span><br><span class="line">Receiver 1: Spring boot neo queue ****** 20</span><br></pre></td></tr></table></figure><p>根据返回结果得到以下结论</p><blockquote><p>一个发送者，N个接受者,经过测试会均匀的将消息发送到N个接收者中</p></blockquote><p><strong>多对多发送</strong></p><p>复制了一份发送者，加入标记，在一百个循环中相互交替发送</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">    public void manyToMany() throws Exception &#123;</span><br><span class="line">        for (int i&#x3D;0;i&lt;100;i++)&#123;</span><br><span class="line">            neoSender.send(i);</span><br><span class="line">            neoSender2.send(i);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Receiver 1: Spring boot neo queue ****** 20</span><br><span class="line">Receiver 2: Spring boot neo queue ****** 20</span><br><span class="line">Receiver 1: Spring boot neo queue ****** 21</span><br><span class="line">Receiver 2: Spring boot neo queue ****** 21</span><br><span class="line">Receiver 1: Spring boot neo queue ****** 22</span><br><span class="line">Receiver 2: Spring boot neo queue ****** 22</span><br><span class="line">Receiver 1: Spring boot neo queue ****** 23</span><br><span class="line">Receiver 2: Spring boot neo queue ****** 23</span><br><span class="line">Receiver 1: Spring boot neo queue ****** 24</span><br><span class="line">Receiver 2: Spring boot neo queue ****** 24</span><br><span class="line">Receiver 1: Spring boot neo queue ****** 25</span><br><span class="line">Receiver 2: Spring boot neo queue ****** 25</span><br></pre></td></tr></table></figure><blockquote><p>结论：和一对多一样，接收端仍然会均匀接收到消息</p></blockquote><h3 id="高级使用"><a href="#高级使用" class="headerlink" title="高级使用"></a>高级使用</h3><p><strong>对象的支持</strong></p><p>Spring Boot 以及完美的支持对象的发送和接收，不需要格外的配置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;发送者</span><br><span class="line">public void send(User user) &#123;</span><br><span class="line">    System.out.println(&quot;Sender object: &quot; + user.toString());</span><br><span class="line">    this.rabbitTemplate.convertAndSend(&quot;object&quot;, user);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;接收者</span><br><span class="line">@RabbitHandler</span><br><span class="line">public void process(User user) &#123;</span><br><span class="line">    System.out.println(&quot;Receiver object : &quot; + user);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Sender object: User&#123;name&#x3D;&#39;neo&#39;, pass&#x3D;&#39;123456&#39;&#125;</span><br><span class="line">Receiver object : User&#123;name&#x3D;&#39;neo&#39;, pass&#x3D;&#39;123456&#39;&#125;</span><br></pre></td></tr></table></figure><p><strong>Topic Exchange</strong></p><p>topic 是 RabbitMQ 中最灵活的一种方式，可以根据 routing_key 自由的绑定不同的队列</p><p>首先对 topic 规则配置，这里使用两个队列来测试</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class TopicRabbitConfig &#123;</span><br><span class="line"></span><br><span class="line">    final static String message &#x3D; &quot;topic.message&quot;;</span><br><span class="line">    final static String messages &#x3D; &quot;topic.messages&quot;;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public Queue queueMessage() &#123;</span><br><span class="line">        return new Queue(TopicRabbitConfig.message);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public Queue queueMessages() &#123;</span><br><span class="line">        return new Queue(TopicRabbitConfig.messages);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    TopicExchange exchange() &#123;</span><br><span class="line">        return new TopicExchange(&quot;exchange&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    Binding bindingExchangeMessage(Queue queueMessage, TopicExchange exchange) &#123;</span><br><span class="line">        return BindingBuilder.bind(queueMessage).to(exchange).with(&quot;topic.message&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    Binding bindingExchangeMessages(Queue queueMessages, TopicExchange exchange) &#123;</span><br><span class="line">        return BindingBuilder.bind(queueMessages).to(exchange).with(&quot;topic.#&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 queueMessages 同时匹配两个队列，queueMessage 只匹配 “topic.message” 队列</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public void send1() &#123;</span><br><span class="line">    String context &#x3D; &quot;hi, i am message 1&quot;;</span><br><span class="line">    System.out.println(&quot;Sender : &quot; + context);</span><br><span class="line">    this.rabbitTemplate.convertAndSend(&quot;exchange&quot;, &quot;topic.message&quot;, context);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void send2() &#123;</span><br><span class="line">    String context &#x3D; &quot;hi, i am messages 2&quot;;</span><br><span class="line">    System.out.println(&quot;Sender : &quot; + context);</span><br><span class="line">    this.rabbitTemplate.convertAndSend(&quot;exchange&quot;, &quot;topic.messages&quot;, context);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>发送send1会匹配到topic.#和topic.message 两个Receiver都可以收到消息，发送send2只有topic.#可以匹配所有只有Receiver2监听到消息</p><p><strong>Fanout Exchange</strong></p><p>Fanout 就是我们熟悉的广播模式或者订阅模式，给 Fanout 交换机发送消息，绑定了这个交换机的所有队列都收到这个消息。</p><p>Fanout 相关配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class FanoutRabbitConfig &#123;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public Queue AMessage() &#123;</span><br><span class="line">        return new Queue(&quot;fanout.A&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public Queue BMessage() &#123;</span><br><span class="line">        return new Queue(&quot;fanout.B&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public Queue CMessage() &#123;</span><br><span class="line">        return new Queue(&quot;fanout.C&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    FanoutExchange fanoutExchange() &#123;</span><br><span class="line">        return new FanoutExchange(&quot;fanoutExchange&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    Binding bindingExchangeA(Queue AMessage,FanoutExchange fanoutExchange) &#123;</span><br><span class="line">        return BindingBuilder.bind(AMessage).to(fanoutExchange);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    Binding bindingExchangeB(Queue BMessage, FanoutExchange fanoutExchange) &#123;</span><br><span class="line">        return BindingBuilder.bind(BMessage).to(fanoutExchange);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    Binding bindingExchangeC(Queue CMessage, FanoutExchange fanoutExchange) &#123;</span><br><span class="line">        return BindingBuilder.bind(CMessage).to(fanoutExchange);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里使用了 A、B、C 三个队列绑定到 Fanout 交换机上面，发送端的 routing_key 写任何字符都会被忽略：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public void send() &#123;</span><br><span class="line">    String context &#x3D; &quot;hi, fanout msg &quot;;</span><br><span class="line">    System.out.println(&quot;Sender : &quot; + context);</span><br><span class="line">    this.rabbitTemplate.convertAndSend(&quot;fanoutExchange&quot;,&quot;&quot;, context);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Sender : hi, fanout msg </span><br><span class="line">...</span><br><span class="line">fanout Receiver B: hi, fanout msg </span><br><span class="line">fanout Receiver A  : hi, fanout msg </span><br><span class="line">fanout Receiver C: hi, fanout msg</span><br></pre></td></tr></table></figure><p>结果说明，绑定到 fanout 交换机上面的队列都收到了消息</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.zouyesheng.com/rabbitmq.html" target="_blank" rel="noopener">RabbitMQ 使用参考</a></p><p><a href="https://github.com/401Studio/WeekLearn/issues/2" target="_blank" rel="noopener">RabbitMQ：Spring 集成 RabbitMQ 与其概念，消息持久化，ACK机制</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;转载&lt;a href=&quot;http://www.ityouknow.com/springboot/2016/11/30/spring-boot-rabbitMQ.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;纯洁的微笑&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;RabbitMQ 即一个消息队列，主要是用来实现应用程序的异步和解耦，同时也能起到消息缓冲，消息分发的作用。消息中间件在互联网公司的使用中越来越多，消息中间件最主要的作用是解耦，中间件最标准的用法是生产者生产消息传送到队列，消费者从队列中拿取消息并处理，生产者不用关心是谁来消费，消费者不用关心谁在生产消息，从而达到解耦的目的。在分布式的系统中，消息队列也会被用在很多其它的方面，比如：分布式事务的支持，RPC 的调用等等。&lt;/p&gt;
&lt;h2 id=&quot;RabbitMQ-介绍&quot;&gt;&lt;a href=&quot;#RabbitMQ-介绍&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ 介绍&quot;&gt;&lt;/a&gt;RabbitMQ 介绍&lt;/h2&gt;&lt;p&gt;RabbitMQ 是实现 AMQP（高级消息队列协议）的消息中间件的一种，最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 RabbitMQ 主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。&lt;/p&gt;
&lt;p&gt;AMQP，即 Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP 的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。&lt;/p&gt;
&lt;p&gt;RabbitMQ 是一个开源的 AMQP 实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等，支持 AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MQ" scheme="http://JavaSsun.github.io/categories/MQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://JavaSsun.github.io/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot面试</title>
    <link href="http://javassun.github.io/2020/02/19/SpringBoot%E9%9D%A2%E8%AF%95/"/>
    <id>http://javassun.github.io/2020/02/19/SpringBoot%E9%9D%A2%E8%AF%95/</id>
    <published>2020-02-19T11:18:33.000Z</published>
    <updated>2020-05-06T06:33:16.949Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>随着 Spring Boot 使用越来越广泛，Spring Boot 已经成为 Java 程序员面试的知识点，比如下面这一段的 Spring Boot 问答：</p><p>问：你觉得 Spring Boot 最大的优势是什么呢？</p><p>答：Spring Boot 的最大的优势是“约定优于配置“。“约定优于配置“是一种软件设计范式，开发人员按照约定的方式来进行编程，可以减少软件开发人员需做决定的数量，获得简单的好处，而又不失灵活性。</p><p>问：Spring Boot 中 “约定优于配置“的具体产品体现在哪里。</p><p>答：Spring Boot Starter、Spring Boot Jpa 都是“约定优于配置“的一种体现。都是通过“约定优于配置“的设计思路来设计的，Spring Boot Starter 在启动的过程中会根据约定的信息对资源进行初始化；Spring Boot Jpa 通过约定的方式来自动生成 Sql ，避免大量无效代码编写。具体详细可以参考：Spring Boot 为什么这么火？</p><p>问：Spring Boot Starter 的工作原理是什么？</p><p>答：Spring Boot 在启动的时候会干这几件事情：</p><ul><li><p>① Spring Boot 在启动时会去依赖的 Starter 包中寻找 resources/META-INF/spring.factories 文件，然后根据文件中配置的 Jar 包去扫描项目所依赖的 Jar 包。</p></li><li><p>② 根据 spring.factories 配置加载 AutoConfigure 类</p></li><li><p>③ 根据 @Conditional 注解的条件，进行自动配置并将 Bean 注入 Spring Context</p></li></ul><p>总结一下，其实就是 Spring Boot 在启动的时候，按照约定去读取 Spring Boot Starter 的配置信息，再根据配置信息对资源进行初始化，并注入到 Spring 容器中。这样 Spring Boot 启动完毕后，就已经准备好了一切资源，使用过程中直接注入对应 Bean 资源即可。</p><a id="more"></a><h2 id="1、Spring-Boot-的自动配置是如何实现的？"><a href="#1、Spring-Boot-的自动配置是如何实现的？" class="headerlink" title="1、Spring Boot 的自动配置是如何实现的？"></a>1、Spring Boot 的自动配置是如何实现的？</h2><p>Spring Boot 项目的启动注解是：@SpringBootApplication，其实它就是由下面三个注解组成的：</p><ul><li><p>@Configuration</p></li><li><p>@ComponentScan</p></li><li><p>@EnableAutoConfiguration</p></li></ul><p>其中 @EnableAutoConfiguration 是实现自动配置的入口，该注解又通过 @Import 注解导入了AutoConfigurationImportSelector，在该类中加载 META-INF/spring.factories 的配置信息。然后筛选出以 EnableAutoConfiguration 为 key 的数据，加载到 IOC 容器中，实现自动配置功能！</p><h2 id="2、什么是嵌入式服务器？我们为什么要使用嵌入式服务器呢"><a href="#2、什么是嵌入式服务器？我们为什么要使用嵌入式服务器呢" class="headerlink" title="2、什么是嵌入式服务器？我们为什么要使用嵌入式服务器呢?"></a>2、什么是嵌入式服务器？我们为什么要使用嵌入式服务器呢?</h2><p>思考一下在你的虚拟机上部署应用程序需要些什么。</p><p>第一步：安装 Java</p><p>第二部：安装 Web 或者是应用程序的服务器（Tomat/Wbesphere/Weblogic 等等）</p><p>第三部：部署应用程序 war 包</p><p>如果我们想简化这些步骤，应该如何做呢？</p><p>让我们来思考如何使服务器成为应用程序的一部分？</p><p>你只需要一个安装了 Java 的虚拟机，就可以直接在上面部署应用程序了，</p><p>是不是很爽？</p><p>这个想法是嵌入式服务器的起源。</p><p>当我们创建一个可以部署的应用程序的时候，我们将会把服务器（例如，tomcat）嵌入到可部署的服务器中。</p><p>例如，对于一个 Spring Boot 应用程序来说，你可以生成一个包含 Embedded Tomcat 的应用程序 jar。你就可以像运行正常 Java 应用程序一样来运行 web 应用程序了。</p><p>嵌入式服务器就是我们的可执行单元包含服务器的二进制文件（例如，tomcat.jar）。</p><h2 id="3、微服务同时调用多个接口，怎么支持事务的啊？"><a href="#3、微服务同时调用多个接口，怎么支持事务的啊？" class="headerlink" title="3、微服务同时调用多个接口，怎么支持事务的啊？"></a>3、微服务同时调用多个接口，怎么支持事务的啊？</h2><p>支持分布式事务，可以使用Spring Boot集成 Aatomikos来解决，但是我一般不建议这样使用，因为使用分布式事务会增加请求的响应时间，影响系统的TPS。一般在实际工作中，会利用消息的补偿机制来处理分布式的事务。</p><h2 id="4、shiro和oauth还有cas他们之间的关系是什么？问下您公司权限是如何设计，还有就是这几个概念的区别。"><a href="#4、shiro和oauth还有cas他们之间的关系是什么？问下您公司权限是如何设计，还有就是这几个概念的区别。" class="headerlink" title="4、shiro和oauth还有cas他们之间的关系是什么？问下您公司权限是如何设计，还有就是这几个概念的区别。"></a>4、shiro和oauth还有cas他们之间的关系是什么？问下您公司权限是如何设计，还有就是这几个概念的区别。</h2><p>cas和oauth是一个解决单点登录的组件，shiro主要是负责权限安全方面的工作，所以功能点不一致。但往往需要单点登陆和权限控制一起来使用，所以就有 cas+shiro或者oauth+shiro这样的组合。</p><p>token一般是客户端登录后服务端生成的令牌，每次访问服务端会进行校验，一般保存到内存即可，也可以放到其他介质；redis可以做Session共享，如果前端web服务器有几台负载，但是需要保持用户登录的状态，这场景使用比较常见。</p><p>我们公司使用oauth+shiro这样的方式来做后台权限的管理，oauth负责多后台统一登录认证，shiro负责给登录用户赋予不同的访问权限。</p><h2 id="5、各服务之间通信，对Restful和Rpc这2种方式如何做选择？"><a href="#5、各服务之间通信，对Restful和Rpc这2种方式如何做选择？" class="headerlink" title="5、各服务之间通信，对Restful和Rpc这2种方式如何做选择？"></a>5、各服务之间通信，对Restful和Rpc这2种方式如何做选择？</h2><p>在传统的SOA治理中，使用rpc的居多；Spring Cloud默认使用restful进行服务之间的通讯。rpc通讯效率会比restful要高一些，但是对于大多数公司来讲，这点效率影响甚微。我建议使用restful这种方式，易于在不同语言实现的服务之间通讯。</p><h2 id="6、怎么设计无状态服务？"><a href="#6、怎么设计无状态服务？" class="headerlink" title="6、怎么设计无状态服务？"></a>6、怎么设计无状态服务？</h2><p>对于无状态服务，首先说一下什么是状态：如果一个数据需要被多个服务共享，才能完成一笔交易，那么这个数据被称为状态。进而依赖这个“状态”数据的服务被称为有状态服务，反之称为无状态服务。</p><p>那么这个无状态服务原则并不是说在微服务架构里就不允许存在状态，表达的真实意思是要把有状态的业务服务改变为无状态的计算类服务，那么状态数据也就相应的迁移到对应的“有状态数据服务”中。</p><p>场景说明：例如我们以前在本地内存中建立的数据缓存、Session缓存，到现在的微服务架构中就应该把这些数据迁移到分布式缓存中存储，让业务服务变成一个无状态的计算节点。迁移后，就可以做到按需动态伸缩，微服务应用在运行时动态增删节点，就不再需要考虑缓存数据如何同步的问题。</p><h2 id="7、Spring-Cache-三种常用的缓存注解和意义？"><a href="#7、Spring-Cache-三种常用的缓存注解和意义？" class="headerlink" title="7、Spring Cache 三种常用的缓存注解和意义？"></a>7、Spring Cache 三种常用的缓存注解和意义？</h2><p>@Cacheable ，用来声明方法是可缓存，将结果存储到缓存中以便后续使用相同参数调用时不需执行实际的方法，直接从缓存中取值。</p><p>@CachePut，使用 @CachePut 标注的方法在执行前，不会去检查缓存中是否存在之前执行过的结果，而是每次都会执行该方法，并将执行结果以键值对的形式存入指定的缓存中。</p><p>@CacheEvict，是用来标注在需要清除缓存元素的方法或类上的，当标记在一个类上时表示其中所有的方法的执行都会触发缓存的清除操作。</p><h2 id="8、Spring-Boot-如何设置支持跨域请求？"><a href="#8、Spring-Boot-如何设置支持跨域请求？" class="headerlink" title="8、Spring Boot 如何设置支持跨域请求？"></a>8、Spring Boot 如何设置支持跨域请求？</h2><p>现代浏览器出于安全的考虑， HTTP 请求时必须遵守同源策略，否则就是跨域的 HTTP 请求，默认情况下是被禁止的，IP（域名）不同、或者端口不同、协议不同（比如 HTTP、HTTPS）都会造成跨域问题。</p><p>一般前端的解决方案有：</p><ul><li><p>① 使用 JSONP 来支持跨域的请求，JSONP 实现跨域请求的原理简单的说，就是动态创建<code>&lt;script&gt;</code>标签，然后利用<code>&lt;script&gt;</code>的 SRC 不受同源策略约束来跨域获取数据。缺点是需要后端配合输出特定的返回信息。</p></li><li><p>② 利用反应代理的机制来解决跨域的问题，前端请求的时候先将请求发送到同源地址的后端，通过后端请求转发来避免跨域的访问。</p></li></ul><p>后来 HTML5 支持了 CORS 协议。CORS 是一个 W3C 标准，全称是”跨域资源共享”（Cross-origin resource sharing），允许浏览器向跨源服务器，发出 XMLHttpRequest 请求，从而克服了 AJAX 只能同源使用的限制。它通过服务器增加一个特殊的 Header[Access-Control-Allow-Origin]来告诉客户端跨域的限制，如果浏览器支持 CORS、并且判断 Origin 通过的话，就会允许 XMLHttpRequest 发起跨域请求。</p><p>前端使用了 CORS 协议，就需要后端设置支持非同源的请求，Spring Boot 设置支持非同源的请求有两种方式。</p><p>第一，配置 CorsFilter。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">@Configuration</span><br><span class="line">public class GlobalCorsConfig &#123;</span><br><span class="line">    @Bean</span><br><span class="line">    public CorsFilter corsFilter() &#123;</span><br><span class="line">        CorsConfiguration config &#x3D; new CorsConfiguration();</span><br><span class="line">          config.addAllowedOrigin(&quot;*&quot;);</span><br><span class="line">          config.setAllowCredentials(true);</span><br><span class="line">          config.addAllowedMethod(&quot;*&quot;);</span><br><span class="line">          config.addAllowedHeader(&quot;*&quot;);</span><br><span class="line">          config.addExposedHeader(&quot;*&quot;);</span><br><span class="line"></span><br><span class="line">        UrlBasedCorsConfigurationSource configSource &#x3D; new UrlBasedCorsConfigurationSource();</span><br><span class="line">        configSource.registerCorsConfiguration(&quot;&#x2F;**&quot;, config);</span><br><span class="line"></span><br><span class="line">        return new CorsFilter(configSource);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>需要配置上述的一段代码。第二种方式稍微简单一些。</p><p>第二，在启动类上添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public class Application extends WebMvcConfigurerAdapter &#123;  </span><br><span class="line"></span><br><span class="line">    @Override  </span><br><span class="line">    public void addCorsMappings(CorsRegistry registry) &#123;  </span><br><span class="line"></span><br><span class="line">        registry.addMapping(&quot;&#x2F;**&quot;)  </span><br><span class="line">                .allowCredentials(true)  </span><br><span class="line">                .allowedHeaders(&quot;*&quot;)  </span><br><span class="line">                .allowedOrigins(&quot;*&quot;)  </span><br><span class="line">                .allowedMethods(&quot;*&quot;);  </span><br><span class="line"></span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="9、JPA-和-Hibernate-有哪些区别？JPA-可以支持动态-SQL-吗？"><a href="#9、JPA-和-Hibernate-有哪些区别？JPA-可以支持动态-SQL-吗？" class="headerlink" title="9、JPA 和 Hibernate 有哪些区别？JPA 可以支持动态 SQL 吗？"></a>9、JPA 和 Hibernate 有哪些区别？JPA 可以支持动态 SQL 吗？</h2><p>JPA本身是一种规范，它的本质是一种ORM规范（不是ORM框架，因为JPA并未提供ORM实现，只是制定了规范）因为JPA是一种规范，所以，只是提供了一些相关的接口，但是接口并不能直接使用，JPA底层需要某种JPA实现，Hibernate 是 JPA 的一个实现集。</p><p>JPA 是根据实体类的注解来创建对应的表和字段，如果需要动态创建表或者字段，需要动态构建对应的实体类，再重新调用Jpa刷新整个Entity。动态SQL，mybatis支持的最好，jpa也可以支持，但是没有Mybatis那么灵活。</p><h2 id="10、Spring-、Spring-Boot-和-Spring-Cloud-的关系"><a href="#10、Spring-、Spring-Boot-和-Spring-Cloud-的关系" class="headerlink" title="10、Spring 、Spring Boot 和 Spring Cloud 的关系?"></a>10、Spring 、Spring Boot 和 Spring Cloud 的关系?</h2><p>Spring 最初最核心的两大核心功能 Spring Ioc 和 Spring Aop 成就了 Spring，Spring 在这两大核心的功能上不断的发展，才有了 Spring 事务、Spring Mvc 等一系列伟大的产品，最终成就了 Spring 帝国，到了后期 Spring 几乎可以解决企业开发中的所有问题。</p><p>Spring Boot 是在强大的 Spring 帝国生态基础上面发展而来，发明 Spring Boot 不是为了取代 Spring ,是为了让人们更容易的使用 Spring 。</p><p>Spring Cloud 是一系列框架的有序集合。它利用 Spring Boot 的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用 Spring Boot 的开发风格做到一键启动和部署。</p><p>Spring Cloud 是为了解决微服务架构中服务治理而提供的一系列功能的开发框架，并且 Spring Cloud 是完全基于 Spring Boot 而开发，Spring Cloud 利用 Spring Boot 特性整合了开源行业中优秀的组件，整体对外提供了一套在微服务架构中服务治理的解决方案。</p><p>用一组不太合理的包含关系来表达它们之间的关系。</p><p>Spring ioc/aop &gt; Spring &gt; Spring Boot &gt; Spring Cloud</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;随着 Spring Boot 使用越来越广泛，Spring Boot 已经成为 Java 程序员面试的知识点，比如下面这一段的 Spring Boot 问答：&lt;/p&gt;
&lt;p&gt;问：你觉得 Spring Boot 最大的优势是什么呢？&lt;/p&gt;
&lt;p&gt;答：Spring Boot 的最大的优势是“约定优于配置“。“约定优于配置“是一种软件设计范式，开发人员按照约定的方式来进行编程，可以减少软件开发人员需做决定的数量，获得简单的好处，而又不失灵活性。&lt;/p&gt;
&lt;p&gt;问：Spring Boot 中 “约定优于配置“的具体产品体现在哪里。&lt;/p&gt;
&lt;p&gt;答：Spring Boot Starter、Spring Boot Jpa 都是“约定优于配置“的一种体现。都是通过“约定优于配置“的设计思路来设计的，Spring Boot Starter 在启动的过程中会根据约定的信息对资源进行初始化；Spring Boot Jpa 通过约定的方式来自动生成 Sql ，避免大量无效代码编写。具体详细可以参考：Spring Boot 为什么这么火？&lt;/p&gt;
&lt;p&gt;问：Spring Boot Starter 的工作原理是什么？&lt;/p&gt;
&lt;p&gt;答：Spring Boot 在启动的时候会干这几件事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;① Spring Boot 在启动时会去依赖的 Starter 包中寻找 resources/META-INF/spring.factories 文件，然后根据文件中配置的 Jar 包去扫描项目所依赖的 Jar 包。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;② 根据 spring.factories 配置加载 AutoConfigure 类&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;③ 根据 @Conditional 注解的条件，进行自动配置并将 Bean 注入 Spring Context&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总结一下，其实就是 Spring Boot 在启动的时候，按照约定去读取 Spring Boot Starter 的配置信息，再根据配置信息对资源进行初始化，并注入到 Spring 容器中。这样 Spring Boot 启动完毕后，就已经准备好了一切资源，使用过程中直接注入对应 Bean 资源即可。&lt;/p&gt;
    
    </summary>
    
    
      <category term="SpringBoot" scheme="http://JavaSsun.github.io/categories/SpringBoot/"/>
    
    
      <category term="面试" scheme="http://JavaSsun.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>ELK日志平台-中</title>
    <link href="http://javassun.github.io/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/"/>
    <id>http://javassun.github.io/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/</id>
    <published>2020-02-11T06:25:35.000Z</published>
    <updated>2020-05-17T04:06:28.931Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于初期系统日志量还在可控范围，选择 ELK+Beats 的方案，并未引入消息队列，后续根据需求可以对系统升级。由此，只需要在日志平台部署 Elasticsearch 和 Logstash 集群，同时在应用服务器部署 Filebeat即可。</p><p><strong>ELK版本务必保持一致，否则可能会出现 Kibana server is not ready yet的情况。</strong><br><font color="red"><strong>警告：</strong><br><strong>ELK 版本 7.4.X 以上需要 Java11 版本</strong><br><strong>ELK 版本 6.6.0 可以使用 Java8 版本</strong><br><strong>因此我们使用 6.6.0 版本</strong><br></font></p><a id="more"></a><h2 id="1-安装前准备"><a href="#1-安装前准备" class="headerlink" title="1 安装前准备"></a>1 安装前准备</h2><h3 id="JAVA环境"><a href="#JAVA环境" class="headerlink" title="JAVA环境"></a>JAVA环境</h3><p>ELK 需要 JAVA 8 以上的运行环境，若未安装则按如下步骤安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 查看是否安装</span><br><span class="line">rpm -qa | grep java</span><br><span class="line"># 批量卸载</span><br><span class="line">rpm -qa | grep java | xargs rpm -e --nodeps</span><br><span class="line">yum install -y java-1.8.0-openjdk*</span><br><span class="line">java -version</span><br><span class="line">openjdk version &quot;1.8.0_151&quot;</span><br></pre></td></tr></table></figure><p>在文件<code>/etc/profile</code>配置环境变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 指向安装目录，其中1.8.0.151需与版本号保持一致</span><br><span class="line">JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0-openjdk-1.8.0.151-1.b12.el6_9.x86_64</span><br><span class="line">PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH</span><br><span class="line">CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar</span><br><span class="line">JAVACMD&#x3D;&#x2F;usr&#x2F;bin&#x2F;java</span><br><span class="line">export JAVA_HOME JAVACMD CLASSPATH PATH</span><br></pre></td></tr></table></figure><p>执行<code>source /etc/profile</code>命令，使配置环境生效</p><h3 id="安装GPG-KEY"><a href="#安装GPG-KEY" class="headerlink" title="安装GPG-KEY"></a>安装GPG-KEY</h3><p>由于后续采用 yum 安装，所以需要下载并安装 GPG-KEY：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm --import https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;GPG-KEY-elasticsearch</span><br></pre></td></tr></table></figure><blockquote><p>yum 命令会安装最新的版本，若需安装较旧的版本，请先从 <a href="https://www.elastic.co/downloads/past-releases" target="_blank" rel="noopener">官方地址</a> 下载对应的旧版本 rpm 包，然后使用<code>rpm -ivh</code>命令安装。</p></blockquote><h2 id="2-Elasticsearch"><a href="#2-Elasticsearch" class="headerlink" title="2 Elasticsearch"></a>2 Elasticsearch</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><ul><li><p>1 如果网速过慢，可以选择笔记附件下载。</p></li><li><p>2 通过 <a href="https://www.elastic.co/downloads/past-releases" target="_blank" rel="noopener">官方地址</a> 下载选择最新版本，然后解压：</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;elasticsearch&#x2F;elasticsearch-6.6.0.tar.gz</span><br><span class="line"></span><br><span class="line">mkdir -p &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">tar -zxvf elasticsearch-6.6.0.tar.gz -C &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">mv &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch-6.6.0 &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch</span><br><span class="line"></span><br><span class="line">cd elasticsearch</span><br><span class="line">mkdir data &#x2F;&#x2F;存数据文件用</span><br><span class="line">mkdir logs &#x2F;&#x2F;存日志文件用 如果有就不用再次创建</span><br></pre></td></tr></table></figure><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/79c3dd35-de46-4154-8137-936d6c2d3f27.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">目录结构介绍：</span><br><span class="line">bin：可执行文件，运行es的命令</span><br><span class="line">config：配置文件目录</span><br><span class="line"> config&#x2F;elasticsearch.yml：ES启动基础配置</span><br><span class="line"> config&#x2F;jvm.options：ES启动时JVM配置</span><br><span class="line"> config&#x2F;log4j2.properties：ES日志输出配置文件</span><br><span class="line">lib：依赖的jar</span><br><span class="line">logs：日志文件夹</span><br><span class="line">modules：es模块</span><br><span class="line">plugins：可以自己开发的插件</span><br><span class="line">data：我们自己创建的，存放es存储文件</span><br></pre></td></tr></table></figure><p>由于 Elasticsearch 新版本不允许以 <strong>root</strong> 身份启动，因此先创建 elk 用户。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">直接以root用户启动 会报错</span><br><span class="line">bin&#x2F;elasticsearch</span><br></pre></td></tr></table></figure><p>所以需要创建用户并赋予es安装目录权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">创建一个esroot用户并设置初始密码</span><br><span class="line">useradd -c &quot;ES user&quot; -d &#x2F;home&#x2F;esroot esroot</span><br><span class="line">passwd esroot</span><br><span class="line"></span><br><span class="line">将es安装目录属主权威改为esroot用户</span><br><span class="line">chown -R esroot &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch</span><br><span class="line"></span><br><span class="line">切换用户到esroot</span><br><span class="line">su esroot</span><br><span class="line"></span><br><span class="line">.&#x2F;elasticsearch -d 重启即可</span><br></pre></td></tr></table></figure><p><strong>可能出现的错误：</strong></p><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/2a7d0653-0f1e-4125-9507-b91ad467c647.png" alt></p><ul><li>1 jvm 的 Xms / Xmx 设置不一致，将其设置一致即可</li></ul><p>启动前，需要修改配置文件<code>jvm.options</code>中 JVM 大小，否则可能会内存溢出，导致启动失败。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd elasticsearch</span><br><span class="line">vim config&#x2F;jvm.options</span><br><span class="line"># 根据实际情况修改</span><br><span class="line">-Xms128m</span><br><span class="line">-Xmx128m</span><br></pre></td></tr></table></figure><ul><li><p>2 要设置系统参数vm.max_map_count=262144<br>原话为：<br><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2Fcurrent%2Fdocker.html%23docker-cli-run-prod-mode" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#docker-cli-run-prod-mode</a><br>The vm.max_map_count kernel setting needs to be set to at least 262144 for production use. Depending on your platform:</p></li><li><p>Linux<br> The vm.max_map_count setting should be set permanently in /etc/sysctl.conf:<br> To apply the setting on a live system type: sysctl -w vm.max_map_count=262144</p></li></ul><blockquote><p>$ grep vm.max_map_count /etc/sysctl.conf</p></blockquote><blockquote><p> vm.max_map_count=262144</p></blockquote><p><strong>解决办法：</strong><br>切换为root用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查看vm.max_map_count属性值，</span><br><span class="line"></span><br><span class="line">如果没有添加则在&#x2F;etc&#x2F;sysctl.conf文件添加vm.max_map_count &#x3D; 262144</span><br><span class="line">grep vm.max_map_count &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line"></span><br><span class="line">或者执行添加临时变量</span><br><span class="line">sysctl -w vm.max_map_count&#x3D;262144</span><br></pre></td></tr></table></figure><h2 id="简要配置"><a href="#简要配置" class="headerlink" title="简要配置"></a>简要配置</h2><p><strong>1-5为elasticsearch.yml配置，6为jvm.options配置</strong></p><ul><li><p>1 配置集群名称（默认备注是，并且默认只有一个集群名）<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/3147066a-cd7c-4896-b9a2-f2741bae7da3.png" alt></p></li><li><p>2 配置当前es节点名称（默认是被注释的，并且默认有一个节点名）<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/12abb2c6-24a1-4d71-861e-68f23ed81be7.png" alt></p></li><li><p>3 配置存储数据的目录路径（用逗号分隔多个位置）和日志文件路径<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/30f50069-f103-4501-8a96-9703411b1b3e.png" alt></p></li><li><p>4 绑定地址为特定IP地址（设置0.0.0.0可以让任何人访问到你的es），设置一个http请求端口<br>添加一行为 http.host: 0.0.0.0 即可。<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/6a74c5c3-69c9-417f-98b6-0ee9704a3cdb.png" alt></p></li><li><p>5 集群启动，参看同目录其他文章。</p></li><li><p>6 配置ES启动JVM参数<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/5bafb14b-cca0-42a9-babc-20803c96c263.png" alt></p></li></ul><p>CentOS7 设置开机启动服务，启动 Elasticsearch，其默认监听 9200 端口。\</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi &#x2F;etc&#x2F;security&#x2F;limits.conf</span><br><span class="line">添加如下内容：</span><br><span class="line">* soft nofile 65536 </span><br><span class="line">* hard nofile 131072 </span><br><span class="line">* soft nproc 2048 </span><br><span class="line">* hard nproc 4096</span><br></pre></td></tr></table></figure><p>在/etc/systemd/system目录下创建elasticsearch.service文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description&#x3D;elasticsearch</span><br><span class="line">[Service]</span><br><span class="line">User&#x3D;esroot</span><br><span class="line">LimitNOFILE&#x3D;100000</span><br><span class="line">LimitNPROC&#x3D;100000</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch&#x2F;bin&#x2F;elasticsearch</span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>设置开机自启</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable elasticsearch</span><br></pre></td></tr></table></figure><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/2c40d70f-16d8-4194-b9ed-368bb40aff2b.png" alt></p><p>最后，安装使用到的插件 可能需要用到 <strong>Java11版本</strong>，看情况安装下述插件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch</span><br><span class="line"># ingest-geoip和ingest-user-agent分别为ip解析插件和agent解析插件</span><br><span class="line">bin&#x2F;elasticsearch-plugin install ingest-geoip</span><br><span class="line">bin&#x2F;elasticsearch-plugin install ingest-user-agent</span><br><span class="line"># 用户管理和monitor管理</span><br><span class="line">bin&#x2F;elasticsearch-plugin install x-pack</span><br></pre></td></tr></table></figure><blockquote><p>安装 x-pack 插件后，对 Elasticsearch 的操作都需要授权，默认用户名为 elastic，默认密码为 changeme。</p></blockquote><p>启动成功图：-d 以后台方式启动<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/7fb9cc65-9e32-4d2f-b36b-e79ff144381a.png" alt></p><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/36b45622-af07-4e53-ad1a-ffb4c6d2fcdc.png" alt></p><h3 id="问题及解决办法"><a href="#问题及解决办法" class="headerlink" title="问题及解决办法"></a>问题及解决办法</h3><h4 id="1-权限问题"><a href="#1-权限问题" class="headerlink" title="1 权限问题"></a>1 权限问题</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Java HotSpot(TM) 64-Bit Server VM warning: Cannot open file logs&#x2F;gc.log due to Permission denied</span><br><span class="line"></span><br><span class="line">[esroot@haoransun elasticsearch]$ Exception in thread &quot;main&quot; org.elasticsearch.bootstrap.BootstrapException: java.nio.file.AccessDeniedException: &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch&#x2F;config&#x2F;elasticsearch.keystore</span><br></pre></td></tr></table></figure><p>解决方法：<br>因为第一次启动不小心用了root启动，导致用root生成了对应的文件。切换es账号之后，没有对应文件的权限导致，删除相关的东西即可。<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/05421b4d-63cb-4019-88e2-3d5b25fe1b01.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf elasticsearch.keystore gc.log.0.current</span><br></pre></td></tr></table></figure><h4 id="2-max-number-of-threads-1024"><a href="#2-max-number-of-threads-1024" class="headerlink" title="2 #### max number of threads [1024]"></a>2 #### max number of threads [1024]</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RROR: [2] bootstrap checks failed</span><br><span class="line">[1]: max number of threads [1024] for user [es] is too low, increase to at least [4096]</span><br><span class="line">[2]: system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk</span><br></pre></td></tr></table></figure><p>解决:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ulimit -a</span><br><span class="line"></span><br><span class="line">max user processes              (-u) 1024</span><br><span class="line">virtual memory          (kbytes, -v) unlimited</span><br><span class="line">file locks                      (-x) unlimited</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vi &#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;90-nproc.conf </span><br><span class="line"></span><br><span class="line"># Default limit for number of user&#39;s processes to prevent</span><br><span class="line"># accidental fork bombs.</span><br><span class="line"># See rhbz #432903 for reasoning.</span><br><span class="line"></span><br><span class="line">* hard nproc 4096</span><br><span class="line">* soft nproc 4096</span><br><span class="line">*          soft    nproc     4096</span><br><span class="line">root       soft    nproc     unlimited</span><br></pre></td></tr></table></figure><h4 id="3-system-call-filters-failed-to-install-check-the-logs-and-fix-your-configuration-or-disable-system-call-filters-at-your-own-risk"><a href="#3-system-call-filters-failed-to-install-check-the-logs-and-fix-your-configuration-or-disable-system-call-filters-at-your-own-risk" class="headerlink" title="3 system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk"></a>3 system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk</h4><p>这是在因为Centos6不支持SecComp，而ES5.2.0默认bootstrap.system_call_filter为true进行检测，所以导致检测失败，失败后直接导致ES不能启动。</p><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在elasticsearch.yml中配置bootstrap.system_call_filter为false，注意要在Memory下面:</span><br><span class="line">bootstrap.memory_lock: false</span><br><span class="line">bootstrap.system_call_filter: false</span><br></pre></td></tr></table></figure><h4 id="4-日志级别报错"><a href="#4-日志级别报错" class="headerlink" title="4 日志级别报错"></a>4 日志级别报错</h4><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/761060a0-6483-4264-b1ec-b739a115edfb.png" alt></p><p>需要修改config配置里的log4j2.properties 文件, 将 logger.deprecation.level = warn 改为 error即可。</p><h4 id="5-main-ERROR-Unable-to-invoke-factory-method-in-class-org-apache-logging-log4j-core"><a href="#5-main-ERROR-Unable-to-invoke-factory-method-in-class-org-apache-logging-log4j-core" class="headerlink" title="5 # main ERROR Unable to invoke factory method in class org.apache.logging.log4j.core"></a>5 # main ERROR Unable to invoke factory method in class org.apache.logging.log4j.core</h4><p>原因：在安装elasticsearch时，新建的logs目录是用root用户建的，因此，logs下的文件是root用户权限，因此，将该权限改为非root用户即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown -R esroot logs&#x2F;</span><br><span class="line">chgrp -R esroot logs&#x2F;</span><br></pre></td></tr></table></figure><p>再次启动，不会报错。</p><h2 id="3-Kibana"><a href="#3-Kibana" class="headerlink" title="3 Kibana"></a>3 Kibana</h2><h3 id="下载kibana安装包"><a href="#下载kibana安装包" class="headerlink" title="下载kibana安装包"></a>下载kibana安装包</h3><p>如果网速过慢，可以选择笔记附件下载。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;kibana&#x2F;kibana-6.6.0-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure><h3 id="解压kibana安装包"><a href="#解压kibana安装包" class="headerlink" title="解压kibana安装包"></a>解压kibana安装包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">tar -zxvf kibana-6.6.0-linux-x86_64.tar.gz  -C &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">mv &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;kibana-6.6.0-linux-x86_64 &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;kibana</span><br></pre></td></tr></table></figure><h3 id="修改kibana配置，config目录下的kibana-yml"><a href="#修改kibana配置，config目录下的kibana-yml" class="headerlink" title="修改kibana配置，config目录下的kibana.yml"></a>修改kibana配置，config目录下的kibana.yml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;kibana&#x2F;config&#x2F;kibana.yml</span><br><span class="line"></span><br><span class="line"># 修改内容</span><br><span class="line">server.port: 5601</span><br><span class="line"></span><br><span class="line">server.host: &quot;内网地址或者是0.0.0.0&quot;</span><br><span class="line"></span><br><span class="line">elasticsearch.url: &quot;http:&#x2F;&#x2F;ElasticSearch所在ip地址:9200&quot;</span><br></pre></td></tr></table></figure><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/daa6f970-9bf4-4e09-8fb3-3b31b51c8906.png" alt></p><p>安装常用插件，如 x-pack</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kibana-plugin install x-pack</span><br></pre></td></tr></table></figure><blockquote><p>安装 x-pack 插件后，访问 Kibana 同样需要授权，且任何 Elasticsearch 的用户名和密码对都可被认证通过。</p></blockquote><h3 id="启动-kibana"><a href="#启动-kibana" class="headerlink" title="启动 kibana"></a>启动 kibana</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd bin </span><br><span class="line">nohup .&#x2F;kibana &amp;</span><br></pre></td></tr></table></figure><h3 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h3><ul><li><strong>1 网络不可访问</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;“type”:“error”,&quot;@timestamp&quot;:“2019-04-06T00:25:22Z”,“tags”:[“fatal”,“root”],“pid”:754,“level”:“fatal”,“error”:&#123;“message”:“listen EADDRNOTAVAIL localhost:5601”,“name”:“Error”,“stack”:&quot;Error: listen EADDRNOTAVAIL localhost:5601\n at Server.setupListenHandle [as _listen2] (net.js:1343:19)\n …</span><br></pre></td></tr></table></figure>解决方案：<br>由于server.host: 之前设置的是阿里云服务器的外网ip地址，所以启动kibana一直报错 将server.host改为”内网地址或者是0.0.0.0”即可</li></ul><ul><li><strong>2 Kibana 运行时 NodeJs 默认会最大分配 1G 内存，可以在启动时增加<code>max-old-space-size</code>参数，以限制其运行内存大小</strong></li></ul><p><strong>同理：kibana not ready yet</strong></p><p><strong>同理：kibana FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim bin&#x2F;kibana</span><br><span class="line"></span><br><span class="line"># 增加--max-old-space-size&#x3D;140参数</span><br><span class="line">NODE_ENV&#x3D;production exec &quot;$&#123;NODE&#125;&quot; $NODE_OPTIONS --max-old-space-size&#x3D;200 --no-warnings &quot;$&#123;DIR&#125;&#x2F;src&#x2F;cli&quot; $&#123;@&#125;</span><br></pre></td></tr></table></figure><h3 id="防护墙开放5601端口，并测试访问"><a href="#防护墙开放5601端口，并测试访问" class="headerlink" title="防护墙开放5601端口，并测试访问"></a>防护墙开放5601端口，并测试访问</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --zone&#x3D;public --add-port&#x3D;5601&#x2F;tcp --permanent</span><br><span class="line">firewall-cmd --reload</span><br><span class="line">firewall-cmd --list-ports</span><br></pre></td></tr></table></figure><p>访问 <a href="http://192.168.121.100:5601/app/kibana" target="_blank" rel="noopener">http://192.168.121.100:5601/app/kibana</a> 即可<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/8cf66438-c28c-4fc6-bfa5-f6d3480629c8.png" alt></p><hr><h2 id="4-Logstash"><a href="#4-Logstash" class="headerlink" title="4 Logstash"></a>4 Logstash</h2><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a><a href="https://www.elastic.co/guide/en/logstash/current/installing-logstash.html#_yum" target="_blank" rel="noopener">安装</a></h3><ul><li>方法1</li></ul><p>首先，在<code>/etc/yum.repos.d</code>目录下创建<code>logstash.repo</code>文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[logstash-6.x] </span><br><span class="line">name&#x3D;Elastic repository for  6.x packages</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;packages&#x2F;6.x&#x2F;yum</span><br><span class="line">gpgcheck&#x3D;1 </span><br><span class="line">gpgkey&#x3D;https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;GPG-KEY-elasticsearch</span><br><span class="line">enabled&#x3D;1 </span><br><span class="line">autorefresh&#x3D;1 </span><br><span class="line">type&#x3D;rpm-md</span><br></pre></td></tr></table></figure><p>使用 yum 安装 Logstash，并测试：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 安装logstash 6.x</span><br><span class="line">$ yum install -y logstash</span><br><span class="line"># 默认安装路径&#x2F;usr&#x2F;share</span><br><span class="line">$ mkdir -p &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line">$ ln -s &#x2F;usr&#x2F;share&#x2F;logstash &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;logstash</span><br><span class="line">$ cd &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;logstash</span><br><span class="line"># 命令行测试</span><br><span class="line">$ bin&#x2F;logstash -e &#39;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&#39;</span><br><span class="line"></span><br><span class="line">The stdin plugin is now waiting for input:</span><br><span class="line">elk</span><br><span class="line">2017-11-21T22:25:07.264Z fhb elk</span><br></pre></td></tr></table></figure><ul><li>方法2<br>按上述连接安装，如果网速过慢，可以使用笔记附件安装</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">tar -zxvf logstash-6.6.0.tar.gz -C &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">mv logstash-6.6.0 logstash</span><br><span class="line"></span><br><span class="line">cd logstash</span><br></pre></td></tr></table></figure><h3 id="安装插件-可能需要一些时间"><a href="#安装插件-可能需要一些时间" class="headerlink" title="安装插件(可能需要一些时间)"></a>安装插件(可能需要一些时间)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;logstash-plugin install logstash-input-jdbc</span><br><span class="line"></span><br><span class="line">bin&#x2F;logstash-plugin install logstash-output-elasticsearch</span><br><span class="line"></span><br><span class="line">安装 x-pack 插件，基本状态信息的监控:</span><br><span class="line">bin&#x2F;logstash-plugin install x-pack</span><br></pre></td></tr></table></figure><p>修改 JVM 内存大小，防止出现内存溢出异常：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ vim config&#x2F;jvm.options</span><br><span class="line"># 根据实际情况修改</span><br><span class="line">-Xms150m</span><br><span class="line">-Xmx150m</span><br></pre></td></tr></table></figure><h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果没有 logs文件夹，则自己创建</span><br><span class="line">mkdir logs</span><br></pre></td></tr></table></figure><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/402f2720-4ed0-43f6-b4ad-e14b50b65e9c.png" alt></p><h3 id="检验安装是否成功"><a href="#检验安装是否成功" class="headerlink" title="检验安装是否成功"></a>检验安装是否成功</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;logstash -e &#39;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&#39;</span><br></pre></td></tr></table></figure><blockquote><p>-e 即允许从命令行指定配置</p></blockquote><p>启动成功后，输入 hello world，会有如下显示，则安装成功。<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/d7cd18ae-eff8-4a43-87a5-3290bd35259b.png" alt></p><h2 id="5-Filebeat"><a href="#5-Filebeat" class="headerlink" title="5 Filebeat"></a>5 Filebeat</h2><h3 id="安装-2"><a href="#安装-2" class="headerlink" title="[安装]"></a>[安装]</h3><ul><li><p>1 网速较慢，使用笔记附件安装</p></li><li><p>2 使用 wget 下载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget  https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;beats&#x2F;filebeat&#x2F;filebeat-6.6.0-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure></li></ul><h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">tar -zxvf filebeat-6.6.0-linux-x86_64.tar.gz -C &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">mv filebeat-6.6.0-linux-x86_64 filebeat</span><br><span class="line"></span><br><span class="line">cd filebeat</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;由于初期系统日志量还在可控范围，选择 ELK+Beats 的方案，并未引入消息队列，后续根据需求可以对系统升级。由此，只需要在日志平台部署 Elasticsearch 和 Logstash 集群，同时在应用服务器部署 Filebeat即可。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ELK版本务必保持一致，否则可能会出现 Kibana server is not ready yet的情况。&lt;/strong&gt;&lt;br&gt;&lt;font color=&quot;red&quot;&gt;&lt;strong&gt;警告：&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;ELK 版本 7.4.X 以上需要 Java11 版本&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;ELK 版本 6.6.0 可以使用 Java8 版本&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;因此我们使用 6.6.0 版本&lt;/strong&gt;&lt;br&gt;&lt;/font&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="ELK" scheme="http://JavaSsun.github.io/categories/ELK/"/>
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/categories/ELK/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
      <category term="日志" scheme="http://JavaSsun.github.io/categories/ELK/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
      <category term="日志" scheme="http://JavaSsun.github.io/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="ELK" scheme="http://JavaSsun.github.io/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>ELK日志平台-上</title>
    <link href="http://javassun.github.io/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/"/>
    <id>http://javassun.github.io/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/</id>
    <published>2020-02-10T02:30:57.000Z</published>
    <updated>2020-05-17T04:06:55.974Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在过往的单体应用时代，我们所有组件都部署到一台服务器中，那时日志管理平台的需求可能并没有那么强烈，我们只需要登录到一台服务器通过shell命令就可以很方便的查看系统日志，并快速定位问题。随着互联网的发展，互联网已经全面渗入到生活的各个领域，使用互联网的用户量也越来越多，单体应用已不能够支持庞大的用户的并发量，那么将单体应用进行拆分，通过水平扩展来支持庞大用户的使用迫在眉睫，微服务概念就是在类似这样的阶段诞生，在微服务盛行的互联网技术时代，单个应用被拆分为多个应用，每个应用集群部署进行负载均衡，那么如果某项业务发生系统错误，开发或运维人员还是以过往单体应用方式登录一台一台登录服务器查看日志来定位问题，这种解决线上问题的效率可想而知。日志管理平台的建设就显得极其重要。通过Logstash去收集每台服务器日志文件，然后按定义的正则模板过滤后传输到Kafka或redis，然后由另一个Logstash从KafKa或redis读取日志存储到elasticsearch中创建索引，最后通过Kibana展示给开发者或运维人员进行分析。这样大大提升了运维线上问题的效率。除此之外，还可以将收集的日志进行大数据分析，得到更有价值的数据给到高层进行决策。</p><p><strong>优点</strong></p><ul><li><p>ELK 提供的功能满足使用要求，并有较高的扩展性。</p></li><li><p>ELK 为一套开源项目，较低的维护成本。</p><a id="more"></a><h2 id="1-相关概念"><a href="#1-相关概念" class="headerlink" title="1 相关概念"></a>1 相关概念</h2><p>ELK 指的是一套解决方案，是 <a href="https://www.elastic.co/cn/products/elasticsearch" target="_blank" rel="noopener">Elasticsearch</a>、<a href="https://www.elastic.co/cn/products/logstash" target="_blank" rel="noopener">Logstash</a> 和 <a href="https://www.elastic.co/cn/products/kibana" target="_blank" rel="noopener">Kibana</a> 三种软件产品的首字母缩写，<a href="https://www.elastic.co/cn/products/beats" target="_blank" rel="noopener">Beats</a> 是 ELK 协议栈的新成员。</p></li><li><p>E：代表 Elasticsearch，负责日志的存储和检索；</p></li><li><p>L：代表 Logstash，负责日志的收集、过滤和格式化；</p></li><li><p>K：代表 Kibana，负责日志数据的可视化；</p></li><li><p>Beats：是一类轻量级数据采集器；</p></li></ul><p>其中，目前 Beats 家族根据功能划分，主要包括 4 种：</p><ul><li>Filebeat：负责收集文件数据；</li><li>Packetbeat：负责收集网络流量数据；</li><li>Metricbeat：负责收集系统级的 CPU 使用率、内存、文件系统、磁盘 IO 和网络 IO 统计数据；</li><li>Winlogbeat：负责收集 Windows 事件日志数据;</li></ul><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/a68a642c-bc33-4ba2-bc23-92ea182d89a4.png" alt></p><p>在我们将要搭建的集中式日志平台系统中，就使用了 Filebeat 作为日志文件收集工具，Filebeat 可以很方便地收集 Nginx、Mysql、Redis、Syslog 等应用的日志文件。</p><h2 id="2-日志平台架构"><a href="#2-日志平台架构" class="headerlink" title="2 日志平台架构"></a>2 日志平台架构</h2><p>ELK 集中日志平台也是经过一次次演变，它的大概收集过程如下：</p><p>1 部署在应用服务器上的数据采集器，近实时收集日志数据推送到日志过滤节点的 Logstash</p><p>2 Logstash 再推送格式化的日志数据到 Elasticsearch 存储</p><p>3 Kibana 通过 Elasticsearch 集中检索日志并可视化</p><h3 id="ES-Logstash-Kibana"><a href="#ES-Logstash-Kibana" class="headerlink" title="ES + Logstash + Kibana"></a>ES + Logstash + Kibana</h3><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/5aa407d6-4820-4acb-99da-95058cc265e4.png" alt></p><p>最开始的架构中，由 Logstash 承担数据采集器和过滤功能，并部署在应用服务器。由于 Logstash 对大量日志进行过滤操作，会消耗应用系统的部分性能，带来不合理的资源分配问题；另一方面，过滤日志的配置，分布在每台应用服务器，不便于集中式配置管理。</p><h3 id="引入Logstash-forwarder"><a href="#引入Logstash-forwarder" class="headerlink" title="引入Logstash-forwarder"></a>引入Logstash-forwarder</h3><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/db6ea5c6-7135-4797-8405-cfb8eea22c36.jpg" alt></p><p>使用该架构，引入 Logstash-forwarder 作为数据采集，Logstash 和应用服务器分离，应用服务器只做数据采集，数据过滤统一在日志平台服务器，解决了之前存在的问题。但是 Logstash-forwarder 和 Logstash 间通信必须由 SSL 加密传输，部署麻烦且系统性能并没有显著提升；另一方面，Logstash-forwarder 的定位并不是数据采集插件，系统不易扩展。</p><h3 id="引入Beats"><a href="#引入Beats" class="headerlink" title="引入Beats"></a>引入Beats</h3><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/086379ce-c6f4-433d-82b9-3c108226af58.jpg" alt></p><p>该架构，基于 Logstash-forwarder 架构，将 Logstash-forwarder 替换为 Beats。由于 Beats 的系统性能开销更小，所以应用服务器性能开销可以忽略不计；另一方面，Beats 可以作为数据采集插件形式工作，可以按需启用 Beats 下不同功能的插件，更灵活，扩展性更强。例如，应用服务器只启用 Filebeat，则只收集日志文件数据，如果某天需要收集系统性能数据时，再启用 Metricbeat 即可，并不需要太多的修改和配置。</p><p>这种 ELK+Beats 的架构，已经满足大部分应用场景了，但当业务系统庞大，日志数据量较大、较实时时，业务系统就和日志系统耦合在一起了。</p><h3 id="引入队列"><a href="#引入队列" class="headerlink" title="引入队列"></a>引入队列</h3><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/b7139e8c-0c37-4ba8-b5ff-b16956ee2b36.jpg" alt></p><p>该架构，引入消息队列，均衡了网络传输，从而降低了网络闭塞，尤其是丢失数据的可能性；另一方面，这样可以系统解耦，具有更好的灵活性和扩展性。</p><h2 id="3-经验"><a href="#3-经验" class="headerlink" title="3 经验"></a>3 经验</h2><p>成熟的 ELK+Beats 架构，因其扩展性很强，是集中式日志平台的首选方案。在实际部署时，是否引入消息队列，根据业务系统量来确定，早期也可以不引入消息队列，简单部署，后续需要扩展再接入消息队列。</p><h2 id="4-ELK概念解读"><a href="#4-ELK概念解读" class="headerlink" title="4 ELK概念解读"></a>4 ELK概念解读</h2><h3 id="1-Elasticsearch"><a href="#1-Elasticsearch" class="headerlink" title="1 Elasticsearch"></a>1 Elasticsearch</h3><h4 id="软件介绍"><a href="#软件介绍" class="headerlink" title="软件介绍"></a>软件介绍</h4><p><strong>Elasticsearch</strong>是一个开源的分布式、RESTful 风格的搜索和数据分析引擎，它的底层是开源库Apache Lucene。</p><p>Lucene 可以说是当下最先进、高性能、全功能的搜索引擎库——无论是开源还是私有，但它也仅仅只是一个库。为了充分发挥其功能，你需要使用 Java 并将 Lucene 直接集成到应用程序中。 更糟糕的是，您可能需要获得信息检索学位才能了解其工作原理，因为Lucene 非常复杂。</p><p>为了解决Lucene使用时的繁复性，于是Elasticsearch便应运而生。它使用 Java 编写，内部采用 Lucene 做索引与搜索，但是它的目标是使全文检索变得更简单，简单来说，就是对Lucene 做了一层封装，它提供了一套简单一致的 RESTful API 来帮助我们实现存储和检索。</p><p>当然，Elasticsearch 不仅仅是 Lucene，并且也不仅仅只是一个全文搜索引擎。 它可以被下面这样准确地形容：</p><ul><li>一个分布式的实时文档存储，每个字段可以被索引与搜索；</li><li>一个分布式实时分析搜索引擎；</li><li>能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据。</li></ul><h4 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h4><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/401b561c-02d3-447c-92ff-5f4cedf50f57.jpg" alt></p><h4 id="ES核心概念"><a href="#ES核心概念" class="headerlink" title="ES核心概念"></a>ES核心概念</h4><h5 id="1-节点-amp-集群（Node-amp-Cluster）"><a href="#1-节点-amp-集群（Node-amp-Cluster）" class="headerlink" title="1 节点 &amp; 集群（Node &amp; Cluster）"></a>1 节点 &amp; 集群（Node &amp; Cluster）</h5><p>Elasticsearch 本质上是一个分布式数据库，允许多台服务器协同工作，每台服务器可以运行多个Elasticsearch实例。单个Elasticsearch实例称为一个节点（Node），一组节点构成一个集群（Cluster）。</p><h5 id="2-索引（Index）"><a href="#2-索引（Index）" class="headerlink" title="2 索引（Index）"></a>2 索引（Index）</h5><p>Elasticsearch 数据管理的顶层单位就叫做 Index（索引），相当于关系型数据库里的数据库的概念。另外，每个Index的名字必须是小写。</p><h5 id="3-Shard-分片"><a href="#3-Shard-分片" class="headerlink" title="3 Shard 分片"></a>3 Shard 分片</h5><p>当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端的请求等，一个节点可能不够。这种情况下，数据可以分为较小的分片。每个分片放到不同的服务器上。<br>当你查询的索引分布在多个分片上时，ES会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即：这个过程对用户来说是透明的。</p><h5 id="4-Replia-副本"><a href="#4-Replia-副本" class="headerlink" title="4 Replia 副本"></a>4 Replia 副本</h5><p>为提高查询吞吐量或实现高可用性，可以使用分片副本。<br>副本是一个分片的精确复制，每个分片可以有零个或多个副本。ES中可以有许多相同的分片，其中之一被选择更改索引操作，这种特殊的分片称为主分片。<br>当主分片丢失时，如：该分片所在的数据不可用时，集群将副本提升为新的主分片。</p><h5 id="5-全文搜索-Full-text-Search"><a href="#5-全文搜索-Full-text-Search" class="headerlink" title="5 全文搜索(Full-text Search)"></a>5 全文搜索(Full-text Search)</h5><p>文检索是指计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。</p><p>在全文搜索的世界中，存在着几个庞大的帝国，也就是主流工具，主要有：</p><ul><li>Apache Lucene</li><li>Elasticsearch</li><li>Solr</li><li>Ferret</li></ul><h5 id="6-倒排索引（Inverted-Index）"><a href="#6-倒排索引（Inverted-Index）" class="headerlink" title="6 倒排索引（Inverted Index）"></a>6 倒排索引（Inverted Index）</h5><p>该索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)。Elasticsearch能够实现快速、高效的搜索功能，正是基于倒排索引原理。</p><h5 id="7-文档（Document）"><a href="#7-文档（Document）" class="headerlink" title="7 文档（Document）"></a>7 文档（Document）</h5><p>index里面单条的记录称为 Document（文档）。许多条 Document 构成了一个 Index。Document 使用 JSON 格式表示。同一个 Index 里面的 Document，不要求有相同的结构（scheme），但是最好保持相同，这样有利于提高搜索效率。</p><h5 id="8-类型（Type）"><a href="#8-类型（Type）" class="headerlink" title="8 类型（Type）"></a>8 类型（Type）</h5><p>Document 可以分组，比如employee这个 Index 里面，可以按部门分组，也可以按职级分组。这种分组就叫做 Type，它是虚拟的逻辑分组，用来过滤 Document，类似关系型数据库中的数据表。</p><p>不同的 Type 应该有相似的结构（Schema），性质完全不同的数据（比如 products 和 logs）应该存成两个 Index，而不是一个 Index 里面的两个 Type（虽然可以做到）。</p><h5 id="9-文档元数据（Document-metadata）"><a href="#9-文档元数据（Document-metadata）" class="headerlink" title="9 文档元数据（Document metadata）"></a>9 文档元数据（Document metadata）</h5><p>文档元数据为_index, _type, _id, 这三者可以唯一表示一个文档，_index表示文档在哪存放，_type表示文档的对象类别，_id为文档的唯一标识。</p><h5 id="10-字段（Fields"><a href="#10-字段（Fields" class="headerlink" title="10 字段（Fields)"></a>10 字段（Fields)</h5><p>每个Document都类似一个JSON结构，它包含了许多字段，每个字段都有其对应的值，多个字段组成了一个 Document，可以类比关系型数据库数据表中的字段。</p><p>在 Elasticsearch 中，文档（Document）归属于一种类型（Type），而这些类型存在于索引（Index）中，下图展示了Elasticsearch与传统关系型数据库的类比：</p><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/7e518ba2-3105-4448-b7ba-bed4bbfeaeff.jpg" alt></p><h4 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h4><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/fec9e928-09be-4fd7-b932-eaaf60a4e582.jpg" alt></p><h3 id="2-Kibana"><a href="#2-Kibana" class="headerlink" title="2 Kibana"></a>2 Kibana</h3><h4 id="软件介绍-1"><a href="#软件介绍-1" class="headerlink" title="软件介绍"></a>软件介绍</h4><p>Kibana 是为 Elasticsearch设计的开源分析和可视化平台。你可以使用 Kibana 来搜索，查看存储在 Elasticsearch 索引中的数据并与之交互。你可以很容易实现高级的数据分析和可视化，以图标的形式展现出来，通过改变Elasticsearch查询时间，可以完成动态仪表盘。</p><p><strong>使用场景</strong></p><ul><li><p>实时监控<br>通过 histogram 面板，配合不同条件的多个 queries 可以对一个事件走很多个维度组合出不同的时间序列走势。时间序列数据是最常见的监控报警了。</p></li><li><p>问题分析<br>关于 elk 的用途，可以参照其对应的商业产品 splunk 的场景：使用 Splunk 的意义在于使信息收集和处理智能化。</p></li></ul><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>搜索和展示信息，可以查看Discover页面。</p><p>图表和地图展示，可以查看Visualize。</p><p>创建一个仪表盘，可以使用Dashboard</p><h3 id="3-Logstash"><a href="#3-Logstash" class="headerlink" title="3 Logstash"></a>3 Logstash</h3><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>建议在使用logstash之前先想清楚自己的需求是什么，从哪种数据源同步到哪里，需要经过怎么样的处理。因为logstash版本迭代较快，每个版本的插件都有点区别，比如filter中的http插件在6.6版本以后才有；output到现在(7.1)都没有jdbc的插件，然而你如果想使用output的jdbc插件就需要自己去安装热心人自己写的插件(logstash-output-jdbc),不幸的是，该作者指出没有很多的时间去维护此插件，不能保证6.3以后用户的正常使用。<br> 也就是说，如果你想用output的jdbc，你就必须使用6.3以下(最好5.x)的版本，如果你想用官方filter的http插件，你就得用6.5以上的版本。</p><blockquote><p>如果目标数据源的type为jdbc，则建议安装logstash-5.4.1或6.x一下的版本，因为logstash-output-jdbc只在6.x以下有效.</p></blockquote><h4 id="软件介绍-2"><a href="#软件介绍-2" class="headerlink" title="软件介绍"></a>软件介绍</h4><p>官方介绍：Logstash is an open source data collection engine with real-time pipelining capabilities。</p><p>Logstash是一个开源数据收集引擎，具有实时管道功能。Logstash可以动态地将来自不同数据源的数据统一起来，并将数据标准化到你所选择的目的地。</p><p><strong>Logstash常用于日志关系系统中做日志采集设备</strong></p><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/11b125b4-251c-4690-9d28-9c31bc618431.jpg" alt></p><h4 id="系统架构-1"><a href="#系统架构-1" class="headerlink" title="系统架构"></a>系统架构</h4><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/06abbb73-b15b-41fb-ab83-de441b586182.jpg" alt></p><p>Logstash的事件（logstash将数据流中等每一条数据称之为一个event）处理流水线有三个主要角色完成：inputs –&gt; filters –&gt; outputs：</p><ul><li><p>inpust：必须，负责产生事件（Inputs generate events），常用：File、syslog、redis、beats（如：Filebeats）</p></li><li><p>filters：可选，负责数据处理与转换（filters modify them），常用：grok、mutate、drop、clone、geoip</p></li><li><p>outpus：必须，负责数据输出（outputs ship them elsewhere），常用：elasticsearch、file、graphite、statsd</p></li><li><p>Codecs：Codecs(编码插件)不是一个单独的流程，而是在输入和输出等插件中用于数据转换的模块，用于对数据进行编码处理，常见的插件如json，multiline。Logstash不只是一个input | filter | output 的数据流，而是一个 input | decode | filter | encode | output 的数据流！codec 就是用来 decode、encode 事件的。</p></li></ul><p>其中inputs和outputs支持codecs（coder&amp;decoder）在1.3.0 版之前，logstash 只支持纯文本形式输入，然后以过滤器处理它。但现在，我们可以在输入 期处理不同类型的数据，所以完整的数据流程应该是：input | decode | filter | encode | output；codec 的引入，使得 logstash 可以更好更方便的与其他有自定义数据格式的运维产品共存，比如：graphite、fluent、netflow、collectd，以及使用 msgpack、json、edn 等通用数据格式的其他产品等。</p><h4 id="集中、转换、存储"><a href="#集中、转换、存储" class="headerlink" title="集中、转换、存储"></a>集中、转换、存储</h4><h5 id="输入-：采集各种样式、大小和来源的数据"><a href="#输入-：采集各种样式、大小和来源的数据" class="headerlink" title="输入 ：采集各种样式、大小和来源的数据"></a>输入 ：<strong>采集各种样式、大小和来源的数据</strong></h5><p>数据往往以各种各样的形式，或分散或集中地存在于很多系统中。Logstash 支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地从日志、指标、Web 应用、数据存储以及各种 AWS 服务采集数据</p><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/eae82eb4-f685-4eba-b74b-357634fe19d9.jpg" alt></p><h5 id="过滤器：实时解析和转换数据"><a href="#过滤器：实时解析和转换数据" class="headerlink" title="过滤器：实时解析和转换数据"></a><strong>过滤器：实时解析和转换数据</strong></h5><p>数据从源传输到存储库的过程中，Logstash 过滤器能够解析各个事件，识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松、更快速地分析和实现商业价值。</p><p>Logstash 能够动态地转换和解析数据，不受格式或复杂度的影响：</p><ul><li>利用 Grok 从非结构化数据中派生出结构</li><li>从 IP 地址破译出地理坐标</li><li>将 PII 数据匿名化，完全排除敏感字段</li><li>整体处理不受数据源、格式或架构的影响</li></ul><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/4be6aefc-3d40-4006-8a3e-1fc15fb15f04.jpg" alt></p><h5 id="选择你的存储，导出你的数据"><a href="#选择你的存储，导出你的数据" class="headerlink" title="选择你的存储，导出你的数据"></a><strong>选择你的存储，导出你的数据</strong></h5><p>尽管 Elasticsearch 是我们的首选输出方向，能够为我们的搜索和分析带来无限可能，但它并非唯一选择。</p><p>Logstash 提供众多输出选择，您可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。</p><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/93857fc5-d1d3-4538-9465-4eabf3670670.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在过往的单体应用时代，我们所有组件都部署到一台服务器中，那时日志管理平台的需求可能并没有那么强烈，我们只需要登录到一台服务器通过shell命令就可以很方便的查看系统日志，并快速定位问题。随着互联网的发展，互联网已经全面渗入到生活的各个领域，使用互联网的用户量也越来越多，单体应用已不能够支持庞大的用户的并发量，那么将单体应用进行拆分，通过水平扩展来支持庞大用户的使用迫在眉睫，微服务概念就是在类似这样的阶段诞生，在微服务盛行的互联网技术时代，单个应用被拆分为多个应用，每个应用集群部署进行负载均衡，那么如果某项业务发生系统错误，开发或运维人员还是以过往单体应用方式登录一台一台登录服务器查看日志来定位问题，这种解决线上问题的效率可想而知。日志管理平台的建设就显得极其重要。通过Logstash去收集每台服务器日志文件，然后按定义的正则模板过滤后传输到Kafka或redis，然后由另一个Logstash从KafKa或redis读取日志存储到elasticsearch中创建索引，最后通过Kibana展示给开发者或运维人员进行分析。这样大大提升了运维线上问题的效率。除此之外，还可以将收集的日志进行大数据分析，得到更有价值的数据给到高层进行决策。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ELK 提供的功能满足使用要求，并有较高的扩展性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ELK 为一套开源项目，较低的维护成本。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="ELK" scheme="http://JavaSsun.github.io/categories/ELK/"/>
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/categories/ELK/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
      <category term="日志" scheme="http://JavaSsun.github.io/categories/ELK/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
      <category term="日志" scheme="http://JavaSsun.github.io/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="ELK" scheme="http://JavaSsun.github.io/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>Java8新特性</title>
    <link href="http://javassun.github.io/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/"/>
    <id>http://javassun.github.io/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/</id>
    <published>2020-02-08T04:43:25.000Z</published>
    <updated>2020-05-23T18:00:54.717Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>2014年，Oracle发布了Java8新版本后，愈来愈多的公司开始尝试使用Java8新特性来摆脱繁琐的语法，在使用Java8代码编写公司项目后，为了追上时代潮流，开始系统学习Java8的一些新特性。在收集整理网上各种Java8学习笔记后，此篇文章算是个人Java8学习笔记的小结。</p><ul><li>速度更块</li><li>代码更少（Lambda表达式）</li><li>强大的Stream API</li><li>便于并行</li><li>最大化减少空指针异常 Optional</li></ul><p><font color="red">核心为：Lambda表达式与Stream API</font></p><a id="more"></a><h2 id="1-Lambda表达式"><a href="#1-Lambda表达式" class="headerlink" title="1. Lambda表达式"></a>1. Lambda表达式</h2><h3 id="1-为什么使用Lambda表达式"><a href="#1-为什么使用Lambda表达式" class="headerlink" title="1. 为什么使用Lambda表达式"></a>1. 为什么使用Lambda表达式</h3><p><strong>Lambda</strong>是一个<font color="red">匿名函数</font>，我们可以把Lambda表达式理解为是<font color="red">一段可以传递的代码</font>（将代码像数据一样传递）。可以写出更简洁、更灵活的代码。作为一种紧凑的代码风格，使Java语言的表达更加凝练。</p><ul><li>从匿名类到 Lambda 的转换</li></ul><p>例子1：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;匿名内部类</span><br><span class="line">Runnable r1 &#x3D; new Runnable()&#123;</span><br><span class="line">     @Override</span><br><span class="line">     public void run()&#123;</span><br><span class="line">         System.out.println(&quot;Hello World!&quot;)</span><br><span class="line">     &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;Lambda 表达式</span><br><span class="line">Runnable r1 &#x3D; () -&gt; System.out.println(&quot;Hello World!&quot;);</span><br></pre></td></tr></table></figure><p>例子2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;原来使用匿名内部类作为参数传递</span><br><span class="line">TreeSet&lt;String&gt; ts &#x3D; new TreeSet&lt;&gt;(new Comparator&lt;String&gt;()&#123;</span><br><span class="line">     @Override</span><br><span class="line">     public int compare(String o1,String o2)&#123;</span><br><span class="line">        return Integer.compare(o1.length,o2.length());</span><br><span class="line">     &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;Lambda 表达式作为参数传递</span><br><span class="line">TreeSet&lt;String&gt; ts2 &#x3D; new TreeSet&lt;&gt;(</span><br><span class="line">     (o1,o2) -&gt; Integer.compare(o1.length(),o2.length())</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p> <font color="red"><strong>匿名内部类</strong></font>：冗余的语法。导致了“Height Problem”（只有一行在工作）</p><h3 id="2-Lambda表达式语法"><a href="#2-Lambda表达式语法" class="headerlink" title="2. Lambda表达式语法"></a>2. Lambda表达式语法</h3><p>Lambda 表达式在Java语言中引入了一个新的语法元素和操作符。这个操作符为 “<font color="red"> -&gt; </font>“，该操作符被称为 Lambda操作符 或 箭头操作符。它将Lambda分为两个部分：</p><p><strong>左侧：</strong>指定了 Lambda 表达式需要的所有参数<br><strong>右侧：</strong>指定了 Lambda 体，即 Lambda 表达式要执行的功能。</p><p><strong>语法格式一：无参，无返回值，Lambda只需一条语句</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Runnable r1 &#x3D; () -&gt; System.out.println(&quot;Hello Lambda&quot;);</span><br></pre></td></tr></table></figure><p><strong>语法格式二：Lambda需要一个参数</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Consumer&lt;String&gt; fun &#x3D; (args) -&gt; System.out.println(args);</span><br></pre></td></tr></table></figure><p><strong>语法格式三：Lambda只需要一个参数时，参数的小括号可省略</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Consummer&lt;String&gt; fun &#x3D; args -&gt; System.out.println(args);</span><br></pre></td></tr></table></figure><p><strong>语法格式四：Lambda需要两个参数，并且有返回值</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">BinaryOperator&lt;Long&gt; bo &#x3D; (x,y) -&gt;&#123;</span><br><span class="line">      System.out.println(&quot;实现函数接口方法&quot;);</span><br><span class="line">      return x + y;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>语法格式五：当Lambda体只有一条语句时，return与大括号可以省略</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BinaryOperator&lt;Long&gt; bo &#x3D; (x,y) -&gt; x + y;</span><br></pre></td></tr></table></figure><p><strong>语法格式六：Long数据类型可以省略，可由编译器推断，即“类型推断”</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">BinaryOperator&lt;Long&gt; bo &#x3D; (Long x,Long y) -&gt; &#123;</span><br><span class="line">         System.out.println(&quot;实现函数接口方法&quot;)；</span><br><span class="line">         x + y;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>Lambda</strong>是<font color="red"><strong>匿名内函数</strong></font>：提供了轻量级的语法。解决了匿名内部类带来的“高度”问题。</p><p>语法：<strong>参数列表</strong> <strong>-&gt;</strong> <strong>函数体</strong>三部分组成。<br>函数体：表达式、语句块。<br><font color="red"><strong>表达式</strong></font>：表达式会被执行然后返回执行结果。<br><font color="red"><strong>语句块</strong></font>：语句块中的语句会被依次执行，就像方法中的语句一样</p><ol><li>return语句会把控制权交给匿名函数的调用者</li><li>break和continue只能在循环中使用。</li><li>如果函数体有返回值。那么函数体内部的每一条路径都要有。</li></ol><p>表达式函数体适合小型<strong>Lambda</strong>表达式。消除了return关键字。简洁。</p><p><font color="red">新包</font>：<strong>java.util.function:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;接收 T对象 返回boolean</span><br><span class="line">Predicate&lt;T&gt; boolean test(T t)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 接收 T对象 不返回任何值</span><br><span class="line">Consumer&lt;T&gt; void accept(T t)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;接收 T对象 返回R对象</span><br><span class="line">Function(T,R) R apply(T t)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;提供 T对象（工厂T）</span><br><span class="line">Supplier&lt;T&gt; T get()</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 一元：接收T 返回T</span><br><span class="line">UnaryOperator&lt;T&gt;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 二元：接收两个T 返回T</span><br><span class="line">BinaryOperator&lt;T&gt;</span><br></pre></td></tr></table></figure><p>一些 Lambda表达式简单例子</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(int x,int y)-&gt;x+y; &#x2F;&#x2F;接收 x y 返回 x与y的和</span><br><span class="line">()-&gt;45;       &#x2F;&#x2F; 不接受参数 返回45</span><br><span class="line">(String s)-&gt;&#123;System.out.println(s);&#125; &#x2F;&#x2F;接收一个字符串，并把它打印在控制台</span><br></pre></td></tr></table></figure><h3 id="3-类型推断"><a href="#3-类型推断" class="headerlink" title="3. 类型推断"></a>3. 类型推断</h3><p>Lambda表达式无需指定类型，程序依然可以编译，因为 javac 根据程序上下文，在后台推断出了参数类型。Lambda表达式的类型依赖于上下文环境，是由编译器推断出来的。即所谓的“类型推断”。</p><h2 id="2-函数式接口"><a href="#2-函数式接口" class="headerlink" title="2. 函数式接口"></a>2. 函数式接口</h2><h3 id="1-什么是函数式接口"><a href="#1-什么是函数式接口" class="headerlink" title="1. 什么是函数式接口"></a>1. 什么是函数式接口</h3><ul><li><p>只包含了一个抽象方法的接口，称为<strong>函数式接口</strong></p></li><li><p>你可以通过 Lambda 表达式来创建该接口的对象。（若 Lambda 表达式抛出一个受检异常，那么该异常需要在目标接口的抽象方法上进行声明）。</p></li><li><p>我们可以在任意函数式接口上使用 <strong>@FunctionalInterface</strong> 注解，这样做可以检查它是否是一个函数式接口，同时 javadoc 也会包含一条声明，说明这个接口是一个函数式接口。</p></li></ul><h3 id="2-自定义函数式接口"><a href="#2-自定义函数式接口" class="headerlink" title="2. 自定义函数式接口"></a>2. 自定义函数式接口</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@FunctionalInterface</span><br><span class="line">public interface MyNumber&#123;</span><br><span class="line">   public double getValue();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;函数式接口中使用泛型：</span><br><span class="line">@FunctionalInterface</span><br><span class="line">public interface MyFunc&lt;T&gt;&#123;</span><br><span class="line">   public T getValue(T t);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;作为参数传递 Lambda 表达式</span><br><span class="line">public String toUpperString(MyFunc&lt;String&gt; mf, String str)&#123;</span><br><span class="line">        return mf.getValue(str);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">       String newStr &#x3D; toUpperString(</span><br><span class="line">       (str) -&gt; str.toUpperCase(), &quot;abcdef&quot;);</span><br><span class="line">       System.out.println(newStr);</span><br></pre></td></tr></table></figure><p><font color="red">作为参数传递 Lambda 表达式：为了将 Lambda 表达式作为参数传递，接收Lambda 表达式的参数类型必须是与该 Lambda 表达式兼容的函数式接口的类型。<br></font></p><h3 id="3-Java内治四大核心函数式接口"><a href="#3-Java内治四大核心函数式接口" class="headerlink" title="3. Java内治四大核心函数式接口"></a>3. Java内治四大核心函数式接口</h3><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/97801292-5716-4519-9bff-9f8f08aed48b.png" alt></p><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/743ea2bc-aeda-44e0-b691-31c354b94f47.png" alt></p><h2 id="3-方法引用与构造器引用"><a href="#3-方法引用与构造器引用" class="headerlink" title="3. 方法引用与构造器引用"></a>3. 方法引用与构造器引用</h2><h3 id="1-方法引用"><a href="#1-方法引用" class="headerlink" title="1. 方法引用"></a>1. 方法引用</h3><p>当要传递给Lambda体的操作，已经有实现的方法了，可以使用方法引用！<br>（实现抽象方法的参数列表，必须与方法引用方法的参数列表保持一致！）<br>方法引用：使用操作符 “::” 将方法名和对象或类的名字分隔开来。 如下三种主要使用情况：</p><ul><li><p><strong>对象::实例方法</strong></p></li><li><p><strong>类::静态方法</strong></p></li><li><p><strong>类::实例方法</strong></p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">() -&gt; System.out.println(x);</span><br><span class="line">等同于</span><br><span class="line">System.out::println;</span><br><span class="line"></span><br><span class="line">BinaryOperator&lt;Double&gt; bo &#x3D; (x,y) -&gt; Math.pow(x,y);</span><br><span class="line">等同于</span><br><span class="line">BinaryOperator&lt;Double&gt; bo &#x3D;Math::pow;</span><br><span class="line"></span><br><span class="line">compare((x,y) -&gt;x.equals(y), &quot;abcdef&quot; , &quot;abcdef&quot;);</span><br><span class="line">等同于</span><br><span class="line">compare(String::equals,&quot;abc&quot;,&quot;abc&quot;);</span><br></pre></td></tr></table></figure><p><strong>注意：当需要引用方法的第一个参数是调用对象，并且第二个参数是需要引<br>用方法的第二个参数(或无参数)时：ClassName::methodName</strong></p><h3 id="2-构造器引用"><a href="#2-构造器引用" class="headerlink" title="2. 构造器引用"></a>2. 构造器引用</h3><p><strong>格式： ClassName::new</strong><br>与函数式接口相结合，自动与函数式接口中方法兼容。 可以把构造器引用赋值给定义的方法，与构造器参数列表要与接口中抽象方法的参数列表一致！</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Function&lt;Integer,MyClass&gt; fun &#x3D; (n) -&gt; new MyClass(n);</span><br><span class="line">等同于</span><br><span class="line">Function&lt;Integer,MyClass&gt; fun &#x3D; MyClass::new;</span><br></pre></td></tr></table></figure><h3 id="3-数字引用"><a href="#3-数字引用" class="headerlink" title="3. 数字引用"></a>3. 数字引用</h3><p><strong>格式： type[] :: new</strong></p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Function&lt;Integer,Integer[]&gt; fun &#x3D; (n) -&gt; new Integer(n);</span><br><span class="line">等同于</span><br><span class="line">Function&lt;Integer,MyClass&gt; fun &#x3D; Integer[]::new;</span><br></pre></td></tr></table></figure><h2 id="4-Stream-API"><a href="#4-Stream-API" class="headerlink" title="4. Stream API"></a>4. Stream API</h2><h3 id="1-了解Stream"><a href="#1-了解Stream" class="headerlink" title="1. 了解Stream"></a>1. 了解Stream</h3><p>Java8中有两大最为重要的改变。第一个是 Lambda 表达式；另外一 个则是 <strong>Stream API(java.util.stream.*)</strong>。 Stream 是 Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。使用Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。也可以使用 Stream API 来并行执行操作。简而言之，Stream API 提供了一种高效且易于使用的处理数据的方式。</p><p>*<em>流(Stream)是数据渠道，用于操作数据源（集合、数组等）所生成的元素序列。<br>*</em><br><font color="red">“集合讲的是数据，流讲的是计算！”</font></p><ol><li>Stream 自己不会存储元素。</li><li>Stream 不会改变源对象。相反，他们会返回一个持有结果的新Stream。</li><li>Stream 操作是延迟执行的。这意味着他们会等到需要结果的时候才执行。</li></ol><h3 id="2-Stream三步骤"><a href="#2-Stream三步骤" class="headerlink" title="2. Stream三步骤"></a>2. Stream三步骤</h3><ul><li><p><strong>创建 Stream</strong><br>一个数据源（如：集合、数组），获取一个流</p></li><li><p><strong>中间操作</strong><br>一个中间操作链，对数据源的数据进行处理 </p></li><li><p><strong>终端操作</strong><br>一个终止操作，执行中间操作链，并产生结果<br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/37346492-7531-44b8-a2bf-681c14b381ec.jpg" alt></p></li></ul><h3 id="3-创建Stream"><a href="#3-创建Stream" class="headerlink" title="3. 创建Stream"></a>3. 创建Stream</h3><h4 id="1-Collection-创建流"><a href="#1-Collection-创建流" class="headerlink" title="1. Collection 创建流"></a>1. Collection 创建流</h4><ul><li><p>default Stream<E> stream() : 返回一个顺序流</E></p></li><li><p>default Stream<E> parallelStream() : 返回一个并行流</E></p></li></ul><h4 id="2-数组-创建流（Arrays的静态方法stream-创建）"><a href="#2-数组-创建流（Arrays的静态方法stream-创建）" class="headerlink" title="2. 数组 创建流（Arrays的静态方法stream()创建）"></a>2. 数组 创建流（Arrays的静态方法stream()创建）</h4><ul><li>static <T> Stream<T> stream(T[] array): 返回一个流</T></T></li></ul><p><strong>重载形式，能够处理对应基本类型的数组</strong></p><ul><li><p>public static IntStream stream(int[] array)</p></li><li><p>public static LongStream stream(long[] array)</p></li><li><p>public static DoubleStream stream(double[] array)</p></li></ul><h4 id="3-由值创建流"><a href="#3-由值创建流" class="headerlink" title="3. 由值创建流"></a>3. 由值创建流</h4><p>可以使用静态方法 Stream.of(), 通过显示值 创建一个流。它可以接收任意数量的参数。</p><ul><li>public static<T> Stream<T> of(T… values) : 返回一个流</T></T></li></ul><h4 id="4-由函数创建流：创建无限流"><a href="#4-由函数创建流：创建无限流" class="headerlink" title="4. 由函数创建流：创建无限流"></a>4. 由函数创建流：创建无限流</h4><p>可以使用静态方法 Stream.iterate() 和 Stream.generate(), 创建无限流。</p><ul><li>迭代</li></ul><p>public static<T> Stream<T> iterate(final T seed, final UnaryOperator<T> f)</T></T></T></p><ul><li>生成</li></ul><p>public static<T> Stream<T> generate(Supplier<T> s)</T></T></T></p><h3 id="4-Stream-的中间操作"><a href="#4-Stream-的中间操作" class="headerlink" title="4. Stream 的中间操作"></a>4. Stream 的中间操作</h3><p>多个中间操作可以连接起来形成一个流水线，除非流水 线上触发终止操作，否则中间操作不会执行任何的处理！ 而在终止操作时一次性全部处理，称为“惰性求值”。</p><p><strong>筛选与切片</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/853fb496-9885-4191-b20d-1d5c8508def5.png" alt></p><p><strong>映射</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/feb89458-0a81-42a9-9aa4-33b20b5991bf.png" alt></p><p><strong>排序</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/3a69b800-08f9-4bca-ab2d-51e3f3446635.png" alt></p><h3 id="5-Stream-的终止操作"><a href="#5-Stream-的终止操作" class="headerlink" title="5. Stream 的终止操作"></a>5. Stream 的终止操作</h3><p>终端操作会从流的流水线生成结果。其结果可以是任何不是流的 值，例如：List、Integer，甚至是 void 。</p><p><strong>查找与匹配</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/1cd0233f-598b-4537-8998-5e5fa24aada0.png" alt><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/bae6b149-cc4f-4f84-aec0-e27bf8afe015.png" alt></p><p><strong>归约</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/037bfd49-78ed-468b-aa65-4ad0242e490b.png" alt></p><p>备注：map 和 reduce 的连接通常称为 map-reduce 模式，因 Google 用它 来进行网络搜索而出名。</p><p><strong>收集</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/2cccbffb-7df8-4a65-8153-537071e75bd7.png" alt></p><p>Collector 接口中方法的实现决定了如何对流执行收集操作(如收集到 List、Set、Map)。但是 Collectors 实用类提供了很多静态方法，可以方便地创建常见收集器实例，具体方法与实例如下表：</p><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/2399d052-df02-4998-909e-559f6b815d8a.png" alt></p><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/15609436-aba0-444c-8ca9-4fc5870b9fb5.png" alt></p><h3 id="6-并行流与串行流"><a href="#6-并行流与串行流" class="headerlink" title="6. 并行流与串行流"></a>6. 并行流与串行流</h3><p><strong>并行流</strong>就是把一个内容分成多个数据块，并用不同的线程分 别处理每个数据块的流。</p><p>Java 8 中将并行进行了优化，我们可以很容易的对数据进行并 行操作。Stream API 可以声明性地通过 parallel() 与 sequential() 在并行流与顺序流之间进行切换。</p><h3 id="7-了解-Fork-Join-框架"><a href="#7-了解-Fork-Join-框架" class="headerlink" title="7. 了解 Fork/Join 框架"></a>7. 了解 Fork/Join 框架</h3><p><strong>Fork/Join 框架</strong>:就是在必要的情况下，将一个大任务，进行拆分(fork)成若干个小任务（拆到不可再拆时），再将一个个的小任务运算的结果进行 join 汇总.</p><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/84eaed9b-717b-47f9-9f0a-f5fde05f7472.jpg" alt></p><h3 id="8-Fork-Join-框架与传统线程池的区别"><a href="#8-Fork-Join-框架与传统线程池的区别" class="headerlink" title="8. Fork/Join 框架与传统线程池的区别"></a>8. Fork/Join 框架与传统线程池的区别</h3><p>采用 “工作窃取”模式（work-stealing）：<br>当执行新的任务时它可以将其拆分分成更小的任务执行，并将小任务加到线程队列中，然后再从一个随机线程的队列中偷一个并把它放在自己的队列中。</p><p>相对于一般的线程池实现,fork/join框架的优势体现在对其中包含的任务的<br>处理方式上.在一般的线程池中,如果一个线程正在执行的任务由于某些原因<br>无法继续运行,那么该线程会处于等待状态.而在fork/join框架实现中,如果<br>某个子问题由于等待另外一个子问题的完成而无法继续运行.那么处理该子<br>问题的线程会主动寻找其他尚未运行的子问题来执行.这种方式减少了线程<br>的等待时间,提高了性能.</p><h2 id="5-新时间日期API"><a href="#5-新时间日期API" class="headerlink" title="5. 新时间日期API"></a>5. 新时间日期API</h2><ul><li>LocalDate、LocalTime、LocalDateTime 类的实 例是<strong>不可变的对象</strong>，分别表示使用 ISO-8601日 历系统的日期、时间、日期和时间。它们提供了简单的日期或时间，并不包含当前的时间信息。也不包含与时区相关的信息。</li></ul><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/1d49dcda-eb3d-4eb7-aa3c-889e5607867f.png" alt></p><p><strong>Instant 时间戳</strong></p><ul><li>用于“时间戳”的运算。它是以Unix元年(传统 的设定为UTC时区1970年1月1日午夜时分)开始 所经历的描述进行运算</li></ul><p><strong>Duration 和 Period</strong></p><ul><li><p>Duration:用于计算两个“时间”间隔</p></li><li><p>Period:用于计算两个“日期”间隔</p></li><li><p>日期的操纵</p></li><li><p>TemporalAdjuster : 时间校正器。有时我们可能需要获 取例如：将日期调整到“下个周日”等操作。</p></li><li><p>TemporalAdjusters : 该类通过静态方法提供了大量的常 用 TemporalAdjuster 的实现。</p></li></ul><p>例如获取下个周日：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LocalDate nextSunday &#x3D; LocalDate.now().with(</span><br><span class="line">   TemporalAdjusters.next(DayOfWeek.SUNDAY)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p><strong>解析与格式化</strong></p><p>java.time.format.DateTimeFormatter 类：该类提供了三种 格式化方法：</p><ul><li><p>预定义的标准格式</p></li><li><p>语言环境相关的格式</p></li><li><p>自定义的格式</p></li></ul><p><strong>时区的处理</strong></p><ul><li>Java8 中加入了对时区的支持，带时区的时间为分别为：</li></ul><p>ZonedDate、ZonedTime、ZonedDateTime<br>其中每个时区都对应着 ID，地区ID都为 “{区域}/{城市}”的格式<br>例如 ：Asia/Shanghai 等</p><p>ZoneId：该类中包含了所有的时区信息</p><p>getAvailableZoneIds() : 可以获取所有时区时区信息<br>of(id) : 用指定的时区信息获取 ZoneId 对象</p><p><strong>与传统日期处理的转换</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/0b30f162-415f-4a9c-a650-ba13116ff20b.png" alt></p><h2 id="6-接口中的默认方法与静态方法"><a href="#6-接口中的默认方法与静态方法" class="headerlink" title="6. 接口中的默认方法与静态方法"></a>6. 接口中的默认方法与静态方法</h2><h3 id="1-接口中的默认方法"><a href="#1-接口中的默认方法" class="headerlink" title="1. 接口中的默认方法"></a>1. 接口中的默认方法</h3><p>Java 8中允许接口中包含具有具体实现的方法，该方法称为 “默认方法”，默认方法使用 default 关键字修饰。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">例如：</span><br><span class="line">interface MyFunc&lt;T&gt;&#123;</span><br><span class="line">  T func(int a);</span><br><span class="line"></span><br><span class="line">  default String getName()&#123;</span><br><span class="line">     return &quot;Hello Java&quot;;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>*<em>接口默认方法的”类优先”原则 *</em></p><p>若一个接口中定义了一个默认方法，而另外一个父类或接口中 又定义了一个同名的方法时</p><ul><li><p>选择父类中的方法。如果一个父类提供了具体的实现，那么 接口中具有相同名称和参数的默认方法会被忽略。</p></li><li><p>接口冲突。如果一个父接口提供一个默认方法，而另一个接 口也提供了一个具有相同名称和参数列表的方法（不管方法 是否是默认方法），那么必须覆盖该方法来解决冲突</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">interface MyFunc&#123;</span><br><span class="line">   default String getName()&#123;</span><br><span class="line">        return &quot;Hello World&quot;;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">interface Named&#123;</span><br><span class="line">   default String getName()&#123;</span><br><span class="line">        return &quot;Hello java8&quot;;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class MyClass implements MyFunc,Named&#123;</span><br><span class="line">   public String getName()&#123;</span><br><span class="line">        return Named.super.getName();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-接口中的静态方法"><a href="#2-接口中的静态方法" class="headerlink" title="2. 接口中的静态方法"></a>2. 接口中的静态方法</h3><p>Java8 中，接口中允许添加静态方法</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">interface Named&#123;</span><br><span class="line">  public Integer myFun();</span><br><span class="line"></span><br><span class="line">  default String getName()&#123;</span><br><span class="line">     return &quot;Hello World&quot;;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  static void show()&#123;</span><br><span class="line">     System.out.println(&quot;Hello Lambda&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="7-其他新特性"><a href="#7-其他新特性" class="headerlink" title="7. 其他新特性"></a>7. 其他新特性</h2><p><strong>Optional 类</strong></p><p>Optional<T> 类(java.util.Optional) 是一个容器类，代表一个值存在或不存在，原来用 null 表示一个值不存在，现在 Optional 可以更好的表达这个概念。并且可以避免空指针异常。</T></p><p><strong>常用方法：</strong><br>Optional.of(T t) : 创建一个 Optional 实例<br>Optional.empty() : 创建一个空的 Optional 实例<br>Optional.ofNullable(T t):若 t 不为 null,创建 Optional 实例,否则创建空实例<br>isPresent() : 判断是否包含值<br>orElse(T t) :  如果调用对象包含值，返回该值，否则返回t<br>orElseGet(Supplier s) :如果调用对象包含值，返回该值，否则返回 s 获取的值<br>map(Function f): 如果有值对其处理，并返回处理后的Optional，否则返回 Optional.empty()<br>flatMap(Function mapper):与 map 类似，要求返回值必须是Optional</p><p><strong>重复注解与类型注解</strong></p><p>Java 8对注解处理提供了两点改进：可重复的注解及可用于类型的注解。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@Target(&#123;TYPE,FIELD,METHOD,PARAMETER,CONSTRUCTOR,LOCAL_VARIABLE&#125;)</span><br><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">public @interface MyAnnotations&#123;</span><br><span class="line">   MyAnnotation[] value();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Repeatable(MyAnnotations.class)</span><br><span class="line">@Target(&#123;TYPE,FIELD,METHOD,PARAMETER,CONSTRUCTOR,LOCAL_VARIABLE,ElementType.TYPE_PARAMETER&#125;)</span><br><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">public @interface MyAnnotation&#123;</span><br><span class="line">   String value();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@MyAnnotation(&quot;Hello&quot;)</span><br><span class="line">@MyAnnotation(&quot;World&quot;)</span><br><span class="line">public void show(@MyAnnotation(&quot;abc&quot;) String str)&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="练习题"><a href="#练习题" class="headerlink" title="练习题"></a>练习题</h2><p>1 交易员</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line">public class Trader &#123;</span><br><span class="line">     private String name;</span><br><span class="line">     private String city;</span><br><span class="line">     public Trader(String name, String city) &#123;</span><br><span class="line">        this.name &#x3D; name;</span><br><span class="line">        this.city &#x3D; city;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; getter setter方法省略</span><br><span class="line"></span><br><span class="line">public class Transaction &#123;</span><br><span class="line">     private Trader trader;</span><br><span class="line">     private int year;</span><br><span class="line">     private int value;</span><br><span class="line">     public Transaction(Trader trader, int year, int value) &#123;</span><br><span class="line">        this.trader &#x3D; trader;</span><br><span class="line">        this.year &#x3D; year;</span><br><span class="line">        this.value &#x3D; value;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class PuttingIntoPractice &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Trader raoul &#x3D; new Trader(&quot;Raoul&quot;,&quot;Cambridge&quot;);</span><br><span class="line">        Trader mario &#x3D; new Trader(&quot;mario&quot;,&quot;Milan&quot;);</span><br><span class="line">        Trader alen &#x3D; new Trader(&quot;alen&quot;,&quot;Cambridge&quot;);</span><br><span class="line">        Trader brian &#x3D; new Trader(&quot;brian&quot;,&quot;Cambridge&quot;);</span><br><span class="line"></span><br><span class="line">  List&lt;Transaction&gt; transactions &#x3D; Arrays.asList(</span><br><span class="line">          new Transaction(brian,2011,300),</span><br><span class="line">          new Transaction(raoul,2012,1000),</span><br><span class="line">          new Transaction(raoul,2011,400),</span><br><span class="line">          new Transaction(mario,2012,710),</span><br><span class="line">          new Transaction(mario,2012,700),</span><br><span class="line">          new Transaction(alen,2012,950)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (1) 找出2011年发生的所有交易，并按交易额排序（从低到高）。</span><br><span class="line">  transactions.stream()</span><br><span class="line">                .filter(transaction -&gt; transaction.getYear() &#x3D;&#x3D; 2011)</span><br><span class="line">.sorted(Comparator.comparing(Transaction::getValue))</span><br><span class="line">                .collect(Collectors.toList())</span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (2) 交易员都在哪些不同的城市工作过？</span><br><span class="line">  transactions.stream()</span><br><span class="line">                .map(transaction -&gt; transaction.getTrader().getCity())</span><br><span class="line">                .distinct()</span><br><span class="line">                .collect(Collectors.toList())</span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (3) 查找所有来自于剑桥的交易员，并按姓名排序。</span><br><span class="line">  transactions.stream()</span><br><span class="line">                .map(Transaction::getTrader)</span><br><span class="line">                .filter(trader -&gt; trader.getCity().equals(&quot;Cambridge&quot;))</span><br><span class="line">                .distinct()</span><br><span class="line">                .sorted(Comparator.comparing(Trader::getName))</span><br><span class="line">                .collect(Collectors.toList())</span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (4) 返回所有交易员的姓名字符串，按字母顺序排序。</span><br><span class="line">  String traderStr &#x3D; transactions.stream()</span><br><span class="line">                .map(transaction -&gt; transaction.getTrader().getName())</span><br><span class="line">                .distinct()</span><br><span class="line">                .sorted()</span><br><span class="line">                .reduce(&quot;&quot;, (n1, n2) -&gt; n1 + n2);</span><br><span class="line">  System.out.println(traderStr);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (5) 有没有交易员是在米兰工作的？</span><br><span class="line">  boolean miLanBased &#x3D; transactions.stream()</span><br><span class="line">                .anyMatch(transaction -&gt; transaction.getTrader()</span><br><span class="line">                        .getCity().equals(&quot;MiLan&quot;));</span><br><span class="line">  System.out.println(miLanBased);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (6) 打印生活在剑桥的交易员的所有交易额。</span><br><span class="line"> transactions.stream()</span><br><span class="line">                .filter(transaction -&gt; transaction.getTrader().getCity().equals(&quot;Cambridge&quot;))</span><br><span class="line">                .map(transaction -&gt; transaction.getValue())</span><br><span class="line">                .collect(Collectors.toList())</span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (7) 所有交易中，最高的交易额是多少？</span><br><span class="line">  int highestValue &#x3D; transactions.stream()</span><br><span class="line">                .map(Transaction::getValue)</span><br><span class="line">                .reduce(0,Integer::max);</span><br><span class="line">  System.out.println(highestValue);</span><br><span class="line"></span><br><span class="line">  transactions.stream()</span><br><span class="line">  .sorted(Comparator.comparing(Transaction::getValue).reversed())</span><br><span class="line">                .findFirst()</span><br><span class="line">                .ifPresent(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (8) 找到交易额最小的交易。</span><br><span class="line">  transactions.stream()</span><br><span class="line">                .map(Transaction::getValue)</span><br><span class="line">                .reduce(Integer::min)</span><br><span class="line">                .ifPresent(System.out::println);</span><br><span class="line"></span><br><span class="line">  transactions.stream()</span><br><span class="line">             .min(Comparator.comparing(Transaction::getValue))</span><br><span class="line">                .ifPresent(System.out::println);</span><br><span class="line"></span><br><span class="line">  transactions.stream()</span><br><span class="line">                .min(Comparator.comparing((Transaction t1)-&gt; t1.getValue()))</span><br><span class="line">                .ifPresent(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (9) 统计每个交易员的记录</span><br><span class="line">  transactions.stream()</span><br><span class="line">       .collect(Collectors.groupingBy(Transaction::getTrader))</span><br><span class="line">                .entrySet().stream()</span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (10) 找到单笔交易最高的交易员</span><br><span class="line">  transactions.stream()</span><br><span class="line">             .max(Comparator.comparing(Transaction::getValue))</span><br><span class="line">                .ifPresent(tran -&gt;&#123;</span><br><span class="line">                    System.out.println(tran.getTrader());</span><br><span class="line">  &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>更多练习参考网络</p><h2 id="8-java8红黑树"><a href="#8-java8红黑树" class="headerlink" title="8. java8红黑树"></a>8. java8红黑树</h2><h3 id="HashMap数据结构"><a href="#HashMap数据结构" class="headerlink" title="HashMap数据结构"></a>HashMap数据结构</h3><p>回顾：HashSet是基于HashCode实现元素不重复的。当插入元素的哈希码相同时，会调用equals方法进行二次比较，如果相同，则新值替旧值。如果不同，则以链表的形式挂在当前元素所在的位置。</p><p>扩容因子：0.75</p><p>如果是1 ，则可能永远是只插入到两个位置，形成部分元素的长链表。每次都要在哈希码相同时进行equals比较（哈希碰撞）。降低性能。</p><p>如果是&lt;0.75,则可能浪费空间。</p><h3 id="数组-链表-红黑树-二叉树的一种"><a href="#数组-链表-红黑树-二叉树的一种" class="headerlink" title="数组-链表-红黑树(二叉树的一种)"></a>数组-链表-红黑树(二叉树的一种)</h3><p><strong>条件：当碰撞元素个数&gt;8 &amp;&amp; 总容量&gt;64 将其转换为红黑树</strong></p><p><font color="red">碰撞元素个数</font>：一个数组元素上所挂载的（链表）元素个数。</p><p><font color="red">JDK7是数组-&gt;链表</font>：一个数组元素上所挂载的（链表）元素个数。</p><p><font color="red">JDK8是数组-链表</font>： 当转变为红黑树时，添加的效率变低。其他效率都高了。平衡二叉树（比当前值与节点值的大小）</p><p>扩容是：原来表会计算hashcode值进行元素的再次填充。</p><p>现在只需要找原来表的总长度+当前所在的位置，就是当前扩容后的位置。（不需要再次进行哈希计算）。</p><p><strong>ConcurrentHashMap：效率提高</strong></p><p>JDK7: ConcurrentLevel = 16<br>JDK8：CAS算法</p><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/7d750713-3d72-48e3-b512-d11dc1900f92.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;2014年，Oracle发布了Java8新版本后，愈来愈多的公司开始尝试使用Java8新特性来摆脱繁琐的语法，在使用Java8代码编写公司项目后，为了追上时代潮流，开始系统学习Java8的一些新特性。在收集整理网上各种Java8学习笔记后，此篇文章算是个人Java8学习笔记的小结。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;速度更块&lt;/li&gt;
&lt;li&gt;代码更少（Lambda表达式）&lt;/li&gt;
&lt;li&gt;强大的Stream API&lt;/li&gt;
&lt;li&gt;便于并行&lt;/li&gt;
&lt;li&gt;最大化减少空指针异常 Optional&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;font color=&quot;red&quot;&gt;核心为：Lambda表达式与Stream API&lt;/font&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Java" scheme="http://JavaSsun.github.io/categories/Java/"/>
    
    
      <category term="Java" scheme="http://JavaSsun.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot+Docker简单配置</title>
    <link href="http://javassun.github.io/2020/01/15/SpringBoot-Docker%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE/"/>
    <id>http://javassun.github.io/2020/01/15/SpringBoot-Docker%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE/</id>
    <published>2020-01-15T14:20:51.000Z</published>
    <updated>2020-05-06T06:33:32.647Z</updated>
    
    <content type="html"><![CDATA[<p>转自<a href="http://www.ityouknow.com/springboot/2018/03/19/spring-boot-docker.html" target="_blank" rel="noopener">纯洁的微笑</a></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Docker 技术发展为微服务落地提供了更加便利的环境，使用 Docker 部署 Spring Boot其实非常简单。</p><p>首先构建一个简单的 Spring Boot 项目，然后给项目添加 Docker 支持，最后对项目进行部署。</p><a id="more"></a><h2 id="一个简单-Spring-Boot-项目"><a href="#一个简单-Spring-Boot-项目" class="headerlink" title="一个简单 Spring Boot 项目"></a>一个简单 Spring Boot 项目</h2><p>在 <code>pom.xml</code> 中 ，使用 Spring Boot 2.0 相关依赖</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;parent&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-parent&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.0.0.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;parent&gt;</span><br></pre></td></tr></table></figure><p>添加 web 和测试依赖</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependencies&gt;</span><br><span class="line">     &lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-web&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-test&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;scope&gt;test&lt;&#x2F;scope&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;&#x2F;dependencies&gt;</span><br></pre></td></tr></table></figure><p>创建一个 DockerController，在其中有一个<code>index()</code>方法，访问时返回：<code>Hello Docker!</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">public class DockerController &#123;</span><br><span class="line"></span><br><span class="line">    @RequestMapping(&quot;&#x2F;&quot;)</span><br><span class="line">    public String index() &#123;</span><br><span class="line">        return &quot;Hello Docker!&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动类</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@SpringBootApplication</span><br><span class="line">public class DockerApplication &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SpringApplication.run(DockerApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>添加完毕后启动项目，启动成功后浏览器访问：<code>http://localhost:8080/</code>，页面返回：<code>Hello Docker!</code>，说明 Spring Boot 项目配置正常。</p><h2 id="Spring-Boot-项目添加-Docker-支持"><a href="#Spring-Boot-项目添加-Docker-支持" class="headerlink" title="Spring Boot 项目添加 Docker 支持"></a>Spring Boot 项目添加 Docker 支持</h2><p>在 <code>pom.xml-properties</code>中添加 Docker 镜像名称</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;docker.image.prefix&gt;springboot&lt;&#x2F;docker.image.prefix&gt;</span><br><span class="line">&lt;&#x2F;properties&gt;</span><br></pre></td></tr></table></figure><p>plugins 中添加 Docker 构建插件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;build&gt;</span><br><span class="line">    &lt;plugins&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-maven-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">        &lt;!-- Docker maven plugin --&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;groupId&gt;com.spotify&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;docker-maven-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.0.0&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;imageName&gt;$&#123;docker.image.prefix&#125;&#x2F;$&#123;project.artifactId&#125;&lt;&#x2F;imageName&gt;</span><br><span class="line">                &lt;dockerDirectory&gt;src&#x2F;main&#x2F;docker&lt;&#x2F;dockerDirectory&gt;</span><br><span class="line">                &lt;resources&gt;</span><br><span class="line">                    &lt;resource&gt;</span><br><span class="line">                        &lt;targetPath&gt;&#x2F;&lt;&#x2F;targetPath&gt;</span><br><span class="line">                        &lt;directory&gt;$&#123;project.build.directory&#125;&lt;&#x2F;directory&gt;</span><br><span class="line">                        &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;&#x2F;include&gt;</span><br><span class="line">                    &lt;&#x2F;resource&gt;</span><br><span class="line">                &lt;&#x2F;resources&gt;</span><br><span class="line">            &lt;&#x2F;configuration&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">        &lt;!-- Docker maven plugin --&gt;</span><br><span class="line">    &lt;&#x2F;plugins&gt;</span><br><span class="line">&lt;&#x2F;build&gt;</span><br></pre></td></tr></table></figure><p>在目录<code>src/main/docker</code>下创建 Dockerfile 文件，Dockerfile 文件用来说明如何来构建镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FROM openjdk:8-jdk-alpine</span><br><span class="line">VOLUME &#x2F;tmp</span><br><span class="line">ADD spring-boot-docker-1.0.jar app.jar</span><br><span class="line">ENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd&#x3D;file:&#x2F;dev&#x2F;.&#x2F;urandom&quot;,&quot;-jar&quot;,&quot;&#x2F;app.jar&quot;]</span><br></pre></td></tr></table></figure><p>这个 Dockerfile 文件很简单，构建 Jdk 基础环境，添加 Spring Boot Jar 到镜像中，简单解释一下:</p><ul><li>FROM ，表示使用 Jdk8 环境 为基础镜像，如果镜像不是本地的会从 DockerHub 进行下载</li><li>VOLUME ，VOLUME 指向了一个<code>/tmp</code>的目录，由于 Spring Boot 使用内置的Tomcat容器，Tomcat 默认使用<code>/tmp</code>作为工作目录。这个命令的效果是：在宿主机的<code>/var/lib/docker</code>目录下创建一个临时文件并把它链接到容器中的<code>/tmp</code>目录</li><li>ADD ，拷贝文件并且重命名</li><li>ENTRYPOINT ，为了缩短 Tomcat 的启动时间，添加<code>java.security.egd</code>的系统属性指向<code>/dev/urandom</code>作为 ENTRYPOINT</li></ul><blockquote><p>这样 Spring Boot 项目添加 Docker 依赖就完成了。</p></blockquote><h2 id="构建打包环境"><a href="#构建打包环境" class="headerlink" title="构建打包环境"></a>构建打包环境</h2><p>需要有一个 Docker 环境来打包 Spring Boot 项目，在 Windows 搭建 Docker 环境很麻烦，这里以 Centos 7 为例。</p><h3 id="安装-Docker-环境"><a href="#安装-Docker-环境" class="headerlink" title="安装 Docker 环境"></a>安装 Docker 环境</h3><p>安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install docker</span><br></pre></td></tr></table></figure><p>安装完成后，使用下面的命令来启动 docker 服务，并将其设置为开机启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">service docker start</span><br><span class="line">chkconfig docker on</span><br><span class="line"></span><br><span class="line">#LCTT 译注：此处采用了旧式的 sysv 语法，如采用CentOS 7中支持的新式 systemd 语法，如下：</span><br><span class="line">systemctl  start docker.service</span><br><span class="line">systemctl  enable docker.service</span><br></pre></td></tr></table></figure><p>使用Docker 中国加速器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi  &#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line"></span><br><span class="line">#添加后：</span><br><span class="line">&#123;</span><br><span class="line">    &quot;registry-mirrors&quot;: [&quot;https:&#x2F;&#x2F;registry.docker-cn.com&quot;],</span><br><span class="line">    &quot;live-restore&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重新启动docker</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><p>输入<code>docker version</code> 返回版本信息则安装正常。</p><h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install java-1.8.0-openjdk*</span><br></pre></td></tr></table></figure><p>配置环境变量 打开 <code>vim /etc/profile</code> 添加一下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0-openjdk-1.8.0.161-0.b14.el7_4.x86_64 </span><br><span class="line">export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin</span><br></pre></td></tr></table></figure><p>修改完成之后，使其生效</p><p>输入<code>java -version</code> 返回版本信息则安装正常。</p><h3 id="安装MAVEN"><a href="#安装MAVEN" class="headerlink" title="安装MAVEN"></a>安装MAVEN</h3><p>下载：<code>http://mirrors.shu.edu.cn/apache/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## 解压</span><br><span class="line">tar vxf apache-maven-3.5.2-bin.tar.gz</span><br><span class="line">## 移动</span><br><span class="line">mv apache-maven-3.5.2 &#x2F;usr&#x2F;local&#x2F;maven3</span><br></pre></td></tr></table></figure><p>修改环境变量， 在<code>/etc/profile</code>中添加以下几行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MAVEN_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;maven3</span><br><span class="line">export MAVEN_HOME</span><br><span class="line">export PATH&#x3D;$&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;&#x2F;bin</span><br></pre></td></tr></table></figure><p>记得执行<code>source /etc/profile</code>使环境变量生效。</p><p>输入<code>mvn -version</code> 返回版本信息则安装正常。</p><blockquote><p>这样整个构建环境就配置完成了。</p></blockquote><h2 id="使用-Docker-部署-Spring-Boot-项目"><a href="#使用-Docker-部署-Spring-Boot-项目" class="headerlink" title="使用 Docker 部署 Spring Boot 项目"></a>使用 Docker 部署 Spring Boot 项目</h2><p>将项目 <code>spring-boot-docker</code> 拷贝服务器中，进入项目路径下进行打包测试。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#打包</span><br><span class="line">mvn package</span><br><span class="line">#启动</span><br><span class="line">java -jar target&#x2F;spring-boot-docker-1.0.jar</span><br></pre></td></tr></table></figure><p>看到 Spring Boot 的启动日志后表明环境配置没有问题，接下来我们使用 DockerFile 构建镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn package docker:build</span><br></pre></td></tr></table></figure><p>第一次构建可能有点慢，当看到以下内容的时候表明构建成功：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">Step 1 : FROM openjdk:8-jdk-alpine</span><br><span class="line"> ---&gt; 224765a6bdbe</span><br><span class="line">Step 2 : VOLUME &#x2F;tmp</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; b4e86cc8654e</span><br><span class="line">Step 3 : ADD spring-boot-docker-1.0.jar app.jar</span><br><span class="line"> ---&gt; a20fe75963ab</span><br><span class="line">Removing intermediate container 593ee5e1ea51</span><br><span class="line">Step 4 : ENTRYPOINT java -Djava.security.egd&#x3D;file:&#x2F;dev&#x2F;.&#x2F;urandom -jar &#x2F;app.jar</span><br><span class="line"> ---&gt; Running in 85d558a10cd4</span><br><span class="line"> ---&gt; 7102f08b5e95</span><br><span class="line">Removing intermediate container 85d558a10cd4</span><br><span class="line">Successfully built 7102f08b5e95</span><br><span class="line">[INFO] Built springboot&#x2F;spring-boot-docker</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 54.346 s</span><br><span class="line">[INFO] Finished at: 2018-03-13T16:20:15+08:00</span><br><span class="line">[INFO] Final Memory: 42M&#x2F;182M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p>使用<code>docker images</code>命令查看构建好的镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker images</span><br><span class="line">REPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">springboot&#x2F;spring-boot-docker   latest              99ce9468da74        6 seconds ago       117.5 MB</span><br></pre></td></tr></table></figure><p><code>springboot/spring-boot-docker</code> 就是我们构建好的镜像，下一步就是运行该镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8080:8080 -t springboot&#x2F;spring-boot-docker</span><br></pre></td></tr></table></figure><p>启动完成之后我们使用<code>docker ps</code>查看正在运行的镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br><span class="line">CONTAINER ID        IMAGE                           COMMAND                  CREATED             STATUS              PORTS                    NAMES</span><br><span class="line">049570da86a9        springboot&#x2F;spring-boot-docker   &quot;java -Djava.security&quot;   30 seconds ago      Up 27 seconds       0.0.0.0:8080-&gt;8080&#x2F;tcp   determined_mahavira</span><br></pre></td></tr></table></figure><p>可以看到我们构建的容器正在在运行，访问浏览器：<code>http://192.168.0.x:8080/</code>,返回</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello Docker!</span><br></pre></td></tr></table></figure><p>说明使用 Docker 部署 Spring Boot 项目成功！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;转自&lt;a href=&quot;http://www.ityouknow.com/springboot/2018/03/19/spring-boot-docker.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;纯洁的微笑&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Docker 技术发展为微服务落地提供了更加便利的环境，使用 Docker 部署 Spring Boot其实非常简单。&lt;/p&gt;
&lt;p&gt;首先构建一个简单的 Spring Boot 项目，然后给项目添加 Docker 支持，最后对项目进行部署。&lt;/p&gt;
    
    </summary>
    
    
      <category term="SpringBoot" scheme="http://JavaSsun.github.io/categories/SpringBoot/"/>
    
    
      <category term="Docker" scheme="http://JavaSsun.github.io/tags/Docker/"/>
    
      <category term="SpringBoot" scheme="http://JavaSsun.github.io/tags/SpringBoot/"/>
    
  </entry>
  
  <entry>
    <title>1-Hystrix知多少</title>
    <link href="http://javassun.github.io/2020/01/01/1-Hystrix%E7%9F%A5%E5%A4%9A%E5%B0%91/"/>
    <id>http://javassun.github.io/2020/01/01/1-Hystrix%E7%9F%A5%E5%A4%9A%E5%B0%91/</id>
    <published>2020-01-01T07:38:15.000Z</published>
    <updated>2020-05-18T08:55:20.501Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>一般来说，互联网的面试，一般都会考察你，什么是分布式系统，高并发，简单的高可用问题。限流、熔断、降级，在分布式的系统架构中，微服务架构中，其实都是最常见、基础和简单的保障系统高可用的手法。dubbo去开发了，spring cloud去开发了，在这个系统的接口调用中，我们是用hystrix去实现一整套的高可用保障机制，基于hystrix去做了限流、熔断和降级。</p><p>hystrix是国外的netflix开源的，netflix是国外很大的视频网站，系统非常复杂，微服务架构，多达几千个服务，为自己的场景，经过大量的工业验证，线上生产环境的实践，产出和开源了高可用相关的一个框架，熔断框架，hystrix。</p><p>hystrix未来或已经成为国内的高可用的限流、熔断和降级这一块的事实上的标准，spring cloud微服务框架，就是集成了hystrix来做微服务架构中的限流、降级和熔断的。</p><a id="more"></a><h2 id="1-连环炮"><a href="#1-连环炮" class="headerlink" title="1. 连环炮"></a>1. 连环炮</h2><h3 id="1-1-高可用架构"><a href="#1-1-高可用架构" class="headerlink" title="1.1 高可用架构"></a>1.1 高可用架构</h3><h3 id="1-2-限流"><a href="#1-2-限流" class="headerlink" title="1.2 限流"></a>1.2 限流</h3><p>如何限流？在工作中是怎么做的？说一下具体的实现？</p><h3 id="1-3-熔断"><a href="#1-3-熔断" class="headerlink" title="1.3 熔断"></a>1.3 熔断</h3><p>如何进行熔断？熔断框架都有哪些？具体实现原理知道吗？</p><h3 id="1-4-降级"><a href="#1-4-降级" class="headerlink" title="1.4 降级"></a>1.4 降级</h3><p>如何进行降级？</p><h2 id="2-hystrix与高可用系统架构：资源隔离-限流-熔断-降级-运维监控"><a href="#2-hystrix与高可用系统架构：资源隔离-限流-熔断-降级-运维监控" class="headerlink" title="2. hystrix与高可用系统架构：资源隔离+限流+熔断+降级+运维监控"></a>2. hystrix与高可用系统架构：资源隔离+限流+熔断+降级+运维监控</h2><h3 id="1、hystrix是什么？"><a href="#1、hystrix是什么？" class="headerlink" title="1、hystrix是什么？"></a>1、hystrix是什么？</h3><p>netflix（国外最大的类似于，爱奇艺，优酷）视频网站，五六年前，也是，感觉自己的系统，整个网站，经常出故障，可用性不太高</p><p>有时候一些vip会员不能支付，有时候看视频就卡顿，看不了视频。。。</p><p>影响公司的收入。。。</p><p>五六年前，netflix，api team，提升高可用性，开发了一个框架，类似于spring，mybatis，hibernate，等等这种框架</p><p>高可用性的框架，hystrix</p><p>hystrix，框架，提供了高可用相关的各种各样的功能，然后确保说在hystrix的保护下，整个系统可以长期处于高可用的状态，100%，99.99999%</p><p>最理想的状况下，软件的故障，就不应该说导致整个系统的崩溃，服务器硬件的一些故障，服务的冗余</p><p>唯一有可能导致系统彻底崩溃，就是类似于之前，支付宝的那个事故，工人施工，挖断了电缆，导致几个机房都停电</p><p>不可用，和产生一些故障或者bug的区别</p><h3 id="2、高可用系统架构"><a href="#2、高可用系统架构" class="headerlink" title="2、高可用系统架构"></a>2、高可用系统架构</h3><p>资源隔离、限流、熔断、降级、运维监控</p><p><strong>资源隔离</strong>：让你的系统里，某一块东西，在故障的情况下，不会耗尽系统所有的资源，比如线程资源</p><p>实际的项目中的一个case，有一块东西，是要用多线程做一些事情，小伙伴做项目的时候，没有太留神，资源隔离，那块代码，在遇到一些故障的情况下，每个线程在跑的时候，因为那个bug，直接就死循环了，导致那块东西启动了大量的线程，每个线程都死循环</p><p>最终导致我的系统资源耗尽，崩溃，不工作，不可用，废掉了</p><p>资源隔离，那一块代码，最多最多就是用掉10个线程，不能再多了，就废掉了，限定好的一些资源</p><p><strong>限流</strong>：高并发的流量涌入进来，比如说突然间一秒钟100万QPS，废掉了，10万QPS进入系统，其他90万QPS被拒绝了</p><p><strong>熔断</strong>：系统后端的一些依赖，出了一些故障，比如说mysql挂掉了，每次请求都是报错的，熔断了，后续的请求过来直接不接收了，拒绝访问，10分钟之后再尝试去看看mysql恢复没有</p><p><strong>降级</strong>：mysql挂了，系统发现了，自动降级，从内存里存的少量数据中，去提取一些数据出来</p><p><strong>运维监控</strong>：监控+报警+优化，各种异常的情况，有问题就及时报警，优化一些系统的配置和参数，或者代码。</p><p><strong>小结</strong></p><p>hystrix对系统进行各种高可用性的系统加固，来应对各种不可用的情况</p><h2 id="2-hystrix要解决的分布式系统可用性问题以及其设计原则"><a href="#2-hystrix要解决的分布式系统可用性问题以及其设计原则" class="headerlink" title="2. hystrix要解决的分布式系统可用性问题以及其设计原则"></a>2. hystrix要解决的分布式系统可用性问题以及其设计原则</h2><p><strong>分布式系统以及其中的故障和hystrix</strong></p><p><img src="/2020/01/01/1-Hystrix%E7%9F%A5%E5%A4%9A%E5%B0%91/76133498-34a0-4806-a404-0ef0e6956377.png" alt></p><h3 id="1、Hystrix到底是什么？"><a href="#1、Hystrix到底是什么？" class="headerlink" title="1、Hystrix到底是什么？"></a>1、Hystrix到底是什么？</h3><p>在分布式系统中，每个服务都可能会调用很多其他服务，被调用的那些服务就是依赖服务，有的时候某些依赖服务出现故障也是很正常的。</p><p>Hystrix可以让我们在分布式系统中对服务间的调用进行控制，加入一些调用延迟或者依赖故障的容错机制。</p><p>Hystrix通过将依赖服务进行资源隔离，进而组织某个依赖服务出现故障的时候，这种故障在整个系统所有的依赖服务调用中进行蔓延，同时Hystrix还提供故障时的fallback降级机制</p><p>总而言之，Hystrix通过这些方法帮助我们提升分布式系统的可用性和稳定性</p><h3 id="2、Hystrix的历史"><a href="#2、Hystrix的历史" class="headerlink" title="2、Hystrix的历史"></a>2、Hystrix的历史</h3><p>hystrix，就是一种高可用保障的一个框架，类似于spring（ioc，mvc），mybatis，activiti，lucene，框架，预先封装好的为了解决某个特定领域的特定问题的一套代码库</p><p>框架，用了框架之后，来解决这个领域的特定的问题，就可以大大减少我们的工作量，提升我们的工作质量和工作效率，框架</p><p>hystrix，高可用性保障的一个框架</p><p>Netflix（可以认为是国外的优酷或者爱奇艺之类的视频网站），API团队从2011年开始做一些提升系统可用性和稳定性的工作，Hystrix就是从那时候开始发展出来的。</p><p>在2012年的时候，Hystrix就变得比较成熟和稳定了，Netflix中，除了API团队以外，很多其他的团队都开始使用Hystrix。</p><p>时至今日，Netflix中每天都有数十亿次的服务间调用，通过Hystrix框架在进行，而Hystrix也帮助Netflix网站提升了整体的可用性和稳定性</p><h3 id="3、初步看一看Hystrix的设计原则是什么？"><a href="#3、初步看一看Hystrix的设计原则是什么？" class="headerlink" title="3、初步看一看Hystrix的设计原则是什么？"></a>3、初步看一看Hystrix的设计原则是什么？</h3><p>hystrix为了实现高可用性的架构，设计hystrix的时候，一些设计原则是什么？？？</p><p>（1）对依赖服务调用时出现的调用延迟和调用失败进行控制和容错保护</p><p>（2）在复杂的分布式系统中，阻止某一个依赖服务的故障在整个系统中蔓延，服务A-&gt;服务B-&gt;服务C，服务C故障了，服务B也故障了，服务A故障了，整套分布式系统全部故障，整体宕机</p><p>（3）提供fail-fast（快速失败）和快速恢复的支持</p><p>（4）提供fallback优雅降级的支持</p><p>（5）支持近实时的监控、报警以及运维操作</p><p>调用延迟+失败，提供容错<br>阻止故障蔓延<br>快速失败+快速恢复<br>降级<br>监控+报警+运维</p><p>完全描述了hystrix的功能，提供整个分布式系统的高可用的架构</p><h3 id="4、Hystrix要解决的问题是什么？"><a href="#4、Hystrix要解决的问题是什么？" class="headerlink" title="4、Hystrix要解决的问题是什么？"></a>4、Hystrix要解决的问题是什么？</h3><p>在复杂的分布式系统架构中，每个服务都有很多的依赖服务，而每个依赖服务都可能会故障</p><p>如果服务没有和自己的依赖服务进行隔离，那么可能某一个依赖服务的故障就会拖垮当前这个服务</p><p>举例来说，某个服务有30个依赖服务，每个依赖服务的可用性非常高，已经达到了99.99%的高可用性</p><p>那么该服务的可用性就是99.99%的30次方，也就是99.7%的可用性</p><p>99.7%的可用性就意味着3%的请求可能会失败，因为3%的时间内系统可能出现了故障不可用了</p><p>对于1亿次访问来说，3%的请求失败，也就意味着300万次请求会失败，也意味着每个月有2个小时的时间系统是不可用的</p><p>在真实生产环境中，可能更加糟糕</p><p>上面也就是说，即使你每个依赖服务都是99.99%高可用性，但是一旦你有几十个依赖服务，还是会导致你每个月都有几个小时是不可用的</p><p>画图分析说，当某一个依赖服务出现了调用延迟或者调用失败时，为什么会拖垮当前这个服务？以及在分布式系统中，故障是如何快速蔓延的？</p><p><img src="/2020/01/01/1-Hystrix%E7%9F%A5%E5%A4%9A%E5%B0%91/430e908e-a25c-4ee3-8280-ecebf71cac28.png" alt></p><h3 id="5、再看Hystrix的更加细节的设计原则是什么？"><a href="#5、再看Hystrix的更加细节的设计原则是什么？" class="headerlink" title="5、再看Hystrix的更加细节的设计原则是什么？"></a>5、再看Hystrix的更加细节的设计原则是什么？</h3><p>（1）阻止任何一个依赖服务耗尽所有的资源，比如tomcat中的所有线程资源</p><p>（2）避免请求排队和积压，采用限流和fail fast来控制故障</p><p>（3）提供fallback降级机制来应对故障</p><p>（4）使用资源隔离技术，比如bulkhead（舱壁隔离技术），swimlane（泳道技术），circuit breaker（短路技术），来限制任何一个依赖服务的故障的影响</p><p>（5）通过近实时的统计/监控/报警功能，来提高故障发现的速度</p><p>（6）通过近实时的属性和配置热修改功能，来提高故障处理和恢复的速度</p><p>（7）保护依赖服务调用的所有故障情况，而不仅仅只是网络故障情况</p><p>调用这个依赖服务的时候，client调用包有bug，阻塞，等等，依赖服务的各种各样的调用的故障，都可以处理</p><h3 id="6、Hystrix是如何实现它的目标的？"><a href="#6、Hystrix是如何实现它的目标的？" class="headerlink" title="6、Hystrix是如何实现它的目标的？"></a>6、Hystrix是如何实现它的目标的？</h3><p>（1）通过HystrixCommand或者HystrixObservableCommand来封装对外部依赖的访问请求，这个访问请求一般会运行在独立的线程中，资源隔离</p><p>（2）对于超出我们设定阈值的服务调用，直接进行超时，不允许其耗费过长时间阻塞住。这个超时时间默认是99.5%的访问时间，但是一般我们可以自己设置一下</p><p>（3）为每一个依赖服务维护一个独立的线程池，或者是semaphore，当线程池已满时，直接拒绝对这个服务的调用</p><p>（4）对依赖服务的调用的成功次数，失败次数，拒绝次数，超时次数，进行统计</p><p>（5）如果对一个依赖服务的调用失败次数超过了一定的阈值，自动进行熔断，在一定时间内对该服务的调用直接降级，一段时间后再自动尝试恢复</p><p>（6）当一个服务调用出现失败，被拒绝，超时，短路等异常情况时，自动调用fallback降级机制</p><p>（7）对属性和配置的修改提供近实时的支持</p><p>画图分析，对依赖进行资源隔离后，如何避免依赖服务调用延迟或失败导致当前服务的故障</p><p><img src="/2020/01/01/1-Hystrix%E7%9F%A5%E5%A4%9A%E5%B0%91/2ba73e70-9465-4327-bb9a-e1a9a487646a.png" alt></p><h2 id="3-电商网站的商品详情页缓存服务业务背景以及框架结构说明"><a href="#3-电商网站的商品详情页缓存服务业务背景以及框架结构说明" class="headerlink" title="3. 电商网站的商品详情页缓存服务业务背景以及框架结构说明"></a>3. 电商网站的商品详情页缓存服务业务背景以及框架结构说明</h2><p>大背景：电商网站，首页，商品详情页，搜索结果页，广告页，促销活动，购物车，订单系统，库存系统，物流系统</p><p>小背景：商品详情页，如何用最快的结果将商品数据填充到一个页面中，然后将页面显示出来</p><p>分布式系统：商品详情页，缓存服务，+底层源数据服务，商品信息服务，店铺信息服务，广告信息服务，推荐信息服务，综合起来组成一个分布式的系统</p><h3 id="1、电商网站的商品详情页系统架构"><a href="#1、电商网站的商品详情页系统架构" class="headerlink" title="1、电商网站的商品详情页系统架构"></a>1、电商网站的商品详情页系统架构</h3><p>（1）小型电商网站的商品详情页系统架构</p><p>（2）大型电商网站的商品详情页系统架构</p><p>（3）页面模板</p><p>举个例子</p><p>将数据动态填充/渲染到一个html模板中，是什么意思呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">    &lt;title&gt;#&#123;name&#125;的页面&lt;&#x2F;title&gt;</span><br><span class="line">    &lt;body&gt;</span><br><span class="line">        商品的价格是：#&#123;price&#125;</span><br><span class="line">        商品的介绍：#&#123;description&#125;</span><br><span class="line">    &lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure><p>上面这个就可以认为是一个页面模板，里面的很多内容是不确定的，#{name}，#{price}，#{description}，这都是一些模板脚本，不确定里面的值是什么？</p><p>将数据填充/渲染到html模板中，是什么意思呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;iphone7 plus（玫瑰金+32G）&quot;,</span><br><span class="line">    &quot;price&quot;: 5599.50</span><br><span class="line">    &quot;description&quot;: &quot;这个手机特别好用。。。。。。&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&lt;html&gt;</span><br><span class="line">    &lt;title&gt;iphone7 plus（玫瑰金+32G）的页面&lt;&#x2F;title&gt;</span><br><span class="line">    &lt;body&gt;</span><br><span class="line">        商品的价格是：5599.50</span><br><span class="line">        商品的介绍：这个手机特别好用。。。。。。</span><br><span class="line">    &lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure><p>上面这个就是一份填充好数据的一个html页面</p><h3 id="2、缓存服务"><a href="#2、缓存服务" class="headerlink" title="2、缓存服务"></a>2、缓存服务</h3><p>缓存服务，订阅一个MQ的消息变更，如果有消息变更的话，那么就会发送一个网络请求，调用一个底层的对应的源数据服务的接口，去获取变更后的数据</p><p>将获取到的变更后的数据填充到分布式的redis缓存中去</p><p>高可用这一块儿，最可能出现说可用性不高的情况，是什么呢？就是说，在接收到消息之后，可能在调用各种底层依赖服务的接口时，会遇到各种不稳定的情况</p><p>比如底层服务的接口调用超时，200ms，2s都没有返回; 底层服务的接口调用失败，比如说卡了500ms之后，返回一个报错</p><p>在分布式系统中，对于这种大量的底层依赖服务的调用，就可能会出现各种可用性的问题，一旦没有处理好的话</p><p>可能就会导致缓存服务自己本身会挂掉，或者故障掉，就会导致什么呢？不可以对外提供服务，严重情况下，甚至会导致说整个商品详情页显示不出来</p><p>缓存服务接收到变更消息后，去调用各个底层依赖服务时的高可用架构的实现</p><h3 id="3、框架结构"><a href="#3、框架结构" class="headerlink" title="3、框架结构"></a>3、框架结构</h3><p><strong>大型电商网站的详情页系统的架构</strong></p><p><img src="/2020/01/01/1-Hystrix%E7%9F%A5%E5%A4%9A%E5%B0%91/8f197a0b-d589-4320-b220-81f744a29a42.png" alt></p><p><strong>小型电商网站的静态化方案</strong></p><p><img src="/2020/01/01/1-Hystrix%E7%9F%A5%E5%A4%9A%E5%B0%91/56054641-b5a0-4509-b545-a50049446cc0.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;一般来说，互联网的面试，一般都会考察你，什么是分布式系统，高并发，简单的高可用问题。限流、熔断、降级，在分布式的系统架构中，微服务架构中，其实都是最常见、基础和简单的保障系统高可用的手法。dubbo去开发了，spring cloud去开发了，在这个系统的接口调用中，我们是用hystrix去实现一整套的高可用保障机制，基于hystrix去做了限流、熔断和降级。&lt;/p&gt;
&lt;p&gt;hystrix是国外的netflix开源的，netflix是国外很大的视频网站，系统非常复杂，微服务架构，多达几千个服务，为自己的场景，经过大量的工业验证，线上生产环境的实践，产出和开源了高可用相关的一个框架，熔断框架，hystrix。&lt;/p&gt;
&lt;p&gt;hystrix未来或已经成为国内的高可用的限流、熔断和降级这一块的事实上的标准，spring cloud微服务框架，就是集成了hystrix来做微服务架构中的限流、降级和熔断的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Hystrix" scheme="http://JavaSsun.github.io/categories/Hystrix/"/>
    
      <category term="面试" scheme="http://JavaSsun.github.io/categories/Hystrix/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/categories/Hystrix/%E9%9D%A2%E8%AF%95/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="面试" scheme="http://JavaSsun.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
      <category term="Hystrix" scheme="http://JavaSsun.github.io/tags/Hystrix/"/>
    
  </entry>
  
  <entry>
    <title>25-Nginx变量原理-应用</title>
    <link href="http://javassun.github.io/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/"/>
    <id>http://javassun.github.io/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/</id>
    <published>2019-12-13T12:10:53.000Z</published>
    <updated>2020-05-14T11:53:59.342Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p><font color="red">学习来源：极客时间-Nginx核心知识100讲，本人购买课程后依据视频讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Nginx中变量是一个非常强大的工具，可以在nginx.conf配置文件中，通过变量去修改各个模块处理请求的方式。因此，<strong>变量是一个解耦工具</strong>。它同样可以在 openresty 中 lua 语言中大有用处。</p><a id="more"></a><h2 id="变量原理"><a href="#变量原理" class="headerlink" title="变量原理"></a>变量原理</h2><h3 id="变量的提供模块与使用模块"><a href="#变量的提供模块与使用模块" class="headerlink" title="变量的提供模块与使用模块"></a>变量的提供模块与使用模块</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/d4564092-81ea-4d1e-a6e6-55b113cd6724.jpg" alt></p><p><strong>流程：</strong></p><p><font color="red">提供变量名的模块</font></p><p>Nginx启动后，发现当前是一个HTTP模块。它其中有一个 <strong>preconfiguration回调方法</strong>，如 realip模块的 realip变量等等。它定义的是一对值，即<strong>变量名</strong>和<strong>解析出当前变量名的方法</strong>。如给出输入（如http请求头部中的名称），输出就是对应的值。此处<strong>定义规则</strong>。</p><p><font color="red">使用变量名的模块</font></p><p>通过变量名完成解耦。</p><p><strong>两个模块各自专注于自己的职责</strong></p><h3 id="变量的特性"><a href="#变量的特性" class="headerlink" title="变量的特性"></a>变量的特性</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/16c0d0ee-eea1-4e84-b72f-0d99716a1a82.jpg" alt></p><h3 id="存放变量的哈希表"><a href="#存放变量的哈希表" class="headerlink" title="存放变量的哈希表"></a>存放变量的哈希表</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/a51c5b96-8f90-4db7-8a3c-5be8fc35c05b.jpg" alt></p><h2 id="HTTP框架提供的请求有关变量"><a href="#HTTP框架提供的请求有关变量" class="headerlink" title="HTTP框架提供的请求有关变量"></a>HTTP框架提供的请求有关变量</h2><p>除许多HTTP模块会提供变量外，Nginx的HTTP框架也提供了大量的变量，这些变量不需要编译、引入新的HTTP模块，而且框架提供的变量往往反映了用户发来的请求时被Nginx处理的流程与细节。因此，熟悉Nginx框架提供的每一个变量的用法是非常有必要的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并include到 nginx.conf配置文件中</span><br><span class="line"></span><br><span class="line">vim var.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/780053e8-ebbd-4515-a257-109fdd50ba0f.jpg" alt><br><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/a8dd34c5-839c-4201-a384-06a439b4a88f.jpg" alt></p><p>为了演示有些变量在不同的阶段时不同的，添加了日志文件。return中，将相关联的变量以一行显示，以逗号分隔。冒号前是变量名，冒号后是变量值。</p><p>做一次访问</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/_u6355_u83B7.PNG" alt></p><h3 id="HTTP框架提供的变量"><a href="#HTTP框架提供的变量" class="headerlink" title="HTTP框架提供的变量"></a>HTTP框架提供的变量</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/535214ab-1e4a-40d3-a006-333711c9259c.jpg" alt></p><h3 id="HTTP请求有关变量"><a href="#HTTP请求有关变量" class="headerlink" title="HTTP请求有关变量"></a>HTTP请求有关变量</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/7b486912-8cd7-47a3-89c7-48843fd52723.jpg" alt></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/c9fdf904-3f7d-416a-b4be-e49b2f4a33c4.jpg" alt></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/e2070844-a852-4cf3-978b-4b27ba67365b.jpg" alt></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/a8abd28c-0ef9-4070-98f4-914b88414852.jpg" alt></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/a43e65e2-6f41-47f0-8f3e-a62e9dc13303.jpg" alt></p><h2 id="HTTP框架提供的其他变量"><a href="#HTTP框架提供的其他变量" class="headerlink" title="HTTP框架提供的其他变量"></a>HTTP框架提供的其他变量</h2><h3 id="TCP连接有关的变量"><a href="#TCP连接有关的变量" class="headerlink" title="TCP连接有关的变量"></a>TCP连接有关的变量</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/d920d0da-2705-45e4-92d3-7591b589a20f.jpg" alt></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/962047ba-83c2-416d-87a1-8a5b26102403.jpg" alt></p><h3 id="Nginx处理请求过程中产生的变量"><a href="#Nginx处理请求过程中产生的变量" class="headerlink" title="Nginx处理请求过程中产生的变量"></a>Nginx处理请求过程中产生的变量</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/e25f6442-1682-4d3e-acf1-8fe712fc7601.jpg" alt></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/b7821b26-bd21-4930-b315-96c7b4f4a582.jpg" alt></p><h3 id="发送HTTP响应时相关变量"><a href="#发送HTTP响应时相关变量" class="headerlink" title="发送HTTP响应时相关变量"></a>发送HTTP响应时相关变量</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/_u6355_u83B71589440450988.PNG" alt></p><h3 id="Nginx系统变量"><a href="#Nginx系统变量" class="headerlink" title="Nginx系统变量"></a>Nginx系统变量</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/14088861-0f90-4cba-ba31-ee728fc9ea81.jpg" alt></p><h2 id="变量防盗链"><a href="#变量防盗链" class="headerlink" title="变量防盗链"></a>变量防盗链</h2><h3 id="简单有效的防盗链手段：referer模块"><a href="#简单有效的防盗链手段：referer模块" class="headerlink" title="简单有效的防盗链手段：referer模块"></a>简单有效的防盗链手段：referer模块</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/52fc1d8f-49eb-4f0a-9260-cde0e218ccd5.jpg" alt></p><h3 id="referer模块的指令"><a href="#referer模块的指令" class="headerlink" title="referer模块的指令"></a>referer模块的指令</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/a01e89ed-9426-420a-98b8-c9255c31d197.jpg" alt></p><h3 id="valid-referers-指令"><a href="#valid-referers-指令" class="headerlink" title="valid_referers 指令"></a>valid_referers 指令</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/e54ac723-8063-4e30-92fc-ae1e90441ddd.jpg" alt></p><p><strong>问题</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/6deb74a6-c5ac-4d39-b36c-32af38a57191.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并include到 nginx.conf中</span><br><span class="line"></span><br><span class="line">vim referer.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/746f4c69-3700-40f1-b5c1-b2ed3c4b9c5c.jpg" alt></p><p>将带测验8个请求放入 testurl中</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/8449207d-4d7c-4da3-b7a8-e161e01c19b2.jpg" alt></p><p><strong>第一个：403 没有匹配上</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/d12d9d27-044e-4f2a-9bd1-ca85d432b590.jpg" alt></p><p><strong>第二个：valid,匹配上了 *.taohui.pub</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/5d42d29d-4018-41ac-84e6-1005638b2f3e.jpg" alt></p><p><strong>第三个：valid，以内没有referer，匹配上了blocked</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/af7b6ab0-34a0-4a1d-a4f5-df816de7855f.jpg" alt></p><p><strong>第四个：valid，匹配上了 none</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/c1f5564a-ef69-45d9-af0e-7a0c27306f77.jpg" alt></p><p><strong>第五个：403 没有匹配上<a href="http://www.taohui.tech" target="_blank" rel="noopener">www.taohui.tech</a></strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/a7a7df59-3678-49ca-a876-6c2f54f8d166.jpg" alt></p><p><strong>第六个：valid，匹配上了 server_name</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/7f671a43-86f3-47e5-99b2-8ec29753c44b.jpg" alt></p><p><strong>第七个：403 没有配置与baidu有关的</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/f3f2d117-77c7-4e6e-b9dd-7664cdcd4f80.jpg" alt></p><p><strong>第八个：匹配上了正则表达式</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/a15fd9ff-cf2e-4ce8-ac7f-94b6d6db4886.jpg" alt></p><h2 id="为复杂业务生成新的变量：map模块"><a href="#为复杂业务生成新的变量：map模块" class="headerlink" title="为复杂业务生成新的变量：map模块"></a>为复杂业务生成新的变量：map模块</h2><p>很多时候，直接使用某些变量的值做逻辑判断是比较困难的，而Map模块提供了可根据1个或多个变量组合成的值结果做判断，进而生成新的变量。再判断新的变量值做逻辑判断。</p><h3 id="通过映射新变量提供更多的可能性：map模块"><a href="#通过映射新变量提供更多的可能性：map模块" class="headerlink" title="通过映射新变量提供更多的可能性：map模块"></a>通过映射新变量提供更多的可能性：map模块</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/85a00cd6-ef9c-4b74-9843-d3add7d242c5.jpg" alt></p><h3 id="map模块的指令"><a href="#map模块的指令" class="headerlink" title="map模块的指令"></a>map模块的指令</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/dd78cd48-64fa-4fad-ac21-41d2f7184f58.jpg" alt></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/65abe6b5-434d-4b47-bc9f-ac482844cf51.jpg" alt></p><p><strong>问题：</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/028fd1ec-f458-4ec8-a901-cc4ce08d150a.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并include到 nginx.conf中</span><br><span class="line"></span><br><span class="line">vim map.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/_u6355_u83B71589442692006.PNG" alt></p><p>将待检测url放入 testurl，方便拷贝访问</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/50eed808-e466-43c3-af8f-b744b4f33625.jpg" alt></p><p>访问 map.taohui.org.cn ，匹配上了 泛域名正则、前缀、后缀。而前缀最优先，所以返回 2:0</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/6e049513-0650-42b2-a1e7-ccca35715a47.jpg" alt></p><p>访问 map.tao123.org.cn，只有正则表达式匹配上 1:0</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/8f07ad7f-d832-45bd-b698-5fa0567236e4.jpg" alt></p><p>访问 map.taohui.tech， 完全匹配 与  后缀匹配 都行，但是完全匹配优先级最高，所以 3:0</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/bf57c2ab-44d3-4e0c-a1c6-af7883535d12.jpg" alt></p><h2 id="通过变量指定少量用户实现AB测试：split-clients模块"><a href="#通过变量指定少量用户实现AB测试：split-clients模块" class="headerlink" title="通过变量指定少量用户实现AB测试：split_clients模块"></a>通过变量指定少量用户实现AB测试：split_clients模块</h2><p>该模块可以根据变量的值按照百分比方式生成新的变量。</p><h3 id="AB测试：split-clients模块"><a href="#AB测试：split-clients模块" class="headerlink" title="AB测试：split_clients模块"></a>AB测试：split_clients模块</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/_u6355_u83B71589443194182.PNG" alt></p><h3 id="split-clients-模块指令"><a href="#split-clients-模块指令" class="headerlink" title="split_clients 模块指令"></a>split_clients 模块指令</h3><p><strong>AB测试：产品推出的功能不太确定用户是否接受，所以推出多个类似功能，让某一个百分比用户去尝试某一类功能，看大家的反馈来决定最终使用哪一个功能的版本。关键：确保按照某一定的百分比决定用户的行为。</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/3b3fc65c-30fd-47b3-82cd-83d467f82da1.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并include到 nginx.conf中</span><br><span class="line"></span><br><span class="line">vim map.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/5f8c251c-a7e5-4e44-a908-c1bfe51b26b9.jpg" alt></p><p>上述问题是已经超过100%了。此时重启会发现，重启失败。</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/485b6f96-2886-43a2-a5bf-4f413c9856d4.jpg" alt></p><p>将 40% 注释掉。再次访问，server-location中额 $variant 取自 split_clients 中的配置项。而他又取决于$(http_testcli)经算法改造后的值，看这个值落在那个区域，就返回后面对应的值。</p><p><strong>testcli: xxx</strong>，xxx值随便填写，<br><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/_u6355_u83B71589443935577.PNG" alt></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/_u6355_u83B71589444022423.PNG" alt></p><h2 id="根据IP地址范围的匹配生成新变量：geo模块"><a href="#根据IP地址范围的匹配生成新变量：geo模块" class="headerlink" title="根据IP地址范围的匹配生成新变量：geo模块"></a>根据IP地址范围的匹配生成新变量：geo模块</h2><p>可根据子网掩码来生成新变量。</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/208fe8ff-79ac-4ae0-9568-9b650664ea54.jpg" alt></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/a751238f-27ba-4fae-b8ae-a7b5c5e6980e.jpg" alt></p><p><strong>geo模块示例</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/9b9883bc-c88a-48d8-9017-54b3afbb84bd.jpg" alt></p><p><strong>演示</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并include到 nginx.conf中</span><br><span class="line"></span><br><span class="line">vim map.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/9a632337-6e6d-48c1-b019-c3f9b08daf6a.jpg" alt></p><p>访问<br><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/_u6355_u83B71589449028238.PNG" alt></p><h2 id="使用变量获得用户的地理位置：geoip模块"><a href="#使用变量获得用户的地理位置：geoip模块" class="headerlink" title="使用变量获得用户的地理位置：geoip模块"></a>使用变量获得用户的地理位置：geoip模块</h2><p>可以根据IP地址库自动的计算出IP地址找到相应的地理位置。</p><h3 id="基于MaxMind数据库从客户端地址获取变量：geoip模块"><a href="#基于MaxMind数据库从客户端地址获取变量：geoip模块" class="headerlink" title="基于MaxMind数据库从客户端地址获取变量：geoip模块"></a>基于MaxMind数据库从客户端地址获取变量：geoip模块</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/_u6355_u83B71589450542232.PNG" alt></p><h3 id="geoip-country指令提供的变量"><a href="#geoip-country指令提供的变量" class="headerlink" title="geoip_country指令提供的变量"></a>geoip_country指令提供的变量</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/557efae0-fbc2-4a0f-be6f-cf302b8ba368.jpg" alt></p><h3 id="geoip-city指令提供的变量"><a href="#geoip-city指令提供的变量" class="headerlink" title="geoip_city指令提供的变量"></a>geoip_city指令提供的变量</h3><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/52203507-2fba-4aa3-9a1c-f52fbf4903ff.jpg" alt></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/212dbcb2-ddaa-4b31-b1a6-3e78e9f4f2ad.jpg" alt></p><p><a href="https://dev.maxmind.com/geoip/legacy/downloadable/" target="_blank" rel="noopener">MaxMind</a>网址，因为Nginx使用C语言，所以选中C语言的GitHub，进行下载。</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/7930ddd0-47f0-4e0e-b982-c81bca70c522.png" alt></p><p><a href="https://github.com/maxmind/geoip-api-c" target="_blank" rel="noopener">Github下载zip文件</a></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/6793d729-e928-47a5-b427-3920b0c71f28.png" alt></p><p><strong>演示</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/d07ee523-b404-4c4b-ab54-24c96cbb361f.jpg" alt></p><p>编译进nginx后</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并include到 nginx.conf中</span><br><span class="line"></span><br><span class="line">vim map.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/e6863285-196c-4e7d-af76-e8df4f44fb06.jpg" alt></p><p>在 <a href="http://www.goubanjia.com/" target="_blank" rel="noopener">http://www.goubanjia.com/</a>选择一些IP来做测试。</p><p>广东IP</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/_u6355_u83B71589453163330.PNG" alt></p><p>纽约IP</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/_u6355_u83B71589453218372.PNG" alt></p><h2 id="对客户端使用keepalive提升连接效率"><a href="#对客户端使用keepalive提升连接效率" class="headerlink" title="对客户端使用keepalive提升连接效率"></a>对客户端使用keepalive提升连接效率</h2><p>此处是 HTTP协议中的Keepalive，不是TCP协议中的Keepalive</p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/86c74fbd-439f-434f-b50c-8e9f25123974.jpg" alt></p><p><strong>语法：</strong></p><p><img src="/2019/12/13/25-Nginx%E5%8F%98%E9%87%8F%E5%8E%9F%E7%90%86-%E5%BA%94%E7%94%A8/2205cb77-407c-4672-8c3d-682654a9a5a4.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-Nginx核心知识100讲，本人购买课程后依据视频讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Nginx中变量是一个非常强大的工具，可以在nginx.conf配置文件中，通过变量去修改各个模块处理请求的方式。因此，&lt;strong&gt;变量是一个解耦工具&lt;/strong&gt;。它同样可以在 openresty 中 lua 语言中大有用处。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Nginx" scheme="http://JavaSsun.github.io/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="http://JavaSsun.github.io/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>24-详解HTTP过滤模块</title>
    <link href="http://javassun.github.io/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/"/>
    <id>http://javassun.github.io/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/</id>
    <published>2019-12-12T11:10:53.000Z</published>
    <updated>2020-05-14T11:51:57.407Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p><font color="red">学习来源：极客时间-Nginx核心知识100讲，本人购买课程后依据视频讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上文介绍了HTTP模块的11个阶段，在<strong>content</strong>阶段会生成返回给用户的响应内容，这部分响应内容还需要再做加工处理的，这就需要用到<strong>HTTP过滤模块</strong>，因此，它是处于 <strong>Log</strong>阶段之前，<strong>content</strong>阶段之后去介入请求的处理。</p><a id="more"></a><h2 id="HTTP过滤模块的调用流程"><a href="#HTTP过滤模块的调用流程" class="headerlink" title="HTTP过滤模块的调用流程"></a>HTTP过滤模块的调用流程</h2><h3 id="HTTP过滤模块位置"><a href="#HTTP过滤模块位置" class="headerlink" title="HTTP过滤模块位置"></a>HTTP过滤模块位置</h3><p>image_filter resize 长 宽；（此处图片略有问题）</p><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/_u6355_u83B7.PNG" alt></p><p><strong>content阶段的 static模块生成响应内容后，到达 header过滤模块的 image_filter，再到 gzip压缩，二者不可翻转。</strong></p><h3 id="返回响应-加工响应内容"><a href="#返回响应-加工响应内容" class="headerlink" title="返回响应-加工响应内容"></a>返回响应-加工响应内容</h3><p>查看 Nginx_module.c数组中内容，也是如下图一样，由下往上看，先被下面的过滤模块处理，在推送到上方的过滤模块。</p><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/_u6355_u83B71589376248179.PNG" alt></p><h2 id="用过滤模块更改响应中的字符串-sub模块"><a href="#用过滤模块更改响应中的字符串-sub模块" class="headerlink" title="用过滤模块更改响应中的字符串-sub模块"></a>用过滤模块更改响应中的字符串-sub模块</h2><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/b3d6ce9b-3543-4171-8024-f6a6365fe8e0.jpg" alt></p><h3 id="sub模块指令"><a href="#sub模块指令" class="headerlink" title="sub模块指令"></a>sub模块指令</h3><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/f13609e6-c454-4416-a81f-fd26a6238b3b.jpg" alt></p><ul><li><p><strong>sub_filter string replacement，将响应中的string换成replacement</strong></p></li><li><p><strong>sub_filter_last_modified：off,是否同时返回上次未修改过的旧内容（默认是不返回旧内容）</strong></p></li><li><p><strong>sub_filter_once：on  只修改 1次，如果改为off，则是扫描整个body内容，全文修改</strong></p></li><li><p><strong>sub_filter_types mimie-type，只针对 mimie-type类型的响应进行替换，默认是 text/html</strong></p></li></ul><h3 id="演示"><a href="#演示" class="headerlink" title="演示"></a>演示</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，include到 nginx.conf中</span><br><span class="line">vim sub.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/be46d0e3-7da9-4c95-be47-dd161c2736a9.jpg" alt></p><p>首先，将配置全部注释，访问域名：端口，得到的是一个index.html欢迎页面。</p><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/312e41fc-b9f1-4657-b13f-2874fbeee811.jpg" alt></p><p>看到 nginx.org 这个超链接中，显示的是<strong>nginx.org</strong>文字，将其替换掉。<strong>替换时忽略大小写</strong>。</p><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/36a19f55-6752-4a68-8bd3-0440f6e09b1d.jpg" alt></p><p>再次访问，发现文字没有变，但是超链接已经变了。（因为开启了只替换一次的功能，所以只替换了超链接，没有替换文字）</p><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/7770d995-813c-4a6c-a224-6c00a5517ff7.jpg" alt></p><p>同时响应头中没有返回<strong>last-modified</strong>有关的内容</p><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/76b8d1d8-ef27-4e57-b0a3-f1d3c16a70e0.jpg" alt></p><p>再次修改配置项，将 once 改为 off , last_modified 改为 on</p><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/e45f5291-7c8c-4116-9ae0-1a107a67333a.jpg" alt></p><p>访问时会发现被替换掉，且有last-modified</p><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/e5feba71-f287-4ba6-bf46-5dba4f3927c0.jpg" alt></p><h2 id="用过滤模块在http响应前后添加内容-addition模块"><a href="#用过滤模块在http响应前后添加内容-addition模块" class="headerlink" title="用过滤模块在http响应前后添加内容-addition模块"></a>用过滤模块在http响应前后添加内容-addition模块</h2><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/6f8bae7e-41c0-474a-93d1-a1804c570499.jpg" alt></p><h3 id="addition模块指令"><a href="#addition模块指令" class="headerlink" title="addition模块指令"></a>addition模块指令</h3><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/20fa76fe-2f13-4024-a514-4061c47c44b2.jpg" alt></p><p>add_before|after_body uri：添加的URI是<strong>子请求</strong>，让Nginx去访问这个URI，将响应内容添加到body前后。</p><h3 id="演示-1"><a href="#演示-1" class="headerlink" title="演示"></a>演示</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，include到 nginx.conf中</span><br><span class="line">vim addition.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/2cced630-36cc-417e-a563-40c1d92ebb95.jpg" alt></p><p>先访问一个存在的文件 a.txt</p><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/85d9e2c2-7f2d-4919-baf2-59a045663850.jpg" alt></p><p>修改 addition.conf ，将3个注释解开，再次访问</p><p><img src="/2019/12/12/24-%E8%AF%A6%E8%A7%A3HTTP%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97/41aacb64-baf1-4429-a122-0cae9ba421c1.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-Nginx核心知识100讲，本人购买课程后依据视频讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;上文介绍了HTTP模块的11个阶段，在&lt;strong&gt;content&lt;/strong&gt;阶段会生成返回给用户的响应内容，这部分响应内容还需要再做加工处理的，这就需要用到&lt;strong&gt;HTTP过滤模块&lt;/strong&gt;，因此，它是处于 &lt;strong&gt;Log&lt;/strong&gt;阶段之前，&lt;strong&gt;content&lt;/strong&gt;阶段之后去介入请求的处理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Nginx" scheme="http://JavaSsun.github.io/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="http://JavaSsun.github.io/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>23-详解HTTP请求的11个阶段</title>
    <link href="http://javassun.github.io/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/"/>
    <id>http://javassun.github.io/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/</id>
    <published>2019-12-11T11:10:53.000Z</published>
    <updated>2020-05-14T11:49:45.413Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p><font color="red">学习来源：极客时间-Nginx核心知识100讲，本人购买课程后依据视频讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>除<strong>HTTP过滤模块</strong> 和 <strong>只提供变量的Nginx模块</strong>之外，所有的HTTP模块必须从Nginx定义好的<strong>11</strong>个阶段进行请求处理。每一个HTTP模块何时生效，有没有机会生效，都要看一个请求究竟处理到哪一个阶段。Nginx是如何定义这11个处理阶段的呢？</p><h2 id="HTTP请求处理时的11个阶段"><a href="#HTTP请求处理时的11个阶段" class="headerlink" title="HTTP请求处理时的11个阶段"></a>HTTP请求处理时的11个阶段</h2><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/_u6355_u83B7.PNG" alt></p><a id="more"></a><ul><li><p><strong>post_read</strong>：read到Header内容，刚读完HTTP头部，没有做任何加工之前的原始数据。涉及到 <font color="red"><strong>realip模块</strong></font>。</p></li><li><p><strong>server_rewrite、rewrite</strong>：涉及到<strong>rewrite模块</strong>.</p></li><li><p><strong>find_config</strong>：Nginx框架会做，其实是在做location的匹配。</p></li><li><p><strong>post_rewrite</strong>：即 rewrite之后，需要做的一些工作</p></li></ul><p><strong>Access有关的三个模块</strong>：确认访问权限的。（能不能访问）</p><ul><li><p><strong>preaccess</strong>：在access之前做一些处理。</p></li><li><p><strong>access</strong>：auth_basic（用户名密码），access（访问IP），auth_request(第三方授权等)</p></li><li><p><strong>post_access</strong>：在access之后做一些处理。</p></li></ul><p><strong>content有关的</strong></p><ul><li><p><strong>precontent</strong>：在处理content之前做一些处理。</p></li><li><p><strong>content</strong>：诸如一些方向代理等都是在这个阶段生效的。</p></li><li><p><strong>log</strong>：打印access日志的</p></li></ul><p><strong>所有的请求都是由上到下一个阶段一个阶段按序执行。</strong>在debug时可以清楚地看到。</p><h2 id="11个阶段的顺序处理"><a href="#11个阶段的顺序处理" class="headerlink" title="11个阶段的顺序处理"></a>11个阶段的顺序处理</h2><p>当一个HTTP请求进入到Nginx这11个阶段时，由于每一个阶段都可能有0-n个HTTP模块，如果某一个模块不再把HTTP请求向下传递，那么后面的模块是不会执行的。同一阶段中的多个模块，也不是每个模块都有机会执行到的，可能会有前面的模块把请求直接传递给下一个阶段的模块去处理。下面看一看HTTP模块顺序以及他们的处理流程。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/f2009d91-a832-44c0-bb11-cdb5ac1dd40c.jpg" alt></p><p><strong>每一个蓝色的模块都属于某一个阶段，这些模块是有序的</strong>。</p><p><strong>char *ngx_module_name[]</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/fe4091aa-9ac8-4596-895b-ed7041e5b2f5.jpg" alt></p><h3 id="顺序处理"><a href="#顺序处理" class="headerlink" title="顺序处理"></a>顺序处理</h3><p>顺序如何确定呢？可以去看 ngx_modules.c，即configure执行时，会用 with添加模块，这些都会出现在 ngx_module_name[]数组中，这些模块出现的顺序非常关键。</p><p>如 <strong>limit_req</strong> 与 <strong>limit_conn</strong>，二者同属于<strong>preaccess阶段</strong>，在数组中则是 limit_conn 先出现，limit_req后出现，但是对应于请求的处理时它们是相反的。<strong>一个HTTP请求，会先被 limit_req处理，再被limit_conn处理</strong>，假设这两个同时生效去阻止一个请求时，假设这两个返回值也不同，limit_req返回值是没有机会得到执行的，他已经先于limit_conn将请求结果返回给用户。</p><p><strong>灰色的是Nginx框架执行的，其他的第三方HTTP模块没有机会在此运行。</strong></p><h3 id="非顺序处理"><a href="#非顺序处理" class="headerlink" title="非顺序处理"></a>非顺序处理</h3><p>有些则是不会顺序执行的。如 access阶段，当某一个access模块满足，可以直接跳到 try_files模块。当content阶段index模块执行时有时会直接跳到log模块执行。</p><h2 id="postread阶段：获取真实客户端地址的realip模块"><a href="#postread阶段：获取真实客户端地址的realip模块" class="headerlink" title="postread阶段：获取真实客户端地址的realip模块"></a>postread阶段：获取真实客户端地址的realip模块</h2><p>它可以发现用户的真实IP地址，为后续模块的限速、限流等等功能提供了前提。</p><h3 id="如何拿到真实的用户IP地址？"><a href="#如何拿到真实的用户IP地址？" class="headerlink" title="如何拿到真实的用户IP地址？"></a>如何拿到真实的用户IP地址？</h3><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/17157206-ab2d-457a-8e29-331609170ff3.jpg" alt></p><p>TCP连接有一个四元组，根据一条连接的Source_IP就能够判断出用户的IP地址了，但是网络中存在许多反向代理，这又导致反向代理后与上游服务器又建立了一个新的TCP连接。因此上游服务器想通过TCP中的Source_IP获取用户原始IP地址，是不可能的。</p><p><strong>举例：</strong></p><p>在家里上网时，家里的路由器可能分配了一个<strong>内网IP 192.168.0.x</strong>，当通过运营商（电信可能给分配了一个<strong>公网的IP：115.204.33.1</strong>）去访问某一个网站时，先命中到它的<strong>CDN</strong>，这个网站使用CDN加速（如图片等），这个CDN如果还没有把我所访问的资源缓存时，它可能要去<strong>回源</strong>，又建立了一条新的连接，回源过程中可能进入到一个<strong>反向代理</strong>中（如服务器买在阿里云，可能会用<strong>阿里云的SLB</strong>），这个SLB又会去建立一个新的连接，到我购买的服务器的<strong>Nginx</strong>，因此，Nginx如果仅通过拿地址的话，只能拿到<strong>反向代理的IP地址（2.2.2.2）</strong>，反向代理之前的<strong>CDN的地址是1.1.1.1</strong>，其实我们要拿到的是用户的<strong>公网地址115.204.33.1.</strong>， 如果要做限速、并发连接控制，肯定是基于这个公网IP进行的。</p><p><strong>现在拿到的remote_addr是2.2.2.2，想要的是115.204.33.1，如何做到呢？</strong></p><p>通过 <strong>2</strong>、<strong>3</strong>即可做到。</p><ul><li><p><strong>HTTP头部中有 X-Forwarded-For用来传递IP，如CDN的IP地址是1.1.1.1，他又建立了一个新的到反向代理的连接，这个方向代理服务器收到的Header中，可能会存在 X-Forwarded-for 与 X-Real-IP，这个是CDN添加的。</strong></p></li><li><p><strong>X-Forwarded-For 与 X-Real-IP不同，X-Real-IP永远都是一个用户真实IP地址，而X-Forwarded-For则是累加的。如上图中反向代理到Nginx的连接中，加上了CDN的IP地址</strong></p></li></ul><h3 id="拿到用户真实IP地址如何使用？"><a href="#拿到用户真实IP地址如何使用？" class="headerlink" title="拿到用户真实IP地址如何使用？"></a>拿到用户真实IP地址如何使用？</h3><p>基于变量来解耦使用。根据我们在realip模块中配置的指令，<strong>realip模块</strong>会把从 <strong>X-Forwarded-For、X-Real-IP</strong>中获取到的用户真实IP地址去覆盖 binary_remote_addr、remote_addr这两个变量的值。而这两个变量原来指向的是直接与Nginx连接的客户端地址。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/1be2a418-5fc1-4400-9f52-4351644d8728.jpg" alt></p><h3 id="realip模块"><a href="#realip模块" class="headerlink" title="realip模块"></a>realip模块</h3><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/45c34dc4-a550-45ac-90bb-451c4f10798e.jpg" alt></p><h3 id="realip模块的指令"><a href="#realip模块的指令" class="headerlink" title="realip模块的指令"></a>realip模块的指令</h3><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/41eb8af6-6c20-4df5-a634-a0034257f583.jpg" alt></p><p>real_ip_recursive：环回地址，默认是关闭的，当它打开时，他会将X-Forwarded-For中，最后的那个地址如果是和客户端地址相同，就会赔pass掉，去取上一个地址。</p><p><strong>例子：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">需要自己添加realip.con配置，并且include到nginx.conf中</span><br><span class="line">vim realip.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/_u6355_u83B71589215977643.PNG" alt></p><p>此处的server_name 用的是 realip_.taohui.tech;<br>因为当前所在的机器是 116.62.160.193，所以这个测试是不会跨服务器的，本机访问，所以将本机设置为可信地址（set_real_ip_from 116.62.160.193;）没有用它的默认配置（ real_ip_header X-Real-IP;），而是重新作了配置（real_ip_header X-Forwarded-For;）环回地址用了默认 off ，对于这样的请求，返回 remote_addr 的地址。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -H &#39;X-Forwarded-For: 1.1.1.1,116.62.160.193&#39; realip taohui.tech</span><br><span class="line"></span><br><span class="line">-H 可以对我的请求中添加一个Header，Header中放了两个IP，一个是1.1.1.1（模拟上一个对端地址），另一个是116.62.160.193；</span><br></pre></td></tr></table></figure><p>返回的 116.62.160.193</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/e52cfd9f-d514-40f6-9aca-2f0226969883.jpg" alt></p><p>如果开启了环回地址 即为 on，Nginx做一次 realod，再次访问，因为我们最后一个地址是本机地址，出发了环回地址被pass掉，发现变为上一个对端地址 1.1.1.1</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/789f10ab-1a2c-4646-b6c1-0d7d5f73f356.jpg" alt></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>以上介绍了 post_read阶段中的realip模块，因为它处于的阶段，可以拿到没有加工过的X-Forwarded-For或X-Real-IP中的用户地址，因为后续的很多模块会去修改 X-Forwarded-For中头部的值。</p><h2 id="rewrite阶段：rewrite模块"><a href="#rewrite阶段：rewrite模块" class="headerlink" title="rewrite阶段：rewrite模块"></a>rewrite阶段：rewrite模块</h2><p><strong>rewrite模块</strong>中的<strong>return指令</strong>会在 server_rewrite 与 rewrite阶段都会生效，生效后，后续的HTTP模块的其他阶段是没有机会得到执行的。</p><h3 id="rewrite模块：return指令"><a href="#rewrite模块：return指令" class="headerlink" title="rewrite模块：return指令"></a>rewrite模块：return指令</h3><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/62d86676-c710-43e4-b52a-bdd1f59ee2c9.jpg" alt></p><p>444 表示Nginx立即关闭连接，不再向客户端返回任何内容。</p><h3 id="rewrite模块：return指令与error-page指令"><a href="#rewrite模块：return指令与error-page指令" class="headerlink" title="rewrite模块：return指令与error_page指令"></a>rewrite模块：return指令与error_page指令</h3><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/ffdd9a3d-294a-4148-9b6b-4b51b00f7f55.jpg" alt></p><h3 id="return示例"><a href="#return示例" class="headerlink" title="return示例"></a>return示例</h3><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/5c75f1a9-fe7a-4e37-9720-d5bafda5d1cd.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建return.conf，并include进nginx.conf</span><br><span class="line">vim return.conf</span><br></pre></td></tr></table></figure><p>root html/  即我们访问 location 下的某个资源时，会去html下去找资源是否存在。如果文件没有找到，会生成一个404错误码，正常会这样返回，但这里注释掉，并且定义了一个 error_page 404 /403.html；即当看到404时给他重新定向到 403.html页面。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/_u6355_u83B71589217726606.PNG" alt></p><p>访问时故意找一个不存在的资源</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/02ea6d8e-a71b-460e-a4a5-c67390fd926f.jpg" alt></p><p>此时，解开 return 404 的注释，再次访问， error_page是没有机会得到执行的。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/36b9a97b-5f89-4733-8205-b6c0f14fdd27.jpg" alt></p><p>再如：在server中加入了一个 return 405;</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/09fad081-c6bd-4e98-b361-d231b97374d4.jpg" alt></p><p>此时会执行谁呢？ 在11个阶段中不难发现， server配置项中的return 是在 server_rewrite中的，location中的return是在 rewrite中的，肯定是 server_rewrite中的return先执行，而 location中的return是没有机会执行的。<strong>即肯定返回405</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/482f0981-162a-44e1-b2a6-7c71e67a86d7.jpg" alt></p><h3 id="rewrite模块：rewrite指令重写URL"><a href="#rewrite模块：rewrite指令重写URL" class="headerlink" title="rewrite模块：rewrite指令重写URL"></a>rewrite模块：rewrite指令重写URL</h3><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/42d90672-258b-43f1-bfca-758460fbbaa2.jpg" alt></p><h4 id="rewrite指令示例（一）"><a href="#rewrite指令示例（一）" class="headerlink" title="rewrite指令示例（一）"></a>rewrite指令示例（一）</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/118bb95d-6343-4197-a1f1-3e588ba5d3b4.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，将它 include到nginx.conf中</span><br><span class="line">vim rewrite.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/40344274-ece7-4745-8cbc-1495bbe764f5.jpg" alt></p><p>首先访问 first/3.txt</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/6b709829-c696-4633-a415-a1f23c883a66.jpg" alt></p><p>在second中间 break注释放开，会有什么不一样呢？</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/d8c0525e-65d8-4b72-b88c-2699d513bf92.jpg" alt></p><h4 id="rewrite指令示例（二）"><a href="#rewrite指令示例（二）" class="headerlink" title="rewrite指令示例（二）"></a>rewrite指令示例（二）</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/0d88d297-907e-452a-9348-28f6bb1db4a8.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，将它 include到nginx.conf中</span><br><span class="line">vim rewrite.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/bd30f763-825d-4e63-a7d6-bc80aba824e9.jpg" alt></p><p>访问第一个，因为指定了 permanent（永久重定向），返回301</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/3717eeea-bc58-4d62-96f1-4c7c6e2c0b4a.jpg" alt></p><p>访问第二个，因为指令了 redirect（临时重定向），返回302</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/b6d719b0-ea6b-4891-93cb-32dcea315dfb.jpg" alt></p><p>访问第三个，因为什么都没有指定，但前面又有一个 http、https等，会返回302</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/f37d3915-6a05-4f68-af33-1c418890ad66.jpg" alt></p><p>访问第四个，虽然前面有 http、https，但最后指定了 permanent，会返回301</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/d55a475a-8a3f-43b6-b002-60a63daee590.jpg" alt></p><p><strong>rewrite_log指令</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/8e0d3f73-8412-402c-b627-4a4c47dae229.jpg" alt></p><p>默认是不会开启的，需要显示开启，打开后，刚刚访问过的所有重定向的URL都会在指定的 <strong>logs/rewrite_error.log</strong>中出现。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim rewrite_error.log</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/8216df9e-65f7-40d8-b14d-81f473e58d38.jpg" alt></p><h3 id="rewrite模块：if指令-条件判断"><a href="#rewrite模块：if指令-条件判断" class="headerlink" title="rewrite模块：if指令-条件判断"></a>rewrite模块：if指令-条件判断</h3><p><strong>if指令</strong>可以让我们判断请求中的变量的值是否满足某个条件，再去决定由哪一个配置块执行，再根据这些配置块调用相应的模块去解析请求。（逻辑判断）</p><h4 id="rewrite模块的if指令"><a href="#rewrite模块的if指令" class="headerlink" title="rewrite模块的if指令"></a>rewrite模块的if指令</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/437f5e32-4633-43cd-a275-e96edcd4a1fc.jpg" alt></p><h4 id="if指令的条件表达式"><a href="#if指令的条件表达式" class="headerlink" title="if指令的条件表达式"></a>if指令的条件表达式</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/fdb72d21-a525-4781-b8aa-671d915b59f6.jpg" alt></p><p><strong>简单示例</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/25e97781-e9a3-4b33-af77-19c7189b6aa5.jpg" alt></p><h2 id="find-config阶段"><a href="#find-config阶段" class="headerlink" title="find_config阶段"></a>find_config阶段</h2><p>当我们在server块下的rewrite系列指令执行完毕后，开始根据用户请求中的URL去location中对应的URL正则表达式进行匹配。这一步【匹配完成后，就确定了由哪一个location对这个请求进行处理。</p><h3 id="处理请求的-location-指令块"><a href="#处理请求的-location-指令块" class="headerlink" title="处理请求的 location 指令块"></a>处理请求的 location 指令块</h3><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/96b8444c-2c2d-44f7-a224-24b101a157ca.jpg" alt></p><p><strong>merge_slashes</strong>可以去合并URL里的斜杠，两个斜杠在一起时，默认打开该配置项，会合并成一个。只有当URL中用到<strong>base64编码</strong>等等规则时，才需要关闭。</p><h4 id="location匹配规则：仅匹配URI，忽略参数"><a href="#location匹配规则：仅匹配URI，忽略参数" class="headerlink" title="location匹配规则：仅匹配URI，忽略参数"></a>location匹配规则：仅匹配URI，忽略参数</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/bc97e48a-b6da-45b3-9a94-ccdb4dfdeb4d.jpg" alt></p><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/46154d9b-cde7-44aa-8011-b571869ddf18.jpg" alt></p><h4 id="location匹配顺序"><a href="#location匹配顺序" class="headerlink" title="location匹配顺序"></a>location匹配顺序</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/db8723bd-dfe2-4cca-a421-fa5e85e6eec4.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，将它 include到nginx.conf中</span><br><span class="line">vim locations.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/afea573c-c8c2-46f9-9964-81a5dfe637a0.jpg" alt></p><p>访问Test1,精确匹配</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/f8816478-51ce-4992-bf10-57198fc681c7.jpg" alt></p><p>访问Test1/,虽然有多个匹配，但是前缀字符串中遵循<strong>最长匹配</strong>的规则，所以匹配到了 Test1/，并且匹配上后，禁止后续正则表达式的匹配。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/fe863375-e5e2-45b7-9d29-5c59ddc3b0d2.jpg" alt></p><p>访问/Test1/Test2 ，/Test1/Test2 与 <del>* /Test1/(\w+)$ 都匹配上了，但由于没有使用 ^</del>禁止正则表达式匹配，所以匹配的是带有正则表达式的最长匹配。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/2c4e6b72-6e3a-4789-beec-aad6474d0f44.jpg" alt></p><p>访问/Test1/Test2/ ，因为正则没有匹配上，所以使用最长字符串匹配</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/937460a9-1add-4e3d-a739-ef415bb617c0.jpg" alt></p><h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><p>以上介绍了 location的匹配规则，对于URI的请求，到底是由哪一个location下的指令去执行，就十分了然了，同时也知道了当location数量非常多时，怎样通过 <strong>禁止正则表达式匹配</strong>、<strong>使用=精确匹配</strong>等等方式对非常频繁发起的请求来减少它们做location匹配的次数。</p><h2 id="preaccess阶段"><a href="#preaccess阶段" class="headerlink" title="preaccess阶段"></a>preaccess阶段</h2><h3 id="对连接做限制的limit-conn模块"><a href="#对连接做限制的limit-conn模块" class="headerlink" title="对连接做限制的limit_conn模块"></a>对连接做限制的limit_conn模块</h3><p><strong>问题：如何限制每个客户端的并发连接数？</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/c2bbb690-8f6f-4a6b-a5e9-ef85c44d74b9.jpg" alt></p><h4 id="limit-conn指令"><a href="#limit-conn指令" class="headerlink" title="limit_conn指令"></a>limit_conn指令</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/7fcdbe6a-773f-4720-9636-475b1fa1f457.jpg" alt></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/0126152a-bb75-4b70-bac7-0030bdb75d55.jpg" alt></p><h4 id="演示"><a href="#演示" class="headerlink" title="演示"></a>演示</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">创建文件并且include到 nginx.conf中</span><br><span class="line">vim limit_conn.conf</span><br><span class="line"></span><br><span class="line">limit_conn_zone $binary_remote_addr zone&#x3D;addr:10m;</span><br><span class="line">#limit_req_zone $binary_remote_addr zone&#x3D;one:10m rate&#x3D;3r&#x2F;s</span><br><span class="line"></span><br><span class="line">server&#123;</span><br><span class="line">    server_name limit.haoran.tech;</span><br><span class="line">    root html&#x2F;;</span><br><span class="line">    error_log logs&#x2F;myerror.log info;</span><br><span class="line">    </span><br><span class="line">    location &#x2F;&#123;</span><br><span class="line">        limit_conn_status 500;</span><br><span class="line">        limit_conn_log_level warn;</span><br><span class="line">        limit_rate 50;</span><br><span class="line">        limit_conn addr 1;</span><br><span class="line">        #limit_req zone&#x3D;one burst&#x3D;1 nodelay;</span><br><span class="line">        #limit_req zone&#x3D;one;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/636ff2ff-a1c4-408a-9b79-9dfa88be33f8.jpg" alt></p><p>上述配置文件定义了一个 <strong>10M</strong> 的共享内存，共享内存中使用 binary_remote_addr，这是一个二进制格式的IP地址（IPV4协议下只有4个字节,效率较高）。</p><p>定义了向用户返回的错误码是500（默认是503）</p><p>将 log_level调成了 warn（默认是error）</p><p>limit_conn_addr 1; 即限制了并发连接数为1（只为演示效果，当有两个客户端同时访问时，就会返回500）</p><p>limit_rate 50; 为了更好的演示，又加上了该配置项，即限制向用户返回的速度，每秒钟只返回50个字节，比较容易出现限制并发连接的场景。</p><p>在一个shell中访问，回复速度非常慢</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/b53e8635-ea6e-477f-baf7-d7e9a41130ae.jpg" alt></p><p>在另一个shell中也访问，会回复500错误码</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/8032adb7-ee5f-4213-b7e5-6d37ba578735.jpg" alt></p><p>在 myerror.log中也可以看到</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/d9f8cbfc-d250-42a1-b59a-542a21ee2700.jpg" alt></p><h4 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h4><p>当Nginx作为资源服务器为用户提供服务时，限制用户能够同时发起的并发连接数，是一个很常用的功能。Nginx默认编辑进去的 ngx_http_limit_conn_module模块提供了这样的功能。<strong>设计好Key是关键</strong>。</p><h3 id="对请求做限制的limit-req模块"><a href="#对请求做限制的limit-req模块" class="headerlink" title="对请求做限制的limit_req模块"></a>对请求做限制的limit_req模块</h3><p><strong>问题：如何限制每个客户端的每秒处理请求数？</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/f310270f-af32-456f-a8bc-10f9d88052ea.jpg" alt></p><h4 id="leaky-bucket算法"><a href="#leaky-bucket算法" class="headerlink" title="leaky bucket算法"></a>leaky bucket算法</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/a55435d0-d50f-48e1-92e6-48e569f84fe6.jpg" alt></p><p>对于突发性流量，前两秒12Mbps，总共24M，2-7s没有流量，7-10为2Mbps，共6M，前10秒总共30M。</p><p>使用了该算法后，可以限制为3Mbps,前10秒总共 30M。</p><p>可以比喻为一个水龙头，向盆里流动的是突发性流量，而盆向下流的则是恒速流量。</p><ul><li><p><strong>当盆burst满的时候，立刻向用户返回503错误码</strong>。</p></li><li><p><strong>当盆burst没有满的时候，但向下速率已经达到最大化的时，水滴就会存在盆里，即用户的响应会变慢，请求并不会被拒绝</strong>。</p></li></ul><h4 id="limit-req指令"><a href="#limit-req指令" class="headerlink" title="limit_req指令"></a>limit_req指令</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/39b5d9e6-fc0a-486b-9ba3-417d57dc2ae0.jpg" alt></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/bafe56ec-ff77-4371-b9de-7bf7dbb7a0f8.jpg" alt></p><p><strong>问题</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/ab666467-5387-42cf-b454-0b3ddf8c26b4.jpg" alt></p><h4 id="演示-1"><a href="#演示-1" class="headerlink" title="演示"></a>演示</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">创建文件并且include到 nginx.conf中</span><br><span class="line">vim limit_conn.conf</span><br><span class="line"></span><br><span class="line">limit_conn_zone $binary_remote_addr zone&#x3D;addr:10m;</span><br><span class="line">#limit_req_zone $binary_remote_addr zone&#x3D;one:10m rate&#x3D;2r&#x2F;m</span><br><span class="line"></span><br><span class="line">server&#123;</span><br><span class="line">    server_name limit.haoran.tech;</span><br><span class="line">    root html&#x2F;;</span><br><span class="line">    error_log logs&#x2F;myerror.log info;</span><br><span class="line">    </span><br><span class="line">    location &#x2F;&#123;</span><br><span class="line">        limit_conn_status 500;</span><br><span class="line">        limit_conn_log_level warn;</span><br><span class="line">        #limit_rate 50;</span><br><span class="line">        #limit_conn addr 1;</span><br><span class="line">        #limit_req zone&#x3D;one burst&#x3D;3 nodelay;</span><br><span class="line">        limit_req zone&#x3D;one;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当没有加 burst 与 nodelay时，结果会是怎样？同时注释掉 limit_rate 这样可以快速返回内容。<strong>每分钟两条</strong></p><p><strong>curl limit.haoran.tech</strong> ，看到结果</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/7db81b53-d952-41df-aa52-23651ef9a701.jpg" alt></p><p>再次访问</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/034093e0-7e6e-4aa0-8022-e4d36bbb5818.jpg" alt></p><p>将  burst的注释解开会是什么样的呢？</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/6f129ccd-e03c-45ef-a3de-27ab1087cea7.jpg" alt></p><p>访问3次都可以看到结果，访问第4次时，会有503错误码。</p><p>现在将限制连接与限制请求同时打开。看下效果。返回500（限制连接生效），返回503（限制请求生效），</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/80d4681d-1e8d-410e-9491-4dc792b7e05d.jpg" alt></p><p>每分钟只能处理2个请求，所以第3次访问时，<strong>limit_req生效</strong>，但其实 第二次访问时 <strong>limit_conn</strong>同样生效了。返回的还是503，而不是500，这是因为 limit_req模块是在limit_conn模块之前生效的，limit_req已经向用户拒绝了，limit_conn就没有机会得到执行了。<br><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/1eba94b3-b698-40f9-9d67-3243174af439.jpg" alt></p><h2 id="access阶段"><a href="#access阶段" class="headerlink" title="access阶段"></a>access阶段</h2><h3 id="对IP做限制的-access-模块"><a href="#对IP做限制的-access-模块" class="headerlink" title="对IP做限制的 access 模块"></a>对IP做限制的 access 模块</h3><p><strong>access模块</strong> 可以控制那些IP可以访问某些URL，那些不可以访问。</p><p><strong>问题：如何限制那些IP地址的访问权限？</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/832769b6-fcc5-4fa5-9da7-4c17ec221d47.jpg" alt></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/066c8482-4e64-46a6-b6a6-4ff35b0056e2.jpg" alt></p><h3 id="对用户名-密码做限制的-auth-basic-模块"><a href="#对用户名-密码做限制的-auth-basic-模块" class="headerlink" title="对用户名-密码做限制的 auth_ basic 模块"></a>对用户名-密码做限制的 auth_ basic 模块</h3><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/609f0ee1-f934-4a18-be91-114657084c86.jpg" alt></p><p><strong>auth_basic模块的指令</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/98ca71bc-ed6b-4332-910d-a6d02f593c64.jpg" alt></p><p><strong>生成密码文件</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/d1d3a69a-f867-448b-a035-8a86dfc57870.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">yum install -y httpd-tools</span><br><span class="line"></span><br><span class="line">htpasswd -c file -b user pass</span><br><span class="line"></span><br><span class="line">-c 指定生成的文件，-b 指定用户名密码</span><br><span class="line"></span><br><span class="line">假设现在已经生成了 auth.pass文件</span><br><span class="line"></span><br><span class="line">vim auth.pass</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/4f016d91-a721-4522-a1fb-80cd531197ce.jpg" alt></p><p>上述密码文件中的密码做了一个简单的base64编码。</p><p>在 nginx.conf配置文件中指定有关配置</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/895f11ef-d463-4cd3-ac87-55a76b65174e.jpg" alt></p><p>浏览器访问 access.taohui.tech；会发现需要输入用户名-密码</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/d41f3894-95a1-4f95-b711-327495299542.jpg" alt></p><p>当我们提供一个非常简单的页面时，如go-access，想对他做一个安全保护，auth_basic是一个不错的做法。</p><h3 id="使用第三方做权限控制的-auth-request-模块"><a href="#使用第三方做权限控制的-auth-request-模块" class="headerlink" title="使用第三方做权限控制的 auth_request 模块"></a>使用第三方做权限控制的 auth_request 模块</h3><p>在生产环境中，往往会有一个动态Web服务器或者相应的一些应用服务器，它们提供更复杂的用户名-密码权限验证，这个时候可以通过访问Nginx的资源池先将这个请求传递给应用服务器上，根据应用服务器返回的结果再判断这个请求资源能不能继续执行，那么Nginx的access阶段有一个模块为 auth_request模块，他就可以完成这样的功能。</p><p><strong>统一的用户权限验证系统</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/7af33897-413a-4e91-ace2-ec13a7099185.jpg" alt></p><p><strong>演示</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/b6a69a3f-c156-4852-9303-e6f37b8e8210.jpg" alt></p><p>当访问 / 时 通过 auth_request 生成子请求,会去访问这个URL test_auth，而这个URL通过 proxy_pass反向代理到本机的另一个Nginx服务器（监听端口为8090），他提供的URL为 auth_upstream。成功后，因为有一个默认的配置 root html/(即使注释了也会正常显示html下的 index页面)，如果被拒绝，就会返回 8090 这台机器的错误码。</p><p>8090这台nginx的内容如下（成功的时候）：</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/7ec46de9-417b-4c2e-9538-92900bc23395.jpg" alt></p><p>访问：</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/cacc2da6-43af-49a1-a0c2-5c875a1c29eb.jpg" alt></p><p>将上游的返回值改为403：</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/b3662788-1074-492f-9d3c-5c370f409aec.jpg" alt></p><p>禁用缓存后，再次访问：</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/e887c996-2eb0-47f2-a0e6-d7c049bc7c2b.jpg" alt></p><h3 id="access阶段的-satisfy-指令"><a href="#access阶段的-satisfy-指令" class="headerlink" title="access阶段的 satisfy 指令"></a>access阶段的 satisfy 指令</h3><p>前面提到了 access 阶段的3个模块，那这三个模块任意一个模块拒绝了用户的请求，用户请求就无法执行了呢？其实并不是这样的，那他们是否严格的按照顺序往下执行呢？同样不是这样的。</p><p>因为 Nginx的HTTP框架中提供了一个 <strong>satisfy指令</strong>，允许我们改变模块的执行顺序。</p><p><strong>限制所有access阶段模块的 satisfy指令</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/9e0e322a-b59c-477b-8787-131df574d6ca.jpg" alt></p><p>即一个 access模块，有三种处理结果：</p><ul><li><p><strong>忽略，即没有任何配置，直接跳到下一个access模块</strong></p></li><li><p><strong>放行（allow），先判断satisfy开关，如果配置为 all（表示必须所有的access模块都同意放行这个请求才可以通过），所以继续执行下一个access模块；如果配置为 any（即不用再去考虑后续的access模块是否同意，直接跳到下一个 post_access阶段执行）</strong></p></li><li><p><strong>拒绝（deny），同样判断satisfy开关，如果配置为 all（直接拒绝请求），不再向下执行。如果是 any，虽然当前这个模块拒绝了，但也会后续模块会同意放行，所以继续执行下一个access模块</strong></p></li></ul><p><strong>问题</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/11fb6c5d-da39-4d6e-afeb-47fc345a904e.jpg" alt></p><ul><li><p><strong>1：肯定不会生效，因为return指令的生效期是 server_rewrite 与 rewrite阶段，二者都领先于 access，access是没有机会得到执行的。</strong></p></li><li><p><strong>2：肯定有影响，即如果 access阶段已经拒绝了，则auth_basic是没有机会输入用户名-密码的。</strong></p></li><li><p><strong>3：可以访问到，配置了 satisfy any</strong></p></li><li><p><strong>4：提到之前，仍然可以访问，因为模块间的顺序ok就行了，配置指令间的顺序无关紧要</strong></p></li><li><p><strong>5：将 deny all 改为 allow all，没有机会输入，因为配置的 satisfy all，任意的模块同意就可以了，allow all是 access模块的，它先于auth_basic模块执行的，它已经同意了，则auth_basic是没有机会输入用户名-密码的。</strong></p></li></ul><h2 id="precontent阶段"><a href="#precontent阶段" class="headerlink" title="precontent阶段"></a>precontent阶段</h2><h3 id="按序访问资源的-try-files-模块"><a href="#按序访问资源的-try-files-模块" class="headerlink" title="按序访问资源的 try_files 模块"></a>按序访问资源的 try_files 模块</h3><p><strong>对于反向代理的场景十分有用，Nginx先尝试去获取磁盘上的文件内容，如果没有再反向代理到上游服务。</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/728821e7-c28a-470a-8c79-2cc85b353fd3.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并include到 nginx.conf文件中</span><br><span class="line">vim tryfiles.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/3eb1c77a-1125-49b9-ac41-bb1c00ee2057.jpg" alt></p><p>访问 /first，如果系统在维护的话可能会有一个 /system/maintenance.html文件，如果这个文件找不到的话，我们就去找 uri（即 html下first有没有），同样没有，$uri/index.html、$uri.html同样都没有，这时使用了 @lasturl 符号 去访问 另一个 location @lasturl。在这个location中返回 200的状态码。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/93bb2a64-19b6-4c1c-9e5a-ae4127d27779.jpg" alt></p><p>访问 /second，一样与一个去尝试，所有文件都找不到时，返回404.</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/e14e4c54-713c-4f5d-afe3-826434d572c8.jpg" alt></p><h3 id="实时拷贝流量-mirror-模块"><a href="#实时拷贝流量-mirror-模块" class="headerlink" title="实时拷贝流量 mirror 模块"></a>实时拷贝流量 mirror 模块</h3><p>mirror模块可以帮我们创造一份镜像流量，如生产环境中处理一些请求，这些请求可能需要把他们同步的拷贝一份到我的测试、开发环境中做处理。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/8611ad8c-6413-4e49-8c81-14d5dcc9d7bb.jpg" alt></p><p>即当请求到了Nginx后，可以生成一个子请求，这个子请求可以通过反向代理去访问我们的其他环境（测试环境等），对其他环境返回值不作处理。</p><p><strong>举例</strong></p><p>需要一个上游服务器</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/8262d188-51e4-42cf-9020-9d191d34a19a.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并include到 nginx.conf文件中</span><br><span class="line">vim mirror.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/dfe18329-89d0-4458-b28a-2415d5d86bde.jpg" alt></p><p>收到一个请求时，会拷贝一份流量到 mirror 中去，/mirror收到后，会指定 internal（内部），将其方向代理到本机的10020端口上去。</p><p>访问8001</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/5602b6ce-74a5-4899-895c-8a0996c08303.jpg" alt></p><p>实时查看日志</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/bd01d90d-8679-434b-90d7-76bcdd1da763.jpg" alt></p><p>再去看上游Nginx(10020)的日志，是否收到</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/8fb49605-4b51-43a3-93b5-482835b2f6f5.jpg" alt></p><h2 id="content阶段"><a href="#content阶段" class="headerlink" title="content阶段"></a>content阶段</h2><h3 id="static模块-root-和-alias-指令"><a href="#static模块-root-和-alias-指令" class="headerlink" title="static模块 root 和 alias 指令"></a>static模块 root 和 alias 指令</h3><p>content阶段中 static模块  默认是在Nginx框架中的，是没有办法做移除的。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/b281027a-aae7-4dfe-88bc-ac86be3b0a78.jpg" alt></p><p><strong>问题</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/85228787-c832-42d3-abcc-d1c9a88e6bf8.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并include到 nginx.conf文件中</span><br><span class="line">vim static.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/8ecfd588-3241-470e-87bb-05787d28f3c5.jpg" alt></p><p><font color="red">直接访问 root/，文件不存在</font></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/0c140f6a-cbcd-47c6-9d3b-709a76fee58e.jpg" alt></p><p>查看日志，在 html后又加上了刚刚 location中的root，因为有个 反斜杠，所有有添加了 index.html，这个文件其实是不存在的。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/b653fc8e-67c4-41b4-8a47-8ab73f3bb163.jpg" alt></p><p><font color="red">直接访问 root/1.txt，文件不存在</font></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/a47c5ad2-58ce-400b-9310-0c10ef8caff9.jpg" alt></p><p>查看日志，它其实是在 html/first/1.txt 后面又添加了 /root/1.txt，即 html/first/1.txt/root/1.txt</p><p><font color="red">直接访问 curl static.taohui.tech/alias/   ,他匹配到了 location /alias  会去访问 html下的index.html，所以应该访问首页</font></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/e81ffef0-5e33-44d9-b9fc-87cdc23a59f0.jpg" alt></p><p><font color="red">直接访问 curl static.taohui.tech/alias/1.txt  ，不会添加完整路径，文件存在</font></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/2c61806a-68d3-412a-bdae-c38891d6fe4e.jpg" alt></p><h3 id="static模块-3个变量"><a href="#static模块-3个变量" class="headerlink" title="static模块 3个变量"></a>static模块 3个变量</h3><p><strong>生成待访问文件的三个相关变量</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/_u6355_u83B71589363559193.PNG" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并include到 nginx.conf文件中</span><br><span class="line">vim static.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/ef33b509-ef3c-4791-9a89-de3d330cd1f9.jpg" alt></p><p>realpath 实际上是一个软链接，他指向了 first目录下，这个目录下有一个1.txt文件</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/2fc334d9-4140-4ae2-b475-c8c70453c88e.jpg" alt></p><p>在下图中可看到，返回3个路径，第一个是完整路径，后两个都是1.txt所在的目录，只不过 document_root 没有做软链接的替换，还是根据配置项拼接出来的，而 realpath_root 已经将 realpath 替换为真实 first目录。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/_u6355_u83B71589363849390.PNG" alt></p><h3 id="static模块提供的其他功能"><a href="#static模块提供的其他功能" class="headerlink" title="static模块提供的其他功能"></a>static模块提供的其他功能</h3><h4 id="静态文件返回时的-content-type"><a href="#静态文件返回时的-content-type" class="headerlink" title="静态文件返回时的 content-type"></a>静态文件返回时的 content-type</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/fcc5c202-7370-4c46-9781-5c3013c3ac45.jpg" alt></p><p>当我们去读磁盘上的文件时，根据文件的扩展名做一次映射。<strong>types指令</strong>就是做这个事情的，为了加速，需要将 content-type  与 扩展名 做一次映射放入 Hash 表中。</p><p><strong>default_type</strong>是在没有文件名时用来告诉用户这个content-type究竟怎样解析</p><h4 id="未找到文件时的错误日志"><a href="#未找到文件时的错误日志" class="headerlink" title="未找到文件时的错误日志"></a>未找到文件时的错误日志</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/73be5c25-2a92-49df-9fa6-4e5a2f18d0e1.jpg" alt></p><h3 id="static模块对url不以斜杠结尾却访问目录的做法"><a href="#static模块对url不以斜杠结尾却访问目录的做法" class="headerlink" title="static模块对url不以斜杠结尾却访问目录的做法"></a>static模块对url不以斜杠结尾却访问目录的做法</h3><p>很多人使用 static 模块的  root/alias 指令将Nginx当做静态资源服务器时，很可能会发现，当我们去访问一个目录，但是在url结尾没有加上斜杠时，实际上Nginx会返回一个301的重定向，那么对于重定向中的内容，Nginx提供了3种不同的指令，去控制location这样的行为。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/d79721a2-30b5-45d1-bc5f-5a23376cb8f0.jpg" alt></p><p><strong>重定向跳转的域名</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/5be98a60-9879-424b-af00-20da33bd9ac6.jpg" alt></p><p><strong>演示</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并且include到 nginx.conf配置文件中</span><br><span class="line">vim dirredirect.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/0f59cecd-1d65-4878-a2fc-ed552e9a8ced.jpg" alt></p><p>在 server_name 中配置了两个域名，第一个是主域名。将 absolute_redireect off 开启（默认是on），root指向 html/ 下有一个 first文件夹。</p><p>先来访问 first文件夹，没有加反斜杠，此时应该获得一个301重定向</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/6f469702-82cb-4d21-9e94-87b8d4cbbbb2.jpg" alt></p><p>将 absolute_redirect off 注释掉。再次访问，发现 在 <strong>Location</strong>中将域名都添加了进去。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/f4c52dee-e694-456e-a032-3adf3c6cb7cc.jpg" alt></p><p>如果头部有一个 <strong>Host: aaa</strong>，那么就会将它替换掉掉Location中的localhost。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/3be924e8-441e-49aa-b014-0639d6707a30.jpg" alt></p><p>将 dirredirect.conf配置文件中的 <strong>server_name_in_redirect on</strong>开启后，再去访问，会发现Location中以主域名来绑定。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/ea6acb6d-f387-4f79-b80e-04aaa22ace11.jpg" alt></p><h3 id="index-与-autoindex模块"><a href="#index-与-autoindex模块" class="headerlink" title="index 与 autoindex模块"></a>index 与 autoindex模块</h3><p>在前面已经演示过，autoindex会以目录形式显示服务器上的资源。但有时在搭建的时候，会没有看到目录结构，看到的是一个文件的内容，这是因为** index 模块** 先于 <strong>autoindex 模块</strong>产生作用。</p><h4 id="对访问-时的处理：content阶段的index模块"><a href="#对访问-时的处理：content阶段的index模块" class="headerlink" title="对访问/时的处理：content阶段的index模块"></a>对访问/时的处理：content阶段的index模块</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/03f6d0ed-8176-4fa7-9d84-94e0b6ba03d1.jpg" alt></p><h4 id="显示目录内容：content阶段的autoindex模块"><a href="#显示目录内容：content阶段的autoindex模块" class="headerlink" title="显示目录内容：content阶段的autoindex模块"></a>显示目录内容：content阶段的autoindex模块</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/ab7fdd2b-3bc0-411f-a706-72de6fa40001.jpg" alt></p><p><strong>autoindex 模块的指令</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/4a0c0058-8c44-4e61-bf74-a4a1031a99fe.jpg" alt></p><p>autoindex_exact_size on|off ：当默认打开的格式（向用户返回的是html格式时才有效）是显式相对的路径。<strong>绝对路径：</strong>以<strong>字节</strong>来显示。<strong>相对路径：</strong>以<strong>K、M</strong>显示。</p><p><strong>演示</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">新建配置文件，并且include到 nginx.conf配置文件中</span><br><span class="line">vim autoindex.conf</span><br></pre></td></tr></table></figure><p>监听了1个8080端口，以server_name指定的域名进行访问，默认没有修改index a.html（注释掉了）。当访问 / 时，会去找 index.html，在 alias指定的html下是有这个文件。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/bf6a5afc-224c-4ace-bb0d-9980a58ef6d6.jpg" alt></p><p>去访问 autoindex.taohui.tech:8080，得到的是index.html内容</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/35ca0dd5-1174-4d4c-8ab4-f29a4e95c157.jpg" alt></p><p>因为 index 模块是没有办法从  Nginx中移除的，所以可以去修改 index指向的文件，将它指向一个不存在的 a.html文件（即将 index a.html 注释解开）</p><p>再次访问autoindex.taohui.tech:8080，是JSON格式返回这个目录</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/d928ea5f-1314-45f7-8c2b-2bfa98a9379b.jpg" alt></p><p>同理，将 autoindex_format json 改为 html</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/f2f0517d-faa7-47bd-9d91-aaa32607b218.jpg" alt></p><p>reload后，再次访问，因为是以相对路径，所以可以显示到K。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/a18c6759-3aae-41de-8cdf-f7b93d5e3473.jpg" alt></p><h3 id="content阶段中有Alibaba提供的concat模块"><a href="#content阶段中有Alibaba提供的concat模块" class="headerlink" title="content阶段中有Alibaba提供的concat模块"></a>content阶段中有Alibaba提供的concat模块</h3><p>concat模块可在一次请求中返回多个文件的内容，这对在Web页面中访问多个小文件来提升性能十分有用。（需要下载并且在 .configure 时编译进Nginx）</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/68e622ae-6d7a-42c3-9890-3cb801bc37d8.jpg" alt></p><p><strong>concat模块的指令</strong></p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/9d3beaf0-7b29-4534-81e5-7649b057033b.jpg" alt></p><ul><li><p><strong>concat 开启或者关闭</strong></p></li><li><p><strong>concat_delimiter：String，如果服务器返回多个文件，通过指定的String分隔符进行分割</strong></p></li><li><p><strong>concat_types: MIME types，对那些文件的类型做合并</strong></p></li><li><p><strong>concat_unique：对某一种文件类型进行合并，还是对多个文件类型进行合并</strong></p></li><li><p><strong>concat_ignore_file_error：如果某个文件出现错误，是忽略它，返回其他文件的内容</strong></p></li><li><p><strong>concat_max_files：最多合并多少个文件，默认为10</strong></p></li></ul><p><strong>看一下淘宝网的做法</strong></p><p>可以看到他的大部分请求，都使用了 <strong>??</strong>，后面添加了多个文件，后面用逗号隔开。</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/02e8a5f0-565f-4068-92ac-01046a0008ab.jpg" alt></p><p>在响应中也可以看到</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/14b5a5c5-325f-42ae-8156-591e00c25231.png" alt></p><p><strong>演示</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">新建配置文件，并且include到 nginx.conf配置文件中</span><br><span class="line">vim concat.conf</span><br></pre></td></tr></table></figure><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/b6d44649-a349-4292-b964-44f983a5e1b3.jpg" alt></p><p>在 concat.conf配置文件中，首先打开了这个功能，最多20个文件，类型是 text/plain，以 <strong>三个分号</strong>来分隔多个文件。</p><p>现在来访问，他回去 html/concat 路径下找 1.txt 与 2.txt，这两个文件是存在的，内容如下：</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/e9612a1d-ca16-462c-a9e5-eaba187d31d5.jpg" alt></p><p>访问：</p><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/d3025d36-8921-429f-81f4-f5eefb3dd611.jpg" alt></p><h2 id="Log阶段（记录请求访问日志的log模块）"><a href="#Log阶段（记录请求访问日志的log模块）" class="headerlink" title="Log阶段（记录请求访问日志的log模块）"></a>Log阶段（记录请求访问日志的log模块）</h2><h3 id="http-log模块"><a href="#http-log模块" class="headerlink" title="http_log模块"></a>http_log模块</h3><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/a7c1944c-6b8c-4a7e-9155-dd3a886d2584.jpg" alt></p><h4 id="access-日志格式"><a href="#access-日志格式" class="headerlink" title="access 日志格式"></a>access 日志格式</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/2b74ec9f-c476-4e23-8162-da5fe03379b0.jpg" alt></p><h4 id="配置日志文件路径"><a href="#配置日志文件路径" class="headerlink" title="配置日志文件路径"></a>配置日志文件路径</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/f2806838-8e42-4e9f-992b-b9357b7a2820.jpg" alt></p><h4 id="对日志文件名包含变量时的优化"><a href="#对日志文件名包含变量时的优化" class="headerlink" title="对日志文件名包含变量时的优化"></a>对日志文件名包含变量时的优化</h4><p><img src="/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/_u6355_u83B71589375413620.PNG" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-Nginx核心知识100讲，本人购买课程后依据视频讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;除&lt;strong&gt;HTTP过滤模块&lt;/strong&gt; 和 &lt;strong&gt;只提供变量的Nginx模块&lt;/strong&gt;之外，所有的HTTP模块必须从Nginx定义好的&lt;strong&gt;11&lt;/strong&gt;个阶段进行请求处理。每一个HTTP模块何时生效，有没有机会生效，都要看一个请求究竟处理到哪一个阶段。Nginx是如何定义这11个处理阶段的呢？&lt;/p&gt;
&lt;h2 id=&quot;HTTP请求处理时的11个阶段&quot;&gt;&lt;a href=&quot;#HTTP请求处理时的11个阶段&quot; class=&quot;headerlink&quot; title=&quot;HTTP请求处理时的11个阶段&quot;&gt;&lt;/a&gt;HTTP请求处理时的11个阶段&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/2019/12/11/23-%E8%AF%A6%E8%A7%A3HTTP%E8%AF%B7%E6%B1%82%E7%9A%8411%E4%B8%AA%E9%98%B6%E6%AE%B5/_u6355_u83B7.PNG&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Nginx" scheme="http://JavaSsun.github.io/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="http://JavaSsun.github.io/tags/Nginx/"/>
    
  </entry>
  
</feed>
