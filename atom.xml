<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>haoran&#39;s blog</title>
  
  <subtitle>Talk is cheap. Show me the code</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://javassun.github.io/"/>
  <updated>2020-06-17T06:48:20.656Z</updated>
  <id>http://javassun.github.io/</id>
  
  <author>
    <name>Allen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>FaaS-又一个为未来</title>
    <link href="http://javassun.github.io/2020/05/17/FaaS-%E5%8F%88%E4%B8%80%E4%B8%AA%E4%B8%BA%E6%9C%AA%E6%9D%A5/"/>
    <id>http://javassun.github.io/2020/05/17/FaaS-%E5%8F%88%E4%B8%80%E4%B8%AA%E4%B8%BA%E6%9C%AA%E6%9D%A5/</id>
    <published>2020-05-17T06:46:18.000Z</published>
    <updated>2020-06-17T06:48:20.656Z</updated>
    
    <content type="html"><![CDATA[<p>转载自：<a href="http://www.uml.org.cn/zjjs/202001023.asp" target="_blank" rel="noopener">http://www.uml.org.cn/zjjs/202001023.asp</a></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>云计算时代出现了大量XaaS形式的概念,从IaaS、PaaS、SaaS到容器云引领的CaaS,再到火热的微服务架构,以及现在越来越多被谈起的Serverless和FaaS,我们正在经历?一个技术飞速变革的时代。</p><h2 id="一、什么是Faas"><a href="#一、什么是Faas" class="headerlink" title="一、什么是Faas"></a>一、什么是Faas</h2><p>云计算时代出现了大量XaaS形式的概念，从IaaS(Infrastructure as a Service)、PaaS(Platform as a Service)、SaaS(Software as a Service)到容器云引领的CaaS(Containers as a Service)，再到火热的微服务架构，它们都在试着将各种软、硬件资源等抽象为一种服务提供给开发者使用，让他们不再担心基础设施、资源需求、中间件等等，在减轻心智负担的同时更好地专注于业务。FaaS是Functions as a Service的简称，它往往和无服务架构(Serverless Architecture)一同被提起。</p><p>Serverless的概念刚刚出现在HackerNews时并不为大众所接受。后来随着微服务和事件驱动架构的发展才慢慢引起关注。Serverless并不是说没有服务器参与，它通过将复杂的服务器架构透明化，使开发者专注于“要做什么”，从而强调了减少开发者对服务器等计算资源的关注、工作粒度从服务器切换到任务的思想。2006年第一个支持“随用随付”的代码执行平台Zimki问世。2014年亚马逊AWS推出了Lambda成为最主要的无服务架构的代表。接着Google、IBM和Microsoft也纷纷推出了各自支持Serverless的平台。</p><a id="more"></a><p>微服务架构近年来是一个非常火爆的话题，大大小小的公司都开始逐步分拆原来的单体应用，试着转换到由各个模块服务组合成大型的复杂应用。Serverless可以看作是比微服务架构更细粒度的架构模式，即FaaS。Lambda也是FaaS的典型代表，它允许用户仅仅上传代码而无需提供和管理服务器，由它负责代码的执行、高可用扩展，支持从别的AWS服务或其他Web应用直接调用等。以电子商务应用为例，微服务中可以将浏览商品、添加购物车、下单、支付、查看物流等拆分为解耦的微服务。在FaaS里，它可以拆分到用户的所有CRUD操作代码。当发生“下单”事件时，将触发相应的Functions，交由Lambda执行。人们在越来越多的场景里将Serverless和FaaS等同起来。</p><p><img src="/2020/05/17/FaaS-%E5%8F%88%E4%B8%80%E4%B8%AA%E4%B8%BA%E6%9C%AA%E6%9D%A5/46d66556-cc8f-4265-bf4f-5a8fc9a1848b.jpg" alt></p><p>假设现在有下面的JavaScript代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">module.exports &#x3D; function(context, callback) &#123; callback(200, &quot;Hello, world!</span><br><span class="line">&quot;); &#125;</span><br></pre></td></tr></table></figure><p>显然它是一个函数，通过FaaS的方式，我们可以通过访问一个URL的方式调用这个函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl -XGET localhost:8080</span><br><span class="line">Hello, world!</span><br></pre></td></tr></table></figure><p>FaaS拥有下面的特点：</p><p>1、FaaS里的应用逻辑单元都可以看作是一个函数，开发人员只关注如何实现这些逻辑，而不用提前考虑性能优化，让工作聚焦在这个函数里，而非应用整体。</p><p>2、FaaS是无状态的，天生满足云原生(Cloud Native App)应用该满足的12因子(12 Factors)中对状态的要求。无状态意味着本地内存、磁盘里的数据无法被后续的操作所使用。大部分的状态需要依赖于外部存储，比如数据库、网络存储等。</p><p>3、FaaS的函数应当可以快速启动执行，并拥有短暂的生命周期。函数在有限的时间里启动并处理任务，并在返回执行结果后终止。如果它执行时间超过了某个阈值，也应该被终止。</p><p>4、FaaS函数启动延时受很多因素的干扰。以AWS Lambda为例，如果采用了JS或Python实现了函数，它的启动时间一般不会超过10~100毫秒。但如果是实现在JVM上的函数，当遇到突发的大流量或者调用间隔过长的情况，启动时间会显著变长。</p><p>5、FaaS需要借助于API Gateway将请求的路由和对应的处理函数进行映射，并将响应结果代理返回给调用方。</p><p>比如对于一个简单的3层Web应用，在这里后端系统实现了大部分业务逻辑：认证、搜索、事务等，它的架构如下：</p><p><img src="/2020/05/17/FaaS-%E5%8F%88%E4%B8%80%E4%B8%AA%E4%B8%BA%E6%9C%AA%E6%9D%A5/e74deb9b-92fd-4dc2-92b5-49436cadb741.png" alt></p><p>如果采用Serverless架构，将认证、数据库等采用第三方的服务，从原来的单体后端里分拆出来(可能需要在原来的客户端里加入一些业务逻辑)。对于大部分的任务，通过函数的形式进行执行，而不再使用一直在线的服务器进行支持，如此一来它的架构看起来就清晰多了：</p><p><img src="/2020/05/17/FaaS-%E5%8F%88%E4%B8%80%E4%B8%AA%E4%B8%BA%E6%9C%AA%E6%9D%A5/7ae0950a-00bd-4583-b1f4-b28d7d7a0b17.png" alt></p><p>这样的拆分除了让各个组件(函数)间充分解耦，每个都很好地实现了单一职责原则(SRP, Single Responsibility Principle)以外，它的好处还有：</p><p><strong>减少开支</strong></p><p>通过购买共享的基础设施，同时减少了花费在运维上的人力成本，最终减少了开支。</p><p><strong>减轻负担</strong></p><p>不再需要重复造轮子，需要什么功能直接集成调用即可，也无需考虑整体的性能，只专注于业务代码的实现。</p><p><strong>易于扩展</strong></p><p>云上提供了自动的弹性扩展，用了多少计算资源，就购买多少，完全按需付费。</p><p><strong>简化管理</strong></p><p>自动化的弹性扩展、减少了打包和部署的复杂度、可以快速推向市场，这些都让管理变得简单高效。</p><p><strong>环保计算</strong></p><p>即使在云的环境上，仍习惯于购买多余的服务器，最终导致空闲。Serverless杜绝了这种情况。</p><p>在Martin Flower的专栏文章Serverless Architectures曾这样定义Serverless架构：</p><p>“Serverless architectures refer to applications that significantly depend on third-party services(AKA Backend as a Service or “BaaS”) or on custom code that is run ephmemeral containers (Function as a Service or “FaaS”)”</p><p>正如前面提到了FaaS的每个函数都拥有快速启动和短暂生命周期的特性，让容器作为任务函数运行的基本单位，是不是非常适合FaaS的场景？同样，作为最热门的容器编排工具的Kubernetes又该怎样应对FaaS呢?</p><h2 id="二、Kubernetes-与-FaaS"><a href="#二、Kubernetes-与-FaaS" class="headerlink" title="二、Kubernetes 与 FaaS"></a>二、Kubernetes 与 FaaS</h2><p>Fission是一款基于Kubernetes的FaaS框架。通过Fission可以轻而易举地将函数发布成HTTP服务。它通过读取用户的源代码，抽象出容器镜像并执行。同时它帮助减轻了Kubernetes的学习负担，开发者无需了解太多K8s也可以搭建出实用的服务。Fission目前主要支持NodeJS和Python，预支持C# .NET，对Golang的支持也在进行中。Fission可以与HTTP路由、Kubernetes Events和其他的事件触发器结合，所有这些函数都只有在运行的时候才会消耗CPU和内存。</p><p>Kubernetes提供了强大的弹性编排系统，并且拥有易于理解的后端API和不断发展壮大的社区。所以Fission将容器编排功能交给了K8s，让自己专注于FaaS的特性。</p><p><img src="/2020/05/17/FaaS-%E5%8F%88%E4%B8%80%E4%B8%AA%E4%B8%BA%E6%9C%AA%E6%9D%A5/3849419e-f5cb-44a1-aaa9-18d0b7f5fe36.jpg" alt></p><p>对于FaaS来说，它最重要的两个特性是将函数转换为服务，同时管理服务的生命周期。有很多办法可以实现这两个特性，但需要考虑一些问题，比如“框架运行在源码级？还是Docker镜像？”，“第一次运行的负载多少能接受”，不同的选择会影响到平台的扩展性、易用性、资源使用以及性能等问题。</p><p>为了使Fission足够易用，它选择在源码级工作。用户不再参与镜像构建、推仓库、镜像认证、镜像版本等过程。但源码级的接口不允许用户打包二进制依赖。Fission采用的方式是在镜像内部放置动态的函数加载工具，让用户可以在源码层操作，同时在需要的时候可以定制镜像。这些镜像在Fission里叫做“环境镜像”，它包含了特定语言的运行时、一组常用的依赖和函数的动态加载工具。如果这些依赖已经足够满足需求，就直接使用这个镜像，否则的话需要重新导入依赖并构建镜像。环境镜像是Fission中唯一与语言相关的部分。可以把它看做是框架里其余部分的统一接口。所以Fission可以更加容易扩展(这看起来就像VFS一样)。</p><p>FaaS优化了函数运行时的资源使用，它的目标是在运行的时候才消费资源。但在冷启动的时候可能会有些资源使用过载，比如对于用户登录的过程，无论多等几秒都是不可接受的。为了改变这个问题，Fission维持了一个面向任何环境容器池。当有函数进来时，Fission无需启动新容器，直接从池里取一个，将函数拷贝到容器里，执行动态加载，并将请求路由到对应的实例。</p><p><img src="/2020/05/17/FaaS-%E5%8F%88%E4%B8%80%E4%B8%AA%E4%B8%BA%E6%9C%AA%E6%9D%A5/301294bf-3023-4596-9d43-e63d21790dd7.png" alt></p><p>除了安装在本地的Fission主程序外，Fission-bundle设计为一组微服务构成:</p><p>Controller: 记录了函数、HTTP路由、事件触发器和环境镜像</p><p>Pool Manager: 管理环境容器，加载函数到容器，函数实例空闲时杀掉</p><p>Router: 接受HTTP请求，并路由到对应的函数实例，必要的话从Pool Manager中请求容器实例</p><p>在Kubernetes上，这些组件都以Deployment的方式运行，并对外暴露Service。除了这三个Fission特有的组件外，还用了Etcd作为资源和映射的存储，同样也以Deployment的方式启动。Controller支持Fission的API，其他的组件监视controller的更新。Router暴露为K8s里的LoadBalancer或NodePort类型的服务(这取决于K8s集群放在哪里)。</p><p>目前，Fission将一个函数映射为一个容器，对于自动扩展为多个实例的特性在后续版本里。以及重用函数Pods来支持多个函数也在计划中(在这种情况下隔离不是必须的)。Fission文档简单介绍了它的工作原理：</p><p>“当Router收到外部请求，它先去缓存Cache里查看是否在请求一个已经存在的服务。如果没有，要访问请求映射的服务函数，需要向Pool Manager申请一个容器实例执行函数。Pool Manager拥有一个空闲Pod池。它选择一个Pod，并把函数加载到里面（通过向容器里的Sidecar发送请求实现），并且把Pod的地址返回给Router。Router将外部请求代理转发到该Pod，并将响应结果返回。Pod会被缓存起来以应对后续的请求。如果空闲了几分钟，它就会被杀死”</p><p>对于较小的REST API来说，Fission是个很好的选择，通过实现webhooks，可以为Slack或其他服务编写chatbots。</p><p>Fission同时还支持根据Kubernetes的Watch机制来出发函数的执行。例如你可以设置一个函数来watch某个命名空间下所有满足某个标签的pod，这个函数将得到序列化的对象和这个上下文的Watch Event类型(added/removed/updated)。又如通过设置事件处理函数可以将它应用于简单的监控，指定当任意一个服务添加到集群时向Slack发送一条消息。当然也有更复杂的应用，例如编写一个watching Kubernetes第三方资源(Third Party Resource)的自定义controller。</p><p>在Fission的官网上有个入门的使用示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ cat hello.js</span><br><span class="line">module.exports &#x3D; function(context, callback) &#123;</span><br><span class="line">callback(200, &quot;Hello, world!\n&quot;);</span><br><span class="line">&#125;</span><br><span class="line"># Upload your function code to fission</span><br><span class="line">$ fission function create --name hello --env nodejs --code hello.js</span><br><span class="line"># Map GET &#x2F;hello to your new function</span><br><span class="line">$ fission route create --method GET --url &#x2F;hello --function hello</span><br><span class="line"># Run the function. This takes about 100msec the first time.</span><br><span class="line">$ curl http:&#x2F;&#x2F;$FISSION_ROUTER&#x2F;hello</span><br><span class="line">Hello, world!</span><br></pre></td></tr></table></figure><p>如果是第一次运行，需要先准备NodeJS的运行环境：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Add the stock NodeJS env to your Fission deployment</span><br><span class="line">$ fission env create --name nodejs --image fission&#x2F;node-env</span><br></pre></td></tr></table></figure><p>通过阅读Fission的源码，可以很清晰地看到它的执行过程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fission env create --name nodejs --image fission&#x2F;node-env</span><br></pre></td></tr></table></figure><p><img src="/2020/05/17/FaaS-%E5%8F%88%E4%B8%80%E4%B8%AA%E4%B8%BA%E6%9C%AA%E6%9D%A5/a1f4d5af-fbe1-49fd-a316-4c97700f4499.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fission function create --name hello --env nodejs --code hello.js</span><br></pre></td></tr></table></figure><p><img src="/2020/05/17/FaaS-%E5%8F%88%E4%B8%80%E4%B8%AA%E4%B8%BA%E6%9C%AA%E6%9D%A5/9a627861-8e90-4c16-9292-7c28d97ad021.png" alt></p><p>同样，由fission主程序执行命令function和子命令create，通过–name参数指定函数名为hello，–env参数确定环境，–code参数确定要执行的函数代码。通过POST向/v1/functions发出请求，携带函数信息的JSON。controller拿到JSON后进行函数资源的存储。首先将拿到UUID，然后写到文件名为该UUID的文件里。接着向ETCD的API发送HTTP请求，在file/name路径下有序存放UUID。最后类似上面env命令，将UUID和序列化后的JSON数据写到ETCD里。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fission route create --method GET --url &#x2F;hello --function hello</span><br></pre></td></tr></table></figure><p><img src="/2020/05/17/FaaS-%E5%8F%88%E4%B8%80%E4%B8%AA%E4%B8%BA%E6%9C%AA%E6%9D%A5/4ce07dea-a63d-426a-a133-139e3aaf0884.png" alt></p><p>fission通过参数–method指定请求所需方法为GET，–url指定API路由为hello，–function指定对应执行的函数为hello。通过POST向/v1/triggers/http发出请求，将路由和函数的映射关系信息发送到controller。controller会在已有的trigger列表里进行重名检查，如果不重复，才会获取UUID并将序列化后的JSON数据写到etcd里。</p><p>前面的都是由本地的fission程序完成的。我们已经预先创建了fission-bundle的Deployment和Service。它创建了名为fission的命名空间，并在里面启动4个Deployment，分别是controller, router, poolMgr, etcd，并创建NodePort类型的Service: controller和router，分别监听端口31313和31314。同时创建另一个名为fission-function的命名空间用来运行执行函数的Pod.</p><p>router使用Cache维护着一份function到service的映射，同时还有trigger集合(有个goroutine通过controller保持对这个trigger集合的更新），在启动时按照添加trigger里的url和针对对应函数的handler初始化路由。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;$FISSION_ROUTER&#x2F;hello</span><br></pre></td></tr></table></figure><p>当执行该curl时，请求发送至router容器。收到请求后会转发到两个对应的handler。一个是用户定义的面向外部的，一个是内部的。实际上它们执行的是同一个handler。任何handler都会先根据funtion名去Cache里查找对应的service名。如果没有命中，将通过poolmgr为函数创建新的Service，并把记录添加到Cache。然后生成一个反向代理，接收外部请求，然后转发至Kubernetes Service。</p><p><img src="/2020/05/17/FaaS-%E5%8F%88%E4%B8%80%E4%B8%AA%E4%B8%BA%E6%9C%AA%E6%9D%A5/12747242-aa3d-4174-9740-9d395314bc75.png" alt></p><p>Poolmgr在创建新的service时，会根据env创建Pod pool(初始大小为3个副本的deployment)，然后从中随机选择一个Ready的Pod。接着为此建立对应的Service。</p><p>Fission是一个开源项目，由Platform 9和社区进行开发。社区正在努力让Kubernetes上的FaaS更加易用和轻松集成。在未来几个月将添加单元测试、与Git集成、函数监控和日志聚合等特性，同时也会跟其他的Events进行集成，对了，还有为更多的语言创建环境。在今年1月份，Fission发布了alpha版。</p><h2 id="三、后记"><a href="#三、后记" class="headerlink" title="三、后记"></a>三、后记</h2><p>容器技术的出现改变了软件交付的思维，微服务和Serverless虽然没有减少软件生命周期中的环节，但确实改变了下游软件部署和维护的理念，提高了软件开发人员的效率。FaaS是未来的一种可能的走势，但一定不会是最终的未来。总有一天FaaS又会被其他技术所代替。生活在这个信息爆炸、技术飞速更迭的时代很烦恼也很幸福。这就是我们所在的时代，我们正在亲身经历着未来。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;转载自：&lt;a href=&quot;http://www.uml.org.cn/zjjs/202001023.asp&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.uml.org.cn/zjjs/202001023.asp&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;云计算时代出现了大量XaaS形式的概念,从IaaS、PaaS、SaaS到容器云引领的CaaS,再到火热的微服务架构,以及现在越来越多被谈起的Serverless和FaaS,我们正在经历?一个技术飞速变革的时代。&lt;/p&gt;
&lt;h2 id=&quot;一、什么是Faas&quot;&gt;&lt;a href=&quot;#一、什么是Faas&quot; class=&quot;headerlink&quot; title=&quot;一、什么是Faas&quot;&gt;&lt;/a&gt;一、什么是Faas&lt;/h2&gt;&lt;p&gt;云计算时代出现了大量XaaS形式的概念，从IaaS(Infrastructure as a Service)、PaaS(Platform as a Service)、SaaS(Software as a Service)到容器云引领的CaaS(Containers as a Service)，再到火热的微服务架构，它们都在试着将各种软、硬件资源等抽象为一种服务提供给开发者使用，让他们不再担心基础设施、资源需求、中间件等等，在减轻心智负担的同时更好地专注于业务。FaaS是Functions as a Service的简称，它往往和无服务架构(Serverless Architecture)一同被提起。&lt;/p&gt;
&lt;p&gt;Serverless的概念刚刚出现在HackerNews时并不为大众所接受。后来随着微服务和事件驱动架构的发展才慢慢引起关注。Serverless并不是说没有服务器参与，它通过将复杂的服务器架构透明化，使开发者专注于“要做什么”，从而强调了减少开发者对服务器等计算资源的关注、工作粒度从服务器切换到任务的思想。2006年第一个支持“随用随付”的代码执行平台Zimki问世。2014年亚马逊AWS推出了Lambda成为最主要的无服务架构的代表。接着Google、IBM和Microsoft也纷纷推出了各自支持Serverless的平台。&lt;/p&gt;
    
    </summary>
    
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/categories/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>分布式ID的花拳绣腿</title>
    <link href="http://javassun.github.io/2020/04/19/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%9A%84%E8%8A%B1%E6%8B%B3%E7%BB%A3%E8%85%BF/"/>
    <id>http://javassun.github.io/2020/04/19/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%9A%84%E8%8A%B1%E6%8B%B3%E7%BB%A3%E8%85%BF/</id>
    <published>2020-04-19T09:20:16.000Z</published>
    <updated>2020-06-17T06:31:14.360Z</updated>
    
    <content type="html"><![CDATA[<p>转载自 原创作者 微信号-mhcoding</p><h2 id="1-为什么要用分布式ID？"><a href="#1-为什么要用分布式ID？" class="headerlink" title="1. 为什么要用分布式ID？"></a>1. 为什么要用分布式ID？</h2><p>在说分布式ID的具体实现之前，我们来简单分析一下为什么用分布式ID？分布式ID应该满足哪些特征？</p><h3 id="1、什么是分布式ID？"><a href="#1、什么是分布式ID？" class="headerlink" title="1、什么是分布式ID？"></a>1、什么是分布式ID？</h3><p>拿MySQL数据库举个栗子：</p><p>在我们业务数据量不大的时候，单库单表完全可以支撑现有业务，数据再大一点搞个MySQL主从同步读写分离也能对付。</p><p>但随着数据日渐增长，主从同步也扛不住了，就需要对数据库进行分库分表，但分库分表后需要有一个唯一ID来标识一条数据，数据库的自增ID显然不能满足需求；特别一点的如订单、优惠券也都需要有<code>唯一ID</code>做标识。此时一个能够生成<code>全局唯一ID</code>的系统是非常必要的。那么这个<code>全局唯一ID</code>就叫<code>分布式ID</code>。</p><a id="more"></a><h3 id="2、那么分布式ID需要满足那些条件？"><a href="#2、那么分布式ID需要满足那些条件？" class="headerlink" title="2、那么分布式ID需要满足那些条件？"></a>2、那么分布式ID需要满足那些条件？</h3><ul><li><p>全局唯一：必须保证ID是全局性唯一的，基本要求</p></li><li><p>高性能：高可用低延时，ID生成响应要块，否则反倒会成为业务瓶颈</p></li><li><p>高可用：100%的可用性是骗人的，但是也要无限接近于100%的可用性</p></li><li><p>好接入：要秉着拿来即用的设计原则，在系统设计和实现上要尽可能的简单</p></li><li><p>趋势递增：最好趋势递增，这个要求就得看具体业务场景了，一般不严格要求</p></li></ul><h2 id="2-分布式ID都有哪些生成方式？"><a href="#2-分布式ID都有哪些生成方式？" class="headerlink" title="2. 分布式ID都有哪些生成方式？"></a>2. 分布式ID都有哪些生成方式？</h2><p>今天主要分析一下以下9种，分布式ID生成器方式以及优缺点：</p><ul><li><p>UUID</p></li><li><p>数据库自增ID</p></li><li><p>数据库多主模式</p></li><li><p>号段模式</p></li><li><p>Redis</p></li><li><p>雪花算法（SnowFlake）</p></li><li><p>滴滴出品（TinyID）</p></li><li><p>百度 （Uidgenerator）</p></li><li><p>美团（Leaf）</p></li></ul><p>那么它们都是如何实现？以及各自有什么优缺点？我们往下看</p><h3 id="1-基于UUID"><a href="#1-基于UUID" class="headerlink" title="1. 基于UUID"></a>1. 基于UUID</h3><p>在Java的世界里，想要得到一个具有唯一性的ID，首先被想到可能就是<code>UUID</code>，毕竟它有着全球唯一的特性。那么<code>UUID</code>可以做<code>分布式ID</code>吗？<strong>答案是可以的，但是并不推荐！</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public static void main(String[] args) &#123; </span><br><span class="line">       String uuid &#x3D; UUID.randomUUID().toString().replaceAll(&quot;-&quot;,&quot;&quot;);</span><br><span class="line">       System.out.println(uuid);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p><code>UUID</code>的生成简单到只有一行代码，输出结果 <code>c2b8c2b9e46c47e3b30dca3b0d447718</code>，但UUID却并不适用于实际的业务需求。像用作订单号<code>UUID</code>这样的字符串没有丝毫的意义，看不出和订单相关的有用信息；而对于数据库来说用作业务<code>主键ID</code>，它不仅是太长还是字符串，存储性能差查询也很耗时，所以不推荐用作<code>分布式ID</code>。</p><p><strong>优点：</strong></p><ul><li>生成足够简单，本地生成无网络消耗，具有唯一性</li></ul><p><strong>缺点：</strong></p><ul><li><p>无序的字符串，不具备趋势自增特性</p></li><li><p>没有具体的业务含义</p></li><li><p>长度过长16 字节128位，36位长度的字符串，存储以及查询对MySQL的性能消耗较大，MySQL官方明确建议主键要尽量越短越好，作为数据库主键 <code>UUID</code> 的无序性会导致数据位置频繁变动，严重影响性能。</p></li></ul><h3 id="2-基于数据库自增ID"><a href="#2-基于数据库自增ID" class="headerlink" title="2. 基于数据库自增ID"></a>2. 基于数据库自增ID</h3><p>基于数据库的<code>auto_increment</code>自增ID完全可以充当<code>分布式ID</code>，具体实现：需要一个单独的MySQL实例用来生成ID，建表结构如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE &#96;SEQ_ID&#96;;</span><br><span class="line">CREATE TABLE SEQID.SEQUENCE_ID (</span><br><span class="line">    id bigint(20) unsigned NOT NULL auto_increment,</span><br><span class="line">    value char(10) NOT NULL default &#39;&#39;,</span><br><span class="line">    PRIMARY KEY (id),</span><br><span class="line">) ENGINE&#x3D;MyISAM;</span><br><span class="line"></span><br><span class="line">insert into SEQUENCE_ID(value)  VALUES (&#39;values&#39;);</span><br></pre></td></tr></table></figure><p>当我们需要一个ID的时候，向表中插入一条记录返回<code>主键ID</code>，但这种方式有一个比较致命的缺点，访问量激增时MySQL本身就是系统的瓶颈，用它来实现分布式服务风险比较大，不推荐！</p><p><strong>优点：</strong></p><ul><li>实现简单，ID单调自增，数值类型查询速度快</li></ul><p><strong>缺点：</strong></p><ul><li>DB单点存在宕机风险，无法扛住高并发场景</li></ul><h3 id="3-基于数据库集群模式"><a href="#3-基于数据库集群模式" class="headerlink" title="3. 基于数据库集群模式"></a>3. 基于数据库集群模式</h3><p>前边说了单点数据库方式不可取，那对上边的方式做一些高可用优化，换成主从模式集群。害怕一个主节点挂掉没法用，那就做双主模式集群，也就是两个Mysql实例都能单独的生产自增ID。</p><p>那这样还会有个问题，两个MySQL实例的自增ID都从1开始，<strong>会生成重复的ID怎么办？</strong></p><p><strong>解决方案</strong>：设置<code>起始值</code>和<code>自增步长</code></p><p>MySQL_1 配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set @@auto_increment_offset &#x3D; 1;     -- 起始值</span><br><span class="line">set @@auto_increment_increment &#x3D; 2;  -- 步长</span><br></pre></td></tr></table></figure><p>MySQL_2 配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set @@auto_increment_offset &#x3D; 2;     -- 起始值</span><br><span class="line">set @@auto_increment_increment &#x3D; 2;  -- 步长</span><br></pre></td></tr></table></figure><p>这样两个MySQL实例的自增ID分别就是：</p><blockquote><p>1、3、5、7、9<br>2、4、6、8、10</p></blockquote><p>那如果集群后的性能还是扛不住高并发咋办？就要进行MySQL扩容增加节点，这是一个比较麻烦的事。</p><p><img src="/2020/04/19/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%9A%84%E8%8A%B1%E6%8B%B3%E7%BB%A3%E8%85%BF/5add20ce-2228-48fc-8e7c-a8fe5b740433.jpg" alt></p><p>从上图可以看出，水平扩展的数据库集群，有利于解决数据库单点压力的问题，同时为了ID生成特性，将自增步长按照机器数量来设置。</p><p>增加第三台<code>MySQL</code>实例需要人工修改一、二两台<code>MySQL实例</code>的起始值和步长，把<code>第三台机器的ID</code>起始生成位置设定在比现有<code>最大自增ID</code>的位置远一些，但必须在一、二两台<code>MySQL实例</code>ID还没有增长到<code>第三台MySQL实例</code>的<code>起始ID</code>值的时候，否则<code>自增ID</code>就要出现重复了，<strong>必要时可能还需要停机修改</strong>。</p><p><strong>优点：</strong></p><ul><li>解决DB单点问题</li></ul><p><strong>缺点：</strong></p><ul><li>不利于后续扩容，而且实际上单个数据库自身压力还是大，依旧无法满足高并发场景。</li></ul><h3 id="4-基于数据库的号段模式"><a href="#4-基于数据库的号段模式" class="headerlink" title="4. 基于数据库的号段模式"></a>4. 基于数据库的号段模式</h3><p>号段模式是当下分布式ID生成器的主流实现方式之一，号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000个ID，具体的业务服务将本号段，生成1~1000的自增ID并加载到内存。表结构如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE id_generator (</span><br><span class="line">  id int(10) NOT NULL,</span><br><span class="line">  max_id bigint(20) NOT NULL COMMENT &#39;当前最大id&#39;,</span><br><span class="line">  step int(20) NOT NULL COMMENT &#39;号段的步长&#39;,</span><br><span class="line">  biz_type    int(20) NOT NULL COMMENT &#39;业务类型&#39;,</span><br><span class="line">  version int(20) NOT NULL COMMENT &#39;版本号&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>biz_type ：代表不同业务类型</p><p>max_id ：当前最大的可用id</p><p>step ：代表号段的长度</p><p>version ：是一个乐观锁，每次都更新version，保证并发时数据的正确性</p><p><img src="/2020/04/19/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%9A%84%E8%8A%B1%E6%8B%B3%E7%BB%A3%E8%85%BF/07bd4a25-2665-4f83-a63a-9d9477b2a49d.png" alt></p><p>等这批号段ID用完，再次向数据库申请新号段，对<code>max_id</code>字段做一次<code>update</code>操作，<code>update max_id= max_id + step</code>，update成功则说明新号段获取成功，新的号段范围是<code>(max_id ,max_id +step]</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update id_generator set max_id &#x3D; #&#123;max_id+step&#125;, version &#x3D; version + 1 where version &#x3D; # &#123;version&#125; and biz_type &#x3D; XXX</span><br></pre></td></tr></table></figure><p>由于多业务端可能同时操作，所以采用版本号<code>version</code>乐观锁方式更新，这种<code>分布式ID</code>生成方式不强依赖于数据库，不会频繁的访问数据库，对数据库的压力小很多。</p><h3 id="5-基于Redis模式"><a href="#5-基于Redis模式" class="headerlink" title="5. 基于Redis模式"></a>5. 基于Redis模式</h3><p><code>Redis</code>也同样可以实现，原理就是利用<code>redis</code>的 <code>incr</code>命令实现ID的原子性自增。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set seq_id 1     &#x2F;&#x2F; 初始化自增ID为1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; incr seq_id      &#x2F;&#x2F; 增加1，并返回递增后的数值</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure><p>用<code>redis</code>实现需要注意一点，要考虑到redis持久化的问题。<code>redis</code>有两种持久化方式<code>RDB</code>和<code>AOF</code></p><ul><li><p><code>RDB</code>会定时打一个快照进行持久化，假如连续自增但<code>redis</code>没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。</p></li><li><p><code>AOF</code>会对每条写命令进行持久化，即使<code>Redis</code>挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致<code>Redis</code>重启恢复的数据时间过长。</p></li></ul><h3 id="6-基于雪花算法（Snowflake）模式"><a href="#6-基于雪花算法（Snowflake）模式" class="headerlink" title="6. 基于雪花算法（Snowflake）模式"></a>6. 基于雪花算法（Snowflake）模式</h3><p>雪花算法（Snowflake）是twitter公司内部分布式项目采用的ID生成算法，开源后广受国内大厂的好评，在该算法影响下各大公司相继开发出各具特色的分布式生成器。</p><p><img src="/2020/04/19/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%9A%84%E8%8A%B1%E6%8B%B3%E7%BB%A3%E8%85%BF/e5a31e85-852c-4d20-b9ca-6c2ad2e7bcb0.jpg" alt></p><p><code>Snowflake</code>生成的是Long类型的ID，一个Long类型占8个字节，每个字节占8比特，也就是说一个Long类型占64个比特。</p><p>Snowflake ID组成结构：<code>正数位</code>（占1比特）+ <code>时间戳</code>（占41比特）+ <code>机器ID</code>（占5比特）+ <code>数据中心</code>（占5比特）+ <code>自增值</code>（占12比特），总共64比特组成的一个Long类型。</p><ul><li><p>第一个bit位（1bit）：Java中long的最高位是符号位代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。</p></li><li><p>时间戳部分（41bit）：毫秒级的时间，不建议存当前时间戳，而是用（当前时间戳 - 固定开始时间戳）的差值，可以使产生的ID从更小的值开始；41位的时间戳可以使用69年，(1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69年</p></li><li><p>工作机器id（10bit）：也被叫做<code>workId</code>，这个可以灵活配置，机房或者机器号组合都可以。</p></li><li><p>序列号部分（12bit），自增值支持同一毫秒内同一个节点可以生成4096个ID</p></li></ul><p>根据这个算法的逻辑，只需要将这个算法用Java语言实现出来，封装为一个工具方法，那么各个业务应用可以直接使用该工具方法来获取分布式ID，只需保证每个业务应用有自己的工作机器id即可，而不需要单独去搭建一个获取分布式ID的应用。</p><p><strong>Java版本的**</strong><code>Snowflake</code>算法实现：**</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * Twitter的SnowFlake算法,使用SnowFlake算法生成一个整数，然后转化为62进制变成一个短地址URL</span><br><span class="line"> *</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class SnowFlakeShortUrl &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 起始的时间戳</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private final static long START_TIMESTAMP &#x3D; 1480166465631L;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 每一部分占用的位数</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private final static long SEQUENCE_BIT &#x3D; 12;   &#x2F;&#x2F;序列号占用的位数</span><br><span class="line">    private final static long MACHINE_BIT &#x3D; 5;     &#x2F;&#x2F;机器标识占用的位数</span><br><span class="line">    private final static long DATA_CENTER_BIT &#x3D; 5; &#x2F;&#x2F;数据中心占用的位数</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 每一部分的最大值</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private final static long MAX_SEQUENCE &#x3D; -1L ^ (-1L &lt;&lt; SEQUENCE_BIT);</span><br><span class="line">    private final static long MAX_MACHINE_NUM &#x3D; -1L ^ (-1L &lt;&lt; MACHINE_BIT);</span><br><span class="line">    private final static long MAX_DATA_CENTER_NUM &#x3D; -1L ^ (-1L &lt;&lt; DATA_CENTER_BIT);</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 每一部分向左的位移</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private final static long MACHINE_LEFT &#x3D; SEQUENCE_BIT;</span><br><span class="line">    private final static long DATA_CENTER_LEFT &#x3D; SEQUENCE_BIT + MACHINE_BIT;</span><br><span class="line">    private final static long TIMESTAMP_LEFT &#x3D; DATA_CENTER_LEFT + DATA_CENTER_BIT;</span><br><span class="line"></span><br><span class="line">    private long dataCenterId;  &#x2F;&#x2F;数据中心</span><br><span class="line">    private long machineId;     &#x2F;&#x2F;机器标识</span><br><span class="line">    private long sequence &#x3D; 0L; &#x2F;&#x2F;序列号</span><br><span class="line">    private long lastTimeStamp &#x3D; -1L;  &#x2F;&#x2F;上一次时间戳</span><br><span class="line"></span><br><span class="line">    private long getNextMill() &#123;</span><br><span class="line">        long mill &#x3D; getNewTimeStamp();</span><br><span class="line">        while (mill &lt;&#x3D; lastTimeStamp) &#123;</span><br><span class="line">            mill &#x3D; getNewTimeStamp();</span><br><span class="line">        &#125;</span><br><span class="line">        return mill;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private long getNewTimeStamp() &#123;</span><br><span class="line">        return System.currentTimeMillis();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 根据指定的数据中心ID和机器标志ID生成指定的序列号</span><br><span class="line">     *</span><br><span class="line">     * @param dataCenterId 数据中心ID</span><br><span class="line">     * @param machineId    机器标志ID</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public SnowFlakeShortUrl(long dataCenterId, long machineId) &#123;</span><br><span class="line">        if (dataCenterId &gt; MAX_DATA_CENTER_NUM || dataCenterId &lt; 0) &#123;</span><br><span class="line">            throw new IllegalArgumentException(&quot;DtaCenterId can&#39;t be greater than MAX_DATA_CENTER_NUM or less than 0！&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        if (machineId &gt; MAX_MACHINE_NUM || machineId &lt; 0) &#123;</span><br><span class="line">            throw new IllegalArgumentException(&quot;MachineId can&#39;t be greater than MAX_MACHINE_NUM or less than 0！&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        this.dataCenterId &#x3D; dataCenterId;</span><br><span class="line">        this.machineId &#x3D; machineId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 产生下一个ID</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public synchronized long nextId() &#123;</span><br><span class="line">        long currTimeStamp &#x3D; getNewTimeStamp();</span><br><span class="line">        if (currTimeStamp &lt; lastTimeStamp) &#123;</span><br><span class="line">            throw new RuntimeException(&quot;Clock moved backwards.  Refusing to generate id&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (currTimeStamp &#x3D;&#x3D; lastTimeStamp) &#123;</span><br><span class="line">            &#x2F;&#x2F;相同毫秒内，序列号自增</span><br><span class="line">            sequence &#x3D; (sequence + 1) &amp; MAX_SEQUENCE;</span><br><span class="line">            &#x2F;&#x2F;同一毫秒的序列数已经达到最大</span><br><span class="line">            if (sequence &#x3D;&#x3D; 0L) &#123;</span><br><span class="line">                currTimeStamp &#x3D; getNextMill();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            &#x2F;&#x2F;不同毫秒内，序列号置为0</span><br><span class="line">            sequence &#x3D; 0L;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        lastTimeStamp &#x3D; currTimeStamp;</span><br><span class="line"></span><br><span class="line">        return (currTimeStamp - START_TIMESTAMP) &lt;&lt; TIMESTAMP_LEFT &#x2F;&#x2F;时间戳部分</span><br><span class="line">                | dataCenterId &lt;&lt; DATA_CENTER_LEFT       &#x2F;&#x2F;数据中心部分</span><br><span class="line">                | machineId &lt;&lt; MACHINE_LEFT             &#x2F;&#x2F;机器标识部分</span><br><span class="line">                | sequence;                             &#x2F;&#x2F;序列号部分</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SnowFlakeShortUrl snowFlake &#x3D; new SnowFlakeShortUrl(2, 3);</span><br><span class="line"></span><br><span class="line">        for (int i &#x3D; 0; i &lt; (1 &lt;&lt; 4); i++) &#123;</span><br><span class="line">            &#x2F;&#x2F;10进制</span><br><span class="line">            System.out.println(snowFlake.nextId());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="7-百度（uid-generator）"><a href="#7-百度（uid-generator）" class="headerlink" title="7. 百度（uid-generator）"></a>7. 百度（uid-generator）</h3><p><code>uid-generator</code>是由百度技术部开发，项目GitHub地址 <a href="https://github.com/baidu/uid-generator" target="_blank" rel="noopener">https://github.com/baidu/uid-generator</a></p><p><code>uid-generator</code>是基于<code>Snowflake</code>算法实现的，与原始的<code>snowflake</code>算法不同在于，<code>uid-generator</code>支持自<code>定义时间戳</code>、<code>工作机器ID</code>和 <code>序列号</code> 等各部分的位数，而且<code>uid-generator</code>中采用用户自定义<code>workId</code>的生成策略。</p><p><code>uid-generator</code>需要与数据库配合使用，需要新增一个<code>WORKER_NODE</code>表。当应用启动时会向数据库表中去插入一条数据，插入成功后返回的自增ID就是该机器的<code>workId</code>数据由host，port组成。</p><p><strong>对于<code>uid-generator</code> ID组成结构</strong>：</p><p><code>workId</code>，占用了22个bit位，时间占用了28个bit位，序列化占用了13个bit位，需要注意的是，和原始的<code>snowflake</code>不太一样，时间的单位是秒，而不是毫秒，<code>workId</code>也不一样，而且同一应用每次重启就会消费一个<code>workId</code>。</p><blockquote><p>参考文献<br><a href="https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md" target="_blank" rel="noopener">https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md</a></p></blockquote><h3 id="8-美团（Leaf）"><a href="#8-美团（Leaf）" class="headerlink" title="8. 美团（Leaf）"></a>8. 美团（Leaf）</h3><p><code>Leaf</code>由美团开发，github地址：<a href="https://github.com/Meituan-Dianping/Leaf" target="_blank" rel="noopener">https://github.com/Meituan-Dianping/Leaf</a></p><p><code>Leaf</code>同时支持号段模式和<code>snowflake</code>算法模式，可以切换使用。</p><h5 id="号段模式"><a href="#号段模式" class="headerlink" title="号段模式"></a>号段模式</h5><p>先导入源码 <a href="https://github.com/Meituan-Dianping/Leaf" target="_blank" rel="noopener">https://github.com/Meituan-Dianping/Leaf</a> ，在建一张表<code>leaf_alloc</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DROP TABLE IF EXISTS &#96;leaf_alloc&#96;;</span><br><span class="line"></span><br><span class="line">CREATE TABLE &#96;leaf_alloc&#96; (</span><br><span class="line">  &#96;biz_tag&#96; varchar(128)  NOT NULL DEFAULT &#39;&#39; COMMENT &#39;业务key&#39;,</span><br><span class="line">  &#96;max_id&#96; bigint(20) NOT NULL DEFAULT &#39;1&#39; COMMENT &#39;当前已经分配了的最大id&#39;,</span><br><span class="line">  &#96;step&#96; int(11) NOT NULL COMMENT &#39;初始步长，也是动态调整的最小步长&#39;,</span><br><span class="line">  &#96;description&#96; varchar(256)  DEFAULT NULL COMMENT &#39;业务key的描述&#39;,</span><br><span class="line">  &#96;update_time&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;数据库维护的更新时间&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;biz_tag&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB;</span><br></pre></td></tr></table></figure><p>然后在项目中开启<code>号段模式</code>，配置对应的数据库信息，并关闭<code>snowflake</code>模式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">leaf.name&#x3D;com.sankuai.leaf.opensource.test</span><br><span class="line">leaf.segment.enable&#x3D;true</span><br><span class="line">leaf.jdbc.url&#x3D;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;leaf_test?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf8&amp;characterSetResults&#x3D;utf8</span><br><span class="line">leaf.jdbc.username&#x3D;root</span><br><span class="line">leaf.jdbc.password&#x3D;root</span><br><span class="line"></span><br><span class="line">leaf.snowflake.enable&#x3D;false</span><br><span class="line">#leaf.snowflake.zk.address&#x3D;</span><br><span class="line">#leaf.snowflake.port&#x3D;</span><br></pre></td></tr></table></figure><p>启动<code>leaf-server</code> 模块的 <code>LeafServerApplication</code>项目就跑起来了</p><p>号段模式获取分布式自增ID的测试url ：http：//localhost：8080/api/segment/get/leaf-segment-test</p><p>监控号段模式：<a href="http://localhost:8080/cache" target="_blank" rel="noopener">http://localhost:8080/cache</a></p><h5 id="snowflake模式"><a href="#snowflake模式" class="headerlink" title="snowflake模式"></a>snowflake模式</h5><p><code>Leaf</code>的snowflake模式依赖于<code>ZooKeeper</code>，不同于<code>原始snowflake</code>算法也主要是在<code>workId</code>的生成上，<code>Leaf</code>中<code>workId</code>是基于<code>ZooKeeper</code>的顺序Id来生成的，每个应用在使用<code>Leaf-snowflake</code>时，启动时都会都在<code>Zookeeper</code>中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个<code>workId</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">leaf.snowflake.enable&#x3D;true</span><br><span class="line">leaf.snowflake.zk.address&#x3D;127.0.0.1</span><br><span class="line">leaf.snowflake.port&#x3D;2181</span><br></pre></td></tr></table></figure><p>snowflake模式获取分布式自增ID的测试url：<a href="http://localhost:8080/api/snowflake/get/test" target="_blank" rel="noopener">http://localhost:8080/api/snowflake/get/test</a></p><h3 id="9-滴滴（Tinyid）"><a href="#9-滴滴（Tinyid）" class="headerlink" title="9. 滴滴（Tinyid）"></a>9. 滴滴（Tinyid）</h3><p><code>Tinyid</code>由滴滴开发，Github地址：<a href="https://github.com/didi/tinyid。" target="_blank" rel="noopener">https://github.com/didi/tinyid。</a></p><p><code>Tinyid</code>是基于号段模式原理实现的与<code>Leaf</code>如出一辙，每个服务获取一个号段（1000,2000]、（2000,3000]、（3000,4000]</p><p><img src="/2020/04/19/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%9A%84%E8%8A%B1%E6%8B%B3%E7%BB%A3%E8%85%BF/7a345b4f-37a2-47be-9cc3-0a3b86c2941b.jpg" alt></p><p><code>Tinyid</code>提供<code>http</code>和<code>tinyid-client</code>两种方式接入</p><h5 id="Http方式接入"><a href="#Http方式接入" class="headerlink" title="Http方式接入"></a>Http方式接入</h5><p>（1）导入Tinyid源码：</p><p>git clone <a href="https://github.com/didi/tinyid.git" target="_blank" rel="noopener">https://github.com/didi/tinyid.git</a></p><p>（2）创建数据表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;tiny_id_info&#96; (</span><br><span class="line">  &#96;id&#96; bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;自增主键&#39;,</span><br><span class="line">  &#96;biz_type&#96; varchar(63) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;业务类型，唯一&#39;,</span><br><span class="line">  &#96;begin_id&#96; bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;开始id，仅记录初始值，无其他含义。初始化时begin_id和max_id应相同&#39;,</span><br><span class="line">  &#96;max_id&#96; bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;当前最大id&#39;,</span><br><span class="line">  &#96;step&#96; int(11) DEFAULT &#39;0&#39; COMMENT &#39;步长&#39;,</span><br><span class="line">  &#96;delta&#96; int(11) NOT NULL DEFAULT &#39;1&#39; COMMENT &#39;每次id增量&#39;,</span><br><span class="line">  &#96;remainder&#96; int(11) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;余数&#39;,</span><br><span class="line">  &#96;create_time&#96; timestamp NOT NULL DEFAULT &#39;2010-01-01 00:00:00&#39; COMMENT &#39;创建时间&#39;,</span><br><span class="line">  &#96;update_time&#96; timestamp NOT NULL DEFAULT &#39;2010-01-01 00:00:00&#39; COMMENT &#39;更新时间&#39;,</span><br><span class="line">  &#96;version&#96; bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;版本号&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;),</span><br><span class="line">  UNIQUE KEY &#96;uniq_biz_type&#96; (&#96;biz_type&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;1 DEFAULT CHARSET&#x3D;utf8 COMMENT &#39;id信息表&#39;;</span><br><span class="line"></span><br><span class="line">CREATE TABLE &#96;tiny_id_token&#96; (</span><br><span class="line">  &#96;id&#96; int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;自增id&#39;,</span><br><span class="line">  &#96;token&#96; varchar(255) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;token&#39;,</span><br><span class="line">  &#96;biz_type&#96; varchar(63) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;此token可访问的业务类型标识&#39;,</span><br><span class="line">  &#96;remark&#96; varchar(255) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;备注&#39;,</span><br><span class="line">  &#96;create_time&#96; timestamp NOT NULL DEFAULT &#39;2010-01-01 00:00:00&#39; COMMENT &#39;创建时间&#39;,</span><br><span class="line">  &#96;update_time&#96; timestamp NOT NULL DEFAULT &#39;2010-01-01 00:00:00&#39; COMMENT &#39;更新时间&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;1 DEFAULT CHARSET&#x3D;utf8 COMMENT &#39;token信息表&#39;;</span><br><span class="line"></span><br><span class="line">INSERT INTO &#96;tiny_id_info&#96; (&#96;id&#96;, &#96;biz_type&#96;, &#96;begin_id&#96;, &#96;max_id&#96;, &#96;step&#96;, &#96;delta&#96;, &#96;remainder&#96;, &#96;create_time&#96;, &#96;update_time&#96;, &#96;version&#96;)</span><br><span class="line">VALUES</span><br><span class="line">    (1, &#39;test&#39;, 1, 1, 100000, 1, 0, &#39;2018-07-21 23:52:58&#39;, &#39;2018-07-22 23:19:27&#39;, 1);</span><br><span class="line"></span><br><span class="line">INSERT INTO &#96;tiny_id_info&#96; (&#96;id&#96;, &#96;biz_type&#96;, &#96;begin_id&#96;, &#96;max_id&#96;, &#96;step&#96;, &#96;delta&#96;, &#96;remainder&#96;, &#96;create_time&#96;, &#96;update_time&#96;, &#96;version&#96;)</span><br><span class="line">VALUES</span><br><span class="line">    (2, &#39;test_odd&#39;, 1, 1, 100000, 2, 1, &#39;2018-07-21 23:52:58&#39;, &#39;2018-07-23 00:39:24&#39;, 3);</span><br><span class="line"></span><br><span class="line">INSERT INTO &#96;tiny_id_token&#96; (&#96;id&#96;, &#96;token&#96;, &#96;biz_type&#96;, &#96;remark&#96;, &#96;create_time&#96;, &#96;update_time&#96;)</span><br><span class="line">VALUES</span><br><span class="line">    (1, &#39;0f673adf80504e2eaa552f5d791b644c&#39;, &#39;test&#39;, &#39;1&#39;, &#39;2017-12-14 16:36:46&#39;, &#39;2017-12-14 16:36:48&#39;);</span><br><span class="line"></span><br><span class="line">INSERT INTO &#96;tiny_id_token&#96; (&#96;id&#96;, &#96;token&#96;, &#96;biz_type&#96;, &#96;remark&#96;, &#96;create_time&#96;, &#96;update_time&#96;)</span><br><span class="line">VALUES</span><br><span class="line">    (2, &#39;0f673adf80504e2eaa552f5d791b644c&#39;, &#39;test_odd&#39;, &#39;1&#39;, &#39;2017-12-14 16:36:46&#39;, &#39;2017-12-14 16:36:48&#39;);</span><br></pre></td></tr></table></figure><p>（3）配置数据库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">datasource.tinyid.names&#x3D;primary</span><br><span class="line">datasource.tinyid.primary.driver-class-name&#x3D;com.mysql.jdbc.Driver</span><br><span class="line">datasource.tinyid.primary.url&#x3D;jdbc:mysql:&#x2F;&#x2F;ip:port&#x2F;databaseName?autoReconnect&#x3D;true&amp;useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8</span><br><span class="line">datasource.tinyid.primary.username&#x3D;root</span><br><span class="line">datasource.tinyid.primary.password&#x3D;123456</span><br></pre></td></tr></table></figure><p>（4）启动<code>tinyid-server</code>后测试</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">获取分布式自增ID: http:&#x2F;&#x2F;localhost:9999&#x2F;tinyid&#x2F;id&#x2F;nextIdSimple?bizType&#x3D;test&amp;token&#x3D;0f673adf80504e2eaa552f5d791b644c&#39;</span><br><span class="line">返回结果: 3</span><br><span class="line"></span><br><span class="line">批量获取分布式自增ID:</span><br><span class="line">http:&#x2F;&#x2F;localhost:9999&#x2F;tinyid&#x2F;id&#x2F;nextIdSimple?bizType&#x3D;test&amp;token&#x3D;0f673adf80504e2eaa552f5d791b644c&amp;batchSize&#x3D;10&#39;</span><br><span class="line">返回结果:  4,5,6,7,8,9,10,11,12,13</span><br></pre></td></tr></table></figure><h5 id="Java客户端方式接入"><a href="#Java客户端方式接入" class="headerlink" title="Java客户端方式接入"></a>Java客户端方式接入</h5><p>重复Http方式的（2）（3）操作</p><p>引入依赖</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.xiaoju.uemc.tinyid&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;tinyid-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;$&#123;tinyid.version&#125;&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><p>配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tinyid.server &#x3D;localhost:9999</span><br><span class="line">tinyid.token &#x3D;0f673adf80504e2eaa552f5d791b644c</span><br></pre></td></tr></table></figure><p><code>test</code> 、<code>tinyid.token</code>是在数据库表中预先插入的数据，<code>test</code> 是具体业务类型，<code>tinyid.token</code>表示可访问的业务类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 获取单个分布式自增ID</span><br><span class="line">Long id &#x3D;  TinyId . nextId( &quot; test &quot; );</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 按需批量分布式自增ID</span><br><span class="line">List&lt; Long &gt; ids &#x3D;  TinyId . nextId( &quot; test &quot; , 10 );</span><br></pre></td></tr></table></figure><h2 id="3-小结"><a href="#3-小结" class="headerlink" title="3. 小结"></a>3. 小结</h2><p>每种生成方式都有它自己的优缺点，具体如何使用还要看具体的业务需求。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;转载自 原创作者 微信号-mhcoding&lt;/p&gt;
&lt;h2 id=&quot;1-为什么要用分布式ID？&quot;&gt;&lt;a href=&quot;#1-为什么要用分布式ID？&quot; class=&quot;headerlink&quot; title=&quot;1. 为什么要用分布式ID？&quot;&gt;&lt;/a&gt;1. 为什么要用分布式ID？&lt;/h2&gt;&lt;p&gt;在说分布式ID的具体实现之前，我们来简单分析一下为什么用分布式ID？分布式ID应该满足哪些特征？&lt;/p&gt;
&lt;h3 id=&quot;1、什么是分布式ID？&quot;&gt;&lt;a href=&quot;#1、什么是分布式ID？&quot; class=&quot;headerlink&quot; title=&quot;1、什么是分布式ID？&quot;&gt;&lt;/a&gt;1、什么是分布式ID？&lt;/h3&gt;&lt;p&gt;拿MySQL数据库举个栗子：&lt;/p&gt;
&lt;p&gt;在我们业务数据量不大的时候，单库单表完全可以支撑现有业务，数据再大一点搞个MySQL主从同步读写分离也能对付。&lt;/p&gt;
&lt;p&gt;但随着数据日渐增长，主从同步也扛不住了，就需要对数据库进行分库分表，但分库分表后需要有一个唯一ID来标识一条数据，数据库的自增ID显然不能满足需求；特别一点的如订单、优惠券也都需要有&lt;code&gt;唯一ID&lt;/code&gt;做标识。此时一个能够生成&lt;code&gt;全局唯一ID&lt;/code&gt;的系统是非常必要的。那么这个&lt;code&gt;全局唯一ID&lt;/code&gt;就叫&lt;code&gt;分布式ID&lt;/code&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="分布式" scheme="http://JavaSsun.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="面试" scheme="http://JavaSsun.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E9%9D%A2%E8%AF%95/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="面试" scheme="http://JavaSsun.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="分布式" scheme="http://JavaSsun.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="系统架构" scheme="http://JavaSsun.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>4-Dockerfile上</title>
    <link href="http://javassun.github.io/2020/04/08/4-Dockerfile%E4%B8%8A/"/>
    <id>http://javassun.github.io/2020/04/08/4-Dockerfile%E4%B8%8A/</id>
    <published>2020-04-08T02:36:35.000Z</published>
    <updated>2020-06-17T06:43:56.972Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在Docker中创建镜像最常用的方式，就是使用Dockerfile。Dockerfile是一个Docker镜像的描述文件，我们可以理解成火箭发射的A、B、C、D…的步骤。Dockerfile其内部<strong>包含了一条条的指令</strong>，<strong>每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建</strong>。</p><p><strong>组成部分</strong></p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/7932ac6c-6b67-4f43-bab8-5e61dd559c48.png" alt></p><a id="more"></a><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>从Docker-Hub上拖下来的Nginx镜像，原本的配置文件可能不符合我们的期望，就要求我们更改配置文件。</p><p><strong>第一种</strong>是容器启动后绕过文件系统，以<code>docker exec</code>进入容器内部，去修改，再reload，太过繁琐。</p><p><strong>另一种</strong>做法是提前将它的配置文件存储到宿主机目录中，在宿主机上进行编辑，之后在容器启动时指定宿主机配置文件目录，覆盖他原有的配置文件，容器启动后，加载宿主机上的配置，可以让他生效。<strong>但是</strong>，容器启动后，发现配置可能不对，需要修改配置，还是需要reload。</p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/98993582-1884-40da-9fcc-4b8cf2b766df.jpg" alt></p><h2 id="制作镜像"><a href="#制作镜像" class="headerlink" title="制作镜像"></a>制作镜像</h2><ul><li><p><strong>基于容器</strong>：先启动起来，使用 docker exec进入容器内部，交互式的修改，修改完后他就会跑到读写层，覆盖下层配置，可以保存为新镜像。这个缺点等于是写死了，多次做变更很麻烦。还比如日常、预发、线上环境不同，需要制作3种不同的镜像，多次变更，头都大了，凭记忆出现精神错乱！！！</p></li><li><p><strong>基于Dockerfile</strong>：构建Docker镜像的指令。一个纯文本文件，里面包含了一些指令而已。</p></li></ul><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/7b1e9135-d1ba-4f06-bced-4de5e5e08773.jpg" alt></p><h3 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/ba2e8863-9dc7-4f4d-9bb9-6ab39dae4078.jpg" alt></p><p><strong>注意事项</strong>：</p><p>Dockerfile首字母必须大写，且需要一个专有目录存放Dockerfile。</p><p>Dockerfile文件中引用到的文件必须与Dockerfiler同目录或子目录，不能是专有目录的父目录或其他目录。</p><p>Dockerfile支持在下层做一个文本隐藏文件，隐藏不需要的文件，<strong>dockeringore</strong>。可在其中写需要隐藏的文件路径，在docker打包生成镜像时不会被打包进去。</p><p>通过 docker build 基于Dockerfile来制作镜像，打好标签。Dockerfile 中 shell命令是底层镜像支持才会运行。</p><p><strong>Environment Replacement</strong></p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/cb4d9720-4542-44ae-ab0a-2738f2151e79.jpg" alt></p><p>${variable:-world}：变量如果为空，就替换为world指定的字符串。</p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/9be897bf-ff0f-4428-b1dc-2b487e64b9c4.png" alt></p><p>${variable:+world}：变量如果有值，就显示world指定的字符串。</p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/dd5e5dc4-ba6b-4566-b42e-a4251859a75e.png" alt></p><h3 id="Dockerfile-Instructions"><a href="#Dockerfile-Instructions" class="headerlink" title="Dockerfile Instructions"></a>Dockerfile Instructions</h3><p><strong>FROM</strong></p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/a4102b43-a3de-464d-9209-837dd8b3680a.jpg" alt></p><p><strong>使用名字引用镜像可能会拉取到恶意的同名基础镜像，使用 @哈希码，则可以保证该镜像的准确性</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir img1</span><br><span class="line">cd img1&#x2F;</span><br><span class="line"># Dockerfile 首字母大写</span><br><span class="line">vim Dockerfile</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/7392b588-830e-493f-bfd4-257c752866ed.png" alt></p><p><strong>MAINTANIER(deprecated)</strong></p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/7eaf391a-eb7d-4726-8a4d-a1f799f143b5.jpg" alt></p><p>当下使用 <strong>LABLE</strong> 标签来替换，他拥有各种K/V信息，作者只是其中的一项，所以它有了更宽泛的含义。</p><p><strong>LABEL</strong>：为镜像指定元数据</p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/916ee23e-250b-4215-bc5e-2a6810c706b7.jpg" alt></p><p>Docker1.7 兼容：推荐使用LABEL</p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/c955a706-251a-476e-a647-6dfa1edd7bfc.png" alt></p><p><strong>COPY</strong></p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/b3f68979-2939-4e4c-9de7-9c122cdc056f.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#Description: test image</span><br><span class="line">FROM busybox:latest</span><br><span class="line">MAINTAINER &quot;Haoransun &lt;haornasun@163.com&gt;&quot;</span><br><span class="line">#LABEL maintainer&#x3D;Haoransun &lt;haornasun@163.com&gt;&quot;</span><br><span class="line"></span><br><span class="line"># index.html 在当前 img1要存在</span><br><span class="line">COPY index.html &#x2F;data&#x2F;web&#x2F;html&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/95ce5b08-7b3c-4db5-843d-5780daa45efb.png" alt></p><p><strong>Docker build</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker build --help</span><br><span class="line"></span><br><span class="line">#  -t 制作时直接打标签</span><br><span class="line"># .&#x2F; 为Dockerfile 当前目录</span><br><span class="line">docker build -t tinyhttpd:v0.1-1 .&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/79bfe976-e7f9-44a2-b029-40e444c05bbf.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 容器运行时可以输入一些命令查看信息，查看完成后容器退出就被删除</span><br><span class="line">docker run --name tinyweb1 --rm tinyhttpd:v0.1-1 cat &#x2F;data&#x2F;web&#x2F;html&#x2F;index.html</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/66fddf0b-946f-4231-a019-2460d50ecc22.png" alt></p><p>如何复制目录呢?</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd img1</span><br><span class="line">cp -r &#x2F;etc&#x2F;yum.repos.d&#x2F; .&#x2F;</span><br><span class="line">ls</span><br><span class="line">ls yum.repos.d&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/a6b2034f-8687-4a96-85a1-fb455c8ad0d1.png" alt></p><p>将yum.repos.d/ 目录下的所有文件打包放在 镜像 /etc/yum.repos.d/文件夹下</p><p><font color="red">Dockerfile中，惜字如金，每一条指令，都会构成一个新的镜像层，两条指令合成一条，就合成，层越多，联合挂载，效率越差</font>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim Dockerfile</span><br><span class="line"># 以下为进入vim编辑器新添加内容，将yum.repos.d 下的所有文件复制到&#x2F;etc&#x2F;&#x2F;yum.repos.d&#x2F; 下，如果不写 yum.repos.d&#x2F; 只有 &#x2F;etc，默认不会创建</span><br><span class="line">COPY yum.repos.d&#x2F; &#x2F;etc&#x2F;yum.repos.d&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/06459c46-1859-46df-97a0-1d574be4a605.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t tinyhttpd:v0.1-2 .&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/8f2a6fd5-c3de-4c97-afeb-eaaea38ef10c.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name tinyweb1 --rm tinyhttpd:v0.1-2 ls &#x2F;etc&#x2F;yum.repos.d&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/5d0c5e6a-6f92-410d-90bf-31b6257da7f2.png" alt></p><p><strong>ADD</strong></p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/22ad7f2b-4738-4d80-a9e3-89d964bca90f.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 展示不会展开的网络下载tar包</span><br><span class="line">vim Dockerfile</span><br><span class="line"></span><br><span class="line"># 添加网络tar包下载路径到 &#x2F;usr&#x2F;local&#x2F;src&#x2F; 如果不存在会自动创建</span><br><span class="line">ADD http:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.18.0.tar.gz &#x2F;usr&#x2F;local&#x2F;src&#x2F;</span><br><span class="line"></span><br><span class="line">docker build -t tinyhttpd:v0.1-3 .&#x2F;</span><br><span class="line">docker run --name tinyweb1 --rm tinyhttpd:v0.1-3 ls &#x2F;usr&#x2F;local&#x2F;src</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/78425531-294a-49fa-8a8a-00c884d7554d.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 展示会展开的tar包，tar包下载到build的工作目录，即Dockerfile所在目录</span><br><span class="line">wget http:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.18.0.tar.gz</span><br><span class="line">ls</span><br><span class="line">pwd</span><br><span class="line">vim Dockerfile</span><br><span class="line">ADD nginx-1.18.0.tar.gz  &#x2F;usr&#x2F;local&#x2F;src&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/1e32b037-4e82-47b6-a70c-7dd844b9357e.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker build -t tinyhttpd:v0.1-4 .&#x2F;</span><br><span class="line">docker run --name tinyweb1 --rm tinyhttpd:v0.1-4 ls &#x2F;usr&#x2F;local&#x2F;src&#x2F;nginx-1.18.0&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/ecffcc08-8f28-4da0-81d0-ea218ddc9588.png" alt></p><p><strong>WORKDIR</strong></p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/9d66e72b-3672-4c35-bdd1-a4308e098c3d.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">!vim</span><br><span class="line"># 指定工作目录，而后的ADD 可以引用该目录，即 .&#x2F; 就代表&#x2F;usr&#x2F;local&#x2F;src&#x2F; 目录</span><br><span class="line">WORKDIR &#x2F;usr&#x2F;local&#x2F;src&#x2F;</span><br><span class="line">ADD nginx-1.18.0.tar.gz .&#x2F;</span><br><span class="line"></span><br><span class="line"># 下面 ADD 中的 .&#x2F; 会逆序找离他最近的一个当做工作目录</span><br><span class="line">WORKDIR &#x2F;usr&#x2F;local&#x2F;src&#x2F;a</span><br><span class="line">ADD index.html .&#x2F;</span><br></pre></td></tr></table></figure><p><strong>VOLUME</strong></p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/55467f03-c39a-48a7-976d-f3e819c4f425.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VOLUME &#x2F;data&#x2F;mysql&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/e3f3bcc8-239e-4649-bcda-3f8f3d946035.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker build -t tinyhttpd:v0.1-5 .&#x2F;</span><br><span class="line">docker run --name tinyweb1 --rm tinyhttpd:v0.1-5 mount</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/167bb70c-d08b-45f4-906c-c26b0ede62b0.png" alt></p><p>或者让容器起来前先睡一会，inspect检查下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --name tinyweb1 --rm tinyhttpd:v0.1-5 sleep 60</span><br><span class="line">docker inspect tinyweb1</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/71c06a20-4ecc-4fb3-99b1-712a6f0e04d6.png" alt></p><p><strong>EXPOSE</strong></p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/ff314e5e-feb7-4343-aecd-72e9866288c6.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 待暴露默认端口，并没有真正暴露，容器运行时 -P 才会暴露</span><br><span class="line">EXPOSE 80&#x2F;tcp</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/89db952a-d3bf-466b-8830-50dc1358beb9.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker build -t tinyhttpd:v0.1-6 .&#x2F;</span><br><span class="line"># &#x2F;bin&#x2F;httpd 启动busybox命令 -f 前台启动 -h 家目录</span><br><span class="line">docker run --name tinyweb1 --rm tinyhttpd:v0.1-6 &#x2F;bin&#x2F;httpd  -f -h &#x2F;data&#x2F;web&#x2F;html&#x2F;</span><br><span class="line"></span><br><span class="line"># 另起终端</span><br><span class="line">docker inspect tinyweb1</span><br><span class="line">curl 172.17.0.2</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/6dfa3f04-00fa-4ef7-b572-6166150bb306.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 没有结果，容器中指定暴露了，但是却没有暴露，上面怎么可以访问呢？同一个桥上，容器本身就可以被宿主机访问，如果其他容器也启动到同一个桥上，也可以互相通信</span><br><span class="line">docker port tinyweb1</span><br><span class="line"></span><br><span class="line"># 将容器端口暴露出来</span><br><span class="line">docker kill tinyweb1</span><br><span class="line"># -P 暴露容器中所有可暴露的端口</span><br><span class="line">docker run --name tinyweb1 --rm -P  tinyhttpd:v0.1-6 &#x2F;bin&#x2F;httpd  -f -h &#x2F;data&#x2F;web&#x2F;html&#x2F;</span><br><span class="line"></span><br><span class="line">docker port tinyweb1</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/5527ac8d-8884-43a5-96f9-f06c597c113b.png" alt></p><p>外部网页可以访问 192.168.121.100:32768</p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/911a505b-ff15-44a3-aa85-0b48136a5d51.png" alt></p><p><strong>ENV</strong></p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/dd78b4d2-5299-48b1-9452-420ce650fcca.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#  doc_root 也可小写 \ 代表换行</span><br><span class="line"></span><br><span class="line">ENV DOC_ROOT&#x3D;&#x2F;data&#x2F;web&#x2F;html&#x2F; \</span><br><span class="line">    WEB_SERVER_PACKAGE&#x3D;&quot;nginx-1.18.0&quot;</span><br><span class="line"></span><br><span class="line"># 如果 DOC_ROOT 为空呢？使用下面这种格式给出默认值</span><br><span class="line">COPY index.html $&#123;DOC_ROOT:-&#x2F;data&#x2F;web&#x2F;html&#x2F;&#125;</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;usr&#x2F;local&#x2F;</span><br><span class="line"></span><br><span class="line">ADD $&#123;WEB_SERVER_PACKAGE&#125;.tar.gz .&#x2F;src&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/cb57f4ff-975b-415c-8a30-256007edafa7.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker build -t tinyhttpd:v0.1-7 .&#x2F;</span><br><span class="line">docker run --name tinyweb1 --rm -P  tinyhttpd:v0.1-7 ls &#x2F;usr&#x2F;local&#x2F;src</span><br><span class="line">docker run --name tinyweb1 --rm -P  tinyhttpd:v0.1-7 ls &#x2F;data&#x2F;web&#x2F;html</span><br></pre></td></tr></table></figure><p>镜像构建和启动容器是两个不同的阶段，上面变量替换是发生在build过程中，那run过程中是否可以呢？<strong>当然可以</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 输出环境变量信息</span><br><span class="line">docker run --name tinyweb1 --rm -P  tinyhttpd:v0.1-7 printenv</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/372cac53-8cb5-4cbe-83a7-8a7477c18e49.png" alt></p><p><strong>build时</strong> Nginx定义为 1.18.0，<strong>run时</strong> Nginx重新赋值为其他版本，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># -e K&#x3D;V 替换带Dockerfile中的环境变量</span><br><span class="line">docker run --name tinyweb1 --rm -P -e WEB_SERVER&#x3D;&quot;nginx-1.15.1&quot;  tinyhttpd:v0.1-7 printenv</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/0982be9e-d69e-4a1a-ab19-c23dd3d1ed31.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name tinyweb1 --rm -P -e WEB_SERVER&#x3D;&quot;nginx-1.15.1&quot;  tinyhttpd:v0.1-7  ls &#x2F;usr&#x2F;local&#x2F;src</span><br></pre></td></tr></table></figure><p>这里还是 1.18.0，Dockerfile 在 build 过程中已经生效了，即使后台做了更改，也只是名称改变，不会改变名称下面的事实内容。</p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/e54c85e6-838e-4c6e-b334-9b93c58142fa.png" alt></p><p>Dockerfile—-&gt;docker build —&gt;docker run —&gt; running container</p><p>这两个阶段 docker build 与 docker run 都可以运行shell命令。</p><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/4d9438e1-24bb-4492-86dc-4b616aceff91.jpg" alt></p><p><strong>RUN</strong></p><p>运行Dockerfile中的命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 手动展开，前提示 FROM 的基础镜像环境中有tar命令</span><br><span class="line">ADD http:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.18.0.tar.gz &#x2F;usr&#x2F;local&#x2F;src&#x2F;</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"># 进入目录  展开到当前目录  移动到 webserver目录下，因为此处只有1个，所以使用通配符</span><br><span class="line">RUN cd &#x2F;usr&#x2F;local&#x2F;src &amp;&amp; \</span><br><span class="line">    tar xf $&#123;WEB_SERVER_PACKAGE&#125;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/ad8fcb2b-468c-4123-821e-a2787003647f.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker build -t tinyhttpd:v0.1-9 .&#x2F;</span><br><span class="line">docker run --name tinyweb1 --rm -P -e WEB_SERVER&#x3D;&quot;nginx-1.15.1&quot;  tinyhttpd:v0.1-9 ls &#x2F;usr&#x2F;local&#x2F;src</span><br></pre></td></tr></table></figure><p><img src="/2020/04/08/4-Dockerfile%E4%B8%8A/caea8af5-0508-42b9-9edf-cf3c204ded96.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># RUN命令可以运行多次，建议多个有关的COMMAND 写到一起</span><br><span class="line">RUN COMMAND 1 &amp;&amp; \</span><br><span class="line">    COMMAND 2 &amp;&amp; \</span><br><span class="line">    COMMAND 3 ...</span><br><span class="line">    </span><br><span class="line"># 比如</span><br><span class="line">FROM centos</span><br><span class="line">RUN yum -y install epel-release &amp;&amp; \</span><br><span class="line">   makecache &amp;&amp; yum install nginx</span><br></pre></td></tr></table></figure><p><strong>CMD</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在Docker中创建镜像最常用的方式，就是使用Dockerfile。Dockerfile是一个Docker镜像的描述文件，我们可以理解成火箭发射的A、B、C、D…的步骤。Dockerfile其内部&lt;strong&gt;包含了一条条的指令&lt;/strong&gt;，&lt;strong&gt;每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;组成部分&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/04/08/4-Dockerfile%E4%B8%8A/7932ac6c-6b67-4f43-bab8-5e61dd559c48.png&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="http://JavaSsun.github.io/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://JavaSsun.github.io/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>3-Docker存储卷</title>
    <link href="http://javassun.github.io/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/"/>
    <id>http://javassun.github.io/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/</id>
    <published>2020-04-07T06:36:35.000Z</published>
    <updated>2020-06-17T06:42:18.060Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/08d2ea30-f590-4305-9b74-9aed3f47ca21.jpg" alt></p><a id="more"></a><h2 id="数据卷基础"><a href="#数据卷基础" class="headerlink" title="数据卷基础"></a>数据卷基础</h2><h3 id="Docker联合文件系统"><a href="#Docker联合文件系统" class="headerlink" title="Docker联合文件系统"></a>Docker联合文件系统</h3><p><code>Docker镜像</code>是有多层<code>只读文件</code>叠加而成，当运行起一个容器的时候，Docker会在制只读层上创建一个<code>读写层</code>。如果运行中的容器需要修改文件，那么并不会修改只读层的文件，只会把该文件复制到<code>读写层</code>然后进行修改，只读层的文件就被隐藏了。当删除了该容器之后，或者重启容器之后，之前对文件的更改会丢失，镜像的只读层以及容器运行是的“读写层”被称为<code>联合文件系统（Union File System）</code><br> 为了实现容器与主机之间、容器与容器之间<code>共享文件</code>，容器中<code>数据的持久化</code>，将容器中的数据<code>备份</code>、<code>迁移</code>、<code>恢复</code>等,Docker加入了数据卷(volumes)机制。简单的讲，就是做了一个文件夹的实时共享，有点像局域网的文件共享。</p><h3 id="数据卷的特点"><a href="#数据卷的特点" class="headerlink" title="数据卷的特点"></a>数据卷的特点</h3><ul><li><p>数据卷存在于宿主机的文件系统中，独立于容器，和容器的生命周期是分离的。</p></li><li><p>数据卷可以是目录也可以是文件，容器可以利用数据卷与宿主机进行数据共享，实现了容器间的数据共享和交换。</p></li><li><p>容器启动初始化时，如果容器使用的镜像包含了数据，这些数据会拷贝到数据卷中。</p></li><li><p>容器对数据卷的修改是实时进行的。</p></li><li><p>数据卷的变化不会影响镜像的更新。数据卷是独立于联合文件系统，镜像是基于联合文件系统。镜像与数据卷之间不会相互影响。</p></li></ul><p><strong>主要是用于有状态容器</strong>。</p><h3 id="为什么需要数据卷呢？"><a href="#为什么需要数据卷呢？" class="headerlink" title="为什么需要数据卷呢？"></a>为什么需要数据卷呢？</h3><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/e7d6399b-01de-4320-af59-6fd4702c13fd.jpg" alt></p><p><strong>Data volumes</strong></p><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/6d764279-0bed-4fcc-9ff2-607fd9af304b.jpg" alt></p><p>Container 运行过程中产生的临时数据写入镜像的读写层，随容器的删除而删除，<strong>需要保留的公有数据可以写在卷上</strong>。</p><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/aa2654b7-c382-4466-a24b-72a2ec3064c3.jpg" alt></p><p><strong>Volume types</strong></p><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/861e77bb-0062-426c-9c7d-e8f83dbd5cb4.jpg" alt></p><h3 id="容器中使用Volumes"><a href="#容器中使用Volumes" class="headerlink" title="容器中使用Volumes"></a>容器中使用Volumes</h3><h4 id="Docker管理-自动生成的Volume"><a href="#Docker管理-自动生成的Volume" class="headerlink" title="Docker管理-自动生成的Volume"></a>Docker管理-自动生成的Volume</h4><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/f05c2218-72c5-4563-b5ad-5daeaf4e1736.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run --name b2 -it -v &#x2F;data busybox</span><br><span class="line"></span><br><span class="line"># 另起终端，</span><br><span class="line">docker inspect b2</span><br></pre></td></tr></table></figure><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/2593af60-f19d-4204-941b-fac07c963e4b.png" alt></p><p>Mounts中的json数组：<strong>卷名称Name，卷在宿主机目录Source，卷在容器中目录 Destination，使用的本地驱动</strong>。</p><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/d320cce3-b553-48c0-a3b9-c7585b0c61aa.png" alt></p><p><strong>在宿主机上该文件夹下写一个文件，容器内也能实时感知</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 宿主机</span><br><span class="line">cd &#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;57927ad4bd5fb473d21b1c1fc93b6a9baf00a3863f81a644b9b8137e01244e62&#x2F;_data</span><br><span class="line"></span><br><span class="line">echo &quot;hello volume&quot; &gt;&gt; test.html</span><br><span class="line"></span><br><span class="line"># 回到另一个终端，</span><br><span class="line">ls &#x2F;data</span><br><span class="line">cat &#x2F;data&#x2F;test.html</span><br></pre></td></tr></table></figure><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/63de25e6-dc58-477c-ab0f-89ae0a88c745.png" alt></p><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/f0db8137-49e5-492f-a8cb-7e2238ff74f1.png" alt></p><p><strong>在容器中写的文件，在宿主机目录下也能实时感知</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 在容器内追加文件内容</span><br><span class="line"></span><br><span class="line">echo &quot;htllo host&quot; &gt;&gt; &#x2F;data&#x2F;test.html</span><br><span class="line"># 回到另一个宿主机终端</span><br><span class="line">cat test.html</span><br></pre></td></tr></table></figure><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/16035730-87d2-4c5a-ba73-507f269bc40a.png" alt></p><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/7b6c4132-4ebd-4a7f-9107-ffbee5752cff.png" alt></p><h4 id="bind-mount-volume-绑定挂在卷"><a href="#bind-mount-volume-绑定挂在卷" class="headerlink" title="bind-mount-volume 绑定挂在卷"></a>bind-mount-volume 绑定挂在卷</h4><p><strong>如果宿主机上该路径不存在，run的时候指明宿主机路径，会自动创建</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># source 宿主机&#x2F;data&#x2F;volumes&#x2F;b2 路径下</span><br><span class="line"># 容器内destination是 &#x2F;data 路径下</span><br><span class="line">docker run --name b2 -it --rm -v &#x2F;data&#x2F;volumes&#x2F;b2:&#x2F;data busybox</span><br></pre></td></tr></table></figure><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/726b1c15-454d-47e9-9cc5-4d1ba15ea603.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;data&#x2F;volumes&#x2F;b2</span><br><span class="line">vim index.html</span><br><span class="line"></span><br><span class="line"># 切换终端查看</span><br><span class="line">cat &#x2F;data&#x2F;index.html</span><br></pre></td></tr></table></figure><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/e9f08599-cc17-4569-a3c0-a635ee417474.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 退出后，容器被删除，但数据卷还在</span><br><span class="line">exit</span><br><span class="line">docker ps -a</span><br><span class="line">ls &#x2F;data&#x2F;volume&#x2F;b2</span><br></pre></td></tr></table></figure><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/3224b294-4634-46e7-8eb4-9c81554e91c6.png" alt></p><p>只要数据卷不删除，下次再启动时，容器内换一个路径也会映射到宿主机的数据卷中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name b2 -it --rm -v &#x2F;data&#x2F;volumes&#x2F;b2:&#x2F;data&#x2F;web&#x2F;html busybox</span><br></pre></td></tr></table></figure><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/d73253a7-44e2-43d1-b791-cf93b93f1dce.png" alt></p><p><strong>过滤 docker inspect显示的消息</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 简单的Go语言魔板过滤</span><br><span class="line"></span><br><span class="line"># inspect实际上列出的是一个JSON数组， .表示JSON根，.Mounts 表示看 Mounts 代表的数据</span><br><span class="line">docker inspect -f &#123;&#123;.Mounts&#125;&#125; b2</span><br><span class="line">docker inspect -f &#123;&#123;.NetworkSettings&#125;&#125; b2</span><br><span class="line">docker inspect -f &#123;&#123;.NetworkSettings.IPAddress&#125;&#125; b2</span><br></pre></td></tr></table></figure><p><strong>可不可以让两个容器关联到一个宿主机的卷上，让容器间共享数据呢</strong>？</p><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/b4b9ffa4-ab17-4f7a-a8cc-e02441c09e73.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># b3容器也关联宿主机上b2关联的目录，只是在容器中是 &#x2F;data目录</span><br><span class="line">docker run --name b3 -it --rm -v &#x2F;data&#x2F;volumes&#x2F;b2:&#x2F;data busybox</span><br><span class="line"></span><br><span class="line"># b2 容器可以看到 b3容器的修改变化</span><br><span class="line">cat &#x2F;data&#x2F;web&#x2F;html&#x2F;index.html</span><br></pre></td></tr></table></figure><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/39a8e0a8-87c8-4d7a-8e62-506c361b9e2e.png" alt><br><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/f4105e19-e5f9-4131-9aa1-f9535bcc2933.png" alt></p><p>b3容器的目录在/data 目录下， b2容器的目录在/data/web/html/ 目录下，但二者都挂载到 宿主机的 /data/volumes.b2 目录下。二者可以通过宿主机共享数据。</p><hr><p><strong>每次在容器初始化时，都要手动指定挂载的宿主机卷，如果不想记住宿主机卷的存放目录呢</strong>？</p><p>Docker 支持去复制别人的的存储卷目录。假设启动b2时，容器内卷与宿主机卷已经定义好了，启动b3时，要使用和b2一模一样的存储卷目录。</p><p>因此，可以定义一个容器，什么也不做，只要指定它宿主机与容器Volumes的对应规则即可，其他容器启动时复制当前容器的规则。</p><p>这个容器就可以被当做<strong>底层基础支撑容器</strong>，其它容器启动时基于该容器获得环境的设定。如果仅仅是这样，有点大材小用，之前介绍或 <strong>Joined-Containers：共享网络 UTS/NETWORK/IPC</strong>。</p><p>如果两个容器关系紧密，如NT：Nginx+Tomcat，Nginx对外提供服务，Tomcat向Nginx提供服务。二者可以使用相同的<strong>基础容器，共享网络</strong>。Tomcat监听LO接口，Nginx监听对外接口，外部访问Nginx，由Nginx反代到Tomcat，Tomcat想等于被隐藏起来。</p><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/c5ff6f83-284d-4991-8145-0849d182eb85.jpg" alt></p><p>除此之外，Tomcat提供动服务，Nginx提供静态服务，二者要想共享数据，在基础容器里可以实现共享目录。</p><p><img src="/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/893238d9-93ab-4f0c-9b2c-b3839ec045af.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个底层基础支撑容器，一般不要随意删除</span><br><span class="line">docker run --name infracon -it -v &#x2F;data&#x2F;infrocon&#x2F;volumes&#x2F;:&#x2F;data&#x2F;web&#x2F;html busybox</span><br><span class="line"></span><br><span class="line"># 另起重点，启动一个busybox容器，取名nginx，复制基础容器的卷规则</span><br><span class="line"></span><br><span class="line"># 共享基础容器的网络、存储卷</span><br><span class="line">docker run --name nginx --network container:infracon --volumes-from infracon -it busybox</span><br><span class="line"></span><br><span class="line"># 另起终端</span><br><span class="line">docker inspect infracon</span><br><span class="line"></span><br><span class="line"># 二者存储卷、网络一样，只是nginx的网络不再显示而已，容器内使用 ifconfig 可以显示。</span><br><span class="line">docker inspect nginx</span><br></pre></td></tr></table></figure><p>这种依赖于人的记忆的容器间的关系，不利于管理与维护，可以用DockerFIle 来指定基础容器的属性，容器间的依赖、启动顺序等等。这就是<strong>容器编排-Docker Compose</strong>。只能实现<strong>单机容器编排</strong>。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/2020/04/07/3-Docker%E5%AD%98%E5%82%A8%E5%8D%B7/08d2ea30-f590-4305-9b74-9aed3f47ca21.jpg&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="http://JavaSsun.github.io/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://JavaSsun.github.io/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>2-Docker容器网络</title>
    <link href="http://javassun.github.io/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/"/>
    <id>http://javassun.github.io/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/</id>
    <published>2020-04-06T10:36:35.000Z</published>
    <updated>2020-06-17T06:40:40.757Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><p>Linux内核支持6种名称空间。</p><ul><li><strong>UTS</strong>：主机名+域名</li><li><strong>USER</strong>：用户</li><li><strong>Mount</strong>：挂载文件系统</li><li><strong>IPC</strong>：进程间通信</li><li><strong>Pid</strong>：进程ID</li><li><strong>Net</strong>：网络</li></ul><p><strong>OVS：OpenVSwitch</strong><br><strong>SDN：软件驱动网络</strong><br><strong>Overlay Network</strong>:基于隧道叠加实现的另外一层网络通信。</p><p>C1要与C5通信，将报文发送给bridge上，由bridge发送给物理网卡，经由隧道转发。</p><a id="more"></a><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/dbe03c63-28be-46d4-a8e3-e277420ade4f.jpg" alt></p><p><strong>四类网络模式</strong></p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/731d3d66-d756-46c3-bf43-c2330f1229a9.png" alt></p><h2 id="2-容器虚拟化网络"><a href="#2-容器虚拟化网络" class="headerlink" title="2. 容器虚拟化网络"></a>2. 容器虚拟化网络</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># docker默认有3种网络</span><br><span class="line">docker networkd ls</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/1acc9212-7a77-42dc-93dd-98f4ffe6883c.png" alt></p><ul><li><strong>bridge</strong>：桥接网络，不是物理桥，默认是net桥。</li></ul><p>自动在本机上创建一个 docker0 的软交换机，也可以当网卡使用。<br><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/6079685d-d4a2-432c-b0e8-c54fb7e44999.png" alt></p><p><strong>启动每一个容器进程，都会自动分配一对虚拟网卡地址，一半在容器上，一半被关联到docker0上，如何关联？通过vethxxx 插在docker0上</strong>。</p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/e95ae173-4d13-4620-affd-67a158f262ec.png" alt></p><p>如何查看呢？ 安装工具 <code>yum -y install bridge-utils</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">brctl show</span><br><span class="line"># 或者</span><br><span class="line">ip link show</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/86ae8f54-1972-4d18-99b2-c912d887efb5.png" alt></p><p>在容器中使用 ifconf 命令可查看另一半 eth0，即软网卡。</p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/21182526-dba5-4eb6-b57d-ac3dca4afd27.jpg" alt></p><p><strong>如何进入一个已经启动的容器内部呢？</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it t2  &#x2F;bin&#x2F;sh</span><br></pre></td></tr></table></figure><p><strong>busybox t2 启动，nginx web1 也启动，如何访问呢？</strong></p><p>在同一个宿主机内的不同容器相互访问，通过bridge交换。</p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/da4b8b7e-7a0c-4aa4-94e6-fe13a6d8f850.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it t2 &#x2F;bin&#x2F;sh</span><br><span class="line">ifconfig</span><br><span class="line"># 另起一个终端，查看nginx容器的网络地址 172.17.0.2</span><br><span class="line">docker inspect web1</span><br><span class="line"># 回到当前busybox容器</span><br><span class="line">ping 172.17.0.2</span><br><span class="line"># -O 直接显示，不保存</span><br><span class="line">wget -O - -q http:&#x2F;&#x2F;172.17.0.2</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/3926ee90-81f3-4f30-8b7e-bc4a39d3f40b.png" alt></p><p><strong>如果通过物理机访问 busybox呢？也是可以的，物理机把 bridge当网卡使用</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl 172.17.0.2</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/7e1963d4-87c4-4350-b8ed-c05201039aea.png" alt></p><p><strong>如果不在宿主机内的进程想要访问当前宿主机的busybox呢</strong>？</p><p>比如 node2 想访问 node1 上的 busybox、nginx容器呢？</p><p>容器启动默认是bridge模式，本宿主机上的其他容器都可以访问。只能在宿主机上添加<strong>dnet规则</strong>，让外部进程访问。</p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/30291da0-47be-41ea-98f1-52b69088bf43.jpg" alt></p><p><strong>如果有多个web服务器呢？默认端口都是80，但物理机只有一个80端口只能分配给一个web容器</strong>，外部进程如何访问呢？</p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/30fd2e45-5056-41af-99e9-fe36cc1eb3df.jpg" alt></p><p>这种通过映射可能做起来非常麻烦，此时就想到了 <strong>Overlay Network</strong>。 C1 可以直接访问 C5的80端口，C5也可以直接访问C1的80端口，不需要在物理机上做映射。</p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/54cb8d15-1f35-4d8e-bb2e-2745e5601057.jpg" alt></p><hr><p>每个容器内部拥有6个隔离独立的名称空间。 User/UTS/Mount/PID/NET/IPC</p><p>如果让不同容器只保存自己的 User、Mount、Pid，共享UTS/NET/IPC，共享另一个容器网络名称空间，对外提供统一的IP。看起来轻巧很多。</p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/47d09ea1-1004-440f-8746-4f3e3fef875d.jpg" alt></p><p>也可以共享宿主机的名称空间，a容器共享宿主机的网络名称空间，b容器通过桥接模式分配网络。</p><p>a容器改自己容器内的网络，宿主机也会跟着变。这就是 <strong>host模式</strong>，让容器使用宿主机的网络名称空间。</p><p><strong>null模式：相当于只有lo，没有网卡，不能执行网络通信，信息孤岛，有些批处理任务容器不需要网络通信，处理完成直接打到卷里</strong>。</p><h2 id="3-Docker4种网络架构"><a href="#3-Docker4种网络架构" class="headerlink" title="3. Docker4种网络架构"></a>3. Docker4种网络架构</h2><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/7d63d35d-85eb-4551-a84d-757ae3d25d64.jpg" alt></p><ul><li><p><strong>Closed Container：</strong> 只有 LO接口。</p></li><li><p><strong>Bridged Container：</strong> 桥接式，有一个private interfave虚拟网卡（17.x.x.x），接到Docker bridge virtual interface。称为Net网络或是桥接式网络。</p></li><li><p><strong>Joined Container</strong>：联盟式网络，User/Mount/Pid各自保管，Net/IPC/UTS 共享。</p></li><li><p><strong>Open Container</strong>：开放式网络，直接共享宿主机的网络名称空间。</p></li></ul><p>查看bridge网络的信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker network ls</span><br><span class="line">docker network inspect bridge</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/6b9f63b6-b183-4ac7-8ad8-844889dcf236.png" alt></p><p><strong>inspect 可以查看docker的对象的详细信息</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker network inspect bridge</span><br><span class="line">docker container inspect web1</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>宿主机的 ip netns 可以模拟容器间通信</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip netns help</span><br></pre></td></tr></table></figure><h2 id="Docker-容器网络"><a href="#Docker-容器网络" class="headerlink" title="Docker 容器网络"></a>Docker 容器网络</h2><h3 id="None式网络"><a href="#None式网络" class="headerlink" title="None式网络"></a>None式网络</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --name t1 -it --network none --rm busybox:latest</span><br><span class="line">ifconfig -a</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/06ad914d-6cc9-48e0-9e54-8c2d67be97fb.png" alt></p><h3 id="桥接式"><a href="#桥接式" class="headerlink" title="桥接式"></a>桥接式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># --rm 退出即删除</span><br><span class="line"># 默认是桥接式网络</span><br><span class="line">docker run --name t1 -it --rm busybox:latest</span><br><span class="line">docker ps -a</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/baa3c322-1f5b-43a6-926a-d5fa1b706023.png" alt></p><p><strong>显示指定容器网络模式</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run --name t1 -it --network bridge --rm busybox:latest</span><br><span class="line">ifconfig</span><br><span class="line"># 查看主机名</span><br><span class="line">hostname</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/9cb0250d-d49d-4304-80c0-c834bff00a3f.png" alt><br><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/c9f9fd84-f872-45d5-9b49-2e48915b1280.png" alt></p><p><strong>在容器启动时注入主机名</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># -h 注入</span><br><span class="line"></span><br><span class="line">docker run --name t1 -it --network bridge -h haoransun --rm busybox:latest</span><br><span class="line">hostname</span><br><span class="line"></span><br><span class="line"># 希望通过主机名访问</span><br><span class="line">cat &#x2F;etc&#x2F;hosts</span><br><span class="line">cat &#x2F;etc&#x2F;resolv.conf</span><br><span class="line">nslookup -type&#x3D;A www.baidu.com</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/4720763b-57b4-4afe-bc38-1ad17b2ee281.png" alt></p><p>如果我们希望通过自定义dns来访问呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># --dns 定义解析</span><br><span class="line"># --dns-search 定义搜索域</span><br><span class="line"></span><br><span class="line">docker run --name t1 -it --network bridge -h haoransun --dns 114.114.114.114 --dns-search ilinux.io --rm busybox:latest</span><br><span class="line"></span><br><span class="line">cat &#x2F;etc&#x2F;resolv.conf</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/dbc6b98c-7be7-4196-b1ab-bbe9060cc6c7.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># --add-host：注入域名:IP 解析</span><br><span class="line">docker run --name t1 -it --network bridge -h haoransun --dns 114.114.114.114 --dns-search ilinux.io --add-host www.haoran.tech:1.1.1.1  --rm busybox:latest</span><br><span class="line"></span><br><span class="line">cat &#x2F;etc&#x2F;hosts</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/0340b75a-38f5-47d7-a7ad-4a554fce557e.png" alt></p><p><strong>总结</strong></p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/f47a9e1b-e913-4dd9-a211-eeee29cd5356.jpg" alt></p><h3 id="Opening-inbound-communication"><a href="#Opening-inbound-communication" class="headerlink" title="Opening inbound communication"></a>Opening inbound communication</h3><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/12fd0418-2ae9-4b96-b7bb-eeebafed588e.jpg" alt></p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/1f550fbc-74ae-4634-9468-1fe0c19d07ac.jpg" alt></p><p><strong>操作，暴露80端口到宿主机随机端口上</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># -p 容器暴露出 80 端口,自动生成映射规则，删除容器自动删除规则</span><br><span class="line">docker run --name myweb --rm -p 80 haoransun&#x2F;httpd:v0.2</span><br></pre></td></tr></table></figure><p>另起一个终端</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker inspect myweb</span><br><span class="line">curl 172.17.0.2</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/3da41707-05d5-485e-9689-6c72afff2060.png" alt></p><p>这只是同一个宿主机的不同容器可以相互通信。如果想要其他宿主机或其他宿主机的容器访问呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 查看80 与 宿主机端口的映射规则</span><br><span class="line">iptables -t nat -vnL</span><br><span class="line"># 或者</span><br><span class="line">docker port myweb</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/fc6a9695-4272-4d7f-8470-deafc55c6439.png" alt></p><p>以网页方式访问宿主机的 192.168.121.200:32768 会被转发到容器内的80端口上。（开放32768端口）</p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/aa8e10f3-622c-4e2a-b4b0-6661662ec864.png" alt></p><p>容器删除时，iptables 对应映射规则也会被删除</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker kill myweb</span><br><span class="line">iptables -t nat -vnL</span><br></pre></td></tr></table></figure><p><strong>暴露在宿主机指定IP的随机端口</strong></p><p>将容器内80端口映射到物理机上所有可用的端口</p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/2cc260ef-bbf2-4d11-9a64-174fc051030e.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 指定宿主机固定IP的随机端口，:: 即宿主机使用什么端口，我也用该端口</span><br><span class="line"></span><br><span class="line">docker run --name myweb --rm -p 192.168.121.200::80 haoransun&#x2F;httpd:v0.2</span><br><span class="line"></span><br><span class="line"># 另起终端</span><br><span class="line">docker port myweb</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/d2bb8ae2-1f87-4f41-9478-390608a5534d.png" alt></p><p><strong>暴露指定端口</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 假设宿主机80端口没有被用到</span><br><span class="line">docker run --name myweb --rm -p 80:80 haoransun&#x2F;httpd:v0.2</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/f83deceb-f8a3-496f-89e1-8330dc5ec1aa.png" alt></p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/371d3286-d244-4cac-b0fc-646ba23fe86d.png" alt></p><p><strong>暴露指定IP+指定端口</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run --name myweb --rm -p 192.168.121.200:8080:80 haoransun&#x2F;httpd:v0.2</span><br><span class="line"></span><br><span class="line"># 另起终端</span><br><span class="line">docker port myweb</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/a863b6e6-69cc-455b-8dd4-3a909e5a8d17.png" alt><br><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/bb26985b-4e28-41f9-a9a9-e41a1dc0f7f6.png" alt></p><p>Nginx容器启动时默认暴露80端口，但外部依然无法访问，使用-P ,不用指定端口，使用默认端口，可以直接暴露</p><h3 id="Joined-Containers"><a href="#Joined-Containers" class="headerlink" title="Joined Containers"></a>Joined Containers</h3><p>效果相当于同一个主机上的两个进程一样</p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/b0fb915f-5da9-43bc-b263-ef538a5fc75b.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 创建 b1 b2 容器</span><br><span class="line">docker run --name b1 -it --rm busybox</span><br><span class="line">ifconfig  # IP地址：172.17.0.2</span><br><span class="line"># 另起终端</span><br><span class="line">docker run --name b2 -it --rm busybox</span><br><span class="line">ifconfig  # IP地址：172.17.0.3</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/59d02ce9-8293-4d44-b54a-80daac1c22c5.png" alt><br><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/24af1782-3515-4fb8-9c31-920b89afee48.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 创建并启动b2容器时添加：--network container:b1 b2共享b1的网络命名空间</span><br><span class="line"></span><br><span class="line">docker run --name b2 --network container:b1  -it --rm busybox</span><br><span class="line"></span><br><span class="line">ifconfig</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/dd3d4ece-6239-41ce-85a1-b2b17347ad5e.png" alt></p><p>在b2上新起一个项目，在b1也能被访问到</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;hello world&quot; &gt; &#x2F;tmp&#x2F;index.html</span><br><span class="line">httpd -h &#x2F;tmp&#x2F;</span><br><span class="line">netstat -tnlp</span><br><span class="line"># 切换回 b1终端</span><br><span class="line">wget -O - -q 127.0.0.1</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/f1a99d3c-8ca2-4369-91f0-fd253cb12190.png" alt><br><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/6365ccc5-bbb8-4b26-8fdd-d063f2a051b5.png" alt></p><h3 id="Host"><a href="#Host" class="headerlink" title="Host"></a>Host</h3><p>共享宿主机的网络名称空间</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --name b2 --network  host  -it --rm busybox</span><br><span class="line">ifconfig</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/957821df-ccc1-40cd-93c1-5a5f3153b4ba.png" alt></p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/1585eb56-5607-43a3-bb0b-bef9e877c5ab.png" alt></p><h3 id="如何更改Docker0默认的网络呢"><a href="#如何更改Docker0默认的网络呢" class="headerlink" title="如何更改Docker0默认的网络呢"></a>如何更改Docker0默认的网络呢</h3><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/8cd2c954-0321-4168-891b-eb43bc4df51c.jpg" alt></p><p><strong>以slave节点为例进行修改</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 确保没有容器正在运行</span><br><span class="line">docker ps</span><br><span class="line">systemctl stop docker</span><br><span class="line"># 此处只添加一个bip，其他选项按需填写</span><br><span class="line">vim &#x2F;etc&#x2F;docker&#x2F;daemon.json </span><br><span class="line">systemctl start docker</span><br><span class="line">ifconfig</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/a76dc041-e4c9-49e8-888e-86e87dadc36b.png" alt></p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/8be09ea5-58fd-4dc5-a8d2-4af65d2e1617.png" alt></p><p>docker默认守护进程的C/S，默认监听Unix Socket格式的地址，即本地通信，<strong>如果想在node2节点上，管理node1节点里的docker容器呢</strong>？</p><p><strong>默认是不可以的</strong>。</p><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/51eda898-e168-4143-93ef-e7e019ca900c.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 其中有 docker.sock文件</span><br><span class="line">ls &#x2F;var&#x2F;run</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/54334a24-cb03-4054-a5a7-e9f7ba8c70e8.png" alt></p><p>更改配置文件即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop docker</span><br><span class="line">!vim</span><br><span class="line">systemctl start docker</span><br><span class="line">ls &#x2F;var&#x2F;run</span><br><span class="line">ss -tnl</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/dfbadbfb-93f3-4616-aded-7430190247de.png" alt></p><p>在node1节点上，使用 docker ps 默认显示本机的，-H可以显示指定机器的容器、镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">docker -H 192.168.121.200:2375 ps</span><br><span class="line">docker -H 192.168.121.200:2375 image ls</span><br></pre></td></tr></table></figure><p><strong>自定义网络桥</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查看插件支持的 network</span><br><span class="line">docker info</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/a0bd00bf-d8c9-4ce3-b4bd-985c281eb3eb.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">docker network --help</span><br><span class="line">docker network create --help</span><br><span class="line">docker network create -d bridge --subnet &quot;192.168.0.0&#x2F;16&quot; --gateway &quot;192.168.0.1&quot; mybr0</span><br><span class="line"></span><br><span class="line">docker network ls</span><br><span class="line"></span><br><span class="line">ifconfig</span><br><span class="line"></span><br><span class="line"># 改名为docker1</span><br><span class="line">ip link set dev br-3291c2f3f6eb name docker1</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/38ee33b8-23e6-4bdb-82c0-9543c8eff5f5.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --name t1 -it --net mybr0 busybox:latest</span><br><span class="line">ifconfig</span><br></pre></td></tr></table></figure><p><img src="/2020/04/06/2-Docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/ae717af7-3ec0-494a-99dc-a9ec7e53af69.jpg" alt></p><p>两个桥上的机器能否通信呢？一个宿主机上创建了两个虚拟交换机，bridge和br0。</p><p><strong>在宿主机上打开接口转发即可</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 默认为1 就是打开的</span><br><span class="line">cat &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;ip_forward</span><br><span class="line">iptables -vnL</span><br></pre></td></tr></table></figure><p>设置两个网段可能就是为了不让通信的，没有必要让二者通信。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-前言&quot;&gt;&lt;a href=&quot;#1-前言&quot; class=&quot;headerlink&quot; title=&quot;1. 前言&quot;&gt;&lt;/a&gt;1. 前言&lt;/h2&gt;&lt;p&gt;Linux内核支持6种名称空间。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;UTS&lt;/strong&gt;：主机名+域名&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;USER&lt;/strong&gt;：用户&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mount&lt;/strong&gt;：挂载文件系统&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IPC&lt;/strong&gt;：进程间通信&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pid&lt;/strong&gt;：进程ID&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Net&lt;/strong&gt;：网络&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;OVS：OpenVSwitch&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;SDN：软件驱动网络&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;Overlay Network&lt;/strong&gt;:基于隧道叠加实现的另外一层网络通信。&lt;/p&gt;
&lt;p&gt;C1要与C5通信，将报文发送给bridge上，由bridge发送给物理网卡，经由隧道转发。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="http://JavaSsun.github.io/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://JavaSsun.github.io/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>1-安装_使用Docker</title>
    <link href="http://javassun.github.io/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/"/>
    <id>http://javassun.github.io/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/</id>
    <published>2020-04-05T06:36:35.000Z</published>
    <updated>2020-06-17T06:38:35.766Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-安装Docker"><a href="#1-安装Docker" class="headerlink" title="1. 安装Docker"></a>1. 安装Docker</h2><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/0c401be3-4ee5-41fe-b2a6-b0c40ec3f933.jpg" alt></p><p><strong>三种方式安装Docker</strong></p><h3 id="1-Extras-Repository"><a href="#1-Extras-Repository" class="headerlink" title="1. Extras Repository"></a>1. Extras Repository</h3><p><strong>CentOS-6.2.32支持Docker，红帽以补丁方式补充。有很多不稳定因素，此处选用CentOS7</strong>。</p><p>自带的有版本太老，自行搜索安装方法。</p><a id="more"></a><h3 id="2-清华镜像安装"><a href="#2-清华镜像安装" class="headerlink" title="2. 清华镜像安装"></a>2. 清华镜像安装</h3><p>Extras-repository默认是启用的。</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/e930e7b7-4634-493b-9817-d03c25b8c580.png" alt></p><p> docker-ce.repo：<a href="https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo</a></p><p>复制上述文件，下载到 yum.repos.d 文件夹中。</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/6abaad00-f853-405c-94d4-d9326b5b3635.jpg" alt></p><p>更改下载下来的repo文件，使其下载镜像走清华镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim docker-ce.repo</span><br></pre></td></tr></table></figure><p>发现它走的还是 docker 网站，速度非常慢。</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/93b15505-dae9-49e7-9c14-98ea0f3c6fab.jpg" alt></p><p>找指定版本：</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/2cac1236-29f4-470c-9c23-a9e90c48aece.jpg" alt></p><p>从地址栏可以看到，只要更改源下载目录即可。</p><p><a href="https://mirrors.tuna.tsinghua.edu.cn/docker-ce" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/docker-ce</a> 这个是地址栏上截取到 linux的父目录替换docker-ce.repo即可。</p><p>vim中使用命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:%s@待替换字符串@新字符串@</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/d663c6cd-b4ff-4f6a-8b23-cb664b3f25e4.jpg" alt></p><p>替换后效果如下图：</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/6d6311ba-3603-4897-b3db-7fb4710d218a.jpg" alt></p><p>验证比较看是否出错：</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/1d1d4b7e-72d7-42e7-a64d-b9284e92bd07.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Extras包</span><br><span class="line">yum install docker-ee</span><br><span class="line"></span><br><span class="line"># CentOS默认</span><br><span class="line">yum install docker-ce</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/495d5aa9-3990-40a0-ae2f-6a91dad2f314.jpg" alt></p><p><strong>参考3，定制镜像加速器</strong>。 </p><h3 id="3-阿里云镜像加速器参考文章（推荐）"><a href="#3-阿里云镜像加速器参考文章（推荐）" class="headerlink" title="3. 阿里云镜像加速器参考文章（推荐）"></a>3. 阿里云镜像加速器参考文章（推荐）</h3><p><a href="wiz://open_document?guid=0d137ef6-7255-42bc-b495-485adfe5a72a&kbguid=&private_kbguid=8f87f846-043e-44f9-9d94-1b22f6274df3">0-Docker（配置国内免费registry mirror）.md</a></p><p><strong>Docker程序环境：</strong></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/d4092c25-582b-41c4-b943-05928c08f768.jpg" alt></p><p><strong>Docker命令预备知识</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 使用下面命令可以列出docker所有的子命令</span><br><span class="line">docker</span><br></pre></td></tr></table></figure><p>可以看到有两类命令，一类是<strong>Management Commands</strong> ，一类是 <strong>Commands</strong>。</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/b6ded96b-2a68-4bb1-bebd-9f39a3d208de.png" alt></p><p>这两个子命令集合可以理解为是新老命令。</p><p>为了兼容老的命令，如下举例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 如创建容器</span><br><span class="line">docker container --help  # 里面有create命令</span><br><span class="line"># 即 docker container create</span><br><span class="line">docker create # 老的command命令里也有create命令</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/c878d723-8839-4a0b-ae04-77e05239ceae.png" alt></p><p><strong>建议以后使用新的分组管理的命令</strong>。</p><p><strong>查看docker-client-version版本</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker version</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/d1ac836a-4d88-4566-ba78-41340cc2feaf.png" alt></p><p><strong>docker info 查看详细信息</strong></p><p>最后一项说明加速器生效。</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/455edcef-538c-4869-8c5e-f2a584fda0a8.png" alt></p><h2 id="2-Docker常用操作"><a href="#2-Docker常用操作" class="headerlink" title="2. Docker常用操作"></a>2. Docker常用操作</h2><p>下面图中给出的还是<strong>老命令</strong>，没有带<strong>中间分组</strong>。</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/8cd0c629-3925-4fa8-8dbb-3cb0405fc5d4.jpg" alt></p><h3 id="1-镜像有关操作"><a href="#1-镜像有关操作" class="headerlink" title="1. 镜像有关操作"></a>1. 镜像有关操作</h3><h4 id="1-搜索镜像-docker-search"><a href="#1-搜索镜像-docker-search" class="headerlink" title="1. 搜索镜像 docker search"></a>1. 搜索镜像 docker search</h4><p><code>docker search nginx</code></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/dd56b2f3-f0de-4eae-b7cd-259278b8620b.png" alt></p><p><strong>以Nginx为例，去 dockerhub 搜索nginx，Tags标签下有不同的docker发行版本</strong></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/d324fa07-1108-413b-b037-37117ac44845.png" alt></p><p><strong>Nginx可以被Ubuntu/CentOS安装，也可以被其他的小发行版本安装，alpine是用来构建非常小的镜像的微型发行版本，可提供程序运行的基础环境，但体积非常小，缺乏生产需要的一些工具，所以一般都是自己定制镜像</strong>。</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/c024b6f3-20ce-44a9-8d37-4479b31fd145.png" alt></p><h4 id="2-下载镜像-显示镜像-删除镜像"><a href="#2-下载镜像-显示镜像-删除镜像" class="headerlink" title="2. 下载镜像 + 显示镜像 + 删除镜像"></a>2. 下载镜像 + 显示镜像 + 删除镜像</h4><p><strong>下载+显示</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 两套方法都可以</span><br><span class="line">docker image pull nginx:1.14-alpine</span><br><span class="line">docker pull nginx:1.14-alpine</span><br><span class="line">docker image ls</span><br><span class="line"># 完全显示</span><br><span class="line">docker image ls --help</span><br><span class="line">docker image ls --no-trunc</span><br><span class="line"></span><br><span class="line">#过滤显示</span><br><span class="line">docker image ls nginx</span><br><span class="line">docker image ls nginx:v2</span><br><span class="line"></span><br><span class="line"># 也可使用go模板进行过滤，自学。</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/241ddc92-19f0-4143-a508-5cd08bfa4394.png" alt></p><p>可以在下载一个busybox为例，再演示一次</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/84faa0b5-3dec-4b4e-a966-382ba1db25db.png" alt></p><p><strong>下载+显示</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 不加标签，默认是latest</span><br><span class="line">docker pull busybox</span><br><span class="line">docker images</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/b5407c48-6017-46b6-9ab6-39c3a14001a3.png" alt></p><p><strong>删除</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 两个都可以</span><br><span class="line">docker image rm busybox</span><br><span class="line">docker rmi busybox</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/de243209-ca8e-43cd-9750-fa690cb9f19b.png" alt></p><h3 id="3-容器有关"><a href="#3-容器有关" class="headerlink" title="3. 容器有关"></a>3. 容器有关</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">docker container --help</span><br><span class="line"></span><br><span class="line"># 创建容器</span><br><span class="line">docker container create xxx</span><br><span class="line">docker create xxx</span><br><span class="line"></span><br><span class="line"># 启动容器</span><br><span class="line">docker container start xxx</span><br><span class="line"></span><br><span class="line"># 停止容器</span><br><span class="line">docker container stop xxx</span><br><span class="line"></span><br><span class="line"># 强行停止容器</span><br><span class="line">docker container kill xxx</span><br><span class="line"></span><br><span class="line"># 创建并启动容器</span><br><span class="line">docker container run xxx</span><br><span class="line"></span><br><span class="line"># 删除容器</span><br><span class="line">docker container rm</span><br><span class="line"></span><br><span class="line"># 暂停容器</span><br><span class="line">docker container pause</span><br><span class="line"></span><br><span class="line"># 取消暂停容器</span><br><span class="line">docker container unpause</span><br><span class="line"></span><br><span class="line"># 哪些容器更消耗资源</span><br><span class="line">docker container top</span><br><span class="line"></span><br><span class="line"># 列出所有容器</span><br><span class="line">docker container ls</span><br><span class="line">docker ps</span><br></pre></td></tr></table></figure><p><strong>显示网络</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker network</span><br><span class="line">docker network ls</span><br></pre></td></tr></table></figure><p>容器启动时如果不指定网络，默认在docker桥上。</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/d1613e92-49a2-4aec-a5ce-0ff66d6ec23a.png" alt></p><p><strong>以启动busybox为例，创建一个首页并访问它</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 新建并启动busybox容器，取名为 b1，交互式访问。</span><br><span class="line">docker run --name b1 -it busybox:latest</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/5bbdc1e6-c082-42c2-8eac-e57bcf10e7b8.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ps</span><br><span class="line">httpd -h</span><br><span class="line">mkdir &#x2F;data&#x2F;html</span><br><span class="line">vi &#x2F;data&#x2F;html&#x2F;index.html</span><br><span class="line"># 写下 BusyBox HTTP Server</span><br><span class="line"></span><br><span class="line"># 启动 busybox -f 工作在前台 -h 指明家目录</span><br><span class="line">httd -f -h &#x2F;data&#x2F;html&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/122042a9-42fb-4576-a27b-cd8ebac13e3d.png" alt></p><p>在另外一个终端内，访问启动起来的busybox</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 查看busybox是否已经起来</span><br><span class="line">docker ps</span><br><span class="line"></span><br><span class="line"># 查看busybox的IP地址</span><br><span class="line">docker inspect b1</span><br><span class="line"></span><br><span class="line">curl 172.17.0.2</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/e664ff0b-97e7-4004-9eff-2de9dea4bc43.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 停止busybox</span><br><span class="line">ctrl +c</span><br><span class="line">exit</span><br><span class="line"></span><br><span class="line">docker ps -a</span><br><span class="line">docker container ls -a </span><br><span class="line"># 交互式再次启动</span><br><span class="line">docker start -a -i b1</span><br><span class="line"></span><br><span class="line"># 转终端</span><br><span class="line">docker ps</span><br></pre></td></tr></table></figure><p><strong>以启动nginx为例，并访问它</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># -d 以后台方式运行</span><br><span class="line">docker run --name web1 -d nginx:1.14-alpine</span><br><span class="line">docker ps</span><br><span class="line">docker inspect web1</span><br><span class="line">curl 172.17.0.2</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/1322f4c6-8a00-47e0-bdfb-cbf2489feac5.png" alt></p><p><strong>以启动redis为例，并访问它</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 如果本地没有当前镜像，会去下载</span><br><span class="line">docker run --name kvstor1 -d redis:4-alpine</span><br><span class="line">docker ps</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/446655f2-e19f-4375-94a5-3714bd9d4792.png" alt></p><p>要访问redis需要有客户端，我们可以<strong>绕过容器的边界</strong>访问它。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it  kvstor1  &#x2F;bin&#x2F;sh</span><br><span class="line">ps</span><br><span class="line">netstat -tnlp</span><br><span class="line">redis-cli</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/54955e1c-6ee5-4745-8cd8-388fbad1af42.png" alt></p><p><strong>查看日志</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker logs web1</span><br><span class="line">docker container logs web1</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/110bda69-2445-472e-a10a-edf8e9f4e6bd.png" alt></p><p><strong>docker event state</strong></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/b2e3d3d4-29bf-441a-8f50-41d64f318bef.jpg" alt></p><h2 id="3-Docker镜像基础"><a href="#3-Docker镜像基础" class="headerlink" title="3. Docker镜像基础"></a>3. Docker镜像基础</h2><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/b82634f3-83c6-4bc6-beb3-0989e38b49cc.jpg" alt></p><p><strong>Aufs</strong></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/f855ba6c-ea93-4f1f-9f8a-08f7141d2937.jpg" alt></p><p><strong>docker info 查看容器镜像系统鞥</strong></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/374e7e56-ce7f-4a18-9a70-720a6a8e99de.png" alt></p><p><strong>Docker Registry</strong></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/0b9124f4-483c-4b01-9e65-dd8749afef7d.jpg" alt></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/ce13e278-d314-4c49-88a4-e8bb235d5520.jpg" alt></p><p><strong>Docker Registry分类</strong></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/785fb9ab-00ea-46f6-a882-2dce5bc56380.jpg" alt></p><p><strong>Registry(repository and index)</strong></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/2f069fc4-8d6a-460d-bf7d-e635330c96e6.jpg" alt></p><p><strong>云原生</strong></p><p>面向云环境运行程序，调用云系统本身既有的功能。为了云计算环境而生。</p><p><strong>Docker Hub</strong></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/d31aa04b-48a0-4139-b6e5-384d3e571d90.jpg" alt></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/0f3a3cfd-1cd1-4a80-9cd2-d5fc8d747eb5.jpg" alt></p><p><em>*docker pull</em></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/65161aec-6aa2-4a1b-b015-5ad8f36a8b80.jpg" alt></p><p>默认从docker hub拉取镜像，我们也可以从其他第三方库拉取镜像，如：<strong>quay.io</strong>。</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/e54fbe07-1779-4b48-a663-e73359f7ba86.jpg" alt></p><p><font color="red">不指定端口，默认是443，即HTTPS默认端口</font>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull quay.io&#x2F;coreos&#x2F;flannel:v0.10.0-amd64</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/d45ba425-9f96-47e8-8862-429dcf426942.png" alt></p><p><strong>Namespace</strong></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/2122c3d2-de16-4139-b275-864885c65ba7.jpg" alt></p><hr><h2 id="4-镜像相关操作"><a href="#4-镜像相关操作" class="headerlink" title="4. 镜像相关操作"></a>4. 镜像相关操作</h2><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/3b6c6bd7-f54f-4e98-9d56-b9a9983e12a7.jpg" alt></p><h3 id="1-基于容器制作镜像-docker-commit"><a href="#1-基于容器制作镜像-docker-commit" class="headerlink" title="1. 基于容器制作镜像 docker commit"></a>1. 基于容器制作镜像 docker commit</h3><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/a2387146-3f14-464f-a99c-09ede7bf6631.jpg" alt></p><p>举例：将busybox中新添加的 index.html 这个可写层作为镜像，基于这个镜像，每次启动，都有了 index.html 页面。</p><p>容器启动后，添加自己的变更，<strong>不能关闭容器</strong>，可以另起终端，制作镜像。</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/35d9d0af-3289-4774-8ac3-8e169e45a567.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 基于运行时容器制作镜像，可能容器还在产生新的内容，加上-p 即commit时暂停容器</span><br><span class="line">docker commit -p b1</span><br><span class="line">docker image ls</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/4ab0e316-9dfa-40aa-95ca-253757a84fd2.png" alt></p><p><strong>commit之后打标签</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker tag --help</span><br><span class="line"># 如果镜像之前有标签，基于标签再打标签，没有就基于镜像ID，打到 haoransun 用户空间下的 httpd:v0.1-1，haoransun可以是我们docker hub的开发者账号</span><br><span class="line">docker tag 4371309b87e0 haoransun&#x2F;httpd:v0.1-1</span><br><span class="line">docker image ls</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/84ba2ff5-3773-4034-80c6-0657967d7a37.png" alt></p><p><strong>再打标签</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker tag haoransun&#x2F;httpd:v0.1-1 haoransun&#x2F;httpd:latest</span><br><span class="line">docker image ls</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/3aba31a2-4f8d-45d0-8fb0-b41adc6dada5.png" alt></p><p>可以看到这两个镜像的 ID是一样的，删除一个镜像，只要他的引用计数不为0，就会一直存在。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># untagged</span><br><span class="line">docker image rm haoransun&#x2F;httpd:latest</span><br><span class="line">docker image ls</span><br></pre></td></tr></table></figure><hr><p><strong>commit时打标签</strong></p><p>镜像定义了基于此镜像启动容器后默认要运行的程序(Cmd)。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 查看要运行的Cmd</span><br><span class="line">docker inspect busybox</span><br><span class="line">docker inspect nginx:1.14-alpine</span><br></pre></td></tr></table></figure><p>busybox<br><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/328981d8-e4ec-4657-a674-94598096b462.png" alt></p><p>nginx<br><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/d435d370-d60b-4bdd-a2a0-abb89413bfbe.png" alt></p><p><strong>期望容器运行后，不再运行默认的shell，而是运行我们指定的命令</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># -a 添加作者+邮箱（前提是本地有这个邮箱文件）</span><br><span class="line"># -c 添加启动时要运行的命令</span><br><span class="line"># -p 制作时暂停容器</span><br><span class="line"># b1 基于刚才运行的b1来做，并起新名</span><br><span class="line"># CMD 与 [] 中间要有空格</span><br><span class="line">docker commit -a &quot;haoransun&quot;&lt;2642487764@qq.com&gt; -c &#39;CMD [&quot;&#x2F;bin&#x2F;httpd&quot;,&quot;-f&quot;,&quot;-h&quot;,&quot;&#x2F;data&#x2F;html&quot;]&#39; -p b1 haoransun&#x2F;httpd:v0.2</span><br><span class="line"></span><br><span class="line">docker image ls</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/2d0e7e71-b599-4e6a-a8a6-d701b10bd8dc.png" alt></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/dc0dd670-a0fb-47f8-8845-3ab62811469f.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 启动容易</span><br><span class="line">docker run --name t2 haoransun&#x2F;httpd:v0.2</span><br><span class="line"># 另起一个终端，去查看</span><br><span class="line">docker container ls</span><br><span class="line">docker inspect t2</span><br><span class="line">curl 172.17.0.3</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/538dc7ab-649b-42ee-9191-7194ca57eede.png" alt></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/69ed0fa1-d2e1-40b5-ac0e-46d5d6c5f1f9.png" alt></p><h3 id="2-推镜像到docker-hub"><a href="#2-推镜像到docker-hub" class="headerlink" title="2. 推镜像到docker hub"></a>2. 推镜像到docker hub</h3><p><strong>将制作好的镜像push到自己的docker hub仓库内</strong></p><p>创建一个httpd仓库</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/29196cd5-7533-4f9a-b116-da8ef13504a2.png" alt></p><p>推的时候要使用 docker login 登录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker login -u haoransun</span><br><span class="line">Password: # 输入密码即可</span><br><span class="line"></span><br><span class="line"># 推送本地所有的 httpd镜像 默认推到docker hub，如果推到其他网站，需跟服务器名</span><br><span class="line">docker push haoransun&#x2F;httpd</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/d4bfd094-4475-46a7-85c7-982e99b9548b.png" alt></p><p>docker hub 可以查看<br><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/3f5f73a4-66ee-485c-b7ca-838af6a7885a.png" alt></p><h3 id="3-推镜像到阿里云"><a href="#3-推镜像到阿里云" class="headerlink" title="3. 推镜像到阿里云"></a>3. 推镜像到阿里云</h3><p><strong>推送到阿里云镜像仓库</strong></p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/88878be6-ef0d-454f-8be6-3d27bd1e276f.png" alt></p><p>点击<strong>管理</strong>,看到打标签要以 <code>registry.cn-hangzhou.aliyuncs.com/haoransun/httpd</code> 开头</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/733a26b1-6a46-489c-b4d6-4b71f0ed6f85.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker tag haoransun&#x2F;httpd:v0.2 registry.cn-hangzhou.aliyuncs.com&#x2F;haoransun&#x2F;httpd:v0.2</span><br><span class="line">docker image ls</span><br><span class="line"># 登出刚才登录docker hub 的用户</span><br><span class="line">docker logout</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/96b2154e-7e3c-4be2-9678-15df8c704716.png" alt></p><p>设置登录镜像仓库的密码，不是登录阿里云的密码</p><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/18e18c54-231d-4398-9681-b9b8e54fd615.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker login --username&#x3D;haoransun registry.cn-hangzhou.aliyuncs.com</span><br><span class="line"></span><br><span class="line">docker push registry.cn-hangzhou.aliyuncs.com&#x2F;haoransun&#x2F;httpd:v0.2</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/0874bd02-ada9-43c1-a26d-51b05b1bfa13.png" alt></p><p>网页查看<br><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/6fef17ed-ae19-43c2-85de-496c3970d157.png" alt></p><h3 id="4-镜像的导入导出"><a href="#4-镜像的导入导出" class="headerlink" title="4. 镜像的导入导出"></a>4. 镜像的导入导出</h3><p>node1制作了镜像，node2也想要这个镜像。</p><p><strong>通过docker hub 或 阿里云 都可以，但还是太麻烦，只是为了做测试用</strong>。</p><p>可以将做好的镜像打包，在另外一个node上用就ok。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># save 打包，-o 指明打包到那个路径 </span><br><span class="line">docker save -o myimages.gz  haoransun&#x2F;httpd:v0.1-1 haoransun&#x2F;httpd:v0.2</span><br><span class="line"></span><br><span class="line"># 使用 scp 将文件传输到 另一个node上</span><br><span class="line">scp myimages.gz 192.168.121.200:&#x2F;root&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/5acd0c54-cbb7-4070-8729-8219fbc4f81a.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker load -i myimages.gz</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/492c827e-a78a-437f-9637-c716085583aa.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-安装Docker&quot;&gt;&lt;a href=&quot;#1-安装Docker&quot; class=&quot;headerlink&quot; title=&quot;1. 安装Docker&quot;&gt;&lt;/a&gt;1. 安装Docker&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/2020/04/05/1-%E5%AE%89%E8%A3%85-%E4%BD%BF%E7%94%A8Docker/0c401be3-4ee5-41fe-b2a6-b0c40ec3f933.jpg&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三种方式安装Docker&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;1-Extras-Repository&quot;&gt;&lt;a href=&quot;#1-Extras-Repository&quot; class=&quot;headerlink&quot; title=&quot;1. Extras Repository&quot;&gt;&lt;/a&gt;1. Extras Repository&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;CentOS-6.2.32支持Docker，红帽以补丁方式补充。有很多不稳定因素，此处选用CentOS7&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;自带的有版本太老，自行搜索安装方法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="http://JavaSsun.github.io/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://JavaSsun.github.io/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>45-自增ID用完怎么办</title>
    <link href="http://javassun.github.io/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/"/>
    <id>http://javassun.github.io/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/</id>
    <published>2020-03-11T13:18:38.000Z</published>
    <updated>2020-05-20T20:17:41.473Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>MySQL里有很多自增的id，每个自增id都是定义了初始值，然后不停地往上加步长。虽然自然数是没有上限的，但是在计算机里，只要定义了表示这个数的字节长度，那它就有上限。比如，无符号整型(unsigned int)是4个字节，上限就是2<sup>32</sup>-1。</p><p>既然自增id有上限，就有可能被用完。但是，自增id用完了会怎么样呢？</p><p>今天这篇文章，我们就来看看MySQL里面的几种自增id，一起分析一下它们的值达到上限以后，会出现什么情况。</p><a id="more"></a><h2 id="1-表定义自增值id"><a href="#1-表定义自增值id" class="headerlink" title="1. 表定义自增值id"></a>1. 表定义自增值id</h2><p>说到自增id，你第一个想到的应该就是表结构定义里的自增字段，也就是在 <strong>第39篇文章</strong> 中和你介绍过的自增主键id。</p><p>表定义的自增值达到上限后的逻辑是：再申请下一个id时，得到的值保持不变。</p><p>我们可以通过下面这个语句序列验证一下：</p><p><img src="/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/8542df98-a3c7-45c2-aca1-e971baf20d6d.png" alt></p><p>可以看到，第一个insert语句插入数据成功后，这个表的AUTO_INCREMENT没有改变（还是4294967295），就导致了第二个insert语句又拿到相同的自增id值，再试图执行插入语句，报主键冲突错误。</p><p>2<sup>32</sup>-1（4294967295）不是一个特别大的数，对于一个频繁插入删除数据的表来说，是可能会被用完的。因此在建表的时候你需要考察你的表是否有可能达到这个上限，如果有可能，就应该创建成8个字节的bigint unsigned。</p><h2 id="2-InnoDB系统自增row-id"><a href="#2-InnoDB系统自增row-id" class="headerlink" title="2. InnoDB系统自增row_id"></a>2. InnoDB系统自增row_id</h2><p>如果你创建的InnoDB表没有指定主键，那么InnoDB会给你创建一个不可见的，长度为6个字节的row_id。InnoDB维护了一个全局的dict_sys.row_id值，所有无主键的InnoDB表，每插入一行数据，都将当前的dict_sys.row_id值作为要插入数据的row_id，然后把dict_sys.row_id的值加1。</p><p>实际上，在代码实现时row_id是一个长度为8字节的无符号长整型(bigint unsigned)。但是，InnoDB在设计时，给row_id留的只是6个字节的长度，这样写到数据表中时只放了最后6个字节，所以row_id能写到数据表中的值，就有两个特征：</p><ol><li><p>row_id写入表中的值范围，是从0到2<sup>48</sup>-1；</p></li><li><p>当dict_sys.row_id=2<sup>48</sup>时，如果再有插入数据的行为要来申请row_id，拿到以后再取最后6个字节的话就是0。</p></li></ol><p>也就是说，写入表的row_id是从0开始到2<sup>48</sup>-1。达到上限后，下一个值就是0，然后继续循环。</p><p>当然，2<sup>48</sup>-1这个值本身已经很大了，但是如果一个MySQL实例跑得足够久的话，还是可能达到这个上限的。在InnoDB逻辑里，申请到row_id=N后，就将这行数据写入表中；如果表中已经存在row_id=N的行，新写入的行就会覆盖原有的行。</p><p>要验证这个结论的话，你可以通过gdb修改系统的自增row_id来实现。注意，用gdb改变量这个操作是为了便于我们复现问题，只能在测试环境使用。</p><p><img src="/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/f0b4de21-192a-4098-9b54-9974638b56db.jpg" alt></p><p>可以看到，在我用gdb将dict_sys.row_id设置为2<sup>48</sup>之后，再插入的a=2的行会出现在表t的第一行，因为这个值的row_id=0。之后再插入的a=3的行，由于row_id=1，就覆盖了之前a=1的行，因为a=1这一行的row_id也是1。</p><p>从这个角度看，我们还是应该在InnoDB表中主动创建自增主键。因为，表自增id到达上限后，再插入数据时报主键冲突错误，是更能被接受的。</p><p>毕竟覆盖数据，就意味着数据丢失，影响的是数据可靠性；报主键冲突，是插入失败，影响的是可用性。而一般情况下，可靠性优先于可用性。</p><h2 id="3-Xid"><a href="#3-Xid" class="headerlink" title="3. Xid"></a>3. Xid</h2><p>在 <strong>第15篇文章《答疑文章（一）：日志和索引相关问题》</strong> 中，我和你介绍redo log和binlog相配合的时候，提到了它们有一个共同的字段叫作Xid。它在MySQL中是用来对应事务的。</p><p>那么，Xid在MySQL内部是怎么生成的呢？</p><p>MySQL内部维护了一个全局变量global_query_id，每次执行语句的时候将它赋值给Query_id，然后给这个变量加1。如果当前语句是这个事务执行的第一条语句，那么MySQL还会同时把Query_id赋值给这个事务的Xid。</p><p>而global_query_id是一个纯内存变量，重启之后就清零了。所以你就知道了，在同一个数据库实例中，不同事务的Xid也是有可能相同的。</p><p>但是MySQL重启之后会重新生成新的binlog文件，这就保证了，同一个binlog文件里，Xid一定是惟一的。</p><p>虽然MySQL重启不会导致同一个binlog里面出现两个相同的Xid，但是如果global_query_id达到上限后，就会继续从0开始计数。从理论上讲，还是就会出现同一个binlog里面出现相同Xid的场景。</p><p>因为global_query_id定义的长度是8个字节，这个自增值的上限是2<sup>64</sup>-1，要出现这种情况，必须是下面这样的过程：</p><ol><li><p>执行一个事务，假设Xid是A；</p></li><li><p>接下来执行2<sup>64</sup>次查询语句，让global_query_id回到A；</p></li><li><p>再启动一个事务，这个事务的Xid也是A。</p></li></ol><p>不过，2<sup>64</sup>这个值太大了，大到你可以认为这个可能性只会存在于理论上。</p><h2 id="4-Innodb-trx-id"><a href="#4-Innodb-trx-id" class="headerlink" title="4. Innodb trx_id"></a>4. Innodb trx_id</h2><p>Xid和InnoDB的trx_id是两个容易混淆的概念。</p><p>Xid是由server层维护的。InnoDB内部使用Xid，就是为了能够在InnoDB事务和server之间做关联。但是，InnoDB自己的trx_id，是另外维护的。</p><p>其实，你应该非常熟悉这个trx_id。它就是在我们在 <strong>第8篇文章《事务到底是隔离的还是不隔离的？》</strong> 中讲事务可见性时，用到的事务id（transaction id）。</p><p>InnoDB内部维护了一个max_trx_id全局变量，每次需要申请一个新的trx_id时，就获得max_trx_id的当前值，然后并将max_trx_id加1。</p><p>InnoDB数据可见性的核心思想是：每一行数据都记录了更新它的trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的trx_id做对比。</p><p>对于正在执行的事务，你可以从information_schema.innodb_trx表中看到事务的trx_id。</p><p>我在上一篇文章的末尾留给你的思考题，就是关于从innodb_trx表里面查到的trx_id的。现在，我们一起来看一个事务现场：</p><p><img src="/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/d63c1cc4-7682-4787-a428-44dd3e0e6a26.png" alt></p><p>session B里，我从innodb_trx表里查出的这两个字段，第二个字段trx_mysql_thread_id就是线程id。显示线程id，是为了说明这两次查询看到的事务对应的线程id都是5，也就是session A所在的线程。</p><p>可以看到，T2时刻显示的trx_id是一个很大的数；T4时刻显示的trx_id是1289，看上去是一个比较正常的数字。这是什么原因呢？</p><p>实际上，在T1时刻，session A还没有涉及到更新，是一个只读事务。而对于只读事务，InnoDB并不会分配trx_id。也就是说：</p><ol><li><p>在T1时刻，trx_id的值其实就是0。而这个很大的数，只是显示用的。一会儿我会再和你说说这个数据的生成逻辑。</p></li><li><p>直到session A 在T3时刻执行insert语句的时候，InnoDB才真正分配了trx_id。所以，T4时刻，session B查到的这个trx_id的值就是1289。</p></li></ol><p>需要注意的是，除了显而易见的修改类语句外，如果在select 语句后面加上for update，这个事务也不是只读事务。</p><p>有同学提出，实验的时候发现不止加1。这是因为：</p><ol><li><p>update 和 delete语句除了事务本身，还涉及到标记删除旧数据，也就是要把数据放到purge队列里等待后续物理删除，这个操作也会把max_trx_id+1， 因此在一个事务中至少加2；</p></li><li><p>InnoDB的后台操作，比如表的索引信息统计这类操作，也是会启动内部事务的，因此你可能看到，trx_id值并不是按照加1递增的。</p></li></ol><p>那么，<strong>T2时刻查到的这个很大的数字是怎么来的呢？</strong></p><p>其实，这个数字是每次查询的时候由系统临时计算出来的。它的算法是：把当前事务的trx变量的指针地址转成整数，再加上2<sup>48</sup>。使用这个算法，就可以保证以下两点：</p><ol><li><p>因为同一个只读事务在执行期间，它的指针地址是不会变的，所以不论是在 innodb_trx还是在innodb_locks表里，同一个只读事务查出来的trx_id就会是一样的。</p></li><li><p>如果有并行的多个只读事务，每个事务的trx变量的指针地址肯定不同。这样，不同的并发只读事务，查出来的trx_id就是不同的。</p></li></ol><p>那么，<strong>为什么还要再加上2<sup>48</sup>呢？</strong></p><p>在显示值里面加上2<sup>48</sup>，目的是要保证只读事务显示的trx_id值比较大，正常情况下就会区别于读写事务的id。但是，trx_id跟row_id的逻辑类似，定义长度也是8个字节。因此，在理论上还是可能出现一个读写事务与一个只读事务显示的trx_id相同的情况。不过这个概率很低，并且也没有什么实质危害，可以不管它。</p><p>另一个问题是，<strong>只读事务不分配trx_id，有什么好处呢？</strong></p><ul><li><p>一个好处是，这样做可以减小事务视图里面活跃事务数组的大小。因为当前正在运行的只读事务，是不影响数据的可见性判断的。所以，在创建事务的一致性视图时，InnoDB就只需要拷贝读写事务的trx_id。</p></li><li><p>另一个好处是，可以减少trx_id的申请次数。在InnoDB里，即使你只是执行一个普通的select语句，在执行过程中，也是要对应一个只读事务的。所以只读事务优化后，普通的查询语句不需要申请trx_id，就大大减少了并发事务申请trx_id的锁冲突。</p></li></ul><p>由于只读事务不分配trx_id，一个自然而然的结果就是trx_id的增加速度变慢了。</p><p>但是，max_trx_id会持久化存储，重启也不会重置为0，那么从理论上讲，只要一个MySQL服务跑得足够久，就可能出现max_trx_id达到2<sup>48</sup>-1的上限，然后从0开始的情况。</p><p>当达到这个状态后，MySQL就会持续出现一个脏读的bug，我们来复现一下这个bug。</p><p>首先我们需要把当前的max_trx_id先修改成2<sup>48</sup>-1。注意：这个case里使用的是可重复读隔离级别。具体的操作流程如下：</p><p><img src="/2020/03/11/45-%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E/b4980826-15ef-4e17-bed7-bf65a9e7ce5c.png" alt></p><p>由于我们已经把系统的max_trx_id设置成了2<sup>48</sup>-1，所以在session A启动的事务TA的低水位就是2<sup>48</sup>-1。</p><p>在T2时刻，session B执行第一条update语句的事务id就是2<sup>48</sup>-1，而第二条update语句的事务id就是0了，这条update语句执行后生成的数据版本上的trx_id就是0。</p><p>在T3时刻，session A执行select语句的时候，判断可见性发现，c=3这个数据版本的trx_id，小于事务TA的低水位，因此认为这个数据可见。</p><p>但，这个是脏读。</p><p>由于低水位值会持续增加，而事务id从0开始计数，就导致了系统在这个时刻之后，所有的查询都会出现脏读的。</p><p>并且，MySQL重启时max_trx_id也不会清0，也就是说重启MySQL，这个bug仍然存在。</p><p>那么，<strong>这个bug也是只存在于理论上吗？</strong></p><p>假设一个MySQL实例的TPS是每秒50万，持续这个压力的话，在17.8年后，就会出现这个情况。如果TPS更高，这个年限自然也就更短了。但是，从MySQL的真正开始流行到现在，恐怕都还没有实例跑到过这个上限。不过，这个bug是只要MySQL实例服务时间够长，就会必然出现的。</p><p>当然，这个例子更现实的意义是，可以加深我们对低水位和数据可见性的理解。你也可以借此机会再回顾下 <strong>第8篇文章</strong> 中的相关内容。</p><h2 id="5-thread-id"><a href="#5-thread-id" class="headerlink" title="5. thread_id"></a>5. thread_id</h2><p>接下来，我们再看看线程id（thread_id）。其实，线程id才是MySQL中最常见的一种自增id。平时我们在查各种现场的时候，show processlist里面的第一列，就是thread_id。</p><p>thread_id的逻辑很好理解：系统保存了一个全局变量thread_id_counter，每新建一个连接，就将thread_id_counter赋值给这个新连接的线程变量。</p><p>thread_id_counter定义的大小是4个字节，因此达到2<sup>32</sup>-1后，它就会重置为0，然后继续增加。但是，你不会在show processlist里看到两个相同的thread_id。</p><p>这，是因为MySQL设计了一个唯一数组的逻辑，给新线程分配thread_id的时候，逻辑代码是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">do &#123; </span><br><span class="line">    new_id&#x3D; thread_id_counter++; </span><br><span class="line">&#125; while (!thread_ids.insert_unique(new_id).second);</span><br></pre></td></tr></table></figure><p>这个代码逻辑简单而且实现优雅，相信你一看就能明白。</p><h2 id="6-小结"><a href="#6-小结" class="headerlink" title="6. 小结"></a>6. 小结</h2><p>今天这篇文章，介绍了MySQL不同的自增id达到上限以后的行为。数据库系统作为一个可能需要7*24小时全年无休的服务，考虑这些边界是非常有必要的。</p><p>每种自增id有各自的应用场景，在达到上限后的表现也不同：</p><ol><li><p>表的自增id达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。</p></li><li><p>row_id达到上限后，则会归0再重新递增，如果出现相同的row_id，后写的数据会覆盖之前的数据。</p></li><li><p>Xid只需要不在同一个binlog文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。</p></li><li><p>InnoDB的max_trx_id 递增值每次MySQL重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的bug，好在留给我们的时间还很充裕。</p></li><li><p>thread_id是我们使用中最常见的，而且也是处理得最好的一个自增id逻辑了。</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;MySQL里有很多自增的id，每个自增id都是定义了初始值，然后不停地往上加步长。虽然自然数是没有上限的，但是在计算机里，只要定义了表示这个数的字节长度，那它就有上限。比如，无符号整型(unsigned int)是4个字节，上限就是2&lt;sup&gt;32&lt;/sup&gt;-1。&lt;/p&gt;
&lt;p&gt;既然自增id有上限，就有可能被用完。但是，自增id用完了会怎么样呢？&lt;/p&gt;
&lt;p&gt;今天这篇文章，我们就来看看MySQL里面的几种自增id，一起分析一下它们的值达到上限以后，会出现什么情况。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>44-一些常见问题</title>
    <link href="http://javassun.github.io/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>http://javassun.github.io/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</id>
    <published>2020-03-09T13:11:38.000Z</published>
    <updated>2020-05-20T20:15:46.633Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="1-join的用法"><a href="#1-join的用法" class="headerlink" title="1. join的用法"></a>1. join的用法</h2><p>在 <strong>第35篇文章《join语句怎么优化？》</strong> 中，在介绍join执行顺序的时候，用的都是straight_join。有人在文后提出了两个问题：</p><ol><li><p>如果用left join的话，左边的表一定是驱动表吗？</p></li><li><p>如果两个表的join包含多个条件的等值匹配，是都要写到on里面呢，还是只把一个条件写到on里面，其他条件写到where部分？</p></li></ol><p>为了同时回答这两个问题，我来构造两个表a和b：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table a(f1 int, f2 int, index(f1))engine&#x3D;innodb; </span><br><span class="line">create table b(f1 int, f2 int)engine&#x3D;innodb; </span><br><span class="line">insert into a values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6); </span><br><span class="line">insert into b values(3,3),(4,4),(5,5),(6,6),(7,7),(8,8);</span><br></pre></td></tr></table></figure><a id="more"></a><p>表a和b都有两个字段f1和f2，不同的是表a的字段f1上有索引。然后，我往两个表中都插入了6条记录，其中在表a和b中同时存在的数据有4行。</p><p>第二个问题，其实就是下面这两种写法的区别：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from a left join b on(a.f1&#x3D;b.f1) and (a.f2&#x3D;b.f2); &#x2F;*Q1*&#x2F; </span><br><span class="line">select * from a left join b on(a.f1&#x3D;b.f1) where (a.f2&#x3D;b.f2);&#x2F;*Q2*&#x2F;</span><br></pre></td></tr></table></figure><p>把这两条语句分别记为Q1和Q2。</p><p>首先，需要说明的是，这两个left join语句的语义逻辑并不相同。我们先来看一下它们的执行结果。</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/f37a2a42-2bf1-49ae-8e77-2a62c3592330.jpg" alt></p><p>可以看到：</p><ul><li>语句Q1返回的数据集是6行，表a中即使没有满足匹配条件的记录，查询结果中也会返回一行，并将表b的各个字段值填成NULL。</li><li>语句Q2返回的是4行。从逻辑上可以这么理解，最后的两行，由于表b中没有匹配的字段，结果集里面b.f2的值是空，不满足where 部分的条件判断，因此不能作为结果集的一部分。</li></ul><p>接下来，我们看看实际执行这两条语句时，MySQL是怎么做的。</p><p>我们先一起看看语句Q1的explain结果：</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/f813e7c6-2c38-4057-99e9-596ff144fdf6.jpg" alt></p><p>可以看到，这个结果符合我们的预期：</p><ul><li>驱动表是表a，被驱动表是表b；</li><li>由于表b的f1字段上没有索引，所以使用的是Block Nexted Loop Join（简称BNL） 算法。</li></ul><p>看到BNL算法，你就应该知道这条语句的执行流程其实是这样的：</p><ol><li><p>把表a的内容读入join_buffer 中。因为是select * ，所以字段f1和f2都被放入join_buffer了。</p></li><li><p>顺序扫描表b，对于每一行数据，判断join条件（也就是a.f1=b.f1 and a.f2=b.f2)是否满足，满足条件的记录, 作为结果集的一行返回。如果语句中有where子句，需要先判断where部分满足条件后，再返回。</p></li><li><p>表b扫描完成后，对于没有被匹配的表a的行（在这个例子中就是(1,1)、(2,2)这两行），把剩余字段补上NULL，再放入结果集中。</p></li></ol><p>对应的流程图如下：</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/798a8f15-e542-41d4-a36f-f79d50154e6a.jpg" alt></p><p>可以看到，这条语句确实是以表a为驱动表，而且从执行效果看，也和使用straight_join是一样的。</p><p>你可能会想，语句Q2的查询结果里面少了最后两行数据，是不是就是把上面流程中的步骤3去掉呢？我们还是先看一下语句Q2的expain结果吧。</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/7c1c19f0-19c9-4cec-a936-ef1a3061a7a2.jpg" alt></p><p>可以看到，这条语句是以表b为驱动表的。而如果一条join语句的Extra字段什么都没写的话，就表示使用的是Index Nested-Loop Join（简称NLJ）算法。</p><p>因此，语句Q2的执行流程是这样的：顺序扫描表b，每一行用b.f1到表a中去查，匹配到记录后判断a.f2=b.f2是否满足，满足条件的话就作为结果集的一部分返回。</p><p>那么，<strong>为什么语句Q1和Q2这两个查询的执行流程会差距这么大呢？</strong>其实，这是因为优化器基于Q2这个查询的语义做了优化。</p><p>为了理解这个问题，我需要再和你交代一个背景知识点：在MySQL里，NULL跟任何值执行等值判断和不等值判断的结果，都是NULL。这里包括， select NULL = NULL 的结果，也是返回NULL。</p><p>因此，语句Q2里面where a.f2=b.f2就表示，查询结果里面不会包含b.f2是NULL的行，这样这个left join的语义就是“找到这两个表里面，f1、f2对应相同的行。对于表a中存在，而表b中匹配不到的行，就放弃”。</p><p>这样，这条语句虽然用的是left join，但是语义跟join是一致的。</p><p>因此，优化器就把这条语句的left join改写成了join，然后因为表a的f1上有索引，就把表b作为驱动表，这样就可以用上NLJ 算法。在执行explain之后，你再执行show warnings，就能看到这个改写的结果，如图5所示。</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/b930959e-05ce-4f47-9d0d-26b6319203a9.jpg" alt></p><p>这个例子说明，即使我们在SQL语句中写成left join，执行过程还是有可能不是从左到右连接的。也就是说，<strong>使用left join时，左边的表不一定是驱动表。</strong></p><p>这样看来，<strong>如果需要left join的语义，就不能把被驱动表的字段放在where条件里面做等值判断或不等值判断，必须都写在on里面。</strong>那如果是join语句呢？</p><p>这时候，我们再看看这两条语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from a join b on(a.f1&#x3D;b.f1) and (a.f2&#x3D;b.f2); &#x2F;*Q3*&#x2F; </span><br><span class="line">select * from a join b on(a.f1&#x3D;b.f1) where (a.f2&#x3D;b.f2);&#x2F;*Q4*&#x2F;</span><br></pre></td></tr></table></figure><p>我们再使用一次看explain 和 show warnings的方法，看看优化器是怎么做的。</p><p><img src="/2020/03/09/44-%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/61ea5c57-d580-42d6-a23d-eb243cae0bc8.jpg" alt></p><p>可以看到，这两条语句都被改写成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from a join b where (a.f1&#x3D;b.f1) and (a.f2&#x3D;b.f2);</span><br></pre></td></tr></table></figure><p>执行计划自然也是一模一样的。</p><p>也就是说，在这种情况下，join将判断条件是否全部放在on部分就没有区别了。</p><h2 id="2-Simple-Nested-Loop-Join-的性能问题"><a href="#2-Simple-Nested-Loop-Join-的性能问题" class="headerlink" title="2. Simple Nested Loop Join 的性能问题"></a>2. Simple Nested Loop Join 的性能问题</h2><p>我们知道，join语句使用不同的算法，对语句的性能影响会很大。</p><p>虽然BNL算法和Simple Nested Loop Join 算法都是要判断M*N次（M和N分别是join的两个表的行数），但是Simple Nested Loop Join 算法的每轮判断都要走全表扫描，因此性能上BNL算法执行起来会快很多。</p><p>为了便于说明，我还是先为你简单描述一下这两个算法。</p><p>BNL算法的执行逻辑是：</p><ol><li><p>首先，将驱动表的数据全部读入内存join_buffer中，这里join_buffer是无序数组；</p></li><li><p>然后，顺序遍历被驱动表的所有行，每一行数据都跟join_buffer中的数据进行匹配，匹配成功则作为结果集的一部分返回。</p></li></ol><p>Simple Nested Loop Join算法的执行逻辑是：顺序取出驱动表中的每一行数据，到被驱动表去做全表扫描匹配，匹配成功则作为结果集的一部分返回。</p><p>有人提出问题，Simple Nested Loop Join算法，其实也是把数据读到内存里，然后按照匹配条件进行判断，为什么性能差距会这么大呢？</p><p>解释这个问题，需要用到MySQL中索引结构和Buffer Pool的相关知识点：</p><ol><li><p>在对被驱动表做全表扫描的时候，如果数据没有在Buffer Pool中，就需要等待这部分数据从磁盘读入；<br>从磁盘读入数据到内存中，会影响正常业务的Buffer Pool命中率，而且这个算法天然会对被驱动表的数据做多次访问，更容易将这些数据页放到Buffer Pool的头部（请参考 <strong>第35篇文章</strong> 中的相关内容)；</p></li><li><p>即使被驱动表数据都在内存中，每次查找“下一个记录的操作”，都是类似指针操作。而join_buffer中是数组，遍历的成本更低。</p></li></ol><p>所以说，BNL算法的性能会更好。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-join的用法&quot;&gt;&lt;a href=&quot;#1-join的用法&quot; class=&quot;headerlink&quot; title=&quot;1. join的用法&quot;&gt;&lt;/a&gt;1. join的用法&lt;/h2&gt;&lt;p&gt;在 &lt;strong&gt;第35篇文章《join语句怎么优化？》&lt;/strong&gt; 中，在介绍join执行顺序的时候，用的都是straight_join。有人在文后提出了两个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;如果用left join的话，左边的表一定是驱动表吗？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;如果两个表的join包含多个条件的等值匹配，是都要写到on里面呢，还是只把一个条件写到on里面，其他条件写到where部分？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了同时回答这两个问题，我来构造两个表a和b：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;create table a(f1 int, f2 int, index(f1))engine&amp;#x3D;innodb; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;create table b(f1 int, f2 int)engine&amp;#x3D;innodb; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;insert into a values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6); &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;insert into b values(3,3),(4,4),(5,5),(6,6),(7,7),(8,8);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>43-要不要使用分区表</title>
    <link href="http://javassun.github.io/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/"/>
    <id>http://javassun.github.io/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/</id>
    <published>2020-03-08T12:31:38.000Z</published>
    <updated>2020-05-20T20:13:58.934Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>经常被问到这样一个问题：分区表有什么问题，为什么公司规范不让使用分区表呢？今天，我们就来聊聊分区表的使用行为，然后再一起回答这个问题。</p><a id="more"></a><h2 id="1-分区表是什么？"><a href="#1-分区表是什么？" class="headerlink" title="1. 分区表是什么？"></a>1. 分区表是什么？</h2><p>为了说明分区表的组织形式，我先创建一个表t：</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/b28f3457-d137-4aa8-90e5-f9a014513aca.png" alt></p><p>在表t中初始化插入了两行记录，按照定义的分区规则，这两行记录分别落在p_2018和p_2019这两个分区上。</p><p>可以看到，这个表包含了一个.frm文件和4个.ibd文件，每个分区对应一个.ibd文件。也就是说：</p><ul><li>对于引擎层来说，这是4个表；</li><li>对于Server层来说，这是1个表。</li></ul><p>你可能会觉得这两句都是废话。其实不然，这两句话非常重要，可以帮我们理解分区表的执行逻辑。</p><h2 id="2-分区表的引擎层行为"><a href="#2-分区表的引擎层行为" class="headerlink" title="2. 分区表的引擎层行为"></a>2. 分区表的引擎层行为</h2><p>先给你举个在分区表加间隙锁的例子，目的是说明对于InnoDB来说，这是4个表。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/886be770-3ff5-4252-b5a6-34828df80510.png" alt></p><p>这里顺便复习一下，在 <strong>第21篇文章</strong> 和你介绍的间隙锁加锁规则。</p><p>我们初始化表t的时候，只插入了两行数据， ftime的值分别是，‘2017-4-1’ 和’2018-4-1’ 。session A的select语句对索引ftime上这两个记录之间的间隙加了锁。如果是一个普通表的话，那么T1时刻，在表t的ftime索引上，间隙和加锁状态应该是图3这样的。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/9c5904d4-c2d7-4875-8ec7-8d975bccb1bb.jpg" alt></p><p>也就是说，‘2017-4-1’ 和’2018-4-1’ 这两个记录之间的间隙是会被锁住的。那么，sesion B的两条插入语句应该都要进入锁等待状态。</p><p>但是，从上面的实验效果可以看出，session B的第一个insert语句是可以执行成功的。这是因为，对于引擎来说，p_2018和p_2019是两个不同的表，也就是说2017-4-1的下一个记录并不是2018-4-1，而是p_2018分区的supremum。所以T1时刻，在表t的ftime索引上，间隙和加锁的状态其实是图4这样的：</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/8eb98e23-1f11-45ac-b693-58f53e1d568a.jpg" alt></p><p>由于分区表的规则，session A的select语句其实只操作了分区p_2018，因此加锁范围就是图4中深绿色的部分。</p><p>所以，session B要写入一行ftime是2018-2-1的时候是可以成功的，而要写入2017-12-1这个记录，就要等session A的间隙锁。</p><p>图5就是这时候的show engine innodb status的部分结果。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/749ad5db-1704-418f-b648-1bd44002566b.jpg" alt></p><p>看完InnoDB引擎的例子，我们再来一个MyISAM分区表的例子。</p><p>我首先用alter table t engine=myisam，把表t改成MyISAM表；然后，我再用下面这个例子说明，对于MyISAM引擎来说，这是4个表。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/6fb65701-4e3d-4dbc-bce1-763ffe81d042.png" alt></p><p>在session A里面，我用sleep(100)将这条语句的执行时间设置为100秒。由于MyISAM引擎只支持表锁，所以这条update语句会锁住整个表t上的读。</p><p>但我们看到的结果是，session B的第一条查询语句是可以正常执行的，第二条语句才进入锁等待状态。</p><p>这正是因为MyISAM的表锁是在引擎层实现的，session A加的表锁，其实是锁在分区p_2018上。因此，只会堵住在这个分区上执行的查询，落到其他分区的查询是不受影响的。</p><p>看到这里，你可能会说，分区表看来还不错嘛，为什么不让用呢？我们使用分区表的一个重要原因就是单表过大。那么，如果不使用分区表的话，我们就是要使用手动分表的方式。</p><p>接下来，我们一起看看手动分表和分区表有什么区别。</p><p>比如，按照年份来划分，我们就分别创建普通表t_2017、t_2018、t_2019等等。手工分表的逻辑，也是找到需要更新的所有分表，然后依次执行更新。在性能上，这和分区表并没有实质的差别。</p><p>分区表和手工分表，一个是由server层来决定使用哪个分区，一个是由应用层代码来决定使用哪个分表。因此，从引擎层看，这两种方式也是没有差别的。</p><p>其实这两个方案的区别，主要是在server层上。从server层看，我们就不得不提到分区表一个被广为诟病的问题：打开表的行为。</p><h2 id="3-分区策略"><a href="#3-分区策略" class="headerlink" title="3. 分区策略"></a>3. 分区策略</h2><p>每当第一次访问一个分区表的时候，MySQL需要把所有的分区都访问一遍。<strong>一个典型的报错情况</strong>是这样的：如果一个分区表的分区很多，比如超过了1000个，而MySQL启动的时候，open_files_limit参数使用的是默认值1024，那么就会在访问这个表的时候，由于需要打开所有的文件，导致打开表文件的个数超过了上限而报错。</p><p>下图就是我创建的一个包含了很多分区的表t_myisam，执行一条插入语句后报错的情况。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/58f26ec6-fae9-4dbd-a120-0070e8c41e6f.jpg" alt></p><p>可以看到，这条insert语句，明显只需要访问一个分区，但语句却无法执行。</p><p>这时，你一定从表名猜到了，这个表我用的是MyISAM引擎。是的，因为使用InnoDB引擎的话，并不会出现这个问题。</p><p>MyISAM分区表使用的分区策略，我们称为<strong>通用分区策略</strong>（generic partitioning），每次访问分区都由server层控制。通用分区策略，是MySQL一开始支持分区表的时候就存在的代码，在文件管理、表管理的实现上很粗糙，因此有比较严重的性能问题。</p><p>从MySQL 5.7.9开始，InnoDB引擎引入了<strong>本地分区策略</strong>（native partitioning）。这个策略是在InnoDB内部自己管理打开分区的行为。</p><p>MySQL从5.7.17开始，将MyISAM分区表标记为即将弃用(deprecated)，意思是“从这个版本开始不建议这么使用，请使用替代方案。在将来的版本中会废弃这个功能”。</p><p>从MySQL 8.0版本开始，就不允许创建MyISAM分区表了，只允许创建已经实现了本地分区策略的引擎。目前来看，只有InnoDB和NDB这两个引擎支持了本地分区策略。</p><p>接下来，我们再看一下分区表在server层的行为。</p><h2 id="4-分区表的server层行为"><a href="#4-分区表的server层行为" class="headerlink" title="4. 分区表的server层行为"></a>4. 分区表的server层行为</h2><p>如果从server层看的话，一个分区表就只是一个表。</p><p>这句话是什么意思呢？接下来，我就用下面这个例子来和你说明。如图8和图9所示，分别是这个例子的操作序列和执行结果图。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/2c1e24c9-f714-49e0-9e62-7e9a52fa0010.jpg" alt></p><p>可以看到，虽然session B只需要操作p_2107这个分区，但是由于session A持有整个表t的MDL锁，就导致了session B的alter语句被堵住。</p><p>这也是DBA同学经常说的，分区表，在做DDL的时候，影响会更大。如果你使用的是普通分表，那么当你在truncate一个分表的时候，肯定不会跟另外一个分表上的查询语句，出现MDL锁冲突。</p><p>到这里我们小结一下：</p><ol><li><p>MySQL在第一次打开分区表的时候，需要访问所有的分区；</p></li><li><p>在server层，认为这是同一张表，因此所有分区共用同一个MDL锁；</p></li><li><p>在引擎层，认为这是不同的表，因此MDL锁之后的执行过程，会根据分区表规则，只访问必要的分区。</p></li></ol><p>而关于“必要的分区”的判断，就是根据SQL语句中的where条件，结合分区规则来实现的。比如我们上面的例子中，where ftime=‘2018-4-1’，根据分区规则year函数算出来的值是2018，那么就会落在p_2019这个分区。</p><p>但是，如果这个where 条件改成 where ftime&gt;=‘2018-4-1’，虽然查询结果相同，但是这时候根据where条件，就要访问p_2019和p_others这两个分区。</p><p>如果查询语句的where条件中没有分区key，那就只能访问所有分区了。当然，这并不是分区表的问题。即使是使用业务分表的方式，where条件中没有使用分表的key，也必须访问所有的分表。</p><p>我们已经理解了分区表的概念，那么什么场景下适合使用分区表呢？</p><h2 id="5-分区表的应用场景"><a href="#5-分区表的应用场景" class="headerlink" title="5. 分区表的应用场景"></a>5. 分区表的应用场景</h2><p>分区表的一个显而易见的优势是对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁。还有，分区表可以很方便的清理历史数据。</p><p>如果一项业务跑的时间足够长，往往就会有根据时间删除历史数据的需求。这时候，按照时间分区的分区表，就可以直接通过alter table t drop partition …这个语法删掉分区，从而删掉过期的历史数据。</p><p>这个alter table t drop partition …操作是直接删除分区文件，效果跟drop普通表类似。与使用delete语句删除数据相比，优势是速度快、对系统影响小。</p><h2 id="6-小结"><a href="#6-小结" class="headerlink" title="6. 小结"></a>6. 小结</h2><p>这篇文章，主要介绍的是server层和引擎层对分区表的处理方式。希望通过这些介绍，你能够对是否选择使用分区表，有更清晰的想法。</p><p>需要注意的是，我是以范围分区（range）为例和你介绍的。实际上，MySQL还支持hash分区、list分区等分区方法。你可以在需要用到的时候，再翻翻 <a href="https://dev.mysql.com/doc/refman/8.0/en/partitioning-types.html" target="_blank" rel="noopener">手册</a>。</p><p>实际使用时，分区表跟用户分表比起来，有两个绕不开的问题：一个是第一次访问的时候需要访问所有分区，另一个是共用MDL锁。</p><p>因此，如果要使用分区表，就不要创建太多的分区。我见过一个用户做了按天分区策略，然后预先创建了10年的分区。这种情况下，访问分区表的性能自然是不好的。这里有两个问题需要注意：</p><ol><li><p>分区并不是越细越好。实际上，单表或者单分区的数据一千万行，只要没有特别大的索引，对于现在的硬件能力来说都已经是小表了。</p></li><li><p>分区也不要提前预留太多，在使用之前预先创建即可。比如，如果是按月分区，每年年底时再把下一年度的12个新分区创建上即可。对于没有数据的历史分区，要及时的drop掉。</p></li></ol><p>至于分区表的其他问题，比如查询需要跨多个分区取数据，查询性能就会比较慢，基本上就不是分区表本身的问题，而是数据量的问题或者说是使用方式的问题了。</p><p>当然，如果你的团队已经维护了成熟的分库分表中间件，用业务分表，对业务开发同学没有额外的复杂性，对DBA也更直观，自然是更好的。</p><h2 id="7-思考"><a href="#7-思考" class="headerlink" title="7. 思考"></a>7. 思考</h2><p>我们举例的表中没有用到自增主键，假设现在要创建一个自增字段id。MySQL要求分区表中的主键必须包含分区字段。如果要在表t的基础上做修改，你会怎么定义这个表的主键呢？为什么这么定义呢？</p><p>即 怎么给分区表t创建自增主键。由于MySQL要求主键包含所有的分区字段，所以肯定是要创建联合主键的。</p><p><strong>回答：</strong></p><p>这时候就有两种可选：一种是(ftime, id)，另一种是(id, ftime)。</p><p>如果从利用率上来看，应该使用(ftime, id)这种模式。因为用ftime做分区key，说明大多数语句都是包含ftime的，使用这种模式，可以利用前缀索引的规则，减少一个索引。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/a356d81c-9939-4171-aca2-d4bcc26ef25a.png" alt></p><p>当然，建议是你要尽量使用InnoDB引擎。InnoDB表要求至少有一个索引，以自增字段作为第一个字段，所以需要加一个id的单独索引。</p><p><img src="/2020/03/08/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/b1dbaf86-ec67-4126-b30a-1c0fcd39299f.png" alt></p><p>当然把字段反过来，创建成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PRIMARY KEY (&#96;id&#96;,&#96;ftime&#96;), </span><br><span class="line">KEY &#96;id&#96; (&#96;ftime&#96;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;经常被问到这样一个问题：分区表有什么问题，为什么公司规范不让使用分区表呢？今天，我们就来聊聊分区表的使用行为，然后再一起回答这个问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>42-grant之后要跟着flush privileges吗</title>
    <link href="http://javassun.github.io/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/"/>
    <id>http://javassun.github.io/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/</id>
    <published>2020-03-07T12:31:38.000Z</published>
    <updated>2020-05-20T20:12:09.913Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在MySQL里面，grant语句是用来给用户赋权的。不知道你有没有见过一些操作文档里面提到，grant之后要马上跟着执行一个flush privileges命令，才能使赋权语句生效。我最开始使用MySQL的时候，就是照着一个操作文档的说明按照这个顺序操作的。</p><p>那么，grant之后真的需要执行flush privileges吗？如果没有执行这个flush命令的话，赋权语句真的不能生效吗？</p><p>接下来，就先和你介绍一下grant语句和flush privileges语句分别做了什么事情，然后再一起来分析这个问题。</p><a id="more"></a><p>为了便于说明，先创建一个用户：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create user &#39;ua&#39;@&#39;%&#39; identified by &#39;pa&#39;;</span><br></pre></td></tr></table></figure><p>这条语句的逻辑是创建一个用户’ua’@’%’，密码是pa。注意，在MySQL里面，用户名(user)+地址(host)才表示一个用户，因此 ua@ip1 和 ua@ip2代表的是两个不同的用户。</p><p>这条命令做了两个动作：</p><ol><li><p>磁盘上，往mysql.user表里插入一行，由于没有指定权限，所以这行数据上所有表示权限的字段的值都是N；</p></li><li><p>内存里，往数组acl_users里插入一个acl_user对象，这个对象的access字段值为0。</p></li></ol><p>图1就是这个时刻用户ua在user表中的状态。</p><p><img src="/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/f72e1569-15c5-42d5-b401-bb8b702e5283.jpg" alt></p><p>在MySQL中，用户权限是有不同的范围的。接下来，就按照用户权限范围从大到小的顺序依次和你说明。</p><h2 id="1-全局权限"><a href="#1-全局权限" class="headerlink" title="1. 全局权限"></a>1. 全局权限</h2><p>全局权限，作用于整个MySQL实例，这些权限信息保存在mysql库的user表里。如果我要给用户ua赋一个最高权限的话，语句是这么写的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant all privileges on *.* to &#39;ua&#39;@&#39;%&#39; with grant option;</span><br></pre></td></tr></table></figure><p>这个grant命令做了两个动作：</p><ol><li><p>磁盘上，将mysql.user表里，用户’ua’@’%’这一行的所有表示权限的字段的值都修改为‘Y’；</p></li><li><p>内存里，从数组acl_users中找到这个用户对应的对象，将access值（权限位）修改为二进制的“全1”。</p></li></ol><p>在这个grant命令执行完成后，如果有新的客户端使用用户名ua登录成功，MySQL会为新连接维护一个线程对象，然后从acl_users数组里查到这个用户的权限，并将权限值拷贝到这个线程对象中。之后在这个连接中执行的语句，所有关于全局权限的判断，都直接使用线程对象内部保存的权限位。</p><p>基于上面的分析我们可以知道：</p><ol><li><p>grant 命令对于全局权限，同时更新了磁盘和内存。命令完成后即时生效，接下来新创建的连接会使用新的权限。</p></li><li><p>对于一个已经存在的连接，它的全局权限不受grant命令的影响。</p></li></ol><p>需要说明的是，<strong>一般在生产环境上要合理控制用户权限的范围</strong>。我们上面用到的这个grant语句就是一个典型的错误示范。如果一个用户有所有权限，一般就不应该设置为所有IP地址都可以访问。</p><p>如果要回收上面的grant语句赋予的权限，你可以使用下面这条命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">revoke all privileges on *.* from &#39;ua&#39;@&#39;%&#39;;</span><br></pre></td></tr></table></figure><p>这条revoke命令的用法与grant类似，做了如下两个动作：</p><ol><li><p>磁盘上，将mysql.user表里，用户’ua’@’%’这一行的所有表示权限的字段的值都修改为“N”；</p></li><li><p>内存里，从数组acl_users中找到这个用户对应的对象，将access的值修改为0。</p></li></ol><h2 id="2-db权限"><a href="#2-db权限" class="headerlink" title="2. db权限"></a>2. db权限</h2><p>除了全局权限，MySQL也支持库级别的权限定义。如果要让用户ua拥有库db1的所有权限，可以执行下面这条命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant all privileges on db1.* to &#39;ua&#39;@&#39;%&#39; with grant option;</span><br></pre></td></tr></table></figure><p>基于库的权限记录保存在mysql.db表中，在内存里则保存在数组acl_dbs中。这条grant命令做了如下两个动作：</p><ol><li><p>磁盘上，往mysql.db表中插入了一行记录，所有权限位字段设置为“Y”；</p></li><li><p>内存里，增加一个对象到数组acl_dbs中，这个对象的权限位为“全1”。</p></li></ol><p>图2就是这个时刻用户ua在db表中的状态。</p><p><img src="/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/4a4625a0-3508-47a4-9c5f-1fef791d2463.jpg" alt></p><p>每次需要判断一个用户对一个数据库读写权限的时候，都需要遍历一次acl_dbs数组，根据user、host和db找到匹配的对象，然后根据对象的权限位来判断。</p><p>也就是说，grant修改db权限的时候，是同时对磁盘和内存生效的。</p><p>grant操作对于已经存在的连接的影响，在全局权限和基于db的权限效果是不同的。接下来，我们做一个对照试验来分别看一下。</p><p><img src="/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/c24d86be-45f6-4476-b3d2-4e7a1a106b80.jpg" alt></p><p>需要说明的是，图中set global sync_binlog这个操作是需要super权限的。</p><p>可以看到，虽然用户ua的super权限在T3时刻已经通过revoke语句回收了，但是在T4时刻执行set global的时候，权限验证还是通过了。这是因为super是全局权限，这个权限信息在线程对象中，而revoke操作影响不到这个线程对象。</p><p>而在T5时刻去掉ua对db1库的所有权限后，在T6时刻session B再操作db1库的表，就会报错“权限不足”。这是因为acl_dbs是一个全局数组，所有线程判断db权限都用这个数组，这样revoke操作马上就会影响到session B。</p><p>这里在代码实现上有一个特别的逻辑，如果当前会话已经处于某一个db里面，之前use这个库的时候拿到的库权限会保存在会话变量中。</p><p>你可以看到在T6时刻，session C和session B对表t的操作逻辑是一样的。但是session B报错，而session C可以执行成功。这是因为session C在T2 时刻执行的use db1，拿到了这个库的权限，在切换出db1库之前，session C对这个库就一直有权限。</p><h2 id="3-表权限和列权限"><a href="#3-表权限和列权限" class="headerlink" title="3. 表权限和列权限"></a>3. 表权限和列权限</h2><p>除了db级别的权限外，MySQL支持更细粒度的表权限和列权限。其中，表权限定义存放在表mysql.tables_priv中，列权限定义存放在表mysql.columns_priv中。这两类权限，组合起来存放在内存的hash结构column_priv_hash中。</p><p>这两类权限的赋权命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create table db1.t1(id int, a int); </span><br><span class="line"></span><br><span class="line">grant all privileges on db1.t1 to &#39;ua&#39;@&#39;%&#39; with grant option; </span><br><span class="line"></span><br><span class="line">GRANT SELECT(id), INSERT (id,a) ON mydb.mytbl TO &#39;ua&#39;@&#39;%&#39; with grant option;</span><br></pre></td></tr></table></figure><p>跟db权限类似，这两个权限每次grant的时候都会修改数据表，也会同步修改内存中的hash结构。因此，对这两类权限的操作，也会马上影响到已经存在的连接。</p><p>看到这里，你一定会问，看来grant语句都是即时生效的，那这么看应该就不需要执行flush privileges语句了呀。</p><p>答案也确实是这样的。</p><p>flush privileges命令会清空acl_users数组，然后从mysql.user表中读取数据重新加载，重新构造一个acl_users数组。也就是说，以数据表中的数据为准，会将全局权限内存数组重新加载一遍。</p><p>同样地，对于db权限、表权限和列权限，MySQL也做了这样的处理。</p><p>也就是说，如果内存的权限数据和磁盘数据表相同的话，不需要执行flush privileges。而如果我们都是用grant/revoke语句来执行的话，内存和数据表本来就是保持同步更新的。</p><p><strong>因此，正常情况下，grant命令之后，没有必要跟着执行flush privileges命令。</strong></p><h2 id="4-flush-privileges使用场景"><a href="#4-flush-privileges使用场景" class="headerlink" title="4. flush privileges使用场景"></a>4. flush privileges使用场景</h2><p>那么，flush privileges是在什么时候使用呢？显然，当数据表中的权限数据跟内存中的权限数据不一致的时候，flush privileges语句可以用来重建内存数据，达到一致状态。</p><p>这种不一致往往是由不规范的操作导致的，比如直接用DML语句操作系统权限表。我们来看一下下面这个场景：</p><p><img src="/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/36990de3-5724-4922-b7a7-b0129ed7bfdc.png" alt></p><p>可以看到，T3时刻虽然已经用delete语句删除了用户ua，但是在T4时刻，仍然可以用ua连接成功。原因就是，这时候内存中acl_users数组中还有这个用户，因此系统判断时认为用户还正常存在。</p><p>在T5时刻执行过flush命令后，内存更新，T6时刻再要用ua来登录的话，就会报错“无法访问”了。</p><p>直接操作系统表是不规范的操作，这个不一致状态也会导致一些更“诡异”的现象发生。比如，前面这个通过delete语句删除用户的例子，就会出现下面的情况：</p><p><img src="/2020/03/07/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80flush-privileges%E5%90%97/e61445ea-4fe8-4fcc-9966-315258c8f83a.png" alt></p><p>可以看到，由于在T3时刻直接删除了数据表的记录，而内存的数据还存在。这就导致了：</p><ol><li><p>T4时刻给用户ua赋权限失败，因为mysql.user表中找不到这行记录；</p></li><li><p>而T5时刻要重新创建这个用户也不行，因为在做内存判断的时候，会认为这个用户还存在。</p></li></ol><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>今天这篇文章，介绍了MySQL用户权限在数据表和内存中的存在形式，以及grant和revoke命令的执行逻辑。</p><p>grant语句会同时修改数据表和内存，判断权限的时候使用的是内存数据。因此，规范地使用grant和revoke语句，是不需要随后加上flush privileges语句的。</p><p>flush privileges语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下再使用。而这种不一致往往是由于直接用DML语句操作系统权限表导致的，所以我们尽量不要使用这类语句。</p><p>另外，在使用grant语句赋权时，你可能还会看到这样的写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant super on *.* to &#39;ua&#39;@&#39;%&#39; identified by &#39;pa&#39;;</span><br></pre></td></tr></table></figure><p>这条命令加了identified by ‘密码’， 语句的逻辑里面除了赋权外，还包含了：</p><ol><li><p>如果用户’ua’@’%’不存在，就创建这个用户，密码是pa；</p></li><li><p>如果用户ua已经存在，就将密码修改成pa。</p></li></ol><p>这也是一种不建议的写法，因为这种写法很容易就会不慎把密码给改了。</p><p>“grant之后随手加flush privileges”，我自己是这么使用了两三年之后，在看代码的时候才发现其实并不需要这样做。</p><h2 id="6-技巧"><a href="#6-技巧" class="headerlink" title="6. 技巧"></a>6. 技巧</h2><p>在grant的时候是支持通配符的：”_”表示一个任意字符，“%”表示任意字符串。这个技巧在一个分库分表方案里面，同一个分库上有多个db的时候，是挺方便的。不过我个人认为，权限赋值的时候，控制的精确性还是要优先考虑的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在MySQL里面，grant语句是用来给用户赋权的。不知道你有没有见过一些操作文档里面提到，grant之后要马上跟着执行一个flush privileges命令，才能使赋权语句生效。我最开始使用MySQL的时候，就是照着一个操作文档的说明按照这个顺序操作的。&lt;/p&gt;
&lt;p&gt;那么，grant之后真的需要执行flush privileges吗？如果没有执行这个flush命令的话，赋权语句真的不能生效吗？&lt;/p&gt;
&lt;p&gt;接下来，就先和你介绍一下grant语句和flush privileges语句分别做了什么事情，然后再一起来分析这个问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>41-如何最快的复制一张表</title>
    <link href="http://javassun.github.io/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/"/>
    <id>http://javassun.github.io/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/</id>
    <published>2020-03-06T11:30:38.000Z</published>
    <updated>2020-05-20T20:10:11.566Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在上一篇文章最后，给你留下的问题是怎么在两张表中拷贝数据。如果可以控制对源表的扫描行数和加锁范围很小的话，我们简单地使用insert … select 语句即可实现。</p><p>当然，为了避免对源表加读锁，更稳妥的方案是先将数据写到外部文本文件，然后再写回目标表。这时，有两种常用的方法。接下来的内容，会和你详细展开一下这两种方法。</p><p>为了便于说明，我还是先创建一个表db1.t，并插入1000行数据，同时创建一个相同结构的表db2.t。</p><a id="more"></a><p><img src="/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/e547ee45-f447-4575-888d-36caac547487.png" alt></p><p>假设，我们要把db1.t里面a&gt;900的数据行导出来，插入到db2.t中。</p><h2 id="1-mysqldump方法"><a href="#1-mysqldump方法" class="headerlink" title="1. mysqldump方法"></a>1. mysqldump方法</h2><p>一种方法是，使用mysqldump命令将数据导出成一组INSERT语句。你可以使用下面的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -h$host -P$port -u$user --add-locks&#x3D;0 --no-create-info --single-transaction --set-gtid-purged&#x3D;OFF db1 t --where&#x3D;&quot;a&gt;900&quot; --result-file&#x3D;&#x2F;client_tmp&#x2F;t.sql</span><br></pre></td></tr></table></figure><p>把结果输出到临时文件。</p><p>这条命令中，主要参数含义如下：</p><ol><li><p>–single-transaction的作用是，在导出数据的时候不需要对表db1.t加表锁，而是使用START TRANSACTION WITH CONSISTENT SNAPSHOT的方法；</p></li><li><p>–add-locks设置为0，表示在输出的文件结果里，不增加” LOCK TABLES <code>t</code> WRITE;” ；</p></li><li><p>–no-create-info的意思是，不需要导出表结构；</p></li><li><p>–set-gtid-purged=off表示的是，不输出跟GTID相关的信息；</p></li><li><p>–result-file指定了输出文件的路径，其中client表示生成的文件是在客户端机器上的。</p></li></ol><p>通过这条mysqldump命令生成的t.sql文件中就包含了如图1所示的INSERT语句。</p><p><img src="/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/02e8acc5-628d-49bd-a9e7-66792537cb23.jpg" alt></p><p>可以看到，一条INSERT语句里面会包含多个value对，这是为了后续用这个文件来写入数据的时候，执行速度可以更快。</p><p>如果你希望生成的文件中一条INSERT语句只插入一行数据的话，可以在执行mysqldump命令时，加上参数–skip-extended-insert。</p><p>然后，你可以通过下面这条命令，将这些INSERT语句放到db2库里去执行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h127.0.0.1 -P13000 -uroot db2 -e &quot;source &#x2F;client_tmp&#x2F;t.sql&quot;</span><br></pre></td></tr></table></figure><p>需要说明的是，source并不是一条SQL语句，而是一个客户端命令。mysql客户端执行这个命令的流程是这样的：</p><ol><li><p>打开文件，默认以分号为结尾读取一条条的SQL语句；</p></li><li><p>将SQL语句发送到服务端执行。</p></li></ol><p>也就是说，服务端执行的并不是这个“source t.sql”语句，而是INSERT语句。所以，不论是在慢查询日志（slow log），还是在binlog，记录的都是这些要被真正执行的INSERT语句。</p><h2 id="2-导出CSV文件"><a href="#2-导出CSV文件" class="headerlink" title="2. 导出CSV文件"></a>2. 导出CSV文件</h2><p>另一种方法是直接将结果导出成.csv文件。MySQL提供了下面的语法，用来将查询结果导出到服务端本地目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from db1.t where a&gt;900 into outfile &#39;&#x2F;server_tmp&#x2F;t.csv&#39;;</span><br></pre></td></tr></table></figure><p>我们在使用这条语句时，需要注意如下几点。</p><ol><li><p>这条语句会将结果保存在服务端。如果你执行命令的客户端和MySQL服务端不在同一个机器上，客户端机器的临时目录下是不会生成t.csv文件的。</p></li><li><p>into outfile指定了文件的生成位置（/server_tmp/），这个位置必须受参数secure_file_priv的限制。参数secure_file_priv的可选值和作用分别是：</p><ul><li>如果设置为empty，表示不限制文件生成的位置，这是不安全的设置；</li><li>如果设置为一个表示路径的字符串，就要求生成的文件只能放在这个指定的目录，或者它的子目录；</li><li>如果设置为NULL，就表示禁止在这个MySQL实例上执行select … into outfile 操作。</li></ul></li><li><p>这条命令不会帮你覆盖文件，因此你需要确保/server_tmp/t.csv这个文件不存在，否则执行语句时就会因为有同名文件的存在而报错。</p></li><li><p>这条命令生成的文本文件中，原则上一个数据行对应文本文件的一行。但是，如果字段中包含换行符，在生成的文本中也会有换行符。不过类似换行符、制表符这类符号，前面都会跟上“\”这个转义符，这样就可以跟字段之间、数据行之间的分隔符区分开。</p></li></ol><p>得到.csv导出文件后，你就可以用下面的load data命令将数据导入到目标表db2.t中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data infile &#39;&#x2F;server_tmp&#x2F;t.csv&#39; into table db2.t;</span><br></pre></td></tr></table></figure><p>这条语句的执行流程如下所示。</p><ol><li><p>打开文件/server_tmp/t.csv，以制表符(\t)作为字段间的分隔符，以换行符（\n）作为记录之间的分隔符，进行数据读取；</p></li><li><p>启动事务。</p></li><li><p>判断每一行的字段数与表db2.t是否相同：</p><ul><li>若不相同，则直接报错，事务回滚；</li><li>若相同，则构造成一行，调用InnoDB引擎接口，写入到表中。</li></ul></li><li><p>重复步骤3，直到/server_tmp/t.csv整个文件读入完成，提交事务。</p></li></ol><p>你可能有一个疑问，<strong>如果binlog_format=statement，这个load语句记录到binlog里以后，怎么在备库重放呢？</strong></p><p>由于/server_tmp/t.csv文件只保存在主库所在的主机上，如果只是把这条语句原文写到binlog中，在备库执行的时候，备库的本地机器上没有这个文件，就会导致主备同步停止。</p><p>所以，这条语句执行的完整流程，其实是下面这样的。</p><ol><li><p>主库执行完成后，将/server_tmp/t.csv文件的内容直接写到binlog文件中。</p></li><li><p>往binlog文件中写入语句load data local infile ‘/tmp/SQL_LOAD_MB-1-0’ INTO TABLE <code>db2</code>.<code>t</code>。</p></li><li><p>把这个binlog日志传到备库。</p></li><li><p>备库的apply线程在执行这个事务日志时：<br>a. 先将binlog中t.csv文件的内容读出来，写入到本地临时目录/tmp/SQL_LOAD_MB-1-0 中；<br>b. 再执行load data语句，往备库的db2.t表中插入跟主库相同的数据。</p></li></ol><p>执行流程如图2所示：</p><p><img src="/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/a054cd4e-3760-4da5-9a5e-745186004290.jpg" alt></p><p>注意，这里备库执行的load data语句里面，多了一个“local”。它的意思是“将执行这条命令的客户端所在机器的本地文件/tmp/SQL_LOAD_MB-1-0的内容，加载到目标表db2.t中”。</p><p>也就是说，<strong>load data命令有两种用法</strong>：</p><ol><li><p>不加“local”，是读取服务端的文件，这个文件必须在secure_file_priv指定的目录或子目录下；</p></li><li><p>加上“local”，读取的是客户端的文件，只要mysql客户端有访问这个文件的权限即可。这时候，MySQL客户端会先把本地文件传给服务端，然后执行上述的load data流程。</p></li></ol><p>另外需要注意的是，<strong>select …into outfile方法不会生成表结构文件</strong>, 所以我们导数据时还需要单独的命令得到表结构定义。mysqldump提供了一个–tab参数，可以同时导出表结构定义文件和csv数据文件。这条命令的使用方法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -h$host -P$port -u$user ---single-transaction --set-gtid-purged&#x3D;OFF db1 t --where&#x3D;&quot;a&gt;900&quot; --tab&#x3D;$secure_file_priv</span><br></pre></td></tr></table></figure><p>这条命令会在$secure_file_priv定义的目录下，创建一个t.sql文件保存建表语句，同时创建一个t.txt文件保存CSV数据。</p><h2 id="3-物理拷贝方法"><a href="#3-物理拷贝方法" class="headerlink" title="3. 物理拷贝方法"></a>3. 物理拷贝方法</h2><p>前面我们提到的mysqldump方法和导出CSV文件的方法，都是逻辑导数据的方法，也就是将数据从表db1.t中读出来，生成文本，然后再写入目标表db2.t中。</p><p>你可能会问，有物理导数据的方法吗？比如，直接把db1.t表的.frm文件和.ibd文件拷贝到db2目录下，是否可行呢？</p><p>答案是不行的。</p><p>因为，一个InnoDB表，除了包含这两个物理文件外，还需要在数据字典中注册。直接拷贝这两个文件的话，因为数据字典中没有db2.t这个表，系统是不会识别和接受它们的。</p><p>不过，在MySQL 5.6版本引入了<strong>可传输表空间</strong>(transportable tablespace)的方法，可以通过导出+导入表空间的方式，实现物理拷贝表的功能。</p><p>假设我们现在的目标是在db1库下，复制一个跟表t相同的表r，具体的执行步骤如下：</p><ol><li><p>执行 create table r like t，创建一个相同表结构的空表；</p></li><li><p>执行alter table r discard tablespace，这时候r.ibd文件会被删除；</p></li><li><p>执行flush table t for export，这时候db1目录下会生成一个t.cfg文件；</p></li><li><p>在db1目录下执行cp t.cfg r.cfg; cp t.ibd r.ibd；这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL进程要有读写权限）；</p></li><li><p>执行unlock tables，这时候t.cfg文件会被删除；</p></li><li><p>执行alter table r import tablespace，将这个r.ibd文件作为表r的新的表空间，由于这个文件的数据内容和t.ibd是相同的，所以表r中就有了和表t相同的数据。</p></li></ol><p>至此，拷贝表数据的操作就完成了。这个流程的执行过程图如下：</p><p><img src="/2020/03/06/41-%E5%A6%82%E4%BD%95%E6%9C%80%E5%BF%AB%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/007f0a52-cad6-4c3f-b6ae-199bbbf0be40.jpg" alt></p><p>关于拷贝表的这个流程，有以下几个注意点：</p><ol><li><p>在第3步执行完flsuh table命令之后，db1.t整个表处于只读状态，直到执行unlock tables命令后才释放读锁；</p></li><li><p>在执行import tablespace的时候，为了让文件里的表空间id和数据字典中的一致，会修改r.ibd的表空间id。而这个表空间id存在于每一个数据页中。因此，如果是一个很大的文件（比如TB级别），每个数据页都需要修改，所以你会看到这个import语句的执行是需要一些时间的。当然，如果是相比于逻辑导入的方法，import语句的耗时是非常短的。</p></li></ol><h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a>4. 小结</h2><p>今天这篇文章，介绍了三种将一个表的数据导入到另外一个表中的方法。</p><p>我们来对比一下这三种方法的优缺点。</p><ol><li><p>物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：</p><ul><li>必须是全表拷贝，不能只拷贝部分数据；</li><li>需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；</li><li>由于是通过拷贝物理文件实现的，源表和目标表都是使用InnoDB引擎时才能使用。</li></ul></li><li><p>用mysqldump生成包含INSERT语句文件的方法，可以在where参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用join这种比较复杂的where条件写法。</p></li><li><p>用select … into outfile的方法是最灵活的，支持所有的SQL写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。</p></li></ol><p>后两种方式都是逻辑备份方式，是可以跨引擎使用的。</p><h2 id="5-思考"><a href="#5-思考" class="headerlink" title="5. 思考"></a>5. 思考</h2><p>我们前面介绍binlog_format=statement的时候，binlog记录的load data命令是带local的。既然这条命令是发送到备库去执行的，那么备库执行的时候也是本地执行，为什么需要这个local呢？如果写到binlog中的命令不带local，又会出现什么问题呢？</p><p><strong>回答：</strong></p><p>这样做的一个原因是，为了确保备库应用binlog正常。因为备库可能配置了secure_file_priv=null，所以如果不用local的话，可能会导入失败，造成主备同步延迟。</p><p>另一种应用场景是使用mysqlbinlog工具解析binlog文件，并应用到目标库的情况。你可以使用下面这条命令 ：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqlbinlog $binlog_file | mysql -h$host -P$port -u$user -p$pwd</span><br></pre></td></tr></table></figure><p>把日志直接解析出来发给目标库执行。增加local，就能让这个方法支持非本地的$host。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在上一篇文章最后，给你留下的问题是怎么在两张表中拷贝数据。如果可以控制对源表的扫描行数和加锁范围很小的话，我们简单地使用insert … select 语句即可实现。&lt;/p&gt;
&lt;p&gt;当然，为了避免对源表加读锁，更稳妥的方案是先将数据写到外部文本文件，然后再写回目标表。这时，有两种常用的方法。接下来的内容，会和你详细展开一下这两种方法。&lt;/p&gt;
&lt;p&gt;为了便于说明，我还是先创建一个表db1.t，并插入1000行数据，同时创建一个相同结构的表db2.t。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>40-insert语句的锁为什么这么多</title>
    <link href="http://javassun.github.io/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/"/>
    <id>http://javassun.github.io/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/</id>
    <published>2020-03-04T11:25:38.000Z</published>
    <updated>2020-05-20T20:07:28.741Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在上一篇文章中，提到MySQL对自增主键锁做了优化，尽量在申请到自增id以后，就释放自增锁。</p><p>因此，insert语句是一个很轻量的操作。不过，这个结论对于“普通的insert语句”才有效。也就是说，还有些insert语句是属于“特殊情况”的，在执行过程中需要给其他资源加锁，或者无法在申请到自增id以后就立马释放自增锁。</p><p>那么，今天这篇文章，我们就一起来聊聊这个话题。</p><a id="more"></a><h2 id="1-insert-…-select-语句"><a href="#1-insert-…-select-语句" class="headerlink" title="1. insert … select 语句"></a>1. insert … select 语句</h2><p>我们先从昨天的问题说起吧。表t和t2的表结构、初始化数据语句如下，今天的例子我们还是针对这两个表展开。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/84586a3d-0459-4a83-8c0a-ba8acc4096e6.png" alt></p><p>现在，我们一起来看看为什么在可重复读隔离级别下，binlog_format=statement时执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t2(c,d) select c,d from t;</span><br></pre></td></tr></table></figure><p>这个语句时，需要对表t的所有行和间隙加锁呢？</p><p>其实，这个问题我们需要考虑的还是日志和数据的一致性。我们看下这个执行序列：</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/e725474a-33e2-44eb-bf69-7935a8844323.png" alt></p><p>实际的执行效果是，如果session B先执行，由于这个语句对表t主键索引加了(-∞,1]这个next-key lock，会在语句执行完成后，才允许session A的insert语句执行。</p><p>但如果没有锁的话，就可能出现session B的insert语句先执行，但是后写入binlog的情况。于是，在binlog_format=statement的情况下，binlog里面就记录了这样的语句序列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(-1,-1,-1); </span><br><span class="line">insert into t2(c,d) select c,d from t;</span><br></pre></td></tr></table></figure><p>这个语句到了备库执行，就会把id=-1这一行也写到表t2中，出现主备不一致。</p><h2 id="2-insert-循环写入"><a href="#2-insert-循环写入" class="headerlink" title="2. insert 循环写入"></a>2. insert 循环写入</h2><p>当然了，执行insert … select 的时候，对目标表也不是锁全表，而是只锁住需要访问的资源。</p><p>如果现在有这么一个需求：要往表t2中插入一行数据，这一行的c值是表t中c值的最大值加1。</p><p>此时，我们可以这么写这条SQL语句 ：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t2(c,d) (select c+1, d from t force index(c) order by c desc limit 1);</span><br></pre></td></tr></table></figure><p>这个语句的加锁范围，就是表t索引c上的(3,4]和(4,supremum]这两个next-key lock，以及主键索引上id=4这一行。</p><p>它的执行流程也比较简单，从表t中按照索引c倒序，扫描第一行，拿到结果写入到表t2中。</p><p>因此整条语句的扫描行数是1。</p><p>这个语句执行的慢查询日志（slow log），如下图所示：</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/c20204d1-ffaf-4362-aac5-6d560bce29de.jpg" alt></p><p>通过这个慢查询日志，我们看到Rows_examined=1，正好验证了执行这条语句的扫描行数为1。</p><p>那么，如果我们是要把这样的一行数据插入到表t中的话：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t(c,d) (select c+1, d from t force index(c) order by c desc limit 1);</span><br></pre></td></tr></table></figure><p>语句的执行流程是怎样的？扫描行数又是多少呢？</p><p>这时候，我们再看慢查询日志就会发现不对了。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/495f0386-cc12-4cfd-a044-64535607038d.png" alt></p><p>可以看到，这时候的Rows_examined的值是5。</p><p>我在前面的文章中提到过，希望你都能够学会用explain的结果来“脑补”整条语句的执行过程。今天，我们就来一起试试。</p><p>如图4所示就是这条语句的explain结果。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/3192619c-cecd-471d-9991-4289b49ea5aa.jpg" alt></p><p>从Extra字段可以看到“Using temporary”字样，表示这个语句用到了临时表。也就是说，执行过程中，需要把表t的内容读出来，写入临时表。</p><p>图中rows显示的是1，我们不妨先对这个语句的执行流程做一个猜测：如果说是把子查询的结果读出来（扫描1行），写入临时表，然后再从临时表读出来（扫描1行），写回表t中。那么，这个语句的扫描行数就应该是2，而不是5。</p><p>所以，这个猜测不对。实际上，Explain结果里的rows=1是因为受到了limit 1 的影响。</p><p>从另一个角度考虑的话，我们可以看看InnoDB扫描了多少行。如图5所示，是在执行这个语句前后查看Innodb_rows_read的结果。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/f1d53f89-8766-44a8-a1bc-95ba4a6582f9.jpg" alt></p><p>可以看到，这个语句执行前后，Innodb_rows_read的值增加了4。因为默认临时表是使用Memory引擎的，所以这4行查的都是表t，也就是说对表t做了全表扫描。</p><p>这样，我们就把整个执行过程理清楚了：</p><ol><li><p>创建临时表，表里有两个字段c和d。</p></li><li><p>按照索引c扫描表t，依次取c=4、3、2、1，然后回表，读到c和d的值写入临时表。这时，Rows_examined=4。</p></li><li><p>由于语义里面有limit 1，所以只取了临时表的第一行，再插入到表t中。这时，Rows_examined的值加1，变成了5。</p></li></ol><p>也就是说，这个语句会导致在表t上做全表扫描，并且会给索引c上的所有间隙都加上共享的next-key lock。所以，这个语句执行期间，其他事务不能在这个表上插入数据。</p><p>至于这个语句的执行为什么需要临时表，原因是这类一边遍历数据，一边更新数据的情况，如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录，新插入的记录如果参与计算逻辑，就跟语义不符。</p><p>由于实现上这个语句没有在子查询中就直接使用limit 1，从而导致了这个语句的执行需要遍历整个表t。它的优化方法也比较简单，就是用前面介绍的方法，先insert into到临时表temp_t，这样就只需要扫描一行；然后再从表temp_t里面取出这行数据插入表t1。</p><p>当然，由于这个语句涉及的数据量很小，你可以考虑使用内存临时表来做这个优化。使用内存临时表优化时，语句序列的写法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create temporary table temp_t(c int,d int) engine&#x3D;memory; </span><br><span class="line">insert into temp_t (select c+1, d from t force index(c) order by c desc limit 1); </span><br><span class="line">insert into t select * from temp_t; </span><br><span class="line">drop table temp_t;</span><br></pre></td></tr></table></figure><h2 id="3-insert-唯一键冲突"><a href="#3-insert-唯一键冲突" class="headerlink" title="3. insert 唯一键冲突"></a>3. insert 唯一键冲突</h2><p>前面的两个例子是使用insert … select的情况，接下来我要介绍的这个例子就是最常见的insert语句出现唯一键冲突的情况。</p><p>对于有唯一键的表，插入数据时出现唯一键冲突也是常见的情况了。我先给你举一个简单的唯一键冲突的例子。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/52f29765-b6c9-4e00-bbfd-1f6d3bb7b712.png" alt></p><p>这个例子也是在可重复读（repeatable read）隔离级别下执行的。可以看到，session B要执行的insert语句进入了锁等待状态。</p><p>也就是说，session A执行的insert语句，发生唯一键冲突的时候，并不只是简单地报错返回，还在冲突的索引上加了锁。我们前面说过，一个next-key lock就是由它右边界的值定义的。这时候，session A持有索引c上的(5,10]共享next-key lock（读锁）。</p><p>至于为什么要加这个读锁，其实我也没有找到合理的解释。从作用上来看，这样做可以避免这一行被别的事务删掉。</p><p>这里<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html" target="_blank" rel="noopener">官方文档</a>有一个描述错误，认为如果冲突的是主键索引，就加记录锁，唯一索引才加next-key lock。但实际上，这两类索引冲突加的都是next-key lock。(已由官方矫正)</p><p>这里，分享一个经典的死锁场景</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/71e2714d-a949-40b4-b6d6-9a7cf1990900.png" alt></p><p>在session A执行rollback语句回滚的时候，session C几乎同时发现死锁并返回。</p><p>这个死锁产生的逻辑是这样的：</p><ol><li><p>在T1时刻，启动session A，并执行insert语句，此时在索引c的c=5上加了记录锁。注意，这个索引是唯一索引，因此退化为记录锁（如果你的印象模糊了，可以回顾下<a href="https://time.geekbang.org/column/article/75659" target="_blank" rel="noopener">第21篇文章</a>介绍的加锁规则）。</p></li><li><p>在T2时刻，session B要执行相同的insert语句，发现了唯一键冲突，加上读锁；同样地，session C也在索引c上，c=5这一个记录上，加了读锁。</p></li><li><p>T3时刻，session A回滚。这时候，session B和session C都试图继续执行插入操作，都要加上写锁。两个session都要等待对方的行锁，所以就出现了死锁。</p></li></ol><p>这个流程的状态变化图如下所示。</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/0bb154f1-15f2-4fe0-bfc9-d67c345aff04.jpg" alt></p><h2 id="4-insert-into-…-on-duplicate-key-update"><a href="#4-insert-into-…-on-duplicate-key-update" class="headerlink" title="4. insert into … on duplicate key update"></a>4. insert into … on duplicate key update</h2><p>上面这个例子是主键冲突后直接报错，如果是改写成</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(11,10,10) on duplicate key update d&#x3D;100;</span><br></pre></td></tr></table></figure><p>的话，就会给索引c上(5,10] 加一个排他的next-key lock（写锁）。</p><p><strong>insert into … on duplicate key update 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。</strong></p><p>注意，如果有多个列违反了唯一性约束，就会按照索引的顺序，修改跟第一个索引冲突的行。</p><p>现在表t里面已经有了(1,1,1)和(2,2,2)这两行，我们再来看看下面这个语句执行的效果：</p><p><img src="/2020/03/04/40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A/2b618770-d89c-435a-84af-2fba062aed59.jpg" alt></p><p>可以看到，主键id是先判断的，MySQL认为这个语句跟id=2这一行冲突，所以修改的是id=2的行。</p><p>需要注意的是，执行这条语句的affected rows返回的是2，很容易造成误解。实际上，真正更新的只有一行，只是在代码实现上，insert和update都认为自己成功了，update计数加了1， insert计数也加了1。</p><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>今天这篇文章，介绍了几种特殊情况下的insert语句。</p><p>insert … select 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下，这个语句会给select的表里扫描到的记录和间隙加读锁。</p><p>而如果insert和select的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。</p><p>insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的next-key lock(S锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。</p><h2 id="6-思考"><a href="#6-思考" class="headerlink" title="6. 思考"></a>6. 思考</h2><p>你平时在两个表之间拷贝数据用的是什么方法，有什么注意事项吗？在你的应用场景里，这个方法，相较于其他方法的优势是什么呢？</p><p><strong>见第41篇文章</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在上一篇文章中，提到MySQL对自增主键锁做了优化，尽量在申请到自增id以后，就释放自增锁。&lt;/p&gt;
&lt;p&gt;因此，insert语句是一个很轻量的操作。不过，这个结论对于“普通的insert语句”才有效。也就是说，还有些insert语句是属于“特殊情况”的，在执行过程中需要给其他资源加锁，或者无法在申请到自增id以后就立马释放自增锁。&lt;/p&gt;
&lt;p&gt;那么，今天这篇文章，我们就一起来聊聊这个话题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>39-自增主键为什么不是连续的</title>
    <link href="http://javassun.github.io/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/"/>
    <id>http://javassun.github.io/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/</id>
    <published>2020-03-03T11:20:38.000Z</published>
    <updated>2020-05-20T20:04:56.819Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 <strong>第4篇文章</strong> 中，我们提到过自增主键，由于自增主键可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑。</p><p>之前见过有的业务设计依赖于自增主键的连续性，也就是说，这个设计假设自增主键是连续的。但实际上，这样的假设是错的，因为自增主键不能保证连续递增。</p><p>今天这篇文章，我们就来说说这个问题，看看什么情况下自增主键会出现 “空洞”？</p><a id="more"></a><p>为了便于说明，我们创建一个表t，其中id是自增主键字段、c是唯一索引。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;t&#96; (</span><br><span class="line">&#96;id&#96; int(11) NOT NULL AUTO_INCREMENT, </span><br><span class="line">&#96;c&#96; int(11) DEFAULT NULL, </span><br><span class="line">&#96;d&#96; int(11) DEFAULT NULL, </span><br><span class="line"> PRIMARY KEY (&#96;id&#96;), </span><br><span class="line"> UNIQUE KEY &#96;c&#96; (&#96;c&#96;) </span><br><span class="line">) ENGINE&#x3D;InnoDB;</span><br></pre></td></tr></table></figure><h2 id="1-自增值保存在哪儿？"><a href="#1-自增值保存在哪儿？" class="headerlink" title="1. 自增值保存在哪儿？"></a>1. 自增值保存在哪儿？</h2><p>在这个空表t里面执行insert into t values(null, 1, 1);插入一行数据，再执行show create table命令，就可以看到如下图所示的结果：</p><p><img src="/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/b6d9b4ae-a205-4a0f-ad5b-5319114c8970.jpg" alt></p><p>可以看到，表定义里面出现了一个AUTO_INCREMENT=2，表示下一次插入数据时，如果需要自动生成自增值，会生成id=2。</p><p>其实，这个输出结果容易引起这样的误解：自增值是保存在表结构定义里的。实际上，<strong>表的结构定义存放在后缀名为.frm的文件中，但是并不会保存自增值。</strong></p><p>不同的引擎对于自增值的保存策略不同。</p><ul><li><p>MyISAM引擎的自增值保存在数据文件中。</p></li><li><p>InnoDB引擎的自增值，其实是保存在了内存里，并且到了MySQL 8.0版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为MySQL重启前的值”，具体情况是：</p><ul><li><p>在MySQL 5.7及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值max(id)，然后将max(id)+1作为这个表当前的自增值。</p><p>举例来说，如果一个表当前数据行里最大的id是10，AUTO_INCREMENT=11。这时候，我们删除id=10的行，AUTO_INCREMENT还是11。但如果马上重启实例，重启后这个表的AUTO_INCREMENT就会变成10。<br>也就是说，MySQL重启可能会修改一个表的AUTO_INCREMENT的值。</p></li><li><p>在MySQL 8.0版本，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启之前的值。</p></li></ul></li></ul><p>理解了MySQL对自增值的保存策略以后，我们再看看自增值修改机制。</p><h2 id="2-自增值修改机制"><a href="#2-自增值修改机制" class="headerlink" title="2. 自增值修改机制"></a>2. 自增值修改机制</h2><p>在MySQL里面，如果字段id被定义为AUTO_INCREMENT，在插入一行数据的时候，自增值的行为如下：</p><ol><li><p>如果插入数据时id字段指定为0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT值填到自增字段；</p></li><li><p>如果插入数据时id字段指定了具体的值，就直接使用语句里指定的值。</p></li></ol><p>根据要插入的值和当前自增值的大小关系，自增值的变更结果也会有所不同。假设，某次要插入的值是X，当前的自增值是Y。</p><ol><li><p>如果X&lt;Y，那么这个表的自增值不变；</p></li><li><p>如果X≥Y，就需要把当前自增值修改为新的自增值。</p></li></ol><p><strong>新的自增值生成算法是</strong>：从auto_increment_offset开始，以auto_increment_increment为步长，持续叠加，直到找到第一个大于X的值，作为新的自增值。</p><p>其中，auto_increment_offset 和 auto_increment_increment是两个系统参数，分别用来表示自增的初始值和步长，默认值都是1。</p><blockquote><p>备注：在一些场景下，使用的就不全是默认值。比如，双M的主备结构里要求双写的时候，我们就可能会设置成auto_increment_increment=2，让一个库的自增id都是奇数，另一个库的自增id都是偶数，避免两个库生成的主键发生冲突。</p></blockquote><p>当auto_increment_offset和auto_increment_increment都是1的时候，新的自增值生成逻辑很简单，就是：</p><ol><li><p>如果准备插入的值&gt;=当前自增值，新的自增值就是“准备插入的值+1”；</p></li><li><p>否则，自增值不变。</p></li></ol><p>这就引入了我们文章开头提到的问题，在这两个参数都设置为1的时候，自增主键id却不能保证是连续的，这是什么原因呢？</p><h2 id="3-自增值的修改时机"><a href="#3-自增值的修改时机" class="headerlink" title="3. 自增值的修改时机"></a>3. 自增值的修改时机</h2><p>要回答这个问题，我们就要看一下自增值的修改时机。</p><p>假设，表t里面已经有了(1,1,1)这条记录，这时我再执行一条插入数据命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(null, 1, 1);</span><br></pre></td></tr></table></figure><p>这个语句的执行流程就是：</p><ol><li><p>执行器调用InnoDB引擎接口写入一行，传入的这一行的值是(0,1,1);</p></li><li><p>InnoDB发现用户没有指定自增id的值，获取表t当前的自增值2；</p></li><li><p>将传入的行的值改成(2,1,1);</p></li><li><p>将表的自增值改成3；</p></li><li><p>继续执行插入数据操作，由于已经存在c=1的记录，所以报Duplicate key error，语句返回。</p></li></ol><p>对应的执行流程图如下：</p><p><img src="/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/585d91a6-baee-4b35-999d-8a8add53b6f4.jpg" alt></p><p>可以看到，这个表的自增值改成3，是在真正执行插入数据的操作之前。这个语句真正执行的时候，因为碰到唯一键c冲突，所以id=2这一行并没有插入成功，但也没有将自增值再改回去。</p><p>所以，在这之后，再插入新的数据行时，拿到的自增id就是3。也就是说，出现了自增主键不连续的情况。</p><p>如图3所示就是完整的演示结果。</p><p><img src="/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/13954a15-61cf-42c9-b5cf-a535ad2f5099.jpg" alt></p><p>可以看到，这个操作序列复现了一个自增主键id不连续的现场(没有id=2的行）。可见，<strong>唯一键冲突是导致自增主键id不连续的第一种原因。</strong></p><p>同样地，事务<strong>回滚也会产生类似的现象，这就是第二种原因。</strong></p><p>下面这个语句序列就可以构造不连续的自增id，你可以自己验证一下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(null,1,1); </span><br><span class="line">begin; </span><br><span class="line">insert into t values(null,2,2); </span><br><span class="line">rollback; </span><br><span class="line">insert into t values(null,2,2); </span><br><span class="line">&#x2F;&#x2F;插入的行是(3,2,2)</span><br></pre></td></tr></table></figure><p>你可能会问，为什么在出现唯一键冲突或者回滚的时候，MySQL没有把表t的自增值改回去呢？如果把表t的当前自增值从3改回2，再插入新数据的时候，不就可以生成id=2的一行数据了吗？</p><p>其实，MySQL这么设计是为了提升性能。接下来，我就跟你分析一下这个设计思路，看看<strong>自增值为什么不能回退。</strong></p><p>假设有两个并行执行的事务，在申请自增值的时候，为了避免两个事务申请到相同的自增id，肯定要加锁，然后顺序申请。</p><ol><li><p>假设事务A申请到了id=2， 事务B申请到id=3，那么这时候表t的自增值是4，之后继续执行。</p></li><li><p>事务B正确提交了，但事务A出现了唯一键冲突。</p></li><li><p>如果允许事务A把自增id回退，也就是把表t的当前自增值改回2，那么就会出现这样的情况：表里面已经有id=3的行，而当前的自增id值是2。</p></li><li><p>接下来，继续执行的其他事务就会申请到id=2，然后再申请到id=3。这时，就会出现插入语句报错“主键冲突”。</p></li></ol><p>而为了解决这个主键冲突，有两种方法：</p><ol><li><p>每次申请id之前，先判断表里面是否已经存在这个id。如果存在，就跳过这个id。但是，这个方法的成本很高。因为，本来申请id是一个很快的操作，现在还要再去主键索引树上判断id是否存在。</p></li><li><p>把自增id的锁范围扩大，必须等到一个事务执行完成并提交，下一个事务才能再申请自增id。这个方法的问题，就是锁的粒度太大，系统并发能力大大下降。</p></li></ol><p>可见，这两个方法都会导致性能问题。造成这些麻烦的罪魁祸首，就是我们假设的这个“允许自增id回退”的前提导致的。</p><p>因此，InnoDB放弃了这个设计，语句执行失败也不回退自增id。也正是因为这样，所以才只保证了自增id是递增的，但不保证是连续的。</p><h2 id="4-自增锁的优化"><a href="#4-自增锁的优化" class="headerlink" title="4. 自增锁的优化"></a>4. 自增锁的优化</h2><p>可以看到，自增id锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请。其实，在MySQL 5.1版本之前，并不是这样的。</p><p>接下来，我会先给你介绍下自增锁设计的历史，这样有助于你分析接下来的一个问题。</p><p>在MySQL 5.0版本的时候，自增锁的范围是语句级别。也就是说，如果一个语句申请了一个表自增锁，这个锁会等语句执行结束以后才释放。显然，这样设计会影响并发度。</p><p>MySQL 5.1.22版本引入了一个新策略，新增参数innodb_autoinc_lock_mode，默认值是1。</p><ol><li><p>这个参数的值被设置为0时，表示采用之前MySQL 5.0版本的策略，即语句执行结束后才释放锁；</p></li><li><p>这个参数的值被设置为1时：</p><ul><li>普通insert语句，自增锁在申请之后就马上释放；</li><li>类似insert … select这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；</li></ul></li><li><p>这个参数的值被设置为2时，所有的申请自增主键的动作都是申请后就释放锁。</p></li></ol><p>你一定有两个疑问：<strong>为什么默认设置下，insert … select 要使用语句级的锁？为什么这个参数的默认值不是2？</strong></p><p>答案是，这么设计还是为了数据的一致性。</p><p>我们一起来看一下这个场景：</p><p><img src="/2020/03/03/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/41f9fd86-2d31-4731-9c11-1c3355780fc9.png" alt></p><p>在这个例子里，我往表t1中插入了4行数据，然后创建了一个相同结构的表t2，然后两个session同时执行向表t2中插入数据的操作。</p><p>你可以设想一下，如果session B是申请了自增值以后马上就释放自增锁，那么就可能出现这样的情况：</p><ul><li>session B先插入了两个记录，(1,1,1)、(2,2,2)；</li><li>然后，session A来申请自增id得到id=3，插入了（3,5,5)；</li><li>之后，session B继续执行，插入两条记录(4,3,3)、 (5,4,4)。</li></ul><p>你可能会说，这也没关系吧，毕竟session B的语义本身就没有要求表t2的所有行的数据都跟session A相同。</p><p>是的，从数据逻辑上看是对的。但是，如果我们现在的binlog_format=statement，你可以设想下，binlog会怎么记录呢？</p><p>由于两个session是同时执行插入数据命令的，所以binlog里面对表t2的更新日志只有两种情况：要么先记session A的，要么先记session B的。</p><p>但不论是哪一种，这个binlog拿去从库执行，或者用来恢复临时实例，备库和临时实例里面，session B这个语句执行出来，生成的结果里面，id都是连续的。这时，这个库就发生了数据不一致。</p><p>你可以分析一下，出现这个问题的原因是什么？</p><p>其实，这是因为原库session B的insert语句，生成的id不连续。这个不连续的id，用statement格式的binlog来串行执行，是执行不出来的。</p><p>而要解决这个问题，有两种思路：</p><ol><li><p>一种思路是，让原库的批量插入数据语句，固定生成连续的id值。所以，自增锁直到语句执行结束才释放，就是为了达到这个目的。</p></li><li><p>另一种思路是，在binlog里面把插入数据的操作都如实记录进来，到备库执行的时候，不再依赖于自增主键去生成。这种情况，其实就是innodb_autoinc_lock_mode设置为2，同时binlog_format设置为row。</p></li></ol><p>因此，<strong>在生产上，尤其是有insert … select这种批量插入数据的场景时，从并发插入数据性能的角度考虑，我建议你这样设置：innodb_autoinc_lock_mode=2 ，并且 binlog_format=row</strong>.这样做，既能提升并发性，又不会出现数据一致性问题。</p><p>需要注意的是，我这里说的<strong>批量插入数据，包含的语句类型是insert … select、replace … select和load data语句。</strong></p><p>但是，在普通的insert语句里面包含多个value值的情况下，即使innodb_autoinc_lock_mode设置为1，也不会等语句执行完成才释放锁。因为这类语句在申请自增id的时候，是可以精确计算出需要多少个id的，然后一次性申请，申请完成后锁就可以释放了。</p><p>也就是说，批量插入数据的语句，之所以需要这么设置，是因为“不知道要预先申请多少个id”。</p><p>既然预先不知道要申请多少个自增id，那么一种直接的想法就是需要一个时申请一个。但如果一个select … insert语句要插入10万行数据，按照这个逻辑的话就要申请10万次。显然，这种申请自增id的策略，在大批量插入数据的情况下，不但速度慢，还会影响并发插入的性能。</p><p>因此，对于批量插入数据的语句，MySQL有一个批量申请自增id的策略：</p><ol><li><p>语句执行过程中，第一次申请自增id，会分配1个；</p></li><li><p>1个用完以后，这个语句第二次申请自增id，会分配2个；</p></li><li><p>2个用完以后，还是这个语句，第三次申请自增id，会分配4个；</p></li><li><p>依此类推，同一个语句去申请自增id，每次申请到的自增id个数都是上一次的两倍。</p></li></ol><p>举个例子，我们一起看看下面的这个语句序列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(null, 1,1);</span><br><span class="line">insert into t values(null, 2,2); </span><br><span class="line">insert into t values(null, 3,3); </span><br><span class="line">insert into t values(null, 4,4); </span><br><span class="line">create table t2 like t; </span><br><span class="line">insert into t2(c,d) select c,d from t; </span><br><span class="line">insert into t2 values(null, 5,5);</span><br></pre></td></tr></table></figure><p>insert…select，实际上往表t2中插入了4行数据。但是，这四行数据是分三次申请的自增id，第一次申请到了id=1，第二次被分配了id=2和id=3， 第三次被分配到id=4到id=7。</p><p>由于这条语句实际只用上了4个id，所以id=5到id=7就被浪费掉了。之后，再执行insert into t2 values(null, 5,5)，实际上插入的数据就是（8,5,5)。</p><p><strong>这是主键id出现自增id不连续的第三种原因。</strong></p><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>今天，我们从“自增主键为什么会出现不连续的值”这个问题开始，首先讨论了自增值的存储。</p><p>在MyISAM引擎里面，自增值是被写在数据文件上的。而在InnoDB中，自增值是被记录在内存的。MySQL直到8.0版本，才给InnoDB表的自增值加上了持久化的能力，确保重启前后一个表的自增值不变。</p><p>然后，分享了在一个语句执行过程中，自增值改变的时机，分析了为什么MySQL在事务回滚的时候不能回收自增id。</p><p>MySQL 5.1.22版本开始引入的参数innodb_autoinc_lock_mode，控制了自增值申请时的锁范围。从并发性能的角度考虑，建议将其设置为2，同时将binlog_format设置为row。在前面的文章中其实多次提到，binlog_format设置为row，是很有必要的。今天的例子给这个结论多了一个理由。</p><h2 id="6-思考"><a href="#6-思考" class="headerlink" title="6. 思考"></a>6. 思考</h2><p>在最后一个例子中，执行  <code>insert into t2(c,d) select c,d from t;</code> 这个语句的时候，如果隔离级别是可重复读（repeatable read），binlog_format=statement。这个语句会对表t的所有记录和间隙加锁。</p><p>你觉得为什么需要这么做呢？</p><p><strong>回答：见第40篇文章</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在 &lt;strong&gt;第4篇文章&lt;/strong&gt; 中，我们提到过自增主键，由于自增主键可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑。&lt;/p&gt;
&lt;p&gt;之前见过有的业务设计依赖于自增主键的连续性，也就是说，这个设计假设自增主键是连续的。但实际上，这样的假设是错的，因为自增主键不能保证连续递增。&lt;/p&gt;
&lt;p&gt;今天这篇文章，我们就来说说这个问题，看看什么情况下自增主键会出现 “空洞”？&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>38-都说InnoDB好_那还要不要使用Memory引擎</title>
    <link href="http://javassun.github.io/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/"/>
    <id>http://javassun.github.io/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/</id>
    <published>2020-03-02T10:30:38.000Z</published>
    <updated>2020-05-20T20:03:08.638Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在上一篇文章末尾留给你的问题是：两个group by 语句都用了order by null，为什么使用内存临时表得到的语句结果里，0这个值在最后一行；而使用磁盘临时表得到的结果里，0这个值在第一行？</p><p>今天我们就来看看，出现这个问题的原因吧。</p><a id="more"></a><h2 id="1-内存表的数据组织结构"><a href="#1-内存表的数据组织结构" class="headerlink" title="1. 内存表的数据组织结构"></a>1. 内存表的数据组织结构</h2><p>为了便于分析，我来把这个问题简化一下，假设有以下的两张表t1 和 t2，其中表t1使用Memory 引擎， 表t2使用InnoDB引擎。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table t1(id int primary key, c int) engine&#x3D;Memory; </span><br><span class="line">create table t2(id int primary key, c int) engine&#x3D;innodb; </span><br><span class="line">insert into t1 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0); </span><br><span class="line">insert into t2 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);</span><br></pre></td></tr></table></figure><p>然后，分别执行 <code>select * from t1</code>和<code>select * from t2</code>。</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/8a7b006c-41cb-474f-91c0-380a7bf01061.jpg" alt></p><p>可以看到，内存表t1的返回结果里面0在最后一行，而InnoDB表t2的返回结果里0在第一行。</p><p>出现这个区别的原因，要从这两个引擎的主键索引的组织方式说起。</p><p>表t2用的是InnoDB引擎，它的主键索引id的组织方式，你已经很熟悉了：InnoDB表的数据就放在主键索引树上，主键索引是B+树。所以表t2的数据组织方式如下图所示：</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/5f62bf38-caf1-4b43-9ea5-98c47f00de26.jpg" alt></p><p>主键索引上的值是有序存储的。在执行select *的时候，就会按照叶子节点从左到右扫描，所以得到的结果里，0就出现在第一行。</p><p>与InnoDB引擎不同，Memory引擎的数据和索引是分开的。我们来看一下表t1中的数据内容。</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/5b8ea2fe-feb6-4a69-91ae-98ad9f3b6af9.jpg" alt></p><p>可以看到，内存表的数据部分以数组的方式单独存放，而主键id索引里，存的是每个数据的位置。主键id是hash索引，可以看到索引上的key并不是有序的。</p><p>在内存表t1中，当我执行select *的时候，走的是全表扫描，也就是顺序扫描这个数组。因此，0就是最后一个被读到，并放入结果集的数据。</p><p>可见，InnoDB和Memory引擎的数据组织方式是不同的：</p><ul><li>InnoDB引擎把数据放在主键索引上，其他索引上保存的是主键id。这种方式，我们称之为<strong>索引组织表</strong>（Index Organizied Table）。</li><li>而Memory引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为<strong>堆组织表</strong>（Heap Organizied Table）。</li></ul><p>从中我们可以看出，这两个引擎的一些典型不同：</p><ol><li><p>InnoDB表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；</p></li><li><p>当数据文件有空洞的时候，InnoDB表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；</p></li><li><p>数据位置发生变化的时候，InnoDB表只需要修改主键索引，而内存表需要修改所有索引；</p></li><li><p>InnoDB表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。</p></li><li><p>InnoDB支持变长数据类型，不同记录的长度可能不同；内存表不支持Blob 和 Text字段，并且即使定义了varchar(N)，实际也当作char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。</p></li></ol><p>由于内存表的这些特性，每个数据行被删除以后，空出的这个位置都可以被接下来要插入的数据复用。比如，如果要在表t1中执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">delete from t1 where id&#x3D;5; </span><br><span class="line">insert into t1 values(10,10); </span><br><span class="line">select * from t1;</span><br></pre></td></tr></table></figure><p>就会看到返回结果里，id=10这一行出现在id=4之后，也就是原来id=5这行数据的位置。</p><p>需要指出的是，表t1的这个主键索引是哈希索引，因此如果执行范围查询，比如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from t1 where id&lt;5;</span><br></pre></td></tr></table></figure><p>是用不上主键索引的，需要走全表扫描。你可以借此再回顾下 *<em>第4篇文章 *</em>的内容。那如果要让内存表支持范围扫描，应该怎么办呢 ？</p><h2 id="2-hash索引和B-Tree索引"><a href="#2-hash索引和B-Tree索引" class="headerlink" title="2. hash索引和B-Tree索引"></a>2. hash索引和B-Tree索引</h2><p>实际上，内存表也是支B-Tree索引的。在id列上创建一个B-Tree索引，SQL语句可以这么写：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t1 add index a_btree_index using btree (id);</span><br></pre></td></tr></table></figure><p>这时，表t1的数据组织形式就变成了这样：</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/d67a12f1-9745-4e66-a93b-ca579205ec89.jpg" alt></p><p>新增的这个B-Tree索引你看着就眼熟了，这跟InnoDB的b+树索引组织形式类似。</p><p>作为对比，你可以看一下这下面这两个语句的输出：</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/b1c2d64c-ef06-4d09-a7cc-f31e9de8d6f4.png" alt></p><p>可以看到，执行select * from t1 where id&lt;5的时候，优化器会选择B-Tree索引，所以返回结果是0到4。 使用force index强行使用主键id这个索引，id=0这一行就在结果集的最末尾了。</p><p>其实，一般在我们的印象中，内存表的优势是速度快，其中的一个原因就是Memory引擎支持hash索引。当然，更重要的原因是，内存表的所有数据都保存在内存，而内存的读写速度总是比磁盘快。</p><p>但是，接下来要跟你说明，为什么我不建议你在生产环境上使用内存表。这里的原因主要包括两个方面：</p><ol><li><p>锁粒度问题；</p></li><li><p>数据持久化问题。</p></li></ol><h2 id="3-内存表的锁"><a href="#3-内存表的锁" class="headerlink" title="3. 内存表的锁"></a>3. 内存表的锁</h2><p>我们先来说说内存表的锁粒度问题。</p><p>内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作。</p><p>需要注意的是，这里的表锁跟之前我们介绍过的MDL锁不同，但都是表级的锁。接下来，我通过下面这个场景，跟你模拟一下内存表的表级锁。</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/6c4b9af9-26ee-4776-b5a9-f2f231f10b45.png" alt></p><p>在这个执行序列里，session A的update语句要执行50秒，在这个语句执行期间session B的查询会进入锁等待状态。session C的show processlist 结果输出如下：</p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/847e10df-561a-4793-91d7-83f675acb085.png" alt></p><p>跟行锁比起来，表锁对并发访问的支持不够好。所以，内存表的锁粒度问题，决定了它在处理并发事务的时候，性能也不会太好。</p><h2 id="4-数据持久性问题"><a href="#4-数据持久性问题" class="headerlink" title="4. 数据持久性问题"></a>4. 数据持久性问题</h2><p>接下来，我们再看看数据持久性的问题。</p><p>数据放在内存中，是内存表的优势，但也是一个劣势。因为，数据库重启的时候，所有的内存表都会被清空。</p><p>你可能会说，如果数据库异常重启，内存表被清空也就清空了，不会有什么问题啊。但是，在高可用架构下，内存表的这个特点简直可以当做bug来看待了。为什么这么说呢？</p><p><strong>我们先看看M-S架构下，使用内存表存在的问题。</strong></p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/db5b7b2f-1f3f-46a7-a413-d08e5f4b4e45.jpg" alt></p><p>我们来看一下下面这个时序：</p><ol><li><p>业务正常访问主库；</p></li><li><p>备库硬件升级，备库重启，内存表t1内容被清空；</p></li><li><p>备库重启后，客户端发送一条update语句，修改表t1的数据行，这时备库应用线程就会报错“找不到要更新的行”。</p></li></ol><p>这样就会导致主备同步停止。当然，如果这时候发生主备切换的话，客户端会看到，表t1的数据“丢失”了。</p><p>在图8中这种有proxy的架构里，大家默认主备切换的逻辑是由数据库系统自己维护的。这样对客户端来说，就是“网络断开，重连之后，发现内存表数据丢失了”。</p><p>你可能说这还好啊，毕竟主备发生切换，连接会断开，业务端能够感知到异常。</p><p>但是，接下来内存表的这个特性就会让使用现象显得更“诡异”了。由于MySQL知道重启之后，内存表的数据会丢失。所以，担心主库重启之后，出现主备不一致，MySQL在实现上做了这样一件事儿：在数据库重启之后，往binlog里面写入一行DELETE FROM t1。</p><p><strong>如果你使用是如图9所示的双M结构的话：</strong></p><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/bf5e6a65-c33e-4ed4-841d-9cc1a4f2ba4c.jpg" alt></p><p>在备库重启的时候，备库binlog里的delete语句就会传到主库，然后把主库内存表的内容删除。这样你在使用的时候就会发现，主库的内存表数据突然被清空了。</p><p>基于上面的分析，你可以看到，内存表并不适合在生产环境上作为普通数据表使用。</p><p>有同学会说，但是内存表执行速度快呀。这个问题，其实你可以这么分析：</p><ol><li><p>如果你的表更新量大，那么并发度是一个很重要的参考指标，InnoDB支持行锁，并发度比内存表好；</p></li><li><p>能放到内存表的数据量都不大。如果你考虑的是读的性能，一个读QPS很高并且数据量不大的表，即使是使用InnoDB，数据也是都会缓存在InnoDB Buffer Pool里的。因此，使用InnoDB表的读性能也不会差。</p></li></ol><p>所以，<strong>建议你把普通内存表都用InnoDB表来代替。</strong>但是，有一个场景却是例外的。</p><p>这个场景就是，我们在第35和36篇说到的用户临时表。在数据量可控，不会耗费过多内存的情况下，你可以考虑使用内存表。</p><p>内存临时表刚好可以无视内存表的两个不足，主要是下面的三个原因：</p><ol><li><p>临时表不会被其他线程访问，没有并发性的问题；</p></li><li><p>临时表重启后也是需要删除的，清空数据这个问题不存在；</p></li><li><p>备库的临时表也不会影响主库的用户线程。</p></li></ol><p>现在，我们回过头再看一下第35篇join语句优化的例子，当时我建议的是创建一个InnoDB临时表，使用的语句序列是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create temporary table temp_t(id int primary key, a int, b int, index(b))engine&#x3D;innodb; </span><br><span class="line">insert into temp_t select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000; </span><br><span class="line">select * from t1 join temp_t on (t1.b&#x3D;temp_t.b);</span><br></pre></td></tr></table></figure><p>了解了内存表的特性，你就知道了， 其实这里使用内存临时表的效果更好，原因有三个：</p><ol><li><p>相比于InnoDB表，使用内存表不需要写磁盘，往表temp_t的写数据的速度更快；</p></li><li><p>索引b使用hash索引，查找的速度比B-Tree索引快；</p></li><li><p>临时表数据只有2000行，占用的内存有限。</p></li></ol><p>因此，你可以对 <strong>第35篇文章</strong> 的语句序列做一个改写，将临时表t1改成内存临时表，并且在字段b上创建一个hash索引。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create temporary table temp_t(id int primary key, a int, b int, index (b))engine&#x3D;memory; </span><br><span class="line">insert into temp_t select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000; </span><br><span class="line">select * from t1 join temp_t on (t1.b&#x3D;temp_t.b);</span><br></pre></td></tr></table></figure><p><img src="/2020/03/02/38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD-%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E/2897310d-b2b2-4fe3-a67d-901ccab9c3c5.jpg" alt></p><p>可以看到，不论是导入数据的时间，还是执行join的时间，使用内存临时表的速度都比使用InnoDB临时表要更快一些。</p><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>今天这篇文章，从“要不要使用内存表”这个问题展开，介绍了Memory引擎的几个特性。</p><p>可以看到，由于重启会丢数据，如果一个备库重启，会导致主备同步线程停止；如果主库跟这个备库是双M架构，还可能导致主库的内存表数据被删掉。</p><p>因此，在生产上，我不建议你使用普通内存表。</p><p>如果你是DBA，可以在建表的审核系统中增加这类规则，要求业务改用InnoDB表。我们在文中也分析了，其实InnoDB表性能还不错，而且数据安全也有保障。而内存表由于不支持行锁，更新语句会阻塞查询，性能也未必就如想象中那么好。</p><p>基于内存表的特性，我们还分析了它的一个适用场景，就是内存临时表。内存表支持hash索引，这个特性利用起来，对复杂查询的加速效果还是很不错的。</p><h2 id="6-思考"><a href="#6-思考" class="headerlink" title="6. 思考"></a>6. 思考</h2><p>假设你刚刚接手的一个数据库上，真的发现了一个内存表。备库重启之后肯定是会导致备库的内存表数据被清空，进而导致主备同步停止。这时，最好的做法是将它修改成InnoDB引擎表。</p><p>假设当时的业务场景暂时不允许你修改引擎，你可以加上什么自动化逻辑，来避免主备同步停止呢？</p><p>即 如果你维护的MySQL系统里有内存表，怎么避免内存表突然丢数据，然后导致主备同步停止的情况。</p><p><strong>回答：</strong><br>我们假设的是主库暂时不能修改引擎，那么就把备库的内存表引擎先都改成InnoDB。对于每个内存表，执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set sql_log_bin&#x3D;off;</span><br><span class="line">alter table tbl_name engine&#x3D;innodb;</span><br></pre></td></tr></table></figure><p>这样就能避免备库重启的时候，数据丢失的问题。</p><p>由于主库重启后，会往binlog里面写“delete from tbl_name”，这个命令传到备库，备库的同名的表数据也会被清空。</p><p>因此，就不会出现主备同步停止的问题。</p><p>如果由于主库异常重启，触发了HA，这时候我们之前修改过引擎的备库变成了主库。而原来的主库变成了新备库，在新备库上把所有的内存表（这时候表里没数据）都改成InnoDB表。</p><p>所以，如果我们不能直接修改主库上的表引擎，可以配置一个自动巡检的工具，在备库上发现内存表就把引擎改了。</p><p>同时，跟业务开发同学约定好建表规则，避免创建新的内存表。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在上一篇文章末尾留给你的问题是：两个group by 语句都用了order by null，为什么使用内存临时表得到的语句结果里，0这个值在最后一行；而使用磁盘临时表得到的结果里，0这个值在第一行？&lt;/p&gt;
&lt;p&gt;今天我们就来看看，出现这个问题的原因吧。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>37-什么时候会使用内部临时表</title>
    <link href="http://javassun.github.io/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/"/>
    <id>http://javassun.github.io/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/</id>
    <published>2020-03-01T07:40:38.000Z</published>
    <updated>2020-05-20T19:58:14.021Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 <strong>第16**</strong> 和 <strong>第34</strong> 篇文章中，分别介绍了sort buffer、内存临时表和join buffer。这三个数据结构都是用来存放语句执行过程中的中间数据，以辅助SQL语句的执行的。其中，我们在排序的时候用到了sort buffer，在使用join语句的时候用到了join buffer。</p><p>然后，你可能会有这样的疑问，MySQL什么时候会使用内部临时表呢？</p><p>今天这篇文章，先给你举两个需要用到内部临时表的例子，来看看内部临时表是怎么工作的。然后，我们再来分析，什么情况下会使用内部临时表。</p><a id="more"></a><h2 id="1-union-执行流程"><a href="#1-union-执行流程" class="headerlink" title="1. union 执行流程"></a>1. union 执行流程</h2><p>为了便于量化分析，我用下面的表t1来举例。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/cb5eac58-76b4-4b8a-b490-126289198b65.png" alt></p><p>然后，我们执行下面这条语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(select 1000 as f) union (select id from t1 order by id desc limit 2);</span><br></pre></td></tr></table></figure><p>这条语句用到了union，它的语义是，取这两个子查询结果的并集。并集的意思就是这两个集合加起来，重复的行只保留一行。</p><p>下图是这个语句的explain结果。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/fec2ea93-ef01-455e-b6c0-a7cd18551677.jpg" alt></p><p>可以看到：</p><ul><li>第二行的key=PRIMARY，说明第二个子句用到了索引id。</li><li>第三行的Extra字段，表示在对子查询的结果集做union的时候，使用了临时表(Using temporary)。</li></ul><p>这个语句的执行流程是这样的：</p><ol><li><p>创建一个内存临时表，这个临时表只有一个整型字段f，并且f是主键字段。</p></li><li><p>执行第一个子查询，得到1000这个值，并存入临时表中。</p></li><li><p>执行第二个子查询：</p><ul><li>拿到第一行id=1000，试图插入临时表中。但由于1000这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行；</li><li>取到第二行id=999，插入临时表成功。</li></ul></li><li><p>从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是1000和999。</p></li></ol><p>这个过程的流程图如下所示：</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/c2fb9818-3a4c-4eb6-abfd-f58da74c1ae2.jpg" alt></p><p>可以看到，这里的内存临时表起到了暂存数据的作用，而且计算过程还用上了临时表主键id的唯一性约束，实现了union的语义。</p><p>顺便提一下，如果把上面这个语句中的union改成union all的话，就没有了“去重”的语义。这样执行的时候，就依次执行子查询，得到的结果直接作为结果集的一部分，发给客户端。因此也就不需要临时表了。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/04f6723d-ff50-4447-bf20-ced938b562ab.png" alt></p><p>可以看到，第二行的Extra字段显示的是Using index，表示只使用了覆盖索引，没有用临时表了。</p><h2 id="2-group-by-执行流程"><a href="#2-group-by-执行流程" class="headerlink" title="2. group by 执行流程"></a>2. group by 执行流程</h2><p>另外一个常见的使用临时表的例子是group by，我们来看一下这个语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id%10 as m, count(*) as c from t1 group by m;</span><br></pre></td></tr></table></figure><p>这个语句的逻辑是把表t1里的数据，按照 id%10 进行分组统计，并按照m的结果排序后输出。它的explain结果如下：</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/ae4c74ca-9826-4f2e-a396-0d79c32cc706.png" alt></p><p>在Extra字段里面，我们可以看到三个信息：</p><ul><li>Using index，表示这个语句使用了覆盖索引，选择了索引a，不需要回表；</li><li>Using temporary，表示使用了临时表；</li><li>Using filesort，表示需要排序。</li></ul><p>这个语句的执行流程是这样的：</p><ol><li><p>创建内存临时表，表里有两个字段m和c，主键是m；</p></li><li><p>扫描表t1的索引a，依次取出叶子节点上的id值，计算id%10的结果，记为x；</p><ul><li>如果临时表中没有主键为x的行，就插入一个记录(x,1);</li><li>如果表中有主键为x的行，就将x这一行的c值加1；</li></ul></li><li><p>遍历完成后，再根据字段m做排序，得到结果集返回给客户端。</p></li></ol><p>这个流程的执行图如下：</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/388f7d5b-3593-4b43-bc9b-56c2919f309b.jpg" alt></p><p>图中最后一步，对内存临时表的排序，在 <strong>第17篇文章</strong> 中已经有过介绍，我把图贴过来，方便你回顾。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/dd8daed5-cf18-4096-8c33-3488ed6e0b95.jpg" alt></p><p>其中，临时表的排序过程就是图6中虚线框内的过程。</p><p>接下来，我们再看一下这条语句的执行结果：</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/cc7dd5c3-c25a-4f07-ae1a-dcf2252ef2f5.png" alt></p><p>如果你的需求并不需要对结果进行排序，那你可以在SQL语句末尾增加order by null，也就是改成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id%10 as m, count(*) as c from t1 group by m order by null;</span><br></pre></td></tr></table></figure><p>这样就跳过了最后排序的阶段，直接从临时表中取数据返回。返回的结果如图8所示。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/3084be14-5fb0-47c0-a8d3-c754ae1e340d.png" alt></p><p>由于表t1中的id值是从1开始的，因此返回的结果集中第一行是id=1；扫描到id=10的时候才插入m=0这一行，因此结果集里最后一行才是m=0。</p><p>这个例子里由于临时表只有10行，内存可以放得下，因此全程只使用了内存临时表。但是，内存临时表的大小是有限制的，参数tmp_table_size就是控制这个内存大小的，默认是16M。</p><p>如果我执行下面这个语句序列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set tmp_table_size&#x3D;1024; </span><br><span class="line">select id%100 as m, count(*) as c from t1 group by m order by null limit 10;</span><br></pre></td></tr></table></figure><p>把内存临时表的大小限制为最大1024字节，并把语句改成id % 100，这样返回结果里有100行数据。但是，这时的内存临时表大小不够存下这100行数据，也就是说，执行过程中会发现内存临时表大小到达了上限（1024字节）。</p><p>那么，这时候就会把内存临时表转成磁盘临时表，磁盘临时表默认使用的引擎是InnoDB。 这时，返回的结果如图9所示。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/127a16ea-dded-4f41-bed8-26731140f612.png" alt></p><p>如果这个表t1的数据量很大，很可能这个查询需要的磁盘临时表就会占用大量的磁盘空间。</p><h2 id="3-group-by-优化方法-–索引"><a href="#3-group-by-优化方法-–索引" class="headerlink" title="3. group by 优化方法 –索引"></a>3. group by 优化方法 –索引</h2><p>可以看到，不论是使用内存临时表还是磁盘临时表，group by逻辑都需要构造一个带唯一索引的表，执行代价都是比较高的。如果表的数据量比较大，上面这个group by语句执行起来就会很慢，我们有什么优化的方法呢？</p><p>要解决group by语句的优化问题，你可以先想一下这个问题：执行group by语句为什么需要临时表？</p><p>group by的语义逻辑，是统计不同的值出现的个数。但是，由于每一行的id%100的结果是无序的，所以我们就需要有一个临时表，来记录并统计结果。</p><p>那么，如果扫描过程中可以保证出现的数据是有序的，是不是就简单了呢？</p><p>假设，现在有一个类似图10的这么一个数据结构，我们来看看group by可以怎么做。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/8b971fe1-2c3b-400c-b8a8-009db9660dc1.jpg" alt></p><p>可以看到，如果可以确保输入的数据是有序的，那么计算group by的时候，就只需要从左到右，顺序扫描，依次累加。也就是下面这个过程：</p><ul><li>当碰到第一个1的时候，已经知道累积了X个0，结果集里的第一行就是(0,X);</li><li>当碰到第一个2的时候，已经知道累积了Y个1，结果集里的第一行就是(1,Y);</li></ul><p>按照这个逻辑执行的话，扫描到整个输入的数据结束，就可以拿到group by的结果，不需要临时表，也不需要再额外排序。</p><p>你一定想到了，InnoDB的索引，就可以满足这个输入有序的条件。</p><p>在MySQL 5.7版本支持了generated column机制，用来实现列数据的关联更新。你可以用下面的方法创建一个列z，然后在z列上创建一个索引（如果是MySQL 5.6及之前的版本，你也可以创建普通列和索引，来解决这个问题）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t1 add column z int generated always as(id % 100), add index(z);</span><br></pre></td></tr></table></figure><p>这样，索引z上的数据就是类似图10这样有序的了。上面的group by语句就可以改成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select z, count(*) as c from t1 group by z;</span><br></pre></td></tr></table></figure><p>优化后的group by语句的explain结果，如下图所示：</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/23fd349e-4e82-48c7-8da8-2d48057d16fa.png" alt></p><p>从Extra字段可以看到，这个语句的执行不再需要临时表，也不需要排序了。</p><h2 id="4-group-by优化方法-–直接排序"><a href="#4-group-by优化方法-–直接排序" class="headerlink" title="4. group by优化方法 –直接排序"></a>4. group by优化方法 –直接排序</h2><p>所以，如果可以通过加索引来完成group by逻辑就再好不过了。但是，如果碰上不适合创建索引的场景，我们还是要老老实实做排序的。那么，这时候的group by要怎么优化呢？</p><p>如果我们明明知道，一个group by语句中需要放到临时表上的数据量特别大，却还是要按照“先放到内存临时表，插入一部分数据后，发现内存临时表不够用了再转成磁盘临时表”，看上去就有点儿傻。</p><p>那么，我们就会想了，MySQL有没有让我们直接走磁盘临时表的方法呢？</p><p>答案是，有的。</p><p>在group by语句中加入SQL_BIG_RESULT这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。</p><p>MySQL的优化器一看，磁盘临时表是B+树存储，存储效率不如数组来得高。所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。</p><p>因此，下面这个语句</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;</span><br></pre></td></tr></table></figure><p>的执行流程就是这样的：</p><ol><li><p>初始化sort_buffer，确定放入一个整型字段，记为m；</p></li><li><p>扫描表t1的索引a，依次取出里面的id值, 将 id%100的值存入sort_buffer中；</p></li><li><p>扫描完成后，对sort_buffer的字段m做排序（如果sort_buffer内存不够用，就会利用磁盘临时文件辅助排序）；</p></li><li><p>排序完成后，就得到了一个有序数组。</p></li></ol><p>根据有序数组，得到数组里面的不同值，以及每个值的出现次数。这一步的逻辑，你已经从前面的图10中了解过了。</p><p>下面两张图分别是执行流程图和执行explain命令得到的结果。</p><p><img src="/2020/03/01/37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/71233a5f-536a-4096-b315-b489c69206d1.jpg" alt></p><p>从Extra字段可以看到，这个语句的执行没有再使用临时表，而是直接用了排序算法。</p><p>基于上面的union、union all和group by语句的执行过程的分析，我们来回答文章开头的问题：MySQL什么时候会使用内部临时表？</p><ol><li><p>如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；</p></li><li><p>join_buffer是无序数组，sort_buffer是有序数组，临时表是二维表结构；</p></li><li><p>如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union需要用到唯一索引约束， group by还需要用到另外一个字段来存累积计数。</p></li></ol><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>通过今天这篇文章，重点讲了group by的几种实现算法，从中可以总结一些使用的指导原则：</p><ol><li><p>如果对group by语句的结果没有排序要求，要在语句后面加 order by null；</p></li><li><p>尽量让group by过程用上表的索引，确认方法是explain结果里没有Using temporary 和 Using filesort；</p></li><li><p>如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大tmp_table_size参数，来避免用到磁盘临时表；</p></li><li><p>如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法得到group by的结果。</p></li></ol><h2 id="6-思考"><a href="#6-思考" class="headerlink" title="6. 思考"></a>6. 思考</h2><p>文章中图8和图9都是order by null，为什么图8的返回结果里面，0是在结果集的最后一行，而图9的结果里面，0是在结果集的第一行？</p><p><strong>回答：见第38篇文章</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;red&quot;&gt;学习来源：极客时间-MySQL实战45讲，本人购买课程后依据图文讲解汇总成个人见解。&lt;/font&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在 &lt;strong&gt;第16**&lt;/strong&gt; 和 &lt;strong&gt;第34&lt;/strong&gt; 篇文章中，分别介绍了sort buffer、内存临时表和join buffer。这三个数据结构都是用来存放语句执行过程中的中间数据，以辅助SQL语句的执行的。其中，我们在排序的时候用到了sort buffer，在使用join语句的时候用到了join buffer。&lt;/p&gt;
&lt;p&gt;然后，你可能会有这样的疑问，MySQL什么时候会使用内部临时表呢？&lt;/p&gt;
&lt;p&gt;今天这篇文章，先给你举两个需要用到内部临时表的例子，来看看内部临时表是怎么工作的。然后，我们再来分析，什么情况下会使用内部临时表。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/categories/MySql/"/>
    
    
      <category term="MySql" scheme="http://JavaSsun.github.io/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot_RabbitMQ配置参数详解</title>
    <link href="http://javassun.github.io/2020/02/26/SpringBoot-RabbitMQ%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/"/>
    <id>http://javassun.github.io/2020/02/26/SpringBoot-RabbitMQ%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/</id>
    <published>2020-02-26T15:45:48.000Z</published>
    <updated>2020-06-03T07:26:31.129Z</updated>
    
    <content type="html"><![CDATA[<p>★RabbitMQ<br>★Version: 1.5.13.RELEASE</p><p>★属性文件：org.springframework.boot.autoconfigure.amqp.RabbitProperties</p><p>★Config:</p><h1 id="base"><a href="#base" class="headerlink" title="base"></a>base</h1><p>spring.rabbitmq.host: 服务Host<br>spring.rabbitmq.port: 服务端口<br>spring.rabbitmq.username: 登陆用户名<br>spring.rabbitmq.password: 登陆密码<br>spring.rabbitmq.virtual-host: 连接到rabbitMQ的vhost<br>spring.rabbitmq.addresses: 指定client连接到的server的地址，多个以逗号分隔(优先取addresses，然后再取host)<br>spring.rabbitmq.requested-heartbeat: 指定心跳超时，单位秒，0为不指定；默认60s<br>spring.rabbitmq.publisher-confirms: 是否启用【发布确认】<br>spring.rabbitmq.publisher-returns: 是否启用【发布返回】<br>spring.rabbitmq.connection-timeout: 连接超时，单位毫秒，0表示无穷大，不超时<br>spring.rabbitmq.parsed-addresses:</p><a id="more"></a><h1 id="ssl"><a href="#ssl" class="headerlink" title="ssl"></a>ssl</h1><p>spring.rabbitmq.ssl.enabled: 是否支持ssl<br>spring.rabbitmq.ssl.key-store: 指定持有SSL certificate的key store的路径<br>spring.rabbitmq.ssl.key-store-password: 指定访问key store的密码<br>spring.rabbitmq.ssl.trust-store: 指定持有SSL certificates的Trust store<br>spring.rabbitmq.ssl.trust-store-password: 指定访问trust store的密码<br>spring.rabbitmq.ssl.algorithm: ssl使用的算法，例如，TLSv1.1</p><h1 id="cache"><a href="#cache" class="headerlink" title="cache"></a>cache</h1><p>spring.rabbitmq.cache.channel.size: 缓存中保持的channel数量<br>spring.rabbitmq.cache.channel.checkout-timeout: 当缓存数量被设置时，从缓存中获取一个channel的超时时间，单位毫秒；如果为0，则总是创建一个新channel<br>spring.rabbitmq.cache.connection.size: 缓存的连接数，只有是CONNECTION模式时生效<br>spring.rabbitmq.cache.connection.mode: 连接工厂缓存模式：CHANNEL 和 CONNECTION</p><h1 id="listener"><a href="#listener" class="headerlink" title="listener"></a>listener</h1><p>spring.rabbitmq.listener.simple.auto-startup: 是否启动时自动启动容器<br>spring.rabbitmq.listener.simple.acknowledge-mode: 表示消息确认方式，其有三种配置方式，分别是none、manual和auto；默认auto<br>spring.rabbitmq.listener.simple.concurrency: 最小的消费者数量<br>spring.rabbitmq.listener.simple.max-concurrency: 最大的消费者数量<br>spring.rabbitmq.listener.simple.prefetch: 指定一个请求能处理多少个消息，如果有事务的话，必须大于等于transaction数量.<br>spring.rabbitmq.listener.simple.transaction-size: 指定一个事务处理的消息数量，最好是小于等于prefetch的数量.<br>spring.rabbitmq.listener.simple.default-requeue-rejected: 决定被拒绝的消息是否重新入队；默认是true（与参数acknowledge-mode有关系）<br>spring.rabbitmq.listener.simple.idle-event-interval: 多少长时间发布空闲容器时间，单位毫秒</p><p>spring.rabbitmq.listener.simple.retry.enabled: 监听重试是否可用<br>spring.rabbitmq.listener.simple.retry.max-attempts: 最大重试次数<br>spring.rabbitmq.listener.simple.retry.initial-interval: 第一次和第二次尝试发布或传递消息之间的间隔<br>spring.rabbitmq.listener.simple.retry.multiplier: 应用于上一重试间隔的乘数<br>spring.rabbitmq.listener.simple.retry.max-interval: 最大重试时间间隔<br>spring.rabbitmq.listener.simple.retry.stateless: 重试是有状态or无状态</p><h1 id="template"><a href="#template" class="headerlink" title="template"></a>template</h1><p>spring.rabbitmq.template.mandatory: 启用强制信息；默认false<br>spring.rabbitmq.template.receive-timeout: receive() 操作的超时时间<br>spring.rabbitmq.template.reply-timeout: sendAndReceive() 操作的超时时间<br>spring.rabbitmq.template.retry.enabled: 发送重试是否可用<br>spring.rabbitmq.template.retry.max-attempts: 最大重试次数<br>spring.rabbitmq.template.retry.initial-interval: 第一次和第二次尝试发布或传递消息之间的间隔<br>spring.rabbitmq.template.retry.multiplier: 应用于上一重试间隔的乘数<br>spring.rabbitmq.template.retry.max-interval: 最大重试时间间隔</p><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p>Spring Cloud中RabbitMQ配置属性表：  <a href="https://blog.csdn.net/en_joker/article/details/80103519" target="_blank" rel="noopener">https://blog.csdn.net/en_joker/article/details/80103519</a></p><p>SpringBoot的RabbitMQ消息队列: 第二模式”Work queues”  <a href="https://blog.csdn.net/lxhjh/article/details/69054342" target="_blank" rel="noopener">https://blog.csdn.net/lxhjh/article/details/69054342</a></p><p>SpringBoot官方文档：<a href="https://docs.spring.io/spring-amqp/docs/1.5.6.RELEASE/reference/html/_reference.html#template-confirms" target="_blank" rel="noopener">https://docs.spring.io/spring-amqp/docs/1.5.6.RELEASE/reference/html/_reference.html</a></p><p>SpringBoot系统- 死信队列： <a href="https://www.cnblogs.com/bigdataZJ/p/springboot-deadletter-queue.html" target="_blank" rel="noopener">https://www.cnblogs.com/bigdataZJ/p/springboot-deadletter-queue.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;★RabbitMQ&lt;br&gt;★Version: 1.5.13.RELEASE&lt;/p&gt;
&lt;p&gt;★属性文件：org.springframework.boot.autoconfigure.amqp.RabbitProperties&lt;/p&gt;
&lt;p&gt;★Config:&lt;/p&gt;
&lt;h1 id=&quot;base&quot;&gt;&lt;a href=&quot;#base&quot; class=&quot;headerlink&quot; title=&quot;base&quot;&gt;&lt;/a&gt;base&lt;/h1&gt;&lt;p&gt;spring.rabbitmq.host: 服务Host&lt;br&gt;spring.rabbitmq.port: 服务端口&lt;br&gt;spring.rabbitmq.username: 登陆用户名&lt;br&gt;spring.rabbitmq.password: 登陆密码&lt;br&gt;spring.rabbitmq.virtual-host: 连接到rabbitMQ的vhost&lt;br&gt;spring.rabbitmq.addresses: 指定client连接到的server的地址，多个以逗号分隔(优先取addresses，然后再取host)&lt;br&gt;spring.rabbitmq.requested-heartbeat: 指定心跳超时，单位秒，0为不指定；默认60s&lt;br&gt;spring.rabbitmq.publisher-confirms: 是否启用【发布确认】&lt;br&gt;spring.rabbitmq.publisher-returns: 是否启用【发布返回】&lt;br&gt;spring.rabbitmq.connection-timeout: 连接超时，单位毫秒，0表示无穷大，不超时&lt;br&gt;spring.rabbitmq.parsed-addresses:&lt;/p&gt;
    
    </summary>
    
    
      <category term="MQ" scheme="http://JavaSsun.github.io/categories/MQ/"/>
    
    
      <category term="MQ" scheme="http://JavaSsun.github.io/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ安装</title>
    <link href="http://javassun.github.io/2020/02/26/RabbitMQ%E5%AE%89%E8%A3%85/"/>
    <id>http://javassun.github.io/2020/02/26/RabbitMQ%E5%AE%89%E8%A3%85/</id>
    <published>2020-02-26T11:40:48.000Z</published>
    <updated>2020-06-03T07:26:54.485Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>个人在<strong>CentOS7</strong>下安装RabbitMQ以及遇到的问题。</p><p><strong>RabbitMQ</strong> 是流行的开源消息队列系统，是 AMQP（Advanced Message Queuing Protocol 高级消息队列协议）的标准实现，用 erlang 语言开发。RabbitMQ 具有良好的性能和时效性，同时还能够非常好的支持集群和负载部署，非常适合在较大规模的分布式系统中使用。并且支持多种开发语言。我们项目中使用RabbitMQ作为消息队列，解耦业务，构建高可靠的消息队列系统。RabbitMQ可以用在订单系统、日志系统、数据收集等常见场景中。</p><h2 id="1-安装RabbitMQ"><a href="#1-安装RabbitMQ" class="headerlink" title="1. 安装RabbitMQ"></a>1. 安装RabbitMQ</h2><p><strong>可能需要sudo权限</strong></p><p>安装 RabbitMQ 之前要安装 Erlang，需要先到<a href="https://www.rabbitmq.com/which-erlang.html" target="_blank" rel="noopener">RabbitMQ官网</a>看下版本对应关系。<font color="red"><strong>必须看</strong></font></p><p>当前最新版rabbitmq-server是rabbitmq-server-3.8.3-1.el7.noarch.rpm，最新版Erlang是erlang-23.0.1-1.el7.x86_64.rpm。我们可以分别在<a href="https://github.com/rabbitmq/erlang-rpm/releases" target="_blank" rel="noopener">Github</a>和<a href="https://www.rabbitmq.com/install-rpm.html#downloads" target="_blank" rel="noopener">RabbitMQ官网</a>下载对应的版本的rpm包。</p><a id="more"></a><p><strong>el7：即CentOS7。</strong></p><p>我们使用的版本：<br><a href="https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.8.3/rabbitmq-server-3.8.3-1.el7.noarch.rpm" target="_blank" rel="noopener">rabbitmq-server-3.8.3-1.el7.noarch.rpm</a></p><p><a href="https://github.com/rabbitmq/erlang-rpm/releases/download/v22.3.4/erlang-22.3.4-1.el7.x86_64.rpm" target="_blank" rel="noopener">erlang-22.3.4-1.el7.x86_64.rpm</a></p><p>下载好rpm包后，接下来我们使用rpm进行安装。</p><p>首先安装依赖socat，安装Erlang时需要这个。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y socat</span><br></pre></td></tr></table></figure><p>接下来安装 <strong>Erlang</strong> 和 <strong>RabbitMQ</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm  -ivh  erlang-22.3.4-1.el7.x86_64.rpm  </span><br><span class="line">rpm  -ivh  rabbitmq-server-3.8.3-1.el7.noarch.rpm</span><br></pre></td></tr></table></figure><p>执行上述两行命令后，即完成了Erlang和RabbitMQ的安装，就这么简单。</p><h2 id="2-RabbitMQ的基本操作"><a href="#2-RabbitMQ的基本操作" class="headerlink" title="2. RabbitMQ的基本操作"></a>2. RabbitMQ的基本操作</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># 启动RabbitMQ：</span><br><span class="line">systemctl start rabbitmq-server</span><br><span class="line"></span><br><span class="line"># 设置RabbitMQ开机自启动：</span><br><span class="line">systemctl enable rabbitmq-server</span><br><span class="line"></span><br><span class="line"># 查看服务状态</span><br><span class="line">systemctl status rabbitmq-server</span><br><span class="line"></span><br><span class="line"># 停止服务</span><br><span class="line">systemctl stop rabbitmq-server</span><br><span class="line"></span><br><span class="line"># 重启服务</span><br><span class="line">systemctl restart rabbitmq-server</span><br><span class="line"></span><br><span class="line"># 查看当前所有用户</span><br><span class="line">rabbitmqctl list_users</span><br><span class="line"></span><br><span class="line"># 查看默认guest用户权限</span><br><span class="line">rabbitmq list_user_permissions guest</span><br><span class="line"></span><br><span class="line"># 由于RabbitMQ默认的账号用户名和密码都是guest，为了安全起见，先删掉默认用户</span><br><span class="line">rabbitmqctl delete_user guest</span><br><span class="line"></span><br><span class="line"># 添加新用户</span><br><span class="line">rabbitmqctl add_user username password</span><br><span class="line"></span><br><span class="line"># 设置用户tag</span><br><span class="line">rabbitmqctl set_user_tags username administrator</span><br><span class="line"></span><br><span class="line"># 赋予用户默认vhost的全部操作权限</span><br><span class="line">rabbitmqctl set_permissions -p &#x2F; username &quot;.*&quot;  &quot;.*&quot;  &quot;.*&quot;</span><br><span class="line"></span><br><span class="line"># 查看用户权限</span><br><span class="line">rabbitmq list_user_permissions username</span><br></pre></td></tr></table></figure><p>更多使用方法，参考<a href="https://www.rabbitmq.com/rabbitmqctl.8.html" target="_blank" rel="noopener">帮助手册</a>。</p><h2 id="3-开启Web管理接口"><a href="#3-开启Web管理接口" class="headerlink" title="3. 开启Web管理接口"></a>3. 开启Web管理接口</h2><p>Web管理界面，只需要启动插件即可使用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rabbitmq-plugins enable rabbitmq_management</span><br></pre></td></tr></table></figure><p>需要开端口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --zone&#x3D;public --add-port&#x3D;15672&#x2F;tcp --permanent</span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure><p>访问：<a href="http://localhost:15672" target="_blank" rel="noopener">http://localhost:15672</a></p><p><img src="/2020/02/26/RabbitMQ%E5%AE%89%E8%A3%85/527bdbf0-fa64-4c46-a500-243872ffb3ac.png" alt></p><p>插件管理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#插件列表：</span><br><span class="line">rabbitmq-plugins list</span><br><span class="line">#启动插件：</span><br><span class="line">rabbitmq-plugins enable XXX （XXX为插件名）</span><br><span class="line">#停用插件：</span><br><span class="line">rabbitmq-plugins disable XXX</span><br></pre></td></tr></table></figure><p>我们可以在后台管理用户、队列等信息。</p><h2 id="4-配置RabbitMQ"><a href="#4-配置RabbitMQ" class="headerlink" title="4. 配置RabbitMQ"></a>4. 配置RabbitMQ</h2><p>关于RabbitMQ的配置，可以下载RabbitMQ的<a href="https://github.com/rabbitmq/rabbitmq-server/blob/master/docs/rabbitmq.config.example" target="_blank" rel="noopener">配置文件模板</a>到<code>/etc/rabbitmq/rabbitmq.config</code>, 然后按照需求更改即可。<br>关于每个配置项的具体作用，可以参考<a href="https://link.jianshu.com/?t=https://www.rabbitmq.com/configure.html" target="_blank" rel="noopener">官方文档</a>。</p><h2 id="5-开启用户远程访问"><a href="#5-开启用户远程访问" class="headerlink" title="5. 开启用户远程访问"></a>5. 开启用户远程访问</h2><p>默认情况下，RabbitMQ的默认的<code>guest</code>用户只允许本机访问， 如果想让<code>guest</code>用户能够远程访问的话，只需要将配置文件中的<code>loopback_users</code>列表置为空即可，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;loopback_users, []&#125;</span><br></pre></td></tr></table></figure><p>另外关于新添加的用户，直接就可以从远程访问的，如果想让新添加的用户只能本地访问，可以将用户名添加到上面的列表, 如只允许<code>admin</code>用户本机访问。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;loopback_users, [&quot;admin&quot;]&#125;</span><br></pre></td></tr></table></figure><p>restart即可</p><h2 id="6-修改RabbitMQ默认端口"><a href="#6-修改RabbitMQ默认端口" class="headerlink" title="6. 修改RabbitMQ默认端口"></a>6. 修改RabbitMQ默认端口</h2><p>RabbitMQ默认开启了几个端口：</p><p><code>4369</code>：erlang发现口</p><p><code>5672</code>：client端通信口，客户端要连接RabbitMQ服务时要用到</p><p><code>15672</code>：后台管理界面ui端口，进入管理后台时访问url如：<a href="http://ip:15672/" target="_blank" rel="noopener">http://ip:15672/</a></p><p><code>25672</code>：server间内部通信口</p><p>在生产环境下，我们出于安全等原因希望修改掉默认的端口号。</p><p><strong>安装新版的RabbitMQ-3.8.3后，发现找不到它的配置文件，按常理，服务的端口开发都可以在配置文件里配置的。但是事实上RabbitMQ-3.8.3并没有生成配置文件，需要我们手动添加配置文件。</strong></p><p>官方建议配置文件的位置：/etc/rabbitmq/rabbitmq.conf</p><p>我们现在要做的是把默认端口5672改成56720，并且允许远程访问。把web管理默认端口15672改成56271。只需如下配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#vim &#x2F;etc&#x2F;rabbitmq&#x2F;rabbitmq.conf</span><br><span class="line">#AMQP 0-9-1 and 1.0 port，默认5672,允许远程访问 </span><br><span class="line">listeners.tcp.default &#x3D; 0.0.0.0:56720 </span><br><span class="line">#web管理，默认15672 </span><br><span class="line">management.tcp.port &#x3D; 56721</span><br><span class="line">management.tcp.ip &#x3D; 0.0.0.0</span><br><span class="line"></span><br><span class="line"># 即 两个端口都要通过防火墙开放</span><br></pre></td></tr></table></figure><p>保存，并重启RabbitMQ服务。使用<code>netstat -lntp</code>查看端口监听情况：</p><p><img src="/2020/02/26/RabbitMQ%E5%AE%89%E8%A3%85/2438bada-3b1a-4288-8e19-0ae29aa2e5da.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@haoransun ~]# firewall-cmd --zone&#x3D;public --add-port&#x3D;56721&#x2F;tcp --permanent</span><br><span class="line">[root@haoransun ~]# firewall-cmd --reload</span><br><span class="line">[root@haoransun ~]# firewall-cmd --list-ports</span><br></pre></td></tr></table></figure><p><img src="/2020/02/26/RabbitMQ%E5%AE%89%E8%A3%85/9354ecc4-857f-480f-93b1-f79d9ef7b3ce.png" alt></p><p>可以到官网地址：<a href="https://www.rabbitmq.com/configure.html" target="_blank" rel="noopener">https://www.rabbitmq.com/configure.html</a>，了解RabbitMQ的性能优化方面的配置。</p><h2 id="7-设置权限"><a href="#7-设置权限" class="headerlink" title="7. 设置权限"></a>7. 设置权限</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rabbitmqctl add_vhost admin</span><br><span class="line"></span><br><span class="line">rabbitmqctl set_permissions -p admin  admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;</span><br></pre></td></tr></table></figure><p>注释：主要是set_permissions的使用，先看下命令的格式：</p><p>set_permissions [-p vhost] {user} {conf} {write} {read}</p><p><strong>注意：</strong></p><ol><li><p>这里的权限，只是针对一般用户的访问权限，注意和角色的区分。举个例子来说，非管理用户（普通用户），角色设置为none，然后在这里配置conf、write、read的权限。</p></li><li><p>conf、write、read采用正则表达式，这里的正则主要是针对exchange和queue。主要2种特殊的表达式：</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">^$：表示完全不匹配（即没有权限）</span><br><span class="line"></span><br><span class="line">.*：表示匹配所有（即所有权限）</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;个人在&lt;strong&gt;CentOS7&lt;/strong&gt;下安装RabbitMQ以及遇到的问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RabbitMQ&lt;/strong&gt; 是流行的开源消息队列系统，是 AMQP（Advanced Message Queuing Protocol 高级消息队列协议）的标准实现，用 erlang 语言开发。RabbitMQ 具有良好的性能和时效性，同时还能够非常好的支持集群和负载部署，非常适合在较大规模的分布式系统中使用。并且支持多种开发语言。我们项目中使用RabbitMQ作为消息队列，解耦业务，构建高可靠的消息队列系统。RabbitMQ可以用在订单系统、日志系统、数据收集等常见场景中。&lt;/p&gt;
&lt;h2 id=&quot;1-安装RabbitMQ&quot;&gt;&lt;a href=&quot;#1-安装RabbitMQ&quot; class=&quot;headerlink&quot; title=&quot;1. 安装RabbitMQ&quot;&gt;&lt;/a&gt;1. 安装RabbitMQ&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;可能需要sudo权限&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;安装 RabbitMQ 之前要安装 Erlang，需要先到&lt;a href=&quot;https://www.rabbitmq.com/which-erlang.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RabbitMQ官网&lt;/a&gt;看下版本对应关系。&lt;font color=&quot;red&quot;&gt;&lt;strong&gt;必须看&lt;/strong&gt;&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;当前最新版rabbitmq-server是rabbitmq-server-3.8.3-1.el7.noarch.rpm，最新版Erlang是erlang-23.0.1-1.el7.x86_64.rpm。我们可以分别在&lt;a href=&quot;https://github.com/rabbitmq/erlang-rpm/releases&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Github&lt;/a&gt;和&lt;a href=&quot;https://www.rabbitmq.com/install-rpm.html#downloads&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RabbitMQ官网&lt;/a&gt;下载对应的版本的rpm包。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MQ" scheme="http://JavaSsun.github.io/categories/MQ/"/>
    
    
      <category term="MQ" scheme="http://JavaSsun.github.io/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>ELK日志平台-中</title>
    <link href="http://javassun.github.io/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/"/>
    <id>http://javassun.github.io/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/</id>
    <published>2020-02-11T06:25:35.000Z</published>
    <updated>2020-06-03T07:33:54.115Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于初期系统日志量还在可控范围，选择 ELK+Beats 的方案，并未引入消息队列，后续根据需求可以对系统升级。由此，只需要在日志平台部署 Elasticsearch 和 Logstash 集群，同时在应用服务器部署 Filebeat即可。</p><p><strong>ELK版本务必保持一致，否则可能会出现 Kibana server is not ready yet的情况。</strong><br><font color="red"><strong>警告：</strong><br><strong>ELK 版本 7.4.X 以上需要 Java11 版本</strong><br><strong>ELK 版本 6.6.0 可以使用 Java8 版本</strong><br><strong>因此我们使用 6.6.0 版本</strong><br></font></p><a id="more"></a><h2 id="1-安装前准备"><a href="#1-安装前准备" class="headerlink" title="1 安装前准备"></a>1 安装前准备</h2><h3 id="JAVA环境"><a href="#JAVA环境" class="headerlink" title="JAVA环境"></a>JAVA环境</h3><p>ELK 需要 JAVA 8 以上的运行环境，若未安装则按如下步骤安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 查看是否安装</span><br><span class="line">rpm -qa | grep java</span><br><span class="line"># 批量卸载</span><br><span class="line">rpm -qa | grep java | xargs rpm -e --nodeps</span><br><span class="line">yum install -y java-1.8.0-openjdk*</span><br><span class="line">java -version</span><br><span class="line">openjdk version &quot;1.8.0_151&quot;</span><br></pre></td></tr></table></figure><p>在文件<code>/etc/profile</code>配置环境变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 指向安装目录，其中1.8.0.151需与版本号保持一致</span><br><span class="line">JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0-openjdk-1.8.0.151-1.b12.el6_9.x86_64</span><br><span class="line">PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH</span><br><span class="line">CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar</span><br><span class="line">JAVACMD&#x3D;&#x2F;usr&#x2F;bin&#x2F;java</span><br><span class="line">export JAVA_HOME JAVACMD CLASSPATH PATH</span><br></pre></td></tr></table></figure><p>执行<code>source /etc/profile</code>命令，使配置环境生效</p><h3 id="安装GPG-KEY"><a href="#安装GPG-KEY" class="headerlink" title="安装GPG-KEY"></a>安装GPG-KEY</h3><p>由于后续采用 yum 安装，所以需要下载并安装 GPG-KEY：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm --import https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;GPG-KEY-elasticsearch</span><br></pre></td></tr></table></figure><blockquote><p>yum 命令会安装最新的版本，若需安装较旧的版本，请先从 <a href="https://www.elastic.co/downloads/past-releases" target="_blank" rel="noopener">官方地址</a> 下载对应的旧版本 rpm 包，然后使用<code>rpm -ivh</code>命令安装。</p></blockquote><h2 id="2-Elasticsearch"><a href="#2-Elasticsearch" class="headerlink" title="2 Elasticsearch"></a>2 Elasticsearch</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><ul><li><p>1 如果网速过慢，可以选择笔记附件下载。</p></li><li><p>2 通过 <a href="https://www.elastic.co/downloads/past-releases" target="_blank" rel="noopener">官方地址</a> 下载选择最新版本，然后解压：</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;elasticsearch&#x2F;elasticsearch-6.6.0.tar.gz</span><br><span class="line"></span><br><span class="line">mkdir -p &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">tar -zxvf elasticsearch-6.6.0.tar.gz -C &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">mv &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch-6.6.0 &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch</span><br><span class="line"></span><br><span class="line">cd elasticsearch</span><br><span class="line">mkdir data &#x2F;&#x2F;存数据文件用</span><br><span class="line">mkdir logs &#x2F;&#x2F;存日志文件用 如果有就不用再次创建</span><br></pre></td></tr></table></figure><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/79c3dd35-de46-4154-8137-936d6c2d3f27.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">目录结构介绍：</span><br><span class="line">bin：可执行文件，运行es的命令</span><br><span class="line">config：配置文件目录</span><br><span class="line"> config&#x2F;elasticsearch.yml：ES启动基础配置</span><br><span class="line"> config&#x2F;jvm.options：ES启动时JVM配置</span><br><span class="line"> config&#x2F;log4j2.properties：ES日志输出配置文件</span><br><span class="line">lib：依赖的jar</span><br><span class="line">logs：日志文件夹</span><br><span class="line">modules：es模块</span><br><span class="line">plugins：可以自己开发的插件</span><br><span class="line">data：我们自己创建的，存放es存储文件</span><br></pre></td></tr></table></figure><p>由于 Elasticsearch 新版本不允许以 <strong>root</strong> 身份启动，因此先创建 elk 用户。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">直接以root用户启动 会报错</span><br><span class="line">bin&#x2F;elasticsearch</span><br></pre></td></tr></table></figure><p>所以需要创建用户并赋予es安装目录权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">创建一个esroot用户并设置初始密码</span><br><span class="line">useradd -c &quot;ES user&quot; -d &#x2F;home&#x2F;esroot esroot</span><br><span class="line">passwd esroot</span><br><span class="line"></span><br><span class="line">将es安装目录属主权威改为esroot用户</span><br><span class="line">chown -R esroot &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch</span><br><span class="line"></span><br><span class="line">切换用户到esroot</span><br><span class="line">su esroot</span><br><span class="line"></span><br><span class="line">.&#x2F;elasticsearch -d 重启即可</span><br></pre></td></tr></table></figure><p><strong>可能出现的错误：</strong></p><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/2a7d0653-0f1e-4125-9507-b91ad467c647.png" alt></p><ul><li>1 jvm 的 Xms / Xmx 设置不一致，将其设置一致即可</li></ul><p>启动前，需要修改配置文件<code>jvm.options</code>中 JVM 大小，否则可能会内存溢出，导致启动失败。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd elasticsearch</span><br><span class="line">vim config&#x2F;jvm.options</span><br><span class="line"># 根据实际情况修改</span><br><span class="line">-Xms128m</span><br><span class="line">-Xmx128m</span><br></pre></td></tr></table></figure><ul><li><p>2 要设置系统参数vm.max_map_count=262144<br>原话为：<br><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2Fcurrent%2Fdocker.html%23docker-cli-run-prod-mode" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#docker-cli-run-prod-mode</a><br>The vm.max_map_count kernel setting needs to be set to at least 262144 for production use. Depending on your platform:</p></li><li><p>Linux<br> The vm.max_map_count setting should be set permanently in /etc/sysctl.conf:<br> To apply the setting on a live system type: sysctl -w vm.max_map_count=262144</p></li></ul><blockquote><p>$ grep vm.max_map_count /etc/sysctl.conf</p></blockquote><blockquote><p> vm.max_map_count=262144</p></blockquote><p><strong>解决办法：</strong><br>切换为root用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查看vm.max_map_count属性值，</span><br><span class="line"></span><br><span class="line">如果没有添加则在&#x2F;etc&#x2F;sysctl.conf文件添加vm.max_map_count &#x3D; 262144</span><br><span class="line">grep vm.max_map_count &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line"></span><br><span class="line">或者执行添加临时变量</span><br><span class="line">sysctl -w vm.max_map_count&#x3D;262144</span><br></pre></td></tr></table></figure><h2 id="简要配置"><a href="#简要配置" class="headerlink" title="简要配置"></a>简要配置</h2><p><strong>1-5为elasticsearch.yml配置，6为jvm.options配置</strong></p><ul><li><p>1 配置集群名称（默认备注是，并且默认只有一个集群名）<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/3147066a-cd7c-4896-b9a2-f2741bae7da3.png" alt></p></li><li><p>2 配置当前es节点名称（默认是被注释的，并且默认有一个节点名）<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/12abb2c6-24a1-4d71-861e-68f23ed81be7.png" alt></p></li><li><p>3 配置存储数据的目录路径（用逗号分隔多个位置）和日志文件路径<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/30f50069-f103-4501-8a96-9703411b1b3e.png" alt></p></li><li><p>4 绑定地址为特定IP地址（设置0.0.0.0可以让任何人访问到你的es），设置一个http请求端口<br>添加一行为 http.host: 0.0.0.0 即可。<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/6a74c5c3-69c9-417f-98b6-0ee9704a3cdb.png" alt></p></li><li><p>5 集群启动，参看同目录其他文章。</p></li><li><p>6 配置ES启动JVM参数<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/5bafb14b-cca0-42a9-babc-20803c96c263.png" alt></p></li></ul><p>CentOS7 设置开机启动服务，启动 Elasticsearch，其默认监听 9200 端口。\</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi &#x2F;etc&#x2F;security&#x2F;limits.conf</span><br><span class="line">添加如下内容：</span><br><span class="line">* soft nofile 65536 </span><br><span class="line">* hard nofile 131072 </span><br><span class="line">* soft nproc 2048 </span><br><span class="line">* hard nproc 4096</span><br></pre></td></tr></table></figure><p>在/etc/systemd/system目录下创建elasticsearch.service文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description&#x3D;elasticsearch</span><br><span class="line">[Service]</span><br><span class="line">User&#x3D;esroot</span><br><span class="line">LimitNOFILE&#x3D;100000</span><br><span class="line">LimitNPROC&#x3D;100000</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch&#x2F;bin&#x2F;elasticsearch</span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure><p>设置开机自启</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable elasticsearch</span><br></pre></td></tr></table></figure><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/2c40d70f-16d8-4194-b9ed-368bb40aff2b.png" alt></p><p>最后，安装使用到的插件 可能需要用到 <strong>Java11版本</strong>，看情况安装下述插件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch</span><br><span class="line"># ingest-geoip和ingest-user-agent分别为ip解析插件和agent解析插件</span><br><span class="line">bin&#x2F;elasticsearch-plugin install ingest-geoip</span><br><span class="line">bin&#x2F;elasticsearch-plugin install ingest-user-agent</span><br><span class="line"># 用户管理和monitor管理</span><br><span class="line">bin&#x2F;elasticsearch-plugin install x-pack</span><br></pre></td></tr></table></figure><blockquote><p>安装 x-pack 插件后，对 Elasticsearch 的操作都需要授权，默认用户名为 elastic，默认密码为 changeme。</p></blockquote><p>启动成功图：-d 以后台方式启动<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/7fb9cc65-9e32-4d2f-b36b-e79ff144381a.png" alt></p><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/36b45622-af07-4e53-ad1a-ffb4c6d2fcdc.png" alt></p><h3 id="问题及解决办法"><a href="#问题及解决办法" class="headerlink" title="问题及解决办法"></a>问题及解决办法</h3><h4 id="1-权限问题"><a href="#1-权限问题" class="headerlink" title="1 权限问题"></a>1 权限问题</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Java HotSpot(TM) 64-Bit Server VM warning: Cannot open file logs&#x2F;gc.log due to Permission denied</span><br><span class="line"></span><br><span class="line">[esroot@haoransun elasticsearch]$ Exception in thread &quot;main&quot; org.elasticsearch.bootstrap.BootstrapException: java.nio.file.AccessDeniedException: &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;elasticsearch&#x2F;config&#x2F;elasticsearch.keystore</span><br></pre></td></tr></table></figure><p>解决方法：<br>因为第一次启动不小心用了root启动，导致用root生成了对应的文件。切换es账号之后，没有对应文件的权限导致，删除相关的东西即可。<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/05421b4d-63cb-4019-88e2-3d5b25fe1b01.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf elasticsearch.keystore gc.log.0.current</span><br></pre></td></tr></table></figure><h4 id="2-max-number-of-threads-1024"><a href="#2-max-number-of-threads-1024" class="headerlink" title="2 #### max number of threads [1024]"></a>2 #### max number of threads [1024]</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RROR: [2] bootstrap checks failed</span><br><span class="line">[1]: max number of threads [1024] for user [es] is too low, increase to at least [4096]</span><br><span class="line">[2]: system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk</span><br></pre></td></tr></table></figure><p>解决:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ulimit -a</span><br><span class="line"></span><br><span class="line">max user processes              (-u) 1024</span><br><span class="line">virtual memory          (kbytes, -v) unlimited</span><br><span class="line">file locks                      (-x) unlimited</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vi &#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;90-nproc.conf </span><br><span class="line"></span><br><span class="line"># Default limit for number of user&#39;s processes to prevent</span><br><span class="line"># accidental fork bombs.</span><br><span class="line"># See rhbz #432903 for reasoning.</span><br><span class="line"></span><br><span class="line">* hard nproc 4096</span><br><span class="line">* soft nproc 4096</span><br><span class="line">*          soft    nproc     4096</span><br><span class="line">root       soft    nproc     unlimited</span><br></pre></td></tr></table></figure><h4 id="3-system-call-filters-failed-to-install-check-the-logs-and-fix-your-configuration-or-disable-system-call-filters-at-your-own-risk"><a href="#3-system-call-filters-failed-to-install-check-the-logs-and-fix-your-configuration-or-disable-system-call-filters-at-your-own-risk" class="headerlink" title="3 system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk"></a>3 system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk</h4><p>这是在因为Centos6不支持SecComp，而ES5.2.0默认bootstrap.system_call_filter为true进行检测，所以导致检测失败，失败后直接导致ES不能启动。</p><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在elasticsearch.yml中配置bootstrap.system_call_filter为false，注意要在Memory下面:</span><br><span class="line">bootstrap.memory_lock: false</span><br><span class="line">bootstrap.system_call_filter: false</span><br></pre></td></tr></table></figure><h4 id="4-日志级别报错"><a href="#4-日志级别报错" class="headerlink" title="4 日志级别报错"></a>4 日志级别报错</h4><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/761060a0-6483-4264-b1ec-b739a115edfb.png" alt></p><p>需要修改config配置里的log4j2.properties 文件, 将 logger.deprecation.level = warn 改为 error即可。</p><h4 id="5-main-ERROR-Unable-to-invoke-factory-method-in-class-org-apache-logging-log4j-core"><a href="#5-main-ERROR-Unable-to-invoke-factory-method-in-class-org-apache-logging-log4j-core" class="headerlink" title="5 # main ERROR Unable to invoke factory method in class org.apache.logging.log4j.core"></a>5 # main ERROR Unable to invoke factory method in class org.apache.logging.log4j.core</h4><p>原因：在安装elasticsearch时，新建的logs目录是用root用户建的，因此，logs下的文件是root用户权限，因此，将该权限改为非root用户即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown -R esroot logs&#x2F;</span><br><span class="line">chgrp -R esroot logs&#x2F;</span><br></pre></td></tr></table></figure><p>再次启动，不会报错。</p><h2 id="3-Kibana"><a href="#3-Kibana" class="headerlink" title="3 Kibana"></a>3 Kibana</h2><h3 id="下载kibana安装包"><a href="#下载kibana安装包" class="headerlink" title="下载kibana安装包"></a>下载kibana安装包</h3><p>如果网速过慢，可以选择笔记附件下载。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;kibana&#x2F;kibana-6.6.0-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure><h3 id="解压kibana安装包"><a href="#解压kibana安装包" class="headerlink" title="解压kibana安装包"></a>解压kibana安装包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">tar -zxvf kibana-6.6.0-linux-x86_64.tar.gz  -C &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">mv &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;kibana-6.6.0-linux-x86_64 &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;kibana</span><br></pre></td></tr></table></figure><h3 id="修改kibana配置，config目录下的kibana-yml"><a href="#修改kibana配置，config目录下的kibana-yml" class="headerlink" title="修改kibana配置，config目录下的kibana.yml"></a>修改kibana配置，config目录下的kibana.yml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;kibana&#x2F;config&#x2F;kibana.yml</span><br><span class="line"></span><br><span class="line"># 修改内容</span><br><span class="line">server.port: 5601</span><br><span class="line"></span><br><span class="line">server.host: &quot;内网地址或者是0.0.0.0&quot;</span><br><span class="line"></span><br><span class="line">elasticsearch.url: &quot;http:&#x2F;&#x2F;ElasticSearch所在ip地址:9200&quot;</span><br></pre></td></tr></table></figure><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/daa6f970-9bf4-4e09-8fb3-3b31b51c8906.png" alt></p><p>安装常用插件，如 x-pack</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kibana-plugin install x-pack</span><br></pre></td></tr></table></figure><blockquote><p>安装 x-pack 插件后，访问 Kibana 同样需要授权，且任何 Elasticsearch 的用户名和密码对都可被认证通过。</p></blockquote><h3 id="启动-kibana"><a href="#启动-kibana" class="headerlink" title="启动 kibana"></a>启动 kibana</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd bin </span><br><span class="line">nohup .&#x2F;kibana &amp;</span><br></pre></td></tr></table></figure><h3 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h3><ul><li><strong>1 网络不可访问</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;“type”:“error”,&quot;@timestamp&quot;:“2019-04-06T00:25:22Z”,“tags”:[“fatal”,“root”],“pid”:754,“level”:“fatal”,“error”:&#123;“message”:“listen EADDRNOTAVAIL localhost:5601”,“name”:“Error”,“stack”:&quot;Error: listen EADDRNOTAVAIL localhost:5601\n at Server.setupListenHandle [as _listen2] (net.js:1343:19)\n …</span><br></pre></td></tr></table></figure>解决方案：<br>由于server.host: 之前设置的是阿里云服务器的外网ip地址，所以启动kibana一直报错 将server.host改为”内网地址或者是0.0.0.0”即可</li></ul><ul><li><strong>2 Kibana 运行时 NodeJs 默认会最大分配 1G 内存，可以在启动时增加<code>max-old-space-size</code>参数，以限制其运行内存大小</strong></li></ul><p><strong>同理：kibana not ready yet</strong></p><p><strong>同理：kibana FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim bin&#x2F;kibana</span><br><span class="line"></span><br><span class="line"># 增加--max-old-space-size&#x3D;140参数</span><br><span class="line">NODE_ENV&#x3D;production exec &quot;$&#123;NODE&#125;&quot; $NODE_OPTIONS --max-old-space-size&#x3D;200 --no-warnings &quot;$&#123;DIR&#125;&#x2F;src&#x2F;cli&quot; $&#123;@&#125;</span><br></pre></td></tr></table></figure><h3 id="防护墙开放5601端口，并测试访问"><a href="#防护墙开放5601端口，并测试访问" class="headerlink" title="防护墙开放5601端口，并测试访问"></a>防护墙开放5601端口，并测试访问</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --zone&#x3D;public --add-port&#x3D;5601&#x2F;tcp --permanent</span><br><span class="line">firewall-cmd --reload</span><br><span class="line">firewall-cmd --list-ports</span><br></pre></td></tr></table></figure><p>访问 <a href="http://192.168.121.100:5601/app/kibana" target="_blank" rel="noopener">http://192.168.121.100:5601/app/kibana</a> 即可<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/8cf66438-c28c-4fc6-bfa5-f6d3480629c8.png" alt></p><hr><h2 id="4-Logstash"><a href="#4-Logstash" class="headerlink" title="4 Logstash"></a>4 Logstash</h2><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a><a href="https://www.elastic.co/guide/en/logstash/current/installing-logstash.html#_yum" target="_blank" rel="noopener">安装</a></h3><ul><li>方法1</li></ul><p>首先，在<code>/etc/yum.repos.d</code>目录下创建<code>logstash.repo</code>文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[logstash-6.x] </span><br><span class="line">name&#x3D;Elastic repository for  6.x packages</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;packages&#x2F;6.x&#x2F;yum</span><br><span class="line">gpgcheck&#x3D;1 </span><br><span class="line">gpgkey&#x3D;https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;GPG-KEY-elasticsearch</span><br><span class="line">enabled&#x3D;1 </span><br><span class="line">autorefresh&#x3D;1 </span><br><span class="line">type&#x3D;rpm-md</span><br></pre></td></tr></table></figure><p>使用 yum 安装 Logstash，并测试：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 安装logstash 6.x</span><br><span class="line">$ yum install -y logstash</span><br><span class="line"># 默认安装路径&#x2F;usr&#x2F;share</span><br><span class="line">$ mkdir -p &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line">$ ln -s &#x2F;usr&#x2F;share&#x2F;logstash &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;logstash</span><br><span class="line">$ cd &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk&#x2F;logstash</span><br><span class="line"># 命令行测试</span><br><span class="line">$ bin&#x2F;logstash -e &#39;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&#39;</span><br><span class="line"></span><br><span class="line">The stdin plugin is now waiting for input:</span><br><span class="line">elk</span><br><span class="line">2017-11-21T22:25:07.264Z fhb elk</span><br></pre></td></tr></table></figure><ul><li>方法2<br>按上述连接安装，如果网速过慢，可以使用笔记附件安装</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">tar -zxvf logstash-6.6.0.tar.gz -C &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">mv logstash-6.6.0 logstash</span><br><span class="line"></span><br><span class="line">cd logstash</span><br></pre></td></tr></table></figure><h3 id="安装插件-可能需要一些时间"><a href="#安装插件-可能需要一些时间" class="headerlink" title="安装插件(可能需要一些时间)"></a>安装插件(可能需要一些时间)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;logstash-plugin install logstash-input-jdbc</span><br><span class="line"></span><br><span class="line">bin&#x2F;logstash-plugin install logstash-output-elasticsearch</span><br><span class="line"></span><br><span class="line">安装 x-pack 插件，基本状态信息的监控:</span><br><span class="line">bin&#x2F;logstash-plugin install x-pack</span><br></pre></td></tr></table></figure><p>修改 JVM 内存大小，防止出现内存溢出异常：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ vim config&#x2F;jvm.options</span><br><span class="line"># 根据实际情况修改</span><br><span class="line">-Xms150m</span><br><span class="line">-Xmx150m</span><br></pre></td></tr></table></figure><h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果没有 logs文件夹，则自己创建</span><br><span class="line">mkdir logs</span><br></pre></td></tr></table></figure><p><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/402f2720-4ed0-43f6-b4ad-e14b50b65e9c.png" alt></p><h3 id="检验安装是否成功"><a href="#检验安装是否成功" class="headerlink" title="检验安装是否成功"></a>检验安装是否成功</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;logstash -e &#39;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&#39;</span><br></pre></td></tr></table></figure><blockquote><p>-e 即允许从命令行指定配置</p></blockquote><p>启动成功后，输入 hello world，会有如下显示，则安装成功。<br><img src="/2020/02/11/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%AD/d7cd18ae-eff8-4a43-87a5-3290bd35259b.png" alt></p><h2 id="5-Filebeat"><a href="#5-Filebeat" class="headerlink" title="5 Filebeat"></a>5 Filebeat</h2><h3 id="安装-2"><a href="#安装-2" class="headerlink" title="[安装]"></a>[安装]</h3><ul><li><p>1 网速较慢，使用笔记附件安装</p></li><li><p>2 使用 wget 下载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget  https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;beats&#x2F;filebeat&#x2F;filebeat-6.6.0-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure></li></ul><h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">tar -zxvf filebeat-6.6.0-linux-x86_64.tar.gz -C &#x2F;usr&#x2F;local&#x2F;geek&#x2F;elk</span><br><span class="line"></span><br><span class="line">mv filebeat-6.6.0-linux-x86_64 filebeat</span><br><span class="line"></span><br><span class="line">cd filebeat</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;由于初期系统日志量还在可控范围，选择 ELK+Beats 的方案，并未引入消息队列，后续根据需求可以对系统升级。由此，只需要在日志平台部署 Elasticsearch 和 Logstash 集群，同时在应用服务器部署 Filebeat即可。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ELK版本务必保持一致，否则可能会出现 Kibana server is not ready yet的情况。&lt;/strong&gt;&lt;br&gt;&lt;font color=&quot;red&quot;&gt;&lt;strong&gt;警告：&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;ELK 版本 7.4.X 以上需要 Java11 版本&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;ELK 版本 6.6.0 可以使用 Java8 版本&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;因此我们使用 6.6.0 版本&lt;/strong&gt;&lt;br&gt;&lt;/font&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="ELK" scheme="http://JavaSsun.github.io/categories/ELK/"/>
    
      <category term="日志" scheme="http://JavaSsun.github.io/categories/ELK/%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="日志" scheme="http://JavaSsun.github.io/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="ELK" scheme="http://JavaSsun.github.io/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>ELK日志平台-上</title>
    <link href="http://javassun.github.io/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/"/>
    <id>http://javassun.github.io/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/</id>
    <published>2020-02-10T02:30:57.000Z</published>
    <updated>2020-06-03T07:33:43.987Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在过往的单体应用时代，我们所有组件都部署到一台服务器中，那时日志管理平台的需求可能并没有那么强烈，我们只需要登录到一台服务器通过shell命令就可以很方便的查看系统日志，并快速定位问题。随着互联网的发展，互联网已经全面渗入到生活的各个领域，使用互联网的用户量也越来越多，单体应用已不能够支持庞大的用户的并发量，那么将单体应用进行拆分，通过水平扩展来支持庞大用户的使用迫在眉睫，微服务概念就是在类似这样的阶段诞生，在微服务盛行的互联网技术时代，单个应用被拆分为多个应用，每个应用集群部署进行负载均衡，那么如果某项业务发生系统错误，开发或运维人员还是以过往单体应用方式登录一台一台登录服务器查看日志来定位问题，这种解决线上问题的效率可想而知。日志管理平台的建设就显得极其重要。通过Logstash去收集每台服务器日志文件，然后按定义的正则模板过滤后传输到Kafka或redis，然后由另一个Logstash从KafKa或redis读取日志存储到elasticsearch中创建索引，最后通过Kibana展示给开发者或运维人员进行分析。这样大大提升了运维线上问题的效率。除此之外，还可以将收集的日志进行大数据分析，得到更有价值的数据给到高层进行决策。</p><p><strong>优点</strong></p><ul><li><p>ELK 提供的功能满足使用要求，并有较高的扩展性。</p></li><li><p>ELK 为一套开源项目，较低的维护成本。</p><a id="more"></a><h2 id="1-相关概念"><a href="#1-相关概念" class="headerlink" title="1 相关概念"></a>1 相关概念</h2><p>ELK 指的是一套解决方案，是 <a href="https://www.elastic.co/cn/products/elasticsearch" target="_blank" rel="noopener">Elasticsearch</a>、<a href="https://www.elastic.co/cn/products/logstash" target="_blank" rel="noopener">Logstash</a> 和 <a href="https://www.elastic.co/cn/products/kibana" target="_blank" rel="noopener">Kibana</a> 三种软件产品的首字母缩写，<a href="https://www.elastic.co/cn/products/beats" target="_blank" rel="noopener">Beats</a> 是 ELK 协议栈的新成员。</p></li><li><p>E：代表 Elasticsearch，负责日志的存储和检索；</p></li><li><p>L：代表 Logstash，负责日志的收集、过滤和格式化；</p></li><li><p>K：代表 Kibana，负责日志数据的可视化；</p></li><li><p>Beats：是一类轻量级数据采集器；</p></li></ul><p>其中，目前 Beats 家族根据功能划分，主要包括 4 种：</p><ul><li>Filebeat：负责收集文件数据；</li><li>Packetbeat：负责收集网络流量数据；</li><li>Metricbeat：负责收集系统级的 CPU 使用率、内存、文件系统、磁盘 IO 和网络 IO 统计数据；</li><li>Winlogbeat：负责收集 Windows 事件日志数据;</li></ul><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/a68a642c-bc33-4ba2-bc23-92ea182d89a4.png" alt></p><p>在我们将要搭建的集中式日志平台系统中，就使用了 Filebeat 作为日志文件收集工具，Filebeat 可以很方便地收集 Nginx、Mysql、Redis、Syslog 等应用的日志文件。</p><h2 id="2-日志平台架构"><a href="#2-日志平台架构" class="headerlink" title="2 日志平台架构"></a>2 日志平台架构</h2><p>ELK 集中日志平台也是经过一次次演变，它的大概收集过程如下：</p><p>1 部署在应用服务器上的数据采集器，近实时收集日志数据推送到日志过滤节点的 Logstash</p><p>2 Logstash 再推送格式化的日志数据到 Elasticsearch 存储</p><p>3 Kibana 通过 Elasticsearch 集中检索日志并可视化</p><h3 id="ES-Logstash-Kibana"><a href="#ES-Logstash-Kibana" class="headerlink" title="ES + Logstash + Kibana"></a>ES + Logstash + Kibana</h3><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/5aa407d6-4820-4acb-99da-95058cc265e4.png" alt></p><p>最开始的架构中，由 Logstash 承担数据采集器和过滤功能，并部署在应用服务器。由于 Logstash 对大量日志进行过滤操作，会消耗应用系统的部分性能，带来不合理的资源分配问题；另一方面，过滤日志的配置，分布在每台应用服务器，不便于集中式配置管理。</p><h3 id="引入Logstash-forwarder"><a href="#引入Logstash-forwarder" class="headerlink" title="引入Logstash-forwarder"></a>引入Logstash-forwarder</h3><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/db6ea5c6-7135-4797-8405-cfb8eea22c36.jpg" alt></p><p>使用该架构，引入 Logstash-forwarder 作为数据采集，Logstash 和应用服务器分离，应用服务器只做数据采集，数据过滤统一在日志平台服务器，解决了之前存在的问题。但是 Logstash-forwarder 和 Logstash 间通信必须由 SSL 加密传输，部署麻烦且系统性能并没有显著提升；另一方面，Logstash-forwarder 的定位并不是数据采集插件，系统不易扩展。</p><h3 id="引入Beats"><a href="#引入Beats" class="headerlink" title="引入Beats"></a>引入Beats</h3><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/086379ce-c6f4-433d-82b9-3c108226af58.jpg" alt></p><p>该架构，基于 Logstash-forwarder 架构，将 Logstash-forwarder 替换为 Beats。由于 Beats 的系统性能开销更小，所以应用服务器性能开销可以忽略不计；另一方面，Beats 可以作为数据采集插件形式工作，可以按需启用 Beats 下不同功能的插件，更灵活，扩展性更强。例如，应用服务器只启用 Filebeat，则只收集日志文件数据，如果某天需要收集系统性能数据时，再启用 Metricbeat 即可，并不需要太多的修改和配置。</p><p>这种 ELK+Beats 的架构，已经满足大部分应用场景了，但当业务系统庞大，日志数据量较大、较实时时，业务系统就和日志系统耦合在一起了。</p><h3 id="引入队列"><a href="#引入队列" class="headerlink" title="引入队列"></a>引入队列</h3><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/b7139e8c-0c37-4ba8-b5ff-b16956ee2b36.jpg" alt></p><p>该架构，引入消息队列，均衡了网络传输，从而降低了网络闭塞，尤其是丢失数据的可能性；另一方面，这样可以系统解耦，具有更好的灵活性和扩展性。</p><h2 id="3-经验"><a href="#3-经验" class="headerlink" title="3 经验"></a>3 经验</h2><p>成熟的 ELK+Beats 架构，因其扩展性很强，是集中式日志平台的首选方案。在实际部署时，是否引入消息队列，根据业务系统量来确定，早期也可以不引入消息队列，简单部署，后续需要扩展再接入消息队列。</p><h2 id="4-ELK概念解读"><a href="#4-ELK概念解读" class="headerlink" title="4 ELK概念解读"></a>4 ELK概念解读</h2><h3 id="1-Elasticsearch"><a href="#1-Elasticsearch" class="headerlink" title="1 Elasticsearch"></a>1 Elasticsearch</h3><h4 id="软件介绍"><a href="#软件介绍" class="headerlink" title="软件介绍"></a>软件介绍</h4><p><strong>Elasticsearch</strong>是一个开源的分布式、RESTful 风格的搜索和数据分析引擎，它的底层是开源库Apache Lucene。</p><p>Lucene 可以说是当下最先进、高性能、全功能的搜索引擎库——无论是开源还是私有，但它也仅仅只是一个库。为了充分发挥其功能，你需要使用 Java 并将 Lucene 直接集成到应用程序中。 更糟糕的是，您可能需要获得信息检索学位才能了解其工作原理，因为Lucene 非常复杂。</p><p>为了解决Lucene使用时的繁复性，于是Elasticsearch便应运而生。它使用 Java 编写，内部采用 Lucene 做索引与搜索，但是它的目标是使全文检索变得更简单，简单来说，就是对Lucene 做了一层封装，它提供了一套简单一致的 RESTful API 来帮助我们实现存储和检索。</p><p>当然，Elasticsearch 不仅仅是 Lucene，并且也不仅仅只是一个全文搜索引擎。 它可以被下面这样准确地形容：</p><ul><li>一个分布式的实时文档存储，每个字段可以被索引与搜索；</li><li>一个分布式实时分析搜索引擎；</li><li>能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据。</li></ul><h4 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h4><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/401b561c-02d3-447c-92ff-5f4cedf50f57.jpg" alt></p><h4 id="ES核心概念"><a href="#ES核心概念" class="headerlink" title="ES核心概念"></a>ES核心概念</h4><h5 id="1-节点-amp-集群（Node-amp-Cluster）"><a href="#1-节点-amp-集群（Node-amp-Cluster）" class="headerlink" title="1 节点 &amp; 集群（Node &amp; Cluster）"></a>1 节点 &amp; 集群（Node &amp; Cluster）</h5><p>Elasticsearch 本质上是一个分布式数据库，允许多台服务器协同工作，每台服务器可以运行多个Elasticsearch实例。单个Elasticsearch实例称为一个节点（Node），一组节点构成一个集群（Cluster）。</p><h5 id="2-索引（Index）"><a href="#2-索引（Index）" class="headerlink" title="2 索引（Index）"></a>2 索引（Index）</h5><p>Elasticsearch 数据管理的顶层单位就叫做 Index（索引），相当于关系型数据库里的数据库的概念。另外，每个Index的名字必须是小写。</p><h5 id="3-Shard-分片"><a href="#3-Shard-分片" class="headerlink" title="3 Shard 分片"></a>3 Shard 分片</h5><p>当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端的请求等，一个节点可能不够。这种情况下，数据可以分为较小的分片。每个分片放到不同的服务器上。<br>当你查询的索引分布在多个分片上时，ES会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即：这个过程对用户来说是透明的。</p><h5 id="4-Replia-副本"><a href="#4-Replia-副本" class="headerlink" title="4 Replia 副本"></a>4 Replia 副本</h5><p>为提高查询吞吐量或实现高可用性，可以使用分片副本。<br>副本是一个分片的精确复制，每个分片可以有零个或多个副本。ES中可以有许多相同的分片，其中之一被选择更改索引操作，这种特殊的分片称为主分片。<br>当主分片丢失时，如：该分片所在的数据不可用时，集群将副本提升为新的主分片。</p><h5 id="5-全文搜索-Full-text-Search"><a href="#5-全文搜索-Full-text-Search" class="headerlink" title="5 全文搜索(Full-text Search)"></a>5 全文搜索(Full-text Search)</h5><p>文检索是指计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。</p><p>在全文搜索的世界中，存在着几个庞大的帝国，也就是主流工具，主要有：</p><ul><li>Apache Lucene</li><li>Elasticsearch</li><li>Solr</li><li>Ferret</li></ul><h5 id="6-倒排索引（Inverted-Index）"><a href="#6-倒排索引（Inverted-Index）" class="headerlink" title="6 倒排索引（Inverted Index）"></a>6 倒排索引（Inverted Index）</h5><p>该索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)。Elasticsearch能够实现快速、高效的搜索功能，正是基于倒排索引原理。</p><h5 id="7-文档（Document）"><a href="#7-文档（Document）" class="headerlink" title="7 文档（Document）"></a>7 文档（Document）</h5><p>index里面单条的记录称为 Document（文档）。许多条 Document 构成了一个 Index。Document 使用 JSON 格式表示。同一个 Index 里面的 Document，不要求有相同的结构（scheme），但是最好保持相同，这样有利于提高搜索效率。</p><h5 id="8-类型（Type）"><a href="#8-类型（Type）" class="headerlink" title="8 类型（Type）"></a>8 类型（Type）</h5><p>Document 可以分组，比如employee这个 Index 里面，可以按部门分组，也可以按职级分组。这种分组就叫做 Type，它是虚拟的逻辑分组，用来过滤 Document，类似关系型数据库中的数据表。</p><p>不同的 Type 应该有相似的结构（Schema），性质完全不同的数据（比如 products 和 logs）应该存成两个 Index，而不是一个 Index 里面的两个 Type（虽然可以做到）。</p><h5 id="9-文档元数据（Document-metadata）"><a href="#9-文档元数据（Document-metadata）" class="headerlink" title="9 文档元数据（Document metadata）"></a>9 文档元数据（Document metadata）</h5><p>文档元数据为_index, _type, _id, 这三者可以唯一表示一个文档，_index表示文档在哪存放，_type表示文档的对象类别，_id为文档的唯一标识。</p><h5 id="10-字段（Fields"><a href="#10-字段（Fields" class="headerlink" title="10 字段（Fields)"></a>10 字段（Fields)</h5><p>每个Document都类似一个JSON结构，它包含了许多字段，每个字段都有其对应的值，多个字段组成了一个 Document，可以类比关系型数据库数据表中的字段。</p><p>在 Elasticsearch 中，文档（Document）归属于一种类型（Type），而这些类型存在于索引（Index）中，下图展示了Elasticsearch与传统关系型数据库的类比：</p><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/7e518ba2-3105-4448-b7ba-bed4bbfeaeff.jpg" alt></p><h4 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h4><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/fec9e928-09be-4fd7-b932-eaaf60a4e582.jpg" alt></p><h3 id="2-Kibana"><a href="#2-Kibana" class="headerlink" title="2 Kibana"></a>2 Kibana</h3><h4 id="软件介绍-1"><a href="#软件介绍-1" class="headerlink" title="软件介绍"></a>软件介绍</h4><p>Kibana 是为 Elasticsearch设计的开源分析和可视化平台。你可以使用 Kibana 来搜索，查看存储在 Elasticsearch 索引中的数据并与之交互。你可以很容易实现高级的数据分析和可视化，以图标的形式展现出来，通过改变Elasticsearch查询时间，可以完成动态仪表盘。</p><p><strong>使用场景</strong></p><ul><li><p>实时监控<br>通过 histogram 面板，配合不同条件的多个 queries 可以对一个事件走很多个维度组合出不同的时间序列走势。时间序列数据是最常见的监控报警了。</p></li><li><p>问题分析<br>关于 elk 的用途，可以参照其对应的商业产品 splunk 的场景：使用 Splunk 的意义在于使信息收集和处理智能化。</p></li></ul><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>搜索和展示信息，可以查看Discover页面。</p><p>图表和地图展示，可以查看Visualize。</p><p>创建一个仪表盘，可以使用Dashboard</p><h3 id="3-Logstash"><a href="#3-Logstash" class="headerlink" title="3 Logstash"></a>3 Logstash</h3><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>建议在使用logstash之前先想清楚自己的需求是什么，从哪种数据源同步到哪里，需要经过怎么样的处理。因为logstash版本迭代较快，每个版本的插件都有点区别，比如filter中的http插件在6.6版本以后才有；output到现在(7.1)都没有jdbc的插件，然而你如果想使用output的jdbc插件就需要自己去安装热心人自己写的插件(logstash-output-jdbc),不幸的是，该作者指出没有很多的时间去维护此插件，不能保证6.3以后用户的正常使用。<br> 也就是说，如果你想用output的jdbc，你就必须使用6.3以下(最好5.x)的版本，如果你想用官方filter的http插件，你就得用6.5以上的版本。</p><blockquote><p>如果目标数据源的type为jdbc，则建议安装logstash-5.4.1或6.x一下的版本，因为logstash-output-jdbc只在6.x以下有效.</p></blockquote><h4 id="软件介绍-2"><a href="#软件介绍-2" class="headerlink" title="软件介绍"></a>软件介绍</h4><p>官方介绍：Logstash is an open source data collection engine with real-time pipelining capabilities。</p><p>Logstash是一个开源数据收集引擎，具有实时管道功能。Logstash可以动态地将来自不同数据源的数据统一起来，并将数据标准化到你所选择的目的地。</p><p><strong>Logstash常用于日志关系系统中做日志采集设备</strong></p><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/11b125b4-251c-4690-9d28-9c31bc618431.jpg" alt></p><h4 id="系统架构-1"><a href="#系统架构-1" class="headerlink" title="系统架构"></a>系统架构</h4><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/06abbb73-b15b-41fb-ab83-de441b586182.jpg" alt></p><p>Logstash的事件（logstash将数据流中等每一条数据称之为一个event）处理流水线有三个主要角色完成：inputs –&gt; filters –&gt; outputs：</p><ul><li><p>inpust：必须，负责产生事件（Inputs generate events），常用：File、syslog、redis、beats（如：Filebeats）</p></li><li><p>filters：可选，负责数据处理与转换（filters modify them），常用：grok、mutate、drop、clone、geoip</p></li><li><p>outpus：必须，负责数据输出（outputs ship them elsewhere），常用：elasticsearch、file、graphite、statsd</p></li><li><p>Codecs：Codecs(编码插件)不是一个单独的流程，而是在输入和输出等插件中用于数据转换的模块，用于对数据进行编码处理，常见的插件如json，multiline。Logstash不只是一个input | filter | output 的数据流，而是一个 input | decode | filter | encode | output 的数据流！codec 就是用来 decode、encode 事件的。</p></li></ul><p>其中inputs和outputs支持codecs（coder&amp;decoder）在1.3.0 版之前，logstash 只支持纯文本形式输入，然后以过滤器处理它。但现在，我们可以在输入 期处理不同类型的数据，所以完整的数据流程应该是：input | decode | filter | encode | output；codec 的引入，使得 logstash 可以更好更方便的与其他有自定义数据格式的运维产品共存，比如：graphite、fluent、netflow、collectd，以及使用 msgpack、json、edn 等通用数据格式的其他产品等。</p><h4 id="集中、转换、存储"><a href="#集中、转换、存储" class="headerlink" title="集中、转换、存储"></a>集中、转换、存储</h4><h5 id="输入-：采集各种样式、大小和来源的数据"><a href="#输入-：采集各种样式、大小和来源的数据" class="headerlink" title="输入 ：采集各种样式、大小和来源的数据"></a>输入 ：<strong>采集各种样式、大小和来源的数据</strong></h5><p>数据往往以各种各样的形式，或分散或集中地存在于很多系统中。Logstash 支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地从日志、指标、Web 应用、数据存储以及各种 AWS 服务采集数据</p><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/eae82eb4-f685-4eba-b74b-357634fe19d9.jpg" alt></p><h5 id="过滤器：实时解析和转换数据"><a href="#过滤器：实时解析和转换数据" class="headerlink" title="过滤器：实时解析和转换数据"></a><strong>过滤器：实时解析和转换数据</strong></h5><p>数据从源传输到存储库的过程中，Logstash 过滤器能够解析各个事件，识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松、更快速地分析和实现商业价值。</p><p>Logstash 能够动态地转换和解析数据，不受格式或复杂度的影响：</p><ul><li>利用 Grok 从非结构化数据中派生出结构</li><li>从 IP 地址破译出地理坐标</li><li>将 PII 数据匿名化，完全排除敏感字段</li><li>整体处理不受数据源、格式或架构的影响</li></ul><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/4be6aefc-3d40-4006-8a3e-1fc15fb15f04.jpg" alt></p><h5 id="选择你的存储，导出你的数据"><a href="#选择你的存储，导出你的数据" class="headerlink" title="选择你的存储，导出你的数据"></a><strong>选择你的存储，导出你的数据</strong></h5><p>尽管 Elasticsearch 是我们的首选输出方向，能够为我们的搜索和分析带来无限可能，但它并非唯一选择。</p><p>Logstash 提供众多输出选择，您可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。</p><p><img src="/2020/02/10/ELK%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0-%E4%B8%8A/93857fc5-d1d3-4538-9465-4eabf3670670.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在过往的单体应用时代，我们所有组件都部署到一台服务器中，那时日志管理平台的需求可能并没有那么强烈，我们只需要登录到一台服务器通过shell命令就可以很方便的查看系统日志，并快速定位问题。随着互联网的发展，互联网已经全面渗入到生活的各个领域，使用互联网的用户量也越来越多，单体应用已不能够支持庞大的用户的并发量，那么将单体应用进行拆分，通过水平扩展来支持庞大用户的使用迫在眉睫，微服务概念就是在类似这样的阶段诞生，在微服务盛行的互联网技术时代，单个应用被拆分为多个应用，每个应用集群部署进行负载均衡，那么如果某项业务发生系统错误，开发或运维人员还是以过往单体应用方式登录一台一台登录服务器查看日志来定位问题，这种解决线上问题的效率可想而知。日志管理平台的建设就显得极其重要。通过Logstash去收集每台服务器日志文件，然后按定义的正则模板过滤后传输到Kafka或redis，然后由另一个Logstash从KafKa或redis读取日志存储到elasticsearch中创建索引，最后通过Kibana展示给开发者或运维人员进行分析。这样大大提升了运维线上问题的效率。除此之外，还可以将收集的日志进行大数据分析，得到更有价值的数据给到高层进行决策。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ELK 提供的功能满足使用要求，并有较高的扩展性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ELK 为一套开源项目，较低的维护成本。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="ELK" scheme="http://JavaSsun.github.io/categories/ELK/"/>
    
      <category term="日志" scheme="http://JavaSsun.github.io/categories/ELK/%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="日志" scheme="http://JavaSsun.github.io/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="ELK" scheme="http://JavaSsun.github.io/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>Java8新特性</title>
    <link href="http://javassun.github.io/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/"/>
    <id>http://javassun.github.io/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/</id>
    <published>2020-02-08T04:43:25.000Z</published>
    <updated>2020-06-03T07:06:18.926Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>2014年，Oracle发布了Java8新版本后，愈来愈多的公司开始尝试使用Java8新特性来摆脱繁琐的语法，在使用Java8代码编写公司项目后，为了追上时代潮流，开始系统学习Java8的一些新特性。在收集整理网上各种Java8学习笔记后，此篇文章算是个人Java8学习笔记的小结。</p><ul><li>速度更块</li><li>代码更少（Lambda表达式）</li><li>强大的Stream API</li><li>便于并行</li><li>最大化减少空指针异常 Optional</li></ul><p><font color="red">核心为：Lambda表达式与Stream API</font></p><a id="more"></a><h2 id="1-Lambda表达式"><a href="#1-Lambda表达式" class="headerlink" title="1. Lambda表达式"></a>1. Lambda表达式</h2><h3 id="1-为什么使用Lambda表达式"><a href="#1-为什么使用Lambda表达式" class="headerlink" title="1. 为什么使用Lambda表达式"></a>1. 为什么使用Lambda表达式</h3><p><strong>Lambda</strong>是一个<font color="red">匿名函数</font>，我们可以把Lambda表达式理解为是<font color="red">一段可以传递的代码</font>（将代码像数据一样传递）。可以写出更简洁、更灵活的代码。作为一种紧凑的代码风格，使Java语言的表达更加凝练。</p><ul><li>从匿名类到 Lambda 的转换</li></ul><p>例子1：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;匿名内部类</span><br><span class="line">Runnable r1 &#x3D; new Runnable()&#123;</span><br><span class="line">     @Override</span><br><span class="line">     public void run()&#123;</span><br><span class="line">         System.out.println(&quot;Hello World!&quot;)</span><br><span class="line">     &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;Lambda 表达式</span><br><span class="line">Runnable r1 &#x3D; () -&gt; System.out.println(&quot;Hello World!&quot;);</span><br></pre></td></tr></table></figure><p>例子2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;原来使用匿名内部类作为参数传递</span><br><span class="line">TreeSet&lt;String&gt; ts &#x3D; new TreeSet&lt;&gt;(new Comparator&lt;String&gt;()&#123;</span><br><span class="line">     @Override</span><br><span class="line">     public int compare(String o1,String o2)&#123;</span><br><span class="line">        return Integer.compare(o1.length,o2.length());</span><br><span class="line">     &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;Lambda 表达式作为参数传递</span><br><span class="line">TreeSet&lt;String&gt; ts2 &#x3D; new TreeSet&lt;&gt;(</span><br><span class="line">     (o1,o2) -&gt; Integer.compare(o1.length(),o2.length())</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p> <font color="red"><strong>匿名内部类</strong></font>：冗余的语法。导致了“Height Problem”（只有一行在工作）</p><h3 id="2-Lambda表达式语法"><a href="#2-Lambda表达式语法" class="headerlink" title="2. Lambda表达式语法"></a>2. Lambda表达式语法</h3><p>Lambda 表达式在Java语言中引入了一个新的语法元素和操作符。这个操作符为 “<font color="red"> -&gt; </font>“，该操作符被称为 Lambda操作符 或 箭头操作符。它将Lambda分为两个部分：</p><p><strong>左侧：</strong>指定了 Lambda 表达式需要的所有参数<br><strong>右侧：</strong>指定了 Lambda 体，即 Lambda 表达式要执行的功能。</p><p><strong>语法格式一：无参，无返回值，Lambda只需一条语句</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Runnable r1 &#x3D; () -&gt; System.out.println(&quot;Hello Lambda&quot;);</span><br></pre></td></tr></table></figure><p><strong>语法格式二：Lambda需要一个参数</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Consumer&lt;String&gt; fun &#x3D; (args) -&gt; System.out.println(args);</span><br></pre></td></tr></table></figure><p><strong>语法格式三：Lambda只需要一个参数时，参数的小括号可省略</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Consummer&lt;String&gt; fun &#x3D; args -&gt; System.out.println(args);</span><br></pre></td></tr></table></figure><p><strong>语法格式四：Lambda需要两个参数，并且有返回值</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">BinaryOperator&lt;Long&gt; bo &#x3D; (x,y) -&gt;&#123;</span><br><span class="line">      System.out.println(&quot;实现函数接口方法&quot;);</span><br><span class="line">      return x + y;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>语法格式五：当Lambda体只有一条语句时，return与大括号可以省略</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BinaryOperator&lt;Long&gt; bo &#x3D; (x,y) -&gt; x + y;</span><br></pre></td></tr></table></figure><p><strong>语法格式六：Long数据类型可以省略，可由编译器推断，即“类型推断”</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">BinaryOperator&lt;Long&gt; bo &#x3D; (Long x,Long y) -&gt; &#123;</span><br><span class="line">         System.out.println(&quot;实现函数接口方法&quot;)；</span><br><span class="line">         x + y;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>Lambda</strong>是<font color="red"><strong>匿名内函数</strong></font>：提供了轻量级的语法。解决了匿名内部类带来的“高度”问题。</p><p>语法：<strong>参数列表</strong> <strong>-&gt;</strong> <strong>函数体</strong>三部分组成。<br>函数体：表达式、语句块。<br><font color="red"><strong>表达式</strong></font>：表达式会被执行然后返回执行结果。<br><font color="red"><strong>语句块</strong></font>：语句块中的语句会被依次执行，就像方法中的语句一样</p><ol><li>return语句会把控制权交给匿名函数的调用者</li><li>break和continue只能在循环中使用。</li><li>如果函数体有返回值。那么函数体内部的每一条路径都要有。</li></ol><p>表达式函数体适合小型<strong>Lambda</strong>表达式。消除了return关键字。简洁。</p><p><font color="red">新包</font>：<strong>java.util.function:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;接收 T对象 返回boolean</span><br><span class="line">Predicate&lt;T&gt; boolean test(T t)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 接收 T对象 不返回任何值</span><br><span class="line">Consumer&lt;T&gt; void accept(T t)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;接收 T对象 返回R对象</span><br><span class="line">Function(T,R) R apply(T t)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;提供 T对象（工厂T）</span><br><span class="line">Supplier&lt;T&gt; T get()</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 一元：接收T 返回T</span><br><span class="line">UnaryOperator&lt;T&gt;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 二元：接收两个T 返回T</span><br><span class="line">BinaryOperator&lt;T&gt;</span><br></pre></td></tr></table></figure><p>一些 Lambda表达式简单例子</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(int x,int y)-&gt;x+y; &#x2F;&#x2F;接收 x y 返回 x与y的和</span><br><span class="line">()-&gt;45;       &#x2F;&#x2F; 不接受参数 返回45</span><br><span class="line">(String s)-&gt;&#123;System.out.println(s);&#125; &#x2F;&#x2F;接收一个字符串，并把它打印在控制台</span><br></pre></td></tr></table></figure><h3 id="3-类型推断"><a href="#3-类型推断" class="headerlink" title="3. 类型推断"></a>3. 类型推断</h3><p>Lambda表达式无需指定类型，程序依然可以编译，因为 javac 根据程序上下文，在后台推断出了参数类型。Lambda表达式的类型依赖于上下文环境，是由编译器推断出来的。即所谓的“类型推断”。</p><h2 id="2-函数式接口"><a href="#2-函数式接口" class="headerlink" title="2. 函数式接口"></a>2. 函数式接口</h2><h3 id="1-什么是函数式接口"><a href="#1-什么是函数式接口" class="headerlink" title="1. 什么是函数式接口"></a>1. 什么是函数式接口</h3><ul><li><p>只包含了一个抽象方法的接口，称为<strong>函数式接口</strong></p></li><li><p>你可以通过 Lambda 表达式来创建该接口的对象。（若 Lambda 表达式抛出一个受检异常，那么该异常需要在目标接口的抽象方法上进行声明）。</p></li><li><p>我们可以在任意函数式接口上使用 <strong>@FunctionalInterface</strong> 注解，这样做可以检查它是否是一个函数式接口，同时 javadoc 也会包含一条声明，说明这个接口是一个函数式接口。</p></li></ul><h3 id="2-自定义函数式接口"><a href="#2-自定义函数式接口" class="headerlink" title="2. 自定义函数式接口"></a>2. 自定义函数式接口</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@FunctionalInterface</span><br><span class="line">public interface MyNumber&#123;</span><br><span class="line">   public double getValue();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;函数式接口中使用泛型：</span><br><span class="line">@FunctionalInterface</span><br><span class="line">public interface MyFunc&lt;T&gt;&#123;</span><br><span class="line">   public T getValue(T t);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;作为参数传递 Lambda 表达式</span><br><span class="line">public String toUpperString(MyFunc&lt;String&gt; mf, String str)&#123;</span><br><span class="line">        return mf.getValue(str);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">       String newStr &#x3D; toUpperString(</span><br><span class="line">       (str) -&gt; str.toUpperCase(), &quot;abcdef&quot;);</span><br><span class="line">       System.out.println(newStr);</span><br></pre></td></tr></table></figure><p><font color="red">作为参数传递 Lambda 表达式：为了将 Lambda 表达式作为参数传递，接收Lambda 表达式的参数类型必须是与该 Lambda 表达式兼容的函数式接口的类型。<br></font></p><h3 id="3-Java内治四大核心函数式接口"><a href="#3-Java内治四大核心函数式接口" class="headerlink" title="3. Java内治四大核心函数式接口"></a>3. Java内治四大核心函数式接口</h3><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/97801292-5716-4519-9bff-9f8f08aed48b.png" alt></p><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/743ea2bc-aeda-44e0-b691-31c354b94f47.png" alt></p><h2 id="3-方法引用与构造器引用"><a href="#3-方法引用与构造器引用" class="headerlink" title="3. 方法引用与构造器引用"></a>3. 方法引用与构造器引用</h2><h3 id="1-方法引用"><a href="#1-方法引用" class="headerlink" title="1. 方法引用"></a>1. 方法引用</h3><p>当要传递给Lambda体的操作，已经有实现的方法了，可以使用方法引用！<br>（实现抽象方法的参数列表，必须与方法引用方法的参数列表保持一致！）<br>方法引用：使用操作符 “::” 将方法名和对象或类的名字分隔开来。 如下三种主要使用情况：</p><ul><li><p><strong>对象::实例方法</strong></p></li><li><p><strong>类::静态方法</strong></p></li><li><p><strong>类::实例方法</strong></p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">() -&gt; System.out.println(x);</span><br><span class="line">等同于</span><br><span class="line">System.out::println;</span><br><span class="line"></span><br><span class="line">BinaryOperator&lt;Double&gt; bo &#x3D; (x,y) -&gt; Math.pow(x,y);</span><br><span class="line">等同于</span><br><span class="line">BinaryOperator&lt;Double&gt; bo &#x3D;Math::pow;</span><br><span class="line"></span><br><span class="line">compare((x,y) -&gt;x.equals(y), &quot;abcdef&quot; , &quot;abcdef&quot;);</span><br><span class="line">等同于</span><br><span class="line">compare(String::equals,&quot;abc&quot;,&quot;abc&quot;);</span><br></pre></td></tr></table></figure><p><strong>注意：当需要引用方法的第一个参数是调用对象，并且第二个参数是需要引<br>用方法的第二个参数(或无参数)时：ClassName::methodName</strong></p><h3 id="2-构造器引用"><a href="#2-构造器引用" class="headerlink" title="2. 构造器引用"></a>2. 构造器引用</h3><p><strong>格式： ClassName::new</strong><br>与函数式接口相结合，自动与函数式接口中方法兼容。 可以把构造器引用赋值给定义的方法，与构造器参数列表要与接口中抽象方法的参数列表一致！</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Function&lt;Integer,MyClass&gt; fun &#x3D; (n) -&gt; new MyClass(n);</span><br><span class="line">等同于</span><br><span class="line">Function&lt;Integer,MyClass&gt; fun &#x3D; MyClass::new;</span><br></pre></td></tr></table></figure><h3 id="3-数字引用"><a href="#3-数字引用" class="headerlink" title="3. 数字引用"></a>3. 数字引用</h3><p><strong>格式： type[] :: new</strong></p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Function&lt;Integer,Integer[]&gt; fun &#x3D; (n) -&gt; new Integer(n);</span><br><span class="line">等同于</span><br><span class="line">Function&lt;Integer,MyClass&gt; fun &#x3D; Integer[]::new;</span><br></pre></td></tr></table></figure><h2 id="4-Stream-API"><a href="#4-Stream-API" class="headerlink" title="4. Stream API"></a>4. Stream API</h2><h3 id="1-了解Stream"><a href="#1-了解Stream" class="headerlink" title="1. 了解Stream"></a>1. 了解Stream</h3><p>Java8中有两大最为重要的改变。第一个是 Lambda 表达式；另外一 个则是 <strong>Stream API(java.util.stream.*)</strong>。 Stream 是 Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。使用Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。也可以使用 Stream API 来并行执行操作。简而言之，Stream API 提供了一种高效且易于使用的处理数据的方式。</p><p>*<em>流(Stream)是数据渠道，用于操作数据源（集合、数组等）所生成的元素序列。<br>*</em><br><font color="red">“集合讲的是数据，流讲的是计算！”</font></p><ol><li>Stream 自己不会存储元素。</li><li>Stream 不会改变源对象。相反，他们会返回一个持有结果的新Stream。</li><li>Stream 操作是延迟执行的。这意味着他们会等到需要结果的时候才执行。</li></ol><h3 id="2-Stream三步骤"><a href="#2-Stream三步骤" class="headerlink" title="2. Stream三步骤"></a>2. Stream三步骤</h3><ul><li><p><strong>创建 Stream</strong><br>一个数据源（如：集合、数组），获取一个流</p></li><li><p><strong>中间操作</strong><br>一个中间操作链，对数据源的数据进行处理 </p></li><li><p><strong>终端操作</strong><br>一个终止操作，执行中间操作链，并产生结果<br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/37346492-7531-44b8-a2bf-681c14b381ec.jpg" alt></p></li></ul><h3 id="3-创建Stream"><a href="#3-创建Stream" class="headerlink" title="3. 创建Stream"></a>3. 创建Stream</h3><h4 id="1-Collection-创建流"><a href="#1-Collection-创建流" class="headerlink" title="1. Collection 创建流"></a>1. Collection 创建流</h4><ul><li><p>default Stream<E> stream() : 返回一个顺序流</E></p></li><li><p>default Stream<E> parallelStream() : 返回一个并行流</E></p></li></ul><h4 id="2-数组-创建流（Arrays的静态方法stream-创建）"><a href="#2-数组-创建流（Arrays的静态方法stream-创建）" class="headerlink" title="2. 数组 创建流（Arrays的静态方法stream()创建）"></a>2. 数组 创建流（Arrays的静态方法stream()创建）</h4><ul><li>static <T> Stream<T> stream(T[] array): 返回一个流</T></T></li></ul><p><strong>重载形式，能够处理对应基本类型的数组</strong></p><ul><li><p>public static IntStream stream(int[] array)</p></li><li><p>public static LongStream stream(long[] array)</p></li><li><p>public static DoubleStream stream(double[] array)</p></li></ul><h4 id="3-由值创建流"><a href="#3-由值创建流" class="headerlink" title="3. 由值创建流"></a>3. 由值创建流</h4><p>可以使用静态方法 Stream.of(), 通过显示值 创建一个流。它可以接收任意数量的参数。</p><ul><li>public static<T> Stream<T> of(T… values) : 返回一个流</T></T></li></ul><h4 id="4-由函数创建流：创建无限流"><a href="#4-由函数创建流：创建无限流" class="headerlink" title="4. 由函数创建流：创建无限流"></a>4. 由函数创建流：创建无限流</h4><p>可以使用静态方法 Stream.iterate() 和 Stream.generate(), 创建无限流。</p><ul><li>迭代</li></ul><p>public static<T> Stream<T> iterate(final T seed, final UnaryOperator<T> f)</T></T></T></p><ul><li>生成</li></ul><p>public static<T> Stream<T> generate(Supplier<T> s)</T></T></T></p><h3 id="4-Stream-的中间操作"><a href="#4-Stream-的中间操作" class="headerlink" title="4. Stream 的中间操作"></a>4. Stream 的中间操作</h3><p>多个中间操作可以连接起来形成一个流水线，除非流水 线上触发终止操作，否则中间操作不会执行任何的处理！ 而在终止操作时一次性全部处理，称为“惰性求值”。</p><p><strong>筛选与切片</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/853fb496-9885-4191-b20d-1d5c8508def5.png" alt></p><p><strong>映射</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/feb89458-0a81-42a9-9aa4-33b20b5991bf.png" alt></p><p><strong>排序</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/3a69b800-08f9-4bca-ab2d-51e3f3446635.png" alt></p><h3 id="5-Stream-的终止操作"><a href="#5-Stream-的终止操作" class="headerlink" title="5. Stream 的终止操作"></a>5. Stream 的终止操作</h3><p>终端操作会从流的流水线生成结果。其结果可以是任何不是流的 值，例如：List、Integer，甚至是 void 。</p><p><strong>查找与匹配</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/1cd0233f-598b-4537-8998-5e5fa24aada0.png" alt><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/bae6b149-cc4f-4f84-aec0-e27bf8afe015.png" alt></p><p><strong>归约</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/037bfd49-78ed-468b-aa65-4ad0242e490b.png" alt></p><p>备注：map 和 reduce 的连接通常称为 map-reduce 模式，因 Google 用它 来进行网络搜索而出名。</p><p><strong>收集</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/2cccbffb-7df8-4a65-8153-537071e75bd7.png" alt></p><p>Collector 接口中方法的实现决定了如何对流执行收集操作(如收集到 List、Set、Map)。但是 Collectors 实用类提供了很多静态方法，可以方便地创建常见收集器实例，具体方法与实例如下表：</p><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/2399d052-df02-4998-909e-559f6b815d8a.png" alt></p><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/15609436-aba0-444c-8ca9-4fc5870b9fb5.png" alt></p><h3 id="6-并行流与串行流"><a href="#6-并行流与串行流" class="headerlink" title="6. 并行流与串行流"></a>6. 并行流与串行流</h3><p><strong>并行流</strong>就是把一个内容分成多个数据块，并用不同的线程分 别处理每个数据块的流。</p><p>Java 8 中将并行进行了优化，我们可以很容易的对数据进行并 行操作。Stream API 可以声明性地通过 parallel() 与 sequential() 在并行流与顺序流之间进行切换。</p><h3 id="7-了解-Fork-Join-框架"><a href="#7-了解-Fork-Join-框架" class="headerlink" title="7. 了解 Fork/Join 框架"></a>7. 了解 Fork/Join 框架</h3><p><strong>Fork/Join 框架</strong>:就是在必要的情况下，将一个大任务，进行拆分(fork)成若干个小任务（拆到不可再拆时），再将一个个的小任务运算的结果进行 join 汇总.</p><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/84eaed9b-717b-47f9-9f0a-f5fde05f7472.jpg" alt></p><h3 id="8-Fork-Join-框架与传统线程池的区别"><a href="#8-Fork-Join-框架与传统线程池的区别" class="headerlink" title="8. Fork/Join 框架与传统线程池的区别"></a>8. Fork/Join 框架与传统线程池的区别</h3><p>采用 “工作窃取”模式（work-stealing）：<br>当执行新的任务时它可以将其拆分分成更小的任务执行，并将小任务加到线程队列中，然后再从一个随机线程的队列中偷一个并把它放在自己的队列中。</p><p>相对于一般的线程池实现,fork/join框架的优势体现在对其中包含的任务的<br>处理方式上.在一般的线程池中,如果一个线程正在执行的任务由于某些原因<br>无法继续运行,那么该线程会处于等待状态.而在fork/join框架实现中,如果<br>某个子问题由于等待另外一个子问题的完成而无法继续运行.那么处理该子<br>问题的线程会主动寻找其他尚未运行的子问题来执行.这种方式减少了线程<br>的等待时间,提高了性能.</p><h2 id="5-新时间日期API"><a href="#5-新时间日期API" class="headerlink" title="5. 新时间日期API"></a>5. 新时间日期API</h2><ul><li>LocalDate、LocalTime、LocalDateTime 类的实 例是<strong>不可变的对象</strong>，分别表示使用 ISO-8601日 历系统的日期、时间、日期和时间。它们提供了简单的日期或时间，并不包含当前的时间信息。也不包含与时区相关的信息。</li></ul><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/1d49dcda-eb3d-4eb7-aa3c-889e5607867f.png" alt></p><p><strong>Instant 时间戳</strong></p><ul><li>用于“时间戳”的运算。它是以Unix元年(传统 的设定为UTC时区1970年1月1日午夜时分)开始 所经历的描述进行运算</li></ul><p><strong>Duration 和 Period</strong></p><ul><li><p>Duration:用于计算两个“时间”间隔</p></li><li><p>Period:用于计算两个“日期”间隔</p></li><li><p>日期的操纵</p></li><li><p>TemporalAdjuster : 时间校正器。有时我们可能需要获 取例如：将日期调整到“下个周日”等操作。</p></li><li><p>TemporalAdjusters : 该类通过静态方法提供了大量的常 用 TemporalAdjuster 的实现。</p></li></ul><p>例如获取下个周日：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LocalDate nextSunday &#x3D; LocalDate.now().with(</span><br><span class="line">   TemporalAdjusters.next(DayOfWeek.SUNDAY)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p><strong>解析与格式化</strong></p><p>java.time.format.DateTimeFormatter 类：该类提供了三种 格式化方法：</p><ul><li><p>预定义的标准格式</p></li><li><p>语言环境相关的格式</p></li><li><p>自定义的格式</p></li></ul><p><strong>时区的处理</strong></p><ul><li>Java8 中加入了对时区的支持，带时区的时间为分别为：</li></ul><p>ZonedDate、ZonedTime、ZonedDateTime<br>其中每个时区都对应着 ID，地区ID都为 “{区域}/{城市}”的格式<br>例如 ：Asia/Shanghai 等</p><p>ZoneId：该类中包含了所有的时区信息</p><p>getAvailableZoneIds() : 可以获取所有时区时区信息<br>of(id) : 用指定的时区信息获取 ZoneId 对象</p><p><strong>与传统日期处理的转换</strong><br><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/0b30f162-415f-4a9c-a650-ba13116ff20b.png" alt></p><h2 id="6-接口中的默认方法与静态方法"><a href="#6-接口中的默认方法与静态方法" class="headerlink" title="6. 接口中的默认方法与静态方法"></a>6. 接口中的默认方法与静态方法</h2><h3 id="1-接口中的默认方法"><a href="#1-接口中的默认方法" class="headerlink" title="1. 接口中的默认方法"></a>1. 接口中的默认方法</h3><p>Java 8中允许接口中包含具有具体实现的方法，该方法称为 “默认方法”，默认方法使用 default 关键字修饰。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">例如：</span><br><span class="line">interface MyFunc&lt;T&gt;&#123;</span><br><span class="line">  T func(int a);</span><br><span class="line"></span><br><span class="line">  default String getName()&#123;</span><br><span class="line">     return &quot;Hello Java&quot;;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>*<em>接口默认方法的”类优先”原则 *</em></p><p>若一个接口中定义了一个默认方法，而另外一个父类或接口中 又定义了一个同名的方法时</p><ul><li><p>选择父类中的方法。如果一个父类提供了具体的实现，那么 接口中具有相同名称和参数的默认方法会被忽略。</p></li><li><p>接口冲突。如果一个父接口提供一个默认方法，而另一个接 口也提供了一个具有相同名称和参数列表的方法（不管方法 是否是默认方法），那么必须覆盖该方法来解决冲突</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">interface MyFunc&#123;</span><br><span class="line">   default String getName()&#123;</span><br><span class="line">        return &quot;Hello World&quot;;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">interface Named&#123;</span><br><span class="line">   default String getName()&#123;</span><br><span class="line">        return &quot;Hello java8&quot;;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class MyClass implements MyFunc,Named&#123;</span><br><span class="line">   public String getName()&#123;</span><br><span class="line">        return Named.super.getName();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-接口中的静态方法"><a href="#2-接口中的静态方法" class="headerlink" title="2. 接口中的静态方法"></a>2. 接口中的静态方法</h3><p>Java8 中，接口中允许添加静态方法</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">interface Named&#123;</span><br><span class="line">  public Integer myFun();</span><br><span class="line"></span><br><span class="line">  default String getName()&#123;</span><br><span class="line">     return &quot;Hello World&quot;;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  static void show()&#123;</span><br><span class="line">     System.out.println(&quot;Hello Lambda&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="7-其他新特性"><a href="#7-其他新特性" class="headerlink" title="7. 其他新特性"></a>7. 其他新特性</h2><p><strong>Optional 类</strong></p><p>Optional<T> 类(java.util.Optional) 是一个容器类，代表一个值存在或不存在，原来用 null 表示一个值不存在，现在 Optional 可以更好的表达这个概念。并且可以避免空指针异常。</T></p><p><strong>常用方法：</strong><br>Optional.of(T t) : 创建一个 Optional 实例<br>Optional.empty() : 创建一个空的 Optional 实例<br>Optional.ofNullable(T t):若 t 不为 null,创建 Optional 实例,否则创建空实例<br>isPresent() : 判断是否包含值<br>orElse(T t) :  如果调用对象包含值，返回该值，否则返回t<br>orElseGet(Supplier s) :如果调用对象包含值，返回该值，否则返回 s 获取的值<br>map(Function f): 如果有值对其处理，并返回处理后的Optional，否则返回 Optional.empty()<br>flatMap(Function mapper):与 map 类似，要求返回值必须是Optional</p><p><strong>重复注解与类型注解</strong></p><p>Java 8对注解处理提供了两点改进：可重复的注解及可用于类型的注解。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@Target(&#123;TYPE,FIELD,METHOD,PARAMETER,CONSTRUCTOR,LOCAL_VARIABLE&#125;)</span><br><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">public @interface MyAnnotations&#123;</span><br><span class="line">   MyAnnotation[] value();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Repeatable(MyAnnotations.class)</span><br><span class="line">@Target(&#123;TYPE,FIELD,METHOD,PARAMETER,CONSTRUCTOR,LOCAL_VARIABLE,ElementType.TYPE_PARAMETER&#125;)</span><br><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">public @interface MyAnnotation&#123;</span><br><span class="line">   String value();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@MyAnnotation(&quot;Hello&quot;)</span><br><span class="line">@MyAnnotation(&quot;World&quot;)</span><br><span class="line">public void show(@MyAnnotation(&quot;abc&quot;) String str)&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="练习题"><a href="#练习题" class="headerlink" title="练习题"></a>练习题</h2><p>1 交易员</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line">public class Trader &#123;</span><br><span class="line">     private String name;</span><br><span class="line">     private String city;</span><br><span class="line">     public Trader(String name, String city) &#123;</span><br><span class="line">        this.name &#x3D; name;</span><br><span class="line">        this.city &#x3D; city;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; getter setter方法省略</span><br><span class="line"></span><br><span class="line">public class Transaction &#123;</span><br><span class="line">     private Trader trader;</span><br><span class="line">     private int year;</span><br><span class="line">     private int value;</span><br><span class="line">     public Transaction(Trader trader, int year, int value) &#123;</span><br><span class="line">        this.trader &#x3D; trader;</span><br><span class="line">        this.year &#x3D; year;</span><br><span class="line">        this.value &#x3D; value;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class PuttingIntoPractice &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Trader raoul &#x3D; new Trader(&quot;Raoul&quot;,&quot;Cambridge&quot;);</span><br><span class="line">        Trader mario &#x3D; new Trader(&quot;mario&quot;,&quot;Milan&quot;);</span><br><span class="line">        Trader alen &#x3D; new Trader(&quot;alen&quot;,&quot;Cambridge&quot;);</span><br><span class="line">        Trader brian &#x3D; new Trader(&quot;brian&quot;,&quot;Cambridge&quot;);</span><br><span class="line"></span><br><span class="line">  List&lt;Transaction&gt; transactions &#x3D; Arrays.asList(</span><br><span class="line">          new Transaction(brian,2011,300),</span><br><span class="line">          new Transaction(raoul,2012,1000),</span><br><span class="line">          new Transaction(raoul,2011,400),</span><br><span class="line">          new Transaction(mario,2012,710),</span><br><span class="line">          new Transaction(mario,2012,700),</span><br><span class="line">          new Transaction(alen,2012,950)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (1) 找出2011年发生的所有交易，并按交易额排序（从低到高）。</span><br><span class="line">  transactions.stream()</span><br><span class="line">                .filter(transaction -&gt; transaction.getYear() &#x3D;&#x3D; 2011)</span><br><span class="line">.sorted(Comparator.comparing(Transaction::getValue))</span><br><span class="line">                .collect(Collectors.toList())</span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (2) 交易员都在哪些不同的城市工作过？</span><br><span class="line">  transactions.stream()</span><br><span class="line">                .map(transaction -&gt; transaction.getTrader().getCity())</span><br><span class="line">                .distinct()</span><br><span class="line">                .collect(Collectors.toList())</span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (3) 查找所有来自于剑桥的交易员，并按姓名排序。</span><br><span class="line">  transactions.stream()</span><br><span class="line">                .map(Transaction::getTrader)</span><br><span class="line">                .filter(trader -&gt; trader.getCity().equals(&quot;Cambridge&quot;))</span><br><span class="line">                .distinct()</span><br><span class="line">                .sorted(Comparator.comparing(Trader::getName))</span><br><span class="line">                .collect(Collectors.toList())</span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (4) 返回所有交易员的姓名字符串，按字母顺序排序。</span><br><span class="line">  String traderStr &#x3D; transactions.stream()</span><br><span class="line">                .map(transaction -&gt; transaction.getTrader().getName())</span><br><span class="line">                .distinct()</span><br><span class="line">                .sorted()</span><br><span class="line">                .reduce(&quot;&quot;, (n1, n2) -&gt; n1 + n2);</span><br><span class="line">  System.out.println(traderStr);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (5) 有没有交易员是在米兰工作的？</span><br><span class="line">  boolean miLanBased &#x3D; transactions.stream()</span><br><span class="line">                .anyMatch(transaction -&gt; transaction.getTrader()</span><br><span class="line">                        .getCity().equals(&quot;MiLan&quot;));</span><br><span class="line">  System.out.println(miLanBased);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (6) 打印生活在剑桥的交易员的所有交易额。</span><br><span class="line"> transactions.stream()</span><br><span class="line">                .filter(transaction -&gt; transaction.getTrader().getCity().equals(&quot;Cambridge&quot;))</span><br><span class="line">                .map(transaction -&gt; transaction.getValue())</span><br><span class="line">                .collect(Collectors.toList())</span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (7) 所有交易中，最高的交易额是多少？</span><br><span class="line">  int highestValue &#x3D; transactions.stream()</span><br><span class="line">                .map(Transaction::getValue)</span><br><span class="line">                .reduce(0,Integer::max);</span><br><span class="line">  System.out.println(highestValue);</span><br><span class="line"></span><br><span class="line">  transactions.stream()</span><br><span class="line">  .sorted(Comparator.comparing(Transaction::getValue).reversed())</span><br><span class="line">                .findFirst()</span><br><span class="line">                .ifPresent(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (8) 找到交易额最小的交易。</span><br><span class="line">  transactions.stream()</span><br><span class="line">                .map(Transaction::getValue)</span><br><span class="line">                .reduce(Integer::min)</span><br><span class="line">                .ifPresent(System.out::println);</span><br><span class="line"></span><br><span class="line">  transactions.stream()</span><br><span class="line">             .min(Comparator.comparing(Transaction::getValue))</span><br><span class="line">                .ifPresent(System.out::println);</span><br><span class="line"></span><br><span class="line">  transactions.stream()</span><br><span class="line">                .min(Comparator.comparing((Transaction t1)-&gt; t1.getValue()))</span><br><span class="line">                .ifPresent(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (9) 统计每个交易员的记录</span><br><span class="line">  transactions.stream()</span><br><span class="line">       .collect(Collectors.groupingBy(Transaction::getTrader))</span><br><span class="line">                .entrySet().stream()</span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        (10) 找到单笔交易最高的交易员</span><br><span class="line">  transactions.stream()</span><br><span class="line">             .max(Comparator.comparing(Transaction::getValue))</span><br><span class="line">                .ifPresent(tran -&gt;&#123;</span><br><span class="line">                    System.out.println(tran.getTrader());</span><br><span class="line">  &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>更多练习参考网络</p><h2 id="8-java8红黑树"><a href="#8-java8红黑树" class="headerlink" title="8. java8红黑树"></a>8. java8红黑树</h2><h3 id="HashMap数据结构"><a href="#HashMap数据结构" class="headerlink" title="HashMap数据结构"></a>HashMap数据结构</h3><p>回顾：HashSet是基于HashCode实现元素不重复的。当插入元素的哈希码相同时，会调用equals方法进行二次比较，如果相同，则新值替旧值。如果不同，则以链表的形式挂在当前元素所在的位置。</p><p>扩容因子：0.75</p><p>如果是1 ，则可能永远是只插入到两个位置，形成部分元素的长链表。每次都要在哈希码相同时进行equals比较（哈希碰撞）。降低性能。</p><p>如果是&lt;0.75,则可能浪费空间。</p><h3 id="数组-链表-红黑树-二叉树的一种"><a href="#数组-链表-红黑树-二叉树的一种" class="headerlink" title="数组-链表-红黑树(二叉树的一种)"></a>数组-链表-红黑树(二叉树的一种)</h3><p><strong>条件：当碰撞元素个数&gt;8 &amp;&amp; 总容量&gt;64 将其转换为红黑树</strong></p><p><font color="red">碰撞元素个数</font>：一个数组元素上所挂载的（链表）元素个数。</p><p><font color="red">JDK7是数组-&gt;链表</font>：一个数组元素上所挂载的（链表）元素个数。</p><p><font color="red">JDK8是数组-链表</font>： 当转变为红黑树时，添加的效率变低。其他效率都高了。平衡二叉树（比当前值与节点值的大小）</p><p>扩容是：原来表会计算hashcode值进行元素的再次填充。</p><p>现在只需要找原来表的总长度+当前所在的位置，就是当前扩容后的位置。（不需要再次进行哈希计算）。</p><p><strong>ConcurrentHashMap：效率提高</strong></p><p>JDK7: ConcurrentLevel = 16<br>JDK8：CAS算法</p><p><img src="/2020/02/08/Java8%E6%96%B0%E7%89%B9%E6%80%A7/7d750713-3d72-48e3-b512-d11dc1900f92.jpg" alt></p><h2 id="9-CompletableFuture"><a href="#9-CompletableFuture" class="headerlink" title="9. CompletableFuture"></a>9. CompletableFuture</h2><p><strong>CompletableFuture</strong>类实现了CompletionStage和Future接口。Future是Java 5添加的类，用来描述一个异步计算的结果，但是获取一个结果时方法较少,要么通过轮询isDone，确认完成后，调用get()获取值，要么调用get()设置一个超时时间。但是这个get()方法会阻塞住调用线程，这种阻塞的方式显然和我们的异步编程的初衷相违背。</p><p>为了解决这个问题，JDK吸收了guava的设计思想，加入了Future的诸多扩展功能形成了CompletableFuture。</p><p><strong>CompletionStage</strong>是一个接口，从命名上看得知是一个完成的阶段，它里面的方法也标明是在某个运行阶段得到了结果之后要做的事情。</p><h3 id="1-Future-Callable"><a href="#1-Future-Callable" class="headerlink" title="1. Future+Callable"></a>1. Future+Callable</h3><p>  在JDK1.5已经提供了Future和Callable的实现,可以用于阻塞式获取结果,如果想要异步获取结果,通常都会以轮询的方式去获取结果,如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;定义一个异步任务</span><br><span class="line">Future&lt;String&gt; future &#x3D; executor.submit(()-&gt;&#123;</span><br><span class="line">       Thread.sleep(2000);</span><br><span class="line">       return &quot;hello world&quot;;</span><br><span class="line">&#125;);</span><br><span class="line">&#x2F;&#x2F;轮询获取结果</span><br><span class="line">while (true)&#123;</span><br><span class="line">    if(future.isDone()) &#123;</span><br><span class="line">         System.out.println(future.get());</span><br><span class="line">         break;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>从上面的形式看来轮询的方式会耗费无谓的CPU资源，而且也不能及时地得到计算结果.所以要实现真正的异步,上述这样是完全不够的,在<strong>Netty</strong>中,我们随处可见异步编程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ChannelFuture f &#x3D; serverBootstrap.bind(port).sync();</span><br><span class="line">f.addListener(new GenericFutureListener&lt;Future&lt;? super Void&gt;&gt;() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void operationComplete(Future&lt;? super Void&gt; future) throws Exception &#123;</span><br><span class="line">                    System.out.println(&quot;complete&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br></pre></td></tr></table></figure><p>而JDK1.8中的<code>CompletableFuture</code>就为我们提供了异步函数式编程,<code>CompletableFuture</code>提供了非常强大的<code>Future</code>的扩展功能，可以帮助我们简化异步编程的复杂性，提供了函数式编程的能力，可以通过回调的方式处理计算结果，并且提供了转换和组合<code>CompletableFuture</code>的方法。</p><h3 id="2-Future扩展"><a href="#2-Future扩展" class="headerlink" title="2. Future扩展"></a>2. Future扩展</h3><h4 id="1-创建CompletableFuture对象"><a href="#1-创建CompletableFuture对象" class="headerlink" title="1. 创建CompletableFuture对象"></a>1. 创建CompletableFuture对象</h4><p><code>CompletableFuture</code>提供了四个静态方法用来创建CompletableFuture对象：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public static CompletableFuture&lt;Void&gt;   runAsync(Runnable runnable)</span><br><span class="line">public static CompletableFuture&lt;Void&gt;   runAsync(Runnable runnable, Executor executor)</span><br><span class="line">public static &lt;U&gt; CompletableFuture&lt;U&gt;  supplyAsync(Supplier&lt;U&gt; supplier)</span><br><span class="line">public static &lt;U&gt; CompletableFuture&lt;U&gt;  supplyAsync(Supplier&lt;U&gt; supplier, Executor executor)</span><br></pre></td></tr></table></figure><p><code>Asynsc</code>表示异步,而<code>supplyAsync</code>与<code>runAsync</code>不同在于前者异步返回一个结果,后者是void.第二个函数第二个参数表示是用我们自己创建的线程池,否则采用默认的<code>ForkJoinPool.commonPool()</code>作为它的线程池.其中<code>Supplier</code>是一个函数式接口,代表是一个生成者的意思,传入0个参数,返回一个结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CompletableFuture&lt;String&gt; future &#x3D; CompletableFuture.supplyAsync(()-&gt;&#123;</span><br><span class="line">            return &quot;hello world&quot;;</span><br><span class="line">  &#125;);</span><br><span class="line">System.out.println(future.get());  &#x2F;&#x2F;阻塞的获取结果  &#39;&#39;helllo world&quot;</span><br></pre></td></tr></table></figure><h4 id="2-主动计算"><a href="#2-主动计算" class="headerlink" title="2. 主动计算"></a>2. 主动计算</h4><p>以下4个方法用于获取结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;同步获取结果</span><br><span class="line">public T    get()</span><br><span class="line">public T    get(long timeout, TimeUnit unit)</span><br><span class="line">public T    getNow(T valueIfAbsent)</span><br><span class="line">public T    join()</span><br></pre></td></tr></table></figure><p><code>getNow</code>有点特殊，如果结果已经计算完则返回结果或者抛出异常，否则返回给定的valueIfAbsent值。<code>join()</code>与<code>get()</code>区别在于<code>join()</code>返回计算的结果或者抛出一个unchecked异常(CompletionException)，而<code>get()</code>返回一个具体的异常.</p><ul><li>主动触发计算</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">public boolean complete(T  value)</span><br><span class="line">public boolean completeExceptionally(Throwable ex)</span><br></pre></td></tr></table></figure><p>上面方法表示当调用<code>CompletableFuture.get()</code>被阻塞的时候,那么这个方法就是结束阻塞,并且<code>get()</code>获取设置的value.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public static CompletableFuture&lt;Integer&gt; compute() &#123;</span><br><span class="line">       final CompletableFuture&lt;Integer&gt; future &#x3D; new CompletableFuture&lt;&gt;();</span><br><span class="line">       return future;</span><br><span class="line">   &#125;</span><br><span class="line">   public static void main(String[] args) throws Exception &#123;</span><br><span class="line">       final CompletableFuture&lt;Integer&gt; f &#x3D; compute();</span><br><span class="line">       class Client extends Thread &#123;</span><br><span class="line">           CompletableFuture&lt;Integer&gt; f;</span><br><span class="line">           Client(String threadName, CompletableFuture&lt;Integer&gt; f) &#123;</span><br><span class="line">               super(threadName);</span><br><span class="line">               this.f &#x3D; f;</span><br><span class="line">           &#125;</span><br><span class="line">           @Override</span><br><span class="line">           public void run() &#123;</span><br><span class="line">               try &#123;</span><br><span class="line">                   System.out.println(this.getName() + &quot;: &quot; + f.get());</span><br><span class="line">               &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                   e.printStackTrace();</span><br><span class="line">               &#125; catch (ExecutionException e) &#123;</span><br><span class="line">                   e.printStackTrace();</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       new Client(&quot;Client1&quot;, f).start();</span><br><span class="line">       new Client(&quot;Client2&quot;, f).start();</span><br><span class="line">       System.out.println(&quot;waiting&quot;);</span><br><span class="line">       &#x2F;&#x2F;设置Future.get()获取到的值</span><br><span class="line">       f.complete(100);</span><br><span class="line">       &#x2F;&#x2F;以异常的形式触发计算</span><br><span class="line">       &#x2F;&#x2F;f.completeExceptionally(new Exception());</span><br><span class="line">       Thread.sleep(1000);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h4 id="3-计算结果完成时的处理"><a href="#3-计算结果完成时的处理" class="headerlink" title="3. 计算结果完成时的处理"></a>3. 计算结果完成时的处理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public CompletableFuture&lt;T&gt;     whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action)</span><br><span class="line">public CompletableFuture&lt;T&gt;     whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action)</span><br><span class="line">public CompletableFuture&lt;T&gt;     whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action, Executor executor)</span><br><span class="line">public CompletableFuture&lt;T&gt;     exceptionally(Function&lt;Throwable,? extends T&gt; fn)</span><br></pre></td></tr></table></figure><meta charset="utf-8">发,`BiConsumer`有两个入参,分别代表计算返回值,另外一个是异常.无返回值.方法不以Async结尾，意味着Action使用相同的线程执行，而Async可能会使用其它的线程去执行(如果使用相同的线程池，也可能会被同一个线程选中执行)。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">future.whenCompleteAsync((v,e)-&gt;&#123;</span><br><span class="line">       System.out.println(&quot;return value:&quot;+v+&quot;  exception:&quot;+e);</span><br><span class="line"> &#125;);</span><br></pre></td></tr></table></figure><ul><li>handle()</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public &lt;U&gt; CompletableFuture&lt;U&gt;     handle(BiFunction&lt;? super T,Throwable,? extends U&gt; fn)</span><br><span class="line">public &lt;U&gt; CompletableFuture&lt;U&gt;     handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn)</span><br><span class="line">public &lt;U&gt; CompletableFuture&lt;U&gt;     handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn, Executor executor)</span><br></pre></td></tr></table></figure><h4 id="4-CompletableFuture的组合"><a href="#4-CompletableFuture的组合" class="headerlink" title="4. CompletableFuture的组合"></a>4. CompletableFuture的组合</h4><ul><li>thenApply<br>当计算结算完成之后,后面可以接继续一系列的thenApply,来完成值的转化.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public &lt;U&gt; CompletableFuture&lt;U&gt;     thenApply(Function&lt;? super T,? extends U&gt; fn)</span><br><span class="line">public &lt;U&gt; CompletableFuture&lt;U&gt;     thenApplyAsync(Function&lt;? super T,? extends U&gt; fn)</span><br><span class="line">public &lt;U&gt; CompletableFuture&lt;U&gt;     thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor)</span><br></pre></td></tr></table></figure><p>它们与handle方法的区别在于handle方法会处理正常计算值和异常，因此它可以屏蔽异常，避免异常继续抛出。而thenApply方法只是用来处理正常值，因此一旦有异常就会抛出。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">  CompletableFuture&lt;String&gt; future &#x3D; CompletableFuture.supplyAsync(()-&gt;&#123;</span><br><span class="line"></span><br><span class="line">            return &quot;hello world&quot;;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">CompletableFuture&lt;String&gt; future3 &#x3D; future.thenApply((element)-&gt;&#123;</span><br><span class="line">            return element+&quot;  addPart&quot;;</span><br><span class="line">        &#125;).thenApply((element)-&gt;&#123;</span><br><span class="line">            return element+&quot;  addTwoPart&quot;;</span><br><span class="line">        &#125;);</span><br><span class="line">        System.out.println(future3.get());&#x2F;&#x2F;hello world  addPart  addTwoPart</span><br></pre></td></tr></table></figure><h4 id="5-CompletableFuture的Consumer"><a href="#5-CompletableFuture的Consumer" class="headerlink" title="5. CompletableFuture的Consumer"></a>5. CompletableFuture的Consumer</h4><p>只对<code>CompletableFuture</code>的结果进行消费,无返回值,也就是最后的<code>CompletableFuture</code>是void.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public CompletableFuture&lt;Void&gt;  thenAccept(Consumer&lt;? super T&gt; action)</span><br><span class="line">public CompletableFuture&lt;Void&gt;  thenAcceptAsync(Consumer&lt;? super T&gt; action)</span><br><span class="line">public CompletableFuture&lt;Void&gt;  thenAcceptAsync(Consumer&lt;? super T&gt; action, Executor executor)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;入参为原始的CompletableFuture的结果.</span><br><span class="line">CompletableFuture future4 &#x3D; future.thenAccept((e)-&gt;&#123;</span><br><span class="line">            System.out.println(&quot;without return value&quot;);</span><br><span class="line">        &#125;);</span><br><span class="line">future4.get();</span><br></pre></td></tr></table></figure><ul><li>thenAcceptBoth</li></ul><p>这个方法用来组合两个<code>CompletableFuture</code>,其中一个<code>CompletableFuture</code>等待另一个<code>CompletableFuture</code>的结果.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CompletableFuture&lt;String&gt; future &#x3D; CompletableFuture.supplyAsync(()-&gt;&#123;</span><br><span class="line">            return &quot;hello world&quot;;</span><br><span class="line">        &#125;);</span><br><span class="line">CompletableFuture future5 &#x3D;  future.thenAcceptBoth(CompletableFuture.completedFuture(&quot;compose&quot;),</span><br><span class="line">                (x, y) -&gt; System.out.println(x+y));&#x2F;&#x2F;hello world compose</span><br></pre></td></tr></table></figure><h4 id="6-Either和ALL"><a href="#6-Either和ALL" class="headerlink" title="6. Either和ALL"></a>6. Either和ALL</h4><p><code>thenAcceptBoth</code>是当两个<code>CompletableFuture</code>都计算完成，而我们下面要了解的方法<code>applyToEither</code>是当任意一个CompletableFuture计算完成的时候就会执行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Random rand &#x3D; new Random();</span><br><span class="line">        CompletableFuture&lt;Integer&gt; future9 &#x3D; CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(1000 + rand.nextInt(1000));</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return 100;</span><br><span class="line">        &#125;);</span><br><span class="line">        CompletableFuture&lt;Integer&gt; future10 &#x3D; CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(1000 + rand.nextInt(1000));</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return 200;</span><br><span class="line">        &#125;);</span><br><span class="line">        &#x2F;&#x2F;两个中任意一个计算完成,那么触发Runnable的执行</span><br><span class="line">        CompletableFuture&lt;String&gt; f &#x3D;  future10.applyToEither(future9,i -&gt; i.toString());</span><br><span class="line">        &#x2F;&#x2F;两个都计算完成,那么触发Runnable的执行</span><br><span class="line">        CompletableFuture f1 &#x3D; future10.acceptEither(future9,(e)-&gt;&#123;</span><br><span class="line">            System.out.println(e);</span><br><span class="line">        &#125;);</span><br><span class="line">        System.out.println(f.get());</span><br></pre></td></tr></table></figure><p>如果想组合超过2个以上的<code>CompletableFuture</code>,<code>allOf</code>和<code>anyOf</code>可能会满足你的要求.<code>allOf</code>方法是当所有的<code>CompletableFuture</code>都执行完后执行计算。<code>anyOf</code>方法是当任意一个<code>CompletableFuture</code>执行完后就会执行计算，计算的结果相同。</p><h4 id="7-练习"><a href="#7-练习" class="headerlink" title="7. 练习"></a>7. 练习</h4><p><strong>1. 进行变换</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public &lt;U&gt; CompletionStage&lt;U&gt; thenApply(Function&lt;? super T,? extends U&gt; fn);</span><br><span class="line"></span><br><span class="line">public &lt;U&gt; CompletionStage&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn);</span><br><span class="line"></span><br><span class="line">public &lt;U&gt; CompletionStage&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn,Executor executor);</span><br></pre></td></tr></table></figure><p>首先说明一下已Async结尾的方法都是可以异步执行的，如果指定了线程池，会在指定的线程池中执行，如果没有指定，默认会在ForkJoinPool.commonPool()中执行。关键的入参只有一个Function，它是函数式接口，所以使用Lambda表示起来会更加优雅。它的入参是上一个阶段计算后的结果，返回值是经过转化后结果。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> @Test</span><br><span class="line">    public void thenApply() &#123;</span><br><span class="line">        String result &#x3D; CompletableFuture.supplyAsync(() -&gt; &quot;hello&quot;).thenApply(s -&gt; s + &quot; world&quot;).join();</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p><strong>2. 进行消耗</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public CompletionStage&lt;Void&gt; thenAccept(Consumer&lt;? super T&gt; action);</span><br><span class="line"></span><br><span class="line">public CompletionStage&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action);</span><br><span class="line"></span><br><span class="line">public CompletionStage&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action,Executor executor);</span><br></pre></td></tr></table></figure><p>thenAccept是针对结果进行消耗，因为他的入参是Consumer，有入参无返回值。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void thenAccept()&#123;    </span><br><span class="line">       CompletableFuture.supplyAsync(() -&gt; &quot;hello&quot;).thenAccept(s -&gt; System.out.println(s+&quot; world&quot;));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p><strong>3. 对上一步的计算结果不关心，执行下一个操作。</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public CompletionStage&lt;Void&gt; thenRun(Runnable action);</span><br><span class="line"></span><br><span class="line">public CompletionStage&lt;Void&gt; thenRunAsync(Runnable action);</span><br><span class="line"></span><br><span class="line">public CompletionStage&lt;Void&gt; thenRunAsync(Runnable action,Executor executor);</span><br></pre></td></tr></table></figure><p>thenRun它的入参是一个Runnable的实例，表示当得到上一步的结果时的操作。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">    public void thenRun()&#123;</span><br><span class="line">        CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;hello&quot;;</span><br><span class="line">        &#125;).thenRun(() -&gt; System.out.println(&quot;hello world&quot;));</span><br><span class="line">        while (true)&#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p><strong>4. 结合两个CompletionStage的结果，进行转化后返回</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombine(CompletionStage&lt;? extends U&gt; other,BiFunction&lt;? super T,? super U,? extends V&gt; fn);</span><br><span class="line"></span><br><span class="line">public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other,BiFunction&lt;? super T,? super U,? extends V&gt; fn);</span><br><span class="line"></span><br><span class="line">public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other,BiFunction&lt;? super T,? super U,? extends V&gt; fn,Executor executor);</span><br></pre></td></tr></table></figure><p>它需要原来的处理返回值，并且other代表的CompletionStage也要返回值之后，利用这两个返回值，进行转换后返回指定类型的值。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> @Test</span><br><span class="line">    public void thenCombine() &#123;</span><br><span class="line">        String result &#x3D; CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;hello&quot;;</span><br><span class="line">        &#125;).thenCombine(CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(3000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;world&quot;;</span><br><span class="line">        &#125;), (s1, s2) -&gt; s1 + &quot; &quot; + s2).join();</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line"># 结果为：</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p><strong>5. 结合两个CompletionStage的结果，进行消耗</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public &lt;U&gt; CompletionStage&lt;Void&gt; thenAcceptBoth(CompletionStage&lt;? extends U&gt; other,BiConsumer&lt;? super T, ? super U&gt; action);</span><br><span class="line"></span><br><span class="line">public &lt;U&gt; CompletionStage&lt;Void&gt; thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other,BiConsumer&lt;? super T, ? super U&gt; action);</span><br><span class="line"></span><br><span class="line">public &lt;U&gt; CompletionStage&lt;Void&gt; thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other,BiConsumer&lt;? super T, ? super U&gt; action,     Executor executor);</span><br></pre></td></tr></table></figure><p>它需要原来的处理返回值，并且other代表的CompletionStage也要返回值之后，利用这两个返回值，进行消耗。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">  @Test</span><br><span class="line">    public void thenAcceptBoth() &#123;</span><br><span class="line">        CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;hello&quot;;</span><br><span class="line">        &#125;).thenAcceptBoth(CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(3000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;world&quot;;</span><br><span class="line">        &#125;), (s1, s2) -&gt; System.out.println(s1 + &quot; &quot; + s2));</span><br><span class="line">        while (true)&#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p><strong>6. 在两个CompletionStage都运行完执行。</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public CompletionStage&lt;Void&gt; runAfterBoth(CompletionStage&lt;?&gt; other,Runnable action); </span><br><span class="line"></span><br><span class="line">public CompletionStage&lt;Void&gt; runAfterBothAsync(CompletionStage&lt;?&gt; other,Runnable action); </span><br><span class="line"></span><br><span class="line">public CompletionStage&lt;Void&gt; runAfterBothAsync(CompletionStage&lt;?&gt; other,Runnable action,Executor executor);</span><br></pre></td></tr></table></figure><p>不关心这两个CompletionStage的结果，只关心这两个CompletionStage执行完毕，之后在进行操作（Runnable）。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">  @Test</span><br><span class="line">    public void runAfterBoth()&#123;</span><br><span class="line">        CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;s1&quot;;</span><br><span class="line">        &#125;).runAfterBothAsync(CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(3000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;s2&quot;;</span><br><span class="line">        &#125;), () -&gt; System.out.println(&quot;hello world&quot;));</span><br><span class="line">        while (true)&#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p><strong>7. 两个CompletionStage，谁计算的快，我就用那个CompletionStage的结果进行下一步的转化操作</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public &lt;U&gt; CompletionStage&lt;U&gt; applyToEither(CompletionStage&lt;? extends T&gt; other,Function&lt;? super T, U&gt; fn);</span><br><span class="line"></span><br><span class="line">public &lt;U&gt; CompletionStage&lt;U&gt; applyToEitherAsync(CompletionStage&lt;? extends T&gt; other,Function&lt;? super T, U&gt; fn); </span><br><span class="line"></span><br><span class="line">public &lt;U&gt; CompletionStage&lt;U&gt; applyToEitherAsync(CompletionStage&lt;? extends T&gt; other,Function&lt;? super T, U&gt; fn,Executor executor);</span><br></pre></td></tr></table></figure><p>我们现实开发场景中，总会碰到有两种渠道完成同一个事情，所以就可以调用这个方法，找一个最快的结果进行处理。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"> @Test</span><br><span class="line">    public void applyToEither() &#123;</span><br><span class="line">        String result &#x3D; CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(3000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;s1&quot;;</span><br><span class="line">        &#125;).applyToEither(CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;hello world&quot;;</span><br><span class="line">        &#125;), s -&gt; s).join();</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p><strong>8. 两个CompletionStage，谁计算的快，我就用那个CompletionStage的结果进行下一步的消耗操作</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public CompletionStage&lt;Void&gt; acceptEither(CompletionStage&lt;? extends T&gt; other,Consumer&lt;? super T&gt; action);</span><br><span class="line"></span><br><span class="line">public CompletionStage&lt;Void&gt; acceptEitherAsync(CompletionStage&lt;? extends T&gt; other,Consumer&lt;? super T&gt; action);</span><br><span class="line"></span><br><span class="line">public CompletionStage&lt;Void&gt; acceptEitherAsync(CompletionStage&lt;? extends T&gt; other,Consumer&lt;? super T&gt; action,Executor executor);</span><br></pre></td></tr></table></figure><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"> @Test</span><br><span class="line">    public void acceptEither() &#123;</span><br><span class="line">        CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(3000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;s1&quot;;</span><br><span class="line">        &#125;).acceptEither(CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;hello world&quot;;</span><br><span class="line">        &#125;), System.out::println);</span><br><span class="line">        while (true)&#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p><strong>9. 两个CompletionStage，任何一个完成了都会执行下一步的操作（Runnable）</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public CompletionStage&lt;Void&gt; runAfterEither(CompletionStage&lt;?&gt; other,Runnable action); </span><br><span class="line"></span><br><span class="line">public CompletionStage&lt;Void&gt; runAfterEitherAsync(CompletionStage&lt;?&gt; other,Runnable action); </span><br><span class="line"></span><br><span class="line">public CompletionStage&lt;Void&gt; runAfterEitherAsync(CompletionStage&lt;?&gt; other,Runnable action,Executor executor);</span><br></pre></td></tr></table></figure><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">    public void runAfterEither() &#123;</span><br><span class="line">        CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(3000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;s1&quot;;</span><br><span class="line">        &#125;).runAfterEither(CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;s2&quot;;</span><br><span class="line">        &#125;), () -&gt; System.out.println(&quot;hello world&quot;));</span><br><span class="line">        while (true) &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p><strong>10. 当运行时出现了异常，可以通过exceptionally进行补偿</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public CompletionStage&lt;T&gt; exceptionally(Function&lt;Throwable, ? extends T&gt; fn);</span><br></pre></td></tr></table></figure><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">   @Test</span><br><span class="line">    public void exceptionally() &#123;</span><br><span class="line">        String result &#x3D; CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(3000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            if (1 &#x3D;&#x3D; 1) &#123;</span><br><span class="line">                throw new RuntimeException(&quot;测试一下异常情况&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;s1&quot;;</span><br><span class="line">        &#125;).exceptionally(e -&gt; &#123;</span><br><span class="line">            System.out.println(e.getMessage());</span><br><span class="line">            return &quot;hello world&quot;;</span><br><span class="line">        &#125;).join();</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">java.lang.RuntimeException: 测试一下异常情况</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p><strong>11. 当运行完成时，对结果的记录。这里的完成时有两种情况，一种是正常执行，返回值。另外一种是遇到异常抛出造成程序的中断。这里为什么要说成记录，因为这几个方法都会返回CompletableFuture，当Action执行完毕后它的结果返回原始的CompletableFuture的计算结果或者返回异常。所以不会对结果产生任何的作用</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public CompletionStage&lt;T&gt; whenComplete(BiConsumer&lt;? super T, ? super Throwable&gt; action);</span><br><span class="line">public CompletionStage&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T, ? super Throwable&gt; action);</span><br><span class="line">public CompletionStage&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T, ? super Throwable&gt; action,Executor executor);</span><br></pre></td></tr></table></figure><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"> @Test</span><br><span class="line">    public void whenComplete() &#123;</span><br><span class="line">        String result &#x3D; CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(3000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            if (1 &#x3D;&#x3D; 1) &#123;</span><br><span class="line">                throw new RuntimeException(&quot;测试一下异常情况&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;s1&quot;;</span><br><span class="line">        &#125;).whenComplete((s, t) -&gt; &#123;</span><br><span class="line">            System.out.println(s);</span><br><span class="line">            System.out.println(t.getMessage());</span><br><span class="line">        &#125;).exceptionally(e -&gt; &#123;</span><br><span class="line">            System.out.println(e.getMessage());</span><br><span class="line">            return &quot;hello world&quot;;</span><br><span class="line">        &#125;).join();</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">null</span><br><span class="line">java.lang.RuntimeException: 测试一下异常情况</span><br><span class="line">java.lang.RuntimeException: 测试一下异常情况</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p>这里也可以看出，如果使用了exceptionally，就会对最终的结果产生影响，它没有口子返回如果没有异常时的正确的值，这也就引出下面我们要介绍的handle。</p><p><strong>12. 运行完成时，对结果的处理。这里的完成时有两种情况，一种是正常执行，返回值。另外一种是遇到异常抛出造成程序的中断</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public &lt;U&gt; CompletionStage&lt;U&gt; handle(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn);</span><br><span class="line"></span><br><span class="line">public &lt;U&gt; CompletionStage&lt;U&gt; handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn);</span><br><span class="line"></span><br><span class="line">public &lt;U&gt; CompletionStage&lt;U&gt; handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn,Executor executor);</span><br></pre></td></tr></table></figure><p>例如：<br>出现异常时</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">  @Test</span><br><span class="line">    public void handle() &#123;</span><br><span class="line">        String result &#x3D; CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(3000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            &#x2F;&#x2F;出现异常</span><br><span class="line">            if (1 &#x3D;&#x3D; 1) &#123;</span><br><span class="line">                throw new RuntimeException(&quot;测试一下异常情况&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;s1&quot;;</span><br><span class="line">        &#125;).handle((s, t) -&gt; &#123;</span><br><span class="line">            if (t !&#x3D; null) &#123;</span><br><span class="line">                return &quot;hello world&quot;;</span><br><span class="line">            &#125;</span><br><span class="line">            return s;</span><br><span class="line">        &#125;).join();</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p>未出现异常时</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">    public void handle() &#123;</span><br><span class="line">        String result &#x3D; CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(3000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return &quot;s1&quot;;</span><br><span class="line">        &#125;).handle((s, t) -&gt; &#123;</span><br><span class="line">            if (t !&#x3D; null) &#123;</span><br><span class="line">                return &quot;hello world&quot;;</span><br><span class="line">            &#125;</span><br><span class="line">            return s;</span><br><span class="line">        &#125;).join();</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 结果为：</span><br><span class="line">s1</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;2014年，Oracle发布了Java8新版本后，愈来愈多的公司开始尝试使用Java8新特性来摆脱繁琐的语法，在使用Java8代码编写公司项目后，为了追上时代潮流，开始系统学习Java8的一些新特性。在收集整理网上各种Java8学习笔记后，此篇文章算是个人Java8学习笔记的小结。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;速度更块&lt;/li&gt;
&lt;li&gt;代码更少（Lambda表达式）&lt;/li&gt;
&lt;li&gt;强大的Stream API&lt;/li&gt;
&lt;li&gt;便于并行&lt;/li&gt;
&lt;li&gt;最大化减少空指针异常 Optional&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;font color=&quot;red&quot;&gt;核心为：Lambda表达式与Stream API&lt;/font&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Java" scheme="http://JavaSsun.github.io/categories/Java/"/>
    
    
      <category term="Java" scheme="http://JavaSsun.github.io/tags/Java/"/>
    
  </entry>
  
</feed>
