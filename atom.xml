<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>haoran&#39;s blog</title>
  
  <subtitle>写代码是热爱,写到世界充满爱</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://javassun.github.io/"/>
  <updated>2024-05-09T07:49:30.894Z</updated>
  <id>http://javassun.github.io/</id>
  
  <author>
    <name>Allen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>研究生总结</title>
    <link href="http://javassun.github.io/2024/05/09/%E7%A0%94%E7%A9%B6%E7%94%9F%E6%80%BB%E7%BB%93/"/>
    <id>http://javassun.github.io/2024/05/09/%E7%A0%94%E7%A9%B6%E7%94%9F%E6%80%BB%E7%BB%93/</id>
    <published>2024-05-09T07:30:35.000Z</published>
    <updated>2024-05-09T07:49:30.894Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><h3 id="1-攻读学位期间的科研成果与参加的项目"><a href="#1-攻读学位期间的科研成果与参加的项目" class="headerlink" title="1. 攻读学位期间的科研成果与参加的项目"></a>1. 攻读学位期间的科研成果与参加的项目</h3><blockquote><p>截止当前日期 2024-05-09</p></blockquote><p>1.发表学术论文<br>[1]    Alzheimer’s disease classification algorithm based on fusion of channel attention and densely connected networks[J]. Journal of Intelligent &amp; Fuzzy Systems (Preprint): 1-21. (已录用，SCI四区，导师一作，本人二作)<br>[2]    A medical text classification approach with ZEN and capsule network[J]. The Journal of Supercomputing, 2024, 80(3): 4353-4377. （已发表，SCI三区，导师一作，本人三作）<br>[3]    Residual-ChebNet: A Residual Connection Graph Convolutional Network for Mild Cognitive Impairment Classification Based on Multimodal Imaging Data.（SCI二区审稿中，导师一作，本人二作）<br>[4]    Hierarchical Medical Classification Based on DLCF[C]//International Conference on Computer and Information Science. Cham: Springer International Publishing, 2022: 101-115.（已发表，EI会议，导师三作，本人二作）</p><p>2.参加的项目<br>[1] 横向课题：固定资产精细化管理模式研究<br>[2] 横向课题：基于LBS的电子烟信息监管工作模式研究<br>[3] 横向课题：以企业文化促进人才队伍建设模式研究(HX20220085)<br>[4] 科技攻关：基于图神经网络与自学习机制的阿尔茨海默病诊断模型—2023年河南省高等学校重点科研项目计划(23B520005)<br>[5] 科技攻关：基于高维多模态医学影像数据的阿尔茨海默病可解释预警模型研究—2024年河南省科技攻关项目(242102211033)</p><a id="more"></a><h3 id="2-论文精读"><a href="#2-论文精读" class="headerlink" title="2. 论文精读"></a>2. 论文精读</h3><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711437447731-72705f33-ffc7-45bf-8401-d6241b33d021.pdf" target="_blank" rel="noopener">📎NIPS-2012-AlexNet-Paper.pdf</a></p><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711437447729-4ad22999-5f1f-48c0-9edc-a31687811902.pdf" target="_blank" rel="noopener">📎Going deeper with convolutions.pdf</a></p><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711437447724-74093781-c1ef-47a1-a218-12cde4f0b1ba.pdf" target="_blank" rel="noopener">📎Rethinking the Inception Architecture for Computer Vision.pdf</a></p><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1715240360528-34c7e14b-eb47-4a83-99bb-8cd5c8c5e424.pdf" target="_blank" rel="noopener">📎MediaPipe-Hands.pdf</a></p><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1715240386024-249efb96-1c6c-4e3a-a3ce-cb6f67d5ebaf.pdf" target="_blank" rel="noopener">📎Visualizing and Understanding Convolutional Networks.pdf</a></p><h3 id="3-感恩相遇"><a href="#3-感恩相遇" class="headerlink" title="3. 感恩相遇"></a>3. 感恩相遇</h3><p>岁月匆匆，时光如梭。回首在河大的整个学习生涯，心中充满欢欣与感激。研究生三年的学习历程不仅丰富了我的专业技能，也拓宽了我的视野和见识。这段宝贵的时光，我结识了许多师友，给予了我无尽的帮助与支持。在此，我要衷心感谢所有与我相伴的人们。</p><p>教诲如春风，师恩似海深。我要特别感谢我的导师梁老师，他在我学业和生活上都给予了我莫大的关怀和指导。从论文选题到最终定稿，都离不开梁老师的悉心指导。他不仅传授我专业知识，还教会我如何克服困难与挫折。梁老师的教诲和支持让我能够不断前行，他的影响将永远铭记在心中。在即将毕业之际，我要向梁老师致以最诚挚的感谢。</p><p>感谢亲爱的父母和我的爱人，多年来你们对我的爱与付出让我感到无比幸福与感动。你们是我永远的依靠和支持，希望你们永远健康快乐。</p><p>明德新民，止于至善。感谢母校河南大学，不仅传授我们渊博的知识，更教给我们做人的道理，让我们充满自信的走向无比宽阔的新天地。感谢软件学院为我们提供的支持与关怀，让我们安心遨游在知识与学习的海洋。</p><p>茫茫人海，感恩相遇。感谢课题组所有的同学们，你们的陪伴让我在科研生活中找到了欢乐，这份友谊让我终生难忘。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;h3 id=&quot;1-攻读学位期间的科研成果与参加的项目&quot;&gt;&lt;a href=&quot;#1-攻读学位期间的科研成果与参加的项目&quot; class=&quot;headerlink&quot; title=&quot;1. 攻读学位期间的科研成果与参加的项目&quot;&gt;&lt;/a&gt;1. 攻读学位期间的科研成果与参加的项目&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;截止当前日期 2024-05-09&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1.发表学术论文&lt;br&gt;[1]    Alzheimer’s disease classification algorithm based on fusion of channel attention and densely connected networks[J]. Journal of Intelligent &amp;amp; Fuzzy Systems (Preprint): 1-21. (已录用，SCI四区，导师一作，本人二作)&lt;br&gt;[2]    A medical text classification approach with ZEN and capsule network[J]. The Journal of Supercomputing, 2024, 80(3): 4353-4377. （已发表，SCI三区，导师一作，本人三作）&lt;br&gt;[3]    Residual-ChebNet: A Residual Connection Graph Convolutional Network for Mild Cognitive Impairment Classification Based on Multimodal Imaging Data.（SCI二区审稿中，导师一作，本人二作）&lt;br&gt;[4]    Hierarchical Medical Classification Based on DLCF[C]//International Conference on Computer and Information Science. Cham: Springer International Publishing, 2022: 101-115.（已发表，EI会议，导师三作，本人二作）&lt;/p&gt;
&lt;p&gt;2.参加的项目&lt;br&gt;[1] 横向课题：固定资产精细化管理模式研究&lt;br&gt;[2] 横向课题：基于LBS的电子烟信息监管工作模式研究&lt;br&gt;[3] 横向课题：以企业文化促进人才队伍建设模式研究(HX20220085)&lt;br&gt;[4] 科技攻关：基于图神经网络与自学习机制的阿尔茨海默病诊断模型—2023年河南省高等学校重点科研项目计划(23B520005)&lt;br&gt;[5] 科技攻关：基于高维多模态医学影像数据的阿尔茨海默病可解释预警模型研究—2024年河南省科技攻关项目(242102211033)&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="论文" scheme="http://JavaSsun.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="搬砖结晶" scheme="http://JavaSsun.github.io/tags/%E6%90%AC%E7%A0%96%E7%BB%93%E6%99%B6/"/>
    
      <category term="图神经网络" scheme="http://JavaSsun.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
      <category term="研究生成果" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E6%88%90%E6%9E%9C/"/>
    
  </entry>
  
  <entry>
    <title>12-ROI文件分析</title>
    <link href="http://javassun.github.io/2023/11/22/12-ROI%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/"/>
    <id>http://javassun.github.io/2023/11/22/12-ROI%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/</id>
    <published>2023-11-22T12:17:38.000Z</published>
    <updated>2024-05-09T07:19:56.244Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p>Dpabi工具提取信号之后在目标目录生成7个文件</p><ul><li>ROI_OrderKey_ROISignal_7.tsv</li><li>ROICorrelation_FisherZ_ROISignal_7.mat</li><li>ROICorrelation_FisherZ_ROISignal_7.txt</li><li>ROICorrelation_ROISignal_7.mat</li><li>ROICorrelation_ROISignal_7.txt</li><li>ROISignals_ROISignal_7.mat</li><li>ROISignals_ROISignal_7.txt<a id="more"></a>ROISignals开头的（130*2个文件）就是需要的fmri时间序列文件，</li></ul><p>共包含txt和mat两种格式，两种格式文件所存内容一致，只是文件格式不一样。</p><p><img src="/2023/11/22/12-ROI%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/wn3rHPn6yZGOBAxtxnBBy9nyhfKao8mY19qqFP2LmTc.png" alt="image"></p><h2 id="ROI-OrderKey-ROISignal-7-tsv"><a href="#ROI-OrderKey-ROISignal-7-tsv" class="headerlink" title="ROI_OrderKey_ROISignal_7.tsv"></a>ROI_OrderKey_ROISignal_7.tsv</h2><p>脑区模板定义文件</p><p><img src="/2023/11/22/12-ROI%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/w39JvZB4E1HuIffdLi1gIx-lar8xJDUs83wJ_EOdcNg.png" alt="image"></p><h2 id="ROISignals-ROISignal-7"><a href="#ROISignals-ROISignal-7" class="headerlink" title="ROISignals_ROISignal_7"></a>ROISignals_ROISignal_7</h2><ul><li>ROISignals_ROISignal_7.mat</li><li>ROISignals_ROISignal_7.txt</li></ul><p>TR如果是140（未去除前N个可能会导致误差的扫描），ROI定义为116</p><p>矩阵为140(TR数)x116(ROI数)，是该被试的time course</p><p><img src="/2023/11/22/12-ROI%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/V8-C1Th1X9Vvp2UtOcTSf-u8H1LxbePXGxm9AaNZ1ck.png" alt="image"></p><h2 id="ROICorrelation-ROISignal-7"><a href="#ROICorrelation-ROISignal-7" class="headerlink" title="ROICorrelation_ROISignal_7"></a>ROICorrelation_ROISignal_7</h2><ul><li>ROICorrelation_ROISignal_7.mat</li><li>ROICorrelation_ROISignal_7.txt</li></ul><p>一般是116x116矩阵，为116个ROI之间的correlation</p><p><img src="/2023/11/22/12-ROI%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/PfKk_V6OX_Ket-cD5-dT9tOCMWEtnMN7uQ-p4J0CWRs.png" alt="image"></p><h2 id="ROICorrelation-FisherZ-ROISignal-7"><a href="#ROICorrelation-FisherZ-ROISignal-7" class="headerlink" title="ROICorrelation_FisherZ_ROISignal_7"></a>ROICorrelation_FisherZ_ROISignal_7</h2><ul><li>ROICorrelation_FisherZ_ROISignal_7.mat</li><li>ROICorrelation_FisherZ_ROISignal_7.txt</li></ul><p>一般是116x116矩阵，为116个ROI之间的correlation，但已经过z转换</p><p><a href="https://blog.csdn.net/qq_41576771/article/details/120937467" target="_blank" rel="noopener">https://blog.csdn.net/qq_41576771/article/details/120937467</a></p><p><img src="/2023/11/22/12-ROI%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/06FE91juRbozEddgmHF8m2mCzMDi38j-XmVddp96zIA.png" alt="image"></p><h2 id="如何将AAL的116个脑区转为90个？"><a href="#如何将AAL的116个脑区转为90个？" class="headerlink" title="如何将AAL的116个脑区转为90个？"></a>如何将AAL的116个脑区转为90个？</h2><ol><li>确定小脑内parcellation unit的编号</li><li>将那些值为上面那些编号的vocel找出来，将其置为0.</li></ol><h2 id="文件具体分析"><a href="#文件具体分析" class="headerlink" title="文件具体分析"></a>文件具体分析</h2><p><a href="http://www.360doc.com/content/20/1013/17/71929693_940267401.shtml" target="_blank" rel="noopener">http://www.360doc.com/content/20/1013/17/71929693_940267401.shtml</a></p><p><a href="https://cloud.tencent.com/developer/column/2030?tag=10802" target="_blank" rel="noopener">https://cloud.tencent.com/developer/column/2030?tag=10802</a></p><p><a href="https://cloud.tencent.com/developer/column/2030" target="_blank" rel="noopener">https://cloud.tencent.com/developer/column/2030</a></p><h3 id="信号文件（基于种子的FC提取）"><a href="#信号文件（基于种子的FC提取）" class="headerlink" title="信号文件（基于种子的FC提取）"></a>信号文件（基于种子的FC提取）</h3><h4 id="ROISignals-ROISignal-7-1"><a href="#ROISignals-ROISignal-7-1" class="headerlink" title="ROISignals_ROISignal_7"></a>ROISignals_ROISignal_7</h4><p>140*116，140为时间序列，116为事先定义好的脑区</p><h4 id="ROICorrelation-ROISignal-7-1"><a href="#ROICorrelation-ROISignal-7-1" class="headerlink" title="ROICorrelation_ROISignal_7"></a>ROICorrelation_ROISignal_7</h4><p>116*116，由上述原始脑信号经过皮尔逊相关系数计算得到的FC-Matrix，<strong>值在-1~1之间</strong></p><h4 id="ROICorrelation-FisherZ-ROISignal-7-1"><a href="#ROICorrelation-FisherZ-ROISignal-7-1" class="headerlink" title="ROICorrelation_FisherZ_ROISignal_7"></a>ROICorrelation_FisherZ_ROISignal_7</h4><p>通过Fisher-Z变换将皮尔逊相关系数的分布由原来的-1~1的偏态转换成正负无穷的正态分布以符合假设检验的前提假说。</p><p><img src="/2023/11/22/12-ROI%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/mQ3HOr3i78jop07_9Iy02f52rK1cp9qbyVSrJXdrOvM.png" alt="image"></p><p>每个被试包含了7个文件，其中“<strong>ROI_OrderKey_SubXXX.tsv</strong>”存储了SubXXX被试所有的ROI编号以及ROI文件路径信息。</p><p>ROICorrelation_Sub001.mat／ROICorrelation_FisherZ_Sub001.mat／ROICorrelation_Sub001.txt／ROICorrelation_FisherZ_Sub001.txt：存储了一个<strong>N*N</strong>的矩阵（<strong>N代表预定义的种子点数目</strong>），其中<strong>第i行与第j列存放了编号分别为i和j的种子点之间的功能连接。“FisherZ”代表这些功能连接的数值经过了Fisher’s Z转换，更加服从正态分布</strong>。</p><p>ROISignals_Sub001.mat／ROISignals_Sub001.txt：<strong>存储了一个P*N的矩阵。P代表了时间点数目，N代表了预定义的种子点数目。矩阵的第i列表示编号为i的种子点的平均时间序列。</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;Dpabi工具提取信号之后在目标目录生成7个文件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ROI_OrderKey_ROISignal_7.tsv&lt;/li&gt;
&lt;li&gt;ROICorrelation_FisherZ_ROISignal_7.mat&lt;/li&gt;
&lt;li&gt;ROICorrelation_FisherZ_ROISignal_7.txt&lt;/li&gt;
&lt;li&gt;ROICorrelation_ROISignal_7.mat&lt;/li&gt;
&lt;li&gt;ROICorrelation_ROISignal_7.txt&lt;/li&gt;
&lt;li&gt;ROISignals_ROISignal_7.mat&lt;/li&gt;
&lt;li&gt;ROISignals_ROISignal_7.txt&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
    
      <category term="Tools" scheme="http://JavaSsun.github.io/tags/Tools/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>11-DTI预处理</title>
    <link href="http://javassun.github.io/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/"/>
    <id>http://javassun.github.io/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/</id>
    <published>2023-11-16T14:17:38.000Z</published>
    <updated>2024-05-09T07:18:30.921Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711518640219-35b94685-d9ea-470f-bfc3-371c2842904a.pdf" target="_blank" rel="noopener">📎DTI数据预处理详细流程分步整理.pdf</a></p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/icPfULROtRhEuZ5d7WK44ISNcm3f5weTbXAB4Eu2dt4.png" alt="image"></p><a id="more"></a><p>文件准备</p><p>设置一个CN/EMCI/LMCI文件夹，下面放入各个被试的数据</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/9JRdzhiS6qAr_K9abMe25LmX9Dh1QmhMl1mWBc61ZBg.png" alt="image"></p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/AyxxQJM2_YFFEzvJn4QKo-Nv9ojLiCrkjt4BQyKRTbA.png" alt="image"></p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/GhLvqAmO33sHLWnQS7CXFa10bLsPMRXYR8QDq6NLzhI.png" alt="image"></p><p>上面是pdf截图，具体细节查看pdf</p><p>第一步：文件夹的准备</p><hr><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/qzn6ct03wXfSLihtEk8s5-NVcaQGVM0zGJ7fRx5ySaE.png" alt="image"></p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/aCOvpgd_3ZjjH-Sq3OKH_mYvdtjEmTKFQrpX8uPwFJI.png" alt="image"></p><p>dcm2nii.sh(无效)</p><p><a href="https://www.jianshu.com/p/220f6f6f59ae" target="_blank" rel="noopener">https://www.jianshu.com/p/220f6f6f59ae</a></p><p>运行不成,使用软件做转换</p><figure class="highlight plain"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd DTI_test</span><br><span class="line">for i in sub*</span><br><span class="line">do echo now processing $&#123;i&#125;</span><br><span class="line">dcm2nii $&#123;i&#125;</span><br><span class="line">#rm -r ~&#x2F;sharefolder&#x2F;DTI_test&#x2F;$&#123;i&#125;&#x2F;00*</span><br><span class="line">mkdir ~&#x2F;sharefolder&#x2F;DTI_test&#x2F;$&#123;i&#125;&#x2F;1</span><br><span class="line">mv ~&#x2F;sharefolder&#x2F;DTI_test&#x2F;$&#123;i&#125;&#x2F;20* ~&#x2F;sharefolder&#x2F;DTI_test&#x2F;$&#123;i&#125;&#x2F;1</span><br><span class="line">done</span><br><span class="line">echo finished, exciting</span><br></pre></td></tr></table></figure><p>第二步：提取b0</p><p>PANDA中使用extract_b0代码</p><figure class="highlight plain"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;new_dev&#x2F;shr&#x2F;Study5&#x2F;CN&#x2F;DTI_Result</span><br><span class="line">for i in &#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;new_dev&#x2F;shr&#x2F;Study5&#x2F;CN&#x2F;DTI_Result&#x2F;*</span><br><span class="line">do cd $&#123;i&#125;&#x2F;1</span><br><span class="line">   fslroi *.nii.gz $&#123;i&#125;_b0.nii.gz 0 1</span><br><span class="line">   # cp $&#123;i&#125;_b0.nii.gz &#x2F;home&#x2F;siying&#x2F;sharefolder&#x2F;DTI_test&#x2F;b0</span><br><span class="line">   # rm $&#123;i&#125;_b0.nii.gz</span><br><span class="line">echo now processing $&#123;i&#125;</span><br><span class="line">   done</span><br></pre></td></tr></table></figure><p>第三步：PANDA中点点点，进行预处理</p><hr><p>选择DICOM–&gt;NifTI</p><hr><p><strong>正式开始</strong></p><h3 id="第一步-文件夹准备"><a href="#第一步-文件夹准备" class="headerlink" title="第一步: 文件夹准备"></a>第一步: 文件夹准备</h3><p>准备 CN/<strong>DTI_Test</strong> 文件夹</p><p>准备 CN/<strong>DTI_Result</strong> 文件夹</p><p>准备 CN/<strong>DTI_Final</strong> 文件夹</p><p>每个文件夹下放入对应受试者的文件夹名称,如下图所示</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/WI-uOGWtskdaZhnV7MdG6xTWMW5WNSmAordcexMP-eU.png" alt="image"></p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/-aO4BGaVM4unls1bxqYTJanWt0JQPOf14kfCszRBGXw.png" alt="image"></p><p><strong>格式转换</strong></p><p>选中DICOM -&gt; NIFTI</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/kEIAT7ac-fZt0IWK8DyKfv1BazFVuSDYQoupuLbt-_A.png" alt="image"></p><p>点击 DICOM Path 挑选Subject, 此处只选择了3个Subject</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/jWl-SjEXinMD1-U2tjS7Yx43oqpCS1iJzRFXsp4cSIk.png" alt="image"></p><p>点击 Result Path 选择转换后图像保存路径,此处选择 CN/<strong>DTI_Result</strong> 文件夹</p><p>Subject_IDs 输入 1:3 因为选择了3个Subject</p><p>Type 选中 fMRI</p><p>点击RUN按钮, 进行格式转换</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/PxLhAD4pHFUjjdZTNyb-3vK0Yb2G5-Ml4xtB7aJXabU.png" alt="image"></p><p>结果展示</p><p>CN/<strong>DTI_Result</strong> 文件夹 会出现每个Subject 对应的新编号,如 00001 00002 此处需要自己记录转换前后名称的变化</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/EzP5laG7jbVGfe0c9dy__ycYhdhC9-T86a5eiVYUU5M.png" alt="image"></p><p>会出现3个文件,具体含义参见最上面</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/gdu44Wdc1PZ3Mp-EZa12dB-BX_Xsj09LMfDkH_A5umE.png" alt="image"></p><p>每一个Subject下新建一个名称为1的文件夹,将上面3个文件放入其中</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/evgJFMPSYdxil9ekiy0_Ngt-9AVUuH3sM34InBUL8AA.png" alt="image"></p><p>其他Subject依次类比</p><h3 id="第二步-提取bo"><a href="#第二步-提取bo" class="headerlink" title="第二步: 提取bo"></a>第二步: 提取bo</h3><figure class="highlight plain"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;new_dev&#x2F;shr&#x2F;Study5&#x2F;CN&#x2F;DTI_Result</span><br><span class="line">for i in &#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;new_dev&#x2F;shr&#x2F;Study5&#x2F;CN&#x2F;DTI_Result&#x2F;*</span><br><span class="line">do cd $&#123;i&#125;&#x2F;1</span><br><span class="line">   fslroi *.nii.gz $&#123;i&#125;_b0.nii.gz 0 1</span><br><span class="line">   # cp $&#123;i&#125;_b0.nii.gz &#x2F;home&#x2F;siying&#x2F;sharefolder&#x2F;DTI_test&#x2F;b0</span><br><span class="line">   # rm $&#123;i&#125;_b0.nii.gz</span><br><span class="line">echo now processing $&#123;i&#125;</span><br><span class="line">   done</span><br></pre></td></tr></table></figure><p><a href="https://www.yuque.com/attachments/yuque/0/2024/sh/22829897/1711518640227-6486b50a-9bac-4025-a077-768985395941.sh" target="_blank" rel="noopener">📎extract_b0.sh</a></p><p>在CN文件夹路径下打开终端</p><p>运行该代码 sh extract_b0.sh</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/J5Nx_SSd4TALocEtWeF6mHpnoy0YjVpnrpZP-FzyB0o.png" alt="image"></p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/ZR2Fh6l3h0pT-IN7onnYiWctpdTg7LQk6wMLOQo0snc.png" alt="image"></p><p>在 DTI_Result 文件夹下 出现 各个 Subject 对应的 b0文件</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/SKpZG_xCiCO3E__YBmCrB1wi8q0TEw-vpktSYi_e9rA.png" alt="image"></p><p>新建一个 b0文件夹, 将这3个b0文件放入其中,后面配准用</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/egSf7qFhu8q23VKRH-e8z1w21NNvOhKcdHjFt13JH_w.png" alt="image"></p><h3 id="第三步-PANDA中点点点"><a href="#第三步-PANDA中点点点" class="headerlink" title="第三步: PANDA中点点点"></a>第三步: PANDA中点点点</h3><p>PANDA 中选择 DICOM/NIFTI Path, 挑选 DTI_Result 文件夹下的各个Subject</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/HTVhJebRgrLozBNbakoxP1U96NdMheHwr8Yd_iMS9e8.png" alt="image"></p><p>Result Path 选择 DTI_Final</p><p>Subject_IDs 输入 1:3 因为选择了3个Subject</p><p>Pipeline Opt 根据自己电脑情况进行设置</p><h4 id="DIffusion-Opt"><a href="#DIffusion-Opt" class="headerlink" title="DIffusion Opt"></a>DIffusion Opt</h4><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/pSc3ycHXaNvEf_fgGMMj0OpiHI21oST3DtrgZJ3KyqM.png" alt="image"></p><p>重采样到 2 2 2</p><p>头骨剥离 0.25</p><p>剪切图像 3</p><p>剩下默认按照图像所示,软件里面应该是默认填充这些选项</p><h4 id="Tracking-Opt"><a href="#Tracking-Opt" class="headerlink" title="Tracking Opt"></a>Tracking Opt</h4><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/8WQE1UtYqooGE3GBFYj0wT5HpAGkodQ1wFcm_N5XIXU.png" alt="image"></p><p>点击 T1 Image 后面的 … 按顺序选择 b0 里面的 bo.nii文件, 顺序要与刚开始输入Subject一致</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/RH0MmQNpZCjxpUtpSanwGVazJG9Laj05nOJfSGQUYTs.png" alt="image"></p><p>Atlas 选择 PANDA 默认提供的 AAL 90 (默认填充)</p><p>T1_Template 选择 EPI.nii 模板文件</p><p>其他全部默认填充</p><p>Network Construction 选择 左边确定性网络, 右边的概率网络耗费时间漫长</p><h3 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h3><p>DTI_Final文件夹如下</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/EXBX_lC0GXRhVKesk-pVPWFVUiQK_VUle_ZkyLD8Nm4.png" alt="image"></p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/Z5RVqTTOy4YOk-NmUQPFT-FaLifnTzF59zHxfJ8plqs.png" alt="image"></p><p>点击 Network - Deterministic</p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/M3nKQLZSHb8l_v5Wd9_cDBvVZTm75KKr9QCTtxpsj3I.png" alt="image"></p><p><img src="/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/w5X4CYnhK52RgmMKDwxpQQLTHzM7Ai00d4P35fowDfk.png" alt="image"></p><p>我们选择 FA 或者 FN 值</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711518640219-35b94685-d9ea-470f-bfc3-371c2842904a.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;📎DTI数据预处理详细流程分步整理.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/11/16/11-DTI%E9%A2%84%E5%A4%84%E7%90%86/icPfULROtRhEuZ5d7WK44ISNcm3f5weTbXAB4Eu2dt4.png&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Tools" scheme="http://JavaSsun.github.io/tags/Tools/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>10-GRETNA处理fMRI</title>
    <link href="http://javassun.github.io/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/"/>
    <id>http://javassun.github.io/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/</id>
    <published>2023-11-05T14:17:38.000Z</published>
    <updated>2024-05-09T07:15:58.736Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p>参考论文过程<br><img src="/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/ER4BnRPhqkGbnCEB4rZiObawvgxkPgg7t7BVSLO6vmA.webp" alt="image"></p><a id="more"></a><p><a href="https://zhuanlan.zhihu.com/p/388847720?utm_id=0" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/388847720?utm_id=0</a></p><p><a href="https://www.bilibili.com/video/BV1JM411h7SR/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&vd_source=cdbbedc88ac17f2589c268d0ab8e73fc" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1JM411h7SR/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&amp;vd_source=cdbbedc88ac17f2589c268d0ab8e73fc</a></p><p>Matlab中输入gretna出现软件界面</p><p><img src="/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/ChOS-ymiY25Tq_vQnwrU7WdwjlkxGRETidE-_aaPGeA.webp" alt="image"></p><p>由上到下依次是：</p><ul><li>FC矩阵网络构建</li><li>网络分析</li><li>矩阵统计比较</li></ul><p>点击第一个 <strong>FC Matrix Construction</strong></p><p><img src="/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/gQZw5hAso22DK-5Lkcwfq-O4Cixo9vgizYB7DosVKw8.webp" alt="image"></p><p>数据分割为</p><p>FunRaw和T1Raw</p><p><img src="/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/8iu-1umTg0wYgOhW9gVVp_DYAWZO8KRbqLNvOJxKMnc.webp" alt="image"></p><p>FunRaw下面存有Subject序列</p><p><img src="/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/43Gc-QoO14GthFtz7FhI6_Vl33gC9bzJeFhVQEOhVuQ.webp" alt="image"></p><p>选进来之后，如下图展示</p><p><img src="/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/3OjE4a5NOWNHX9PTw0kFyr-c_Zfds4iQ4qQWMZFsRTw.webp" alt="image"></p><p>一般选择除了平滑和Scrubbing两个步骤不做</p><p><img src="/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/jk7KcPWn5lVM37jUIoaVr3OKiV30cA1UptNSuawFcOs.png" alt="image"></p><h4 id="DiCOM-to-NifTI"><a href="#DiCOM-to-NifTI" class="headerlink" title="DiCOM to NifTI"></a>DiCOM to NifTI</h4><h4 id="Remove-First-Images"><a href="#Remove-First-Images" class="headerlink" title="Remove First Images"></a>Remove First Images</h4><p>移除前20个时间点，下图demo选择的是10</p><h4 id="Slice-Timing"><a href="#Slice-Timing" class="headerlink" title="Slice Timing"></a>Slice Timing</h4><p>TR=3 下图demo中是2</p><p>Slice Order : Starting at odd</p><p>Reference Slice: Middle Slice</p><h4 id="Relagin"><a href="#Relagin" class="headerlink" title="Relagin"></a>Relagin</h4><p>Num Phasses: Register to first</p><h4 id="Normalize"><a href="#Normalize" class="headerlink" title="Normalize"></a>Normalize</h4><p>EPI 由于此处没有T1Raw图像，所以直接选择 EPI</p><p><img src="/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/zJmjvcnGeyOGkJweZLzArFoT2Vhvo8i-cJ1Yt0hTcNw.webp" alt="image"></p><h4 id="完整版本"><a href="#完整版本" class="headerlink" title="完整版本"></a>完整版本</h4><p><img src="/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/aN88E7L82Zc75_43XjwEEyBAgGgkMhGKDdBgVigl5p4.webp" alt="image"></p><p>选择Load Configuration 选中/home/pugongying/data/jupyterLab/new_dev/shr/AD-Predict/MyFunPreproAndNetConConfig.mat 文件</p><p>提前设置好的配置自动加载进来,重新检查一遍</p><p>选择FunRaw文件夹</p><p><img src="/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/LzCWMGkGVNIjqFJBe9F7q4KLpG_ai3NCz211L_AC6rA.webp" alt="image"></p><p>结果如下展示</p><p><img src="/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/QoS82vaPSYvZuk235w2r1jyXaUhIb01hm8e-5c7rYIo.webp" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;参考论文过程&lt;br&gt;&lt;img src=&quot;/2023/11/05/10-GRETNA%E5%A4%84%E7%90%86fMRI/ER4BnRPhqkGbnCEB4rZiObawvgxkPgg7t7BVSLO6vmA.webp&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Tools" scheme="http://JavaSsun.github.io/tags/Tools/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>9-(图)利用Matlab的spm12工具处理fMRI为ROI</title>
    <link href="http://javassun.github.io/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/"/>
    <id>http://javassun.github.io/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/</id>
    <published>2023-10-28T11:17:38.000Z</published>
    <updated>2024-05-09T07:14:26.457Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p>目录</p><ol><li>下载DICOM格式数据</li><li>DICOM -&gt; NIFTI格式 输出s开头文件</li><li>时间层校正Slice Timing 输出as开头文件</li><li>头动校正Realignment 输出ras开头文件</li><li>归一化Normalize 输出w开头文件</li><li>平滑Smooth 输出sw开头文件</li><li>配准Co-register reslice</li><li>提取ROI<a id="more"></a><h2 id="1-下载DICOM格式数据"><a href="#1-下载DICOM格式数据" class="headerlink" title="1. 下载DICOM格式数据"></a>1. 下载DICOM格式数据</h2>登录地址：</li></ol><p><a href="https://ida.loni.usc.edu/ladvq_search.xjsp?project=ADNI&page=SEARCH&subPage=ADV_QUERY" target="_blank" rel="noopener">https://ida.loni.usc.edu/ladvq_search.xjsp?project=ADNI&amp;page=SEARCH&amp;subPage=ADV_QUERY</a></p><p>输入登录账号及密码-&gt;ADNI GO-&gt;DOWNLOAD IMAGE Collections-&gt;Advanced Search(beta)-&gt;</p><p>确定Research Group: <strong>EMCI LCMI AD CN</strong></p><p>Image Description:<strong>Resting State fMRI</strong>-&gt; Display in result-&gt;csv download （注：网页加载很慢）</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/1e9z639rKvpYaT9YgV5FStnOMmOyq4BwiRswSGVfgDg.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/fRrZ19WNykNII1PWXOyxTyJMNyLmp4MCzfvK_2GB9ig.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/Vw37Xi-DfA-MHwLpqd1qDdIPwieoBAroziS-NfjdBiM.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/pCqNq_4gnBXixyZhPK0a6RH-8cxaT8R1fnMnlTcG3gc.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/aOswtYv_pA6-3BIHlSv75BWGFCb4lR-hzKKcGYMcRHA.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/NSCfkwolKmcHLHRB1SF9h-D8OqAhGq104mPPnccp8UI.png" alt="image"></p><p><strong>建议单个下，如果all同时下，会出现断网，网中断，下载失败或文件不全。且不好统计哪些是下载过的**</strong>。**</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/i5u21kD-EZDQt5mqmbbQHEBMnMEc3gx_T0XrxCDmQE8.png" alt="image"></p><p>已知下载好的文件格式解压如下（注：<strong>文件必须是6720个dicom</strong>，如果少了，说明网络中断导致文件没下载全，需要重新下载。）：</p><p>事先在每个subject里存好每个步骤对应路径（可以用程序在每个人对应路径下创建以下文件夹）:</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/MP5HhP13RAUM17F9JFwLjRrcPbDBY5-Lv1gwjOQN5Y0.png" alt="image"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="comment">## 在每个subject下面提前创建每个步骤对应的文件夹</span></span><br><span class="line"><span class="comment"># * 2.NiFTI</span></span><br><span class="line"><span class="comment"># * 3.SliceTime</span></span><br><span class="line"><span class="comment"># * 4.Realignment</span></span><br><span class="line"><span class="comment"># * 5.Normalize</span></span><br><span class="line"><span class="comment"># * 6.Smooth</span></span><br><span class="line"><span class="comment"># * 7.ROI</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 原始的dcm文件每个subject有6720个dicom,少了，则是网络中断，需要重新下载</span></span><br><span class="line">prefix_dir = <span class="string">"/home/pugongying/data/Brain/fMRI-Test/ADNI/"</span></span><br><span class="line">nifti_folder_name = <span class="string">"2.NiFTI"</span></span><br><span class="line">sliceTime_folder_name = <span class="string">"3.SliceTime"</span></span><br><span class="line">realignment_folder_name = <span class="string">"4.Realignment"</span></span><br><span class="line">normalize_folder_name = <span class="string">"5.Normalize"</span></span><br><span class="line">smooth_folder_name = <span class="string">"6.Smooth"</span></span><br><span class="line">co_register_folder_name = <span class="string">"7.Co-register"</span></span><br><span class="line">ROI_folder_name = <span class="string">"8.ROI"</span></span><br><span class="line"></span><br><span class="line">folders = glob.glob(os.path.join(prefix_dir, <span class="string">"*/Resting_State_fMRI/*"</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> folder <span class="keyword">in</span> folders:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(os.path.join(folder, nifti_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, nifti_folder_name))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(os.path.join(folder, sliceTime_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, sliceTime_folder_name))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(os.path.join(folder, realignment_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, realignment_folder_name))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(os.path.join(folder, normalize_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, normalize_folder_name))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(os.path.join(folder, smooth_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, smooth_folder_name))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(os.path.join(folder, co_register_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, co_register_folder_name))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(os.path.join(folder, ROI_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, ROI_folder_name))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">glob.glob(os.path.join(prefix_dir, <span class="string">"*/Resting_State_fMRI/*/*"</span>))</span><br></pre></td></tr></table></figure><p>Matlab 配好spm12 环境，输入spm（以下三个窗口都不要随意叉掉，后面要用到）</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/KIu0xjeNOdgAHuv-l6ZGv6XBKPL4M9UU0eJ8rylp5FM.png" alt="image"></p><p><strong>Dicom import</strong></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/P6QiMhuMbDMGz8lH_wps6LXUU2hcUzNYv5v2jaEkdIg.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/DK18MO6WA22rQg5HE7gJrx5HEVl72IkoQpxWzRMVLlM.png" alt="image"></p><p>文件输入选中6720个文件</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/8CCfYtVg08mB50tHlhWmhtdVD_tQRGrOeeAa5SBC2iA.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/554A3V06Rw3sV-5nW4NWlDahgnEjFQJtmr7O2rUsUtY.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/j80e-rERYBin03RoAHruQ35_w3xCveR1FgcD8ZZA6Mk.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/Kr9lzCXmzS9667MMH0xm5l2Cq79YfqO61rL4HOF5Pbc.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/2AftP8opDBqUomm-kkbAruVS_MvXpBCwnhL4GzDr4mk.png" alt="image"></p><p>文件输出保存路径</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/7GfDz9yO-4uZlkV1lXECM36kNy_7XyLOUfeMMcb3joI.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/p3VhJC8PwrASUq-TlKpxo-aR3or4og-EFfCFMCKuOI0.png" alt="image"></p><p>如果点错了，想要重选，点击红框以选中路径，文件路径就会消失，重选即可）</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/8pjIbsBxllp27jccGIGOq2qPiUf8jBUn08HZ3AZC4wg.png" alt="image"></p><p>选好后点击done:</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/gMhadCjz6TBzoWMtR61VTRhpV5otDjkko8PlFc0UJqc.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/G_Icy-TkazwgYWBzDFfGnVDF6t-6NjegRJQlDtEBV2U.png" alt="image"></p><p>想要批量处理，可以先直接把第一个没加文件的Module List复制</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/Cu12bhMrC--RaSa-xkjSrU1kA3FzkoilIUiz2TbXu7M.png" alt="image"></p><p>想要批量处理，可以先直接把第一个Module List 复制</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/g5ea0B7LGu7t-6UrsVVZgQeS9Prgcvk54ay3fo4g6tA.png" alt="image"></p><p>显示处理进度，耗时5分钟</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/WBZ5IG6Mw0nGsiuqfxQo9902S6rLvHmboK0A0svElpU.png" alt="image"></p><p><strong>有时候源文件生出结果只有一个文件，这个subject是不可用的，</strong></p><h2 id="2-DICOM-gt-NIFTI格式-输出s开头文件"><a href="#2-DICOM-gt-NIFTI格式-输出s开头文件" class="headerlink" title="2. DICOM -&gt; NIFTI格式 输出s开头文件"></a>2. DICOM -&gt; NIFTI格式 输出s开头文件</h2><p>原始的多个dicm文件得到140的nii文件</p><h2 id="3-时间层校正Slice-Timing-输出as开头文件"><a href="#3-时间层校正Slice-Timing-输出as开头文件" class="headerlink" title="3. 时间层校正Slice Timing 输出as开头文件"></a>3. 时间层校正Slice Timing 输出as开头文件</h2><p>Number pf slice: 48</p><p>TR: 3</p><p>TA: 3-3/48</p><p>Slice order：输入修改参数 1:2:47 2:2:48</p><p>Reference Slice：输入47（这里也可以是24，一般取48/2=24 中间较好）</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/f9Crl-v4JAbSTRDED5FUd-tNsWlCDgAAdk3nEbdGrUY.png" alt="image"></p><p>选择上一步骤的140个文件，设置参数后运行</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/b2BozTyHJyhmqbAjzITzDh_CzSULjBZknobh3eGGDfI.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/0X-nlner2g-ccKL8Sq90-GaLtB00yHm6QDlE9wEf-oY.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/51qA7y-t1_DiSRCQTQLvrhZd01A6ZHScDFQzs1aLgHo.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/oRrmKi_Ecm1-tat1bGSp6T4BiUvOiEicLgd3kv965xM.png" alt="image"></p><h2 id="4-头动校正Realignment-输出ras开头文件"><a href="#4-头动校正Realignment-输出ras开头文件" class="headerlink" title="4. 头动校正Realignment 输出ras开头文件"></a>4. 头动校正Realignment 输出ras开头文件</h2><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/Wf9tFa7e_7tJwEkXozeH9WgpjG9kUOi4jgVSdNk7ScY.png" alt="image"></p><p>输入上一步骤得到的140个文件，没有参数设置，直接运行</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/hYBSGGYrpiC2Ym_DGlMrC7Xhc86Hafk9zjdOcoIzJpw.png" alt="image"></p><p>运行后会得到如下头动文件，自行记录和判定即可。</p><p>得到的中间图查看是否符合规范</p><h2 id="5-归一化Normalize-输出w开头文件"><a href="#5-归一化Normalize-输出w开头文件" class="headerlink" title="5. 归一化Normalize 输出w开头文件"></a>5. 归一化Normalize 输出w开头文件</h2><p>修改Voxel sizes—[改为3 3 3]</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/vAXInrMTFVPt7gRAhWS4TpIDbNkgdlsaDhRfXhBMOc4.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/vuW_kxJ_-JzgbLtWkfHVKiiVgk2TANG3Bohc10p1wi4.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/GbYetXI_sud0KtpIbHaQHrlPNM8MbStA3SghJotWibo.png" alt="image"></p><h2 id="6-平滑Smooth-输出sw开头文件"><a href="#6-平滑Smooth-输出sw开头文件" class="headerlink" title="6. 平滑Smooth 输出sw开头文件"></a>6. 平滑Smooth 输出sw开头文件</h2><p>将默认的[8,8,8],改成[6,6,6]</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/VVAU9aGSNhXZN8ldEUgaVUSmn8uEDVVMgUbClChsldo.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/GUJX6GZPtA7glzDl0M-0-ZbfRYnZ8JLLq503QVOShfA.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/z_UE-eqLOi4i4qj9kTMHMRELdioIsKzg8XxwXAEv3IY.png" alt="image"></p><h2 id="7-配准Co-register-reslice"><a href="#7-配准Co-register-reslice" class="headerlink" title="7. 配准Co-register reslice"></a>7. 配准Co-register reslice</h2><p>选择Coregister（Reslice）</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/vBukOosEhMuSUGNQUtyiUHQLw90a5ck8O06aIny7ycM.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/GUJX6GZPtA7glzDl0M-0-ZbfRYnZ8JLLq503QVOShfA.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/Y-1Qla-ySf0OBxzkaTKrfN6CfuYWEoCLZxsbOiI46XY.png" alt="image"></p><p>然后点击运行。运行完成后，将得到的rswaf开头的130个新文件。</p><h2 id="8-提取ROI"><a href="#8-提取ROI" class="headerlink" title="8. 提取ROI"></a>8. 提取ROI</h2><p>在matlab里输入dpabi，运行dpabi。在出现的可视化操作界面中，按下图顺序点击按钮</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/yblbrd21O2Xa0hiwP5bWjYTk4E6HjceOuonNygkhj6c.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/Ir6FoJFlpnybi58Rbgk4XobtAnE-GhUk27IV_DL2588.png" alt="image"></p><p>  </p><p>在出现的界面中，点击Add image 添加rswaf开头的187个文件</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/k_hXth3tZFBsvhxSzyF0khTpaOmCZaN1CjHe18Z9zXY.png" alt="image"></p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/CEFY0eJnELQJ4HHHCvwikudsO5DeMeLDB5WumBjcCbY.png" alt="image"></p><p>点击Define ROI 选择AAL atlas，然后点OK</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/Ir6FoJFlpnybi58Rbgk4XobtAnE-GhUk27IV_DL2588.png" alt="image"></p><p>然后点击Output Dir 来修改输出路径，接着点击Extract</p><p><img src="/2023/10/28/9-%E5%9B%BE-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/Ir6FoJFlpnybi58Rbgk4XobtAnE-GhUk27IV_DL2588.png" alt="image"></p><p>运行完成后，在定义的输出路径下有130*7=910个文件</p><p>其中ROISignals开头的（130*2个文件）就是需要的fmri时间序列文件，</p><p>共包含txt和mat两种格式，两种格式文件所存内容一致，只是文件格式不一样。</p><p>可以使用BrainNetView等工具进行绘制（有待验证）</p><p>ROISignals开头的每个mat文件，储存了1×116的矩阵，表示该时间点下，116个脑区各自的数值。将130个mat文件按顺序组合成130*116的矩阵（可用matlab批处理完成），即是最终的数据矩阵。</p><p><strong>130x116 去除了前10个时间序列节点，因为机器启动热加载导致的不平衡等问题**</strong>。**</p><p>AAL模板中 前90个为大脑脑区，研究中使用较多。后26个为小脑脑区，研究中使用较少。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;目录&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;下载DICOM格式数据&lt;/li&gt;
&lt;li&gt;DICOM -&amp;gt; NIFTI格式 输出s开头文件&lt;/li&gt;
&lt;li&gt;时间层校正Slice Timing 输出as开头文件&lt;/li&gt;
&lt;li&gt;头动校正Realignment 输出ras开头文件&lt;/li&gt;
&lt;li&gt;归一化Normalize 输出w开头文件&lt;/li&gt;
&lt;li&gt;平滑Smooth 输出sw开头文件&lt;/li&gt;
&lt;li&gt;配准Co-register reslice&lt;/li&gt;
&lt;li&gt;提取ROI&lt;/li&gt;&lt;/ol&gt;
    
    </summary>
    
    
    
      <category term="Tools" scheme="http://JavaSsun.github.io/tags/Tools/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>9-(文)利用Matlab的spm12工具处理fMRI为ROI</title>
    <link href="http://javassun.github.io/2023/10/26/9-%E6%96%87-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/"/>
    <id>http://javassun.github.io/2023/10/26/9-%E6%96%87-%E5%88%A9%E7%94%A8Matlab%E7%9A%84spm12%E5%B7%A5%E5%85%B7%E5%A4%84%E7%90%86fMRI%E4%B8%BAROI/</id>
    <published>2023-10-26T07:17:38.000Z</published>
    <updated>2024-05-09T07:11:55.554Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p><a href="https://www.bilibili.com/video/BV1Ee411T74n/?spm_id_from=333.337.search-card.all.click&vd_source=cdbbedc88ac17f2589c268d0ab8e73fc" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1Ee411T74n/?spm_id_from=333.337.search-card.all.click&amp;vd_source=cdbbedc88ac17f2589c268d0ab8e73fc</a></p><h2 id="预备工具"><a href="#预备工具" class="headerlink" title="预备工具"></a>预备工具</h2><p>1matlab<br>2spm12<br>3dpabi（提取ROIs）<br>4AAL1/2/3模板</p><a id="more"></a><h2 id="1-下载DICOM数据"><a href="#1-下载DICOM数据" class="headerlink" title="1. 下载DICOM数据"></a>1. 下载DICOM数据</h2><p><a href="https://ida.loni.usc.edu/home/projectPage.jsp?project=ADNI" target="_blank" rel="noopener">https://ida.loni.usc.edu/home/projectPage.jsp?project=ADNI</a>  </p><h2 id="2-DICOM转换为NIFTI输出s开头文件"><a href="#2-DICOM转换为NIFTI输出s开头文件" class="headerlink" title="2. DICOM转换为NIFTI输出s开头文件"></a>2. DICOM转换为NIFTI输出s开头文件</h2><p>可以直接下载官网提供的nii文件，省时间</p><h2 id="3-时间层校正Slice-Timing输出as开头文件"><a href="#3-时间层校正Slice-Timing输出as开头文件" class="headerlink" title="3. 时间层校正Slice Timing输出as开头文件"></a>3. 时间层校正Slice Timing输出as开头文件</h2><p>修改参数</p><p>Number of slice(nslices)：48 实际nii的最后一个维度</p><p>TR：3（3000ms）可通过ADNI-Collections中待下载文件的Description查看</p><p>TA：TR-TR/nslices（扫描第一张到最后一张的起始时间差）</p><p>信号收集（slice order）：使用Matlab的冒泡表达式表示顺序</p><p>●顺序（sequential）：48:-1:1</p><p>●或间隔（interleaved）：1:2:47 2:2:48</p><p>Reference Slice：nslices/2 最好选择中间的切片，如当前为 48/2=24</p><h2 id="4-头动校正Realignment-Realign-Est-amp-Res-输入ras开头文件"><a href="#4-头动校正Realignment-Realign-Est-amp-Res-输入ras开头文件" class="headerlink" title="4. 头动校正Realignment(Realign Est &amp; Res) 输入ras开头文件"></a>4. 头动校正Realignment(Realign Est &amp; Res) 输入ras开头文件</h2><p>修改参数</p><p>Num Passes：选择Register to mean（均值）</p><h2 id="5-归一化Normalize-Est-amp-Wri-输出w开头文件"><a href="#5-归一化Normalize-Est-amp-Wri-输出w开头文件" class="headerlink" title="5. 归一化Normalize(Est &amp; Wri)输出w开头文件"></a>5. 归一化Normalize(Est &amp; Wri)输出w开头文件</h2><p>修改参数</p><p>修改Voxel size：3 3 3  </p><p>选择上一层产生的mean*.nii文件用于 Image to Align</p><h2 id="6-平滑Smooth-输出sw开头文件"><a href="#6-平滑Smooth-输出sw开头文件" class="headerlink" title="6. 平滑Smooth 输出sw开头文件"></a>6. 平滑Smooth 输出sw开头文件</h2><p>修改参数</p><p>FWHM为高斯平滑核的大小：选择[6,6,6]。</p><h2 id="7-配准Co-register-reslice"><a href="#7-配准Co-register-reslice" class="headerlink" title="7. 配准Co-register(reslice)"></a>7. 配准Co-register(reslice)</h2><p>配准到 AAL1 模板</p><p>AAL模板可以从谷歌搜索下载：</p><p><a href="https://www.gin.cnrs.fr/en/tools/aal/" target="_blank" rel="noopener">https://www.gin.cnrs.fr/en/tools/aal/</a></p><p><a href="https://www.oxcns.org/aal3.html" target="_blank" rel="noopener">https://www.oxcns.org/aal3.html</a></p><h2 id="8-提取ROI"><a href="#8-提取ROI" class="headerlink" title="8. 提取ROI"></a>8. 提取ROI</h2><p>matlab窗口输入 dpabi</p><p>Utilities–&gt;ROI Extractor  </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1Ee411T74n/?spm_id_from=333.337.search-card.all.click&amp;vd_source=cdbbedc88ac17f2589c268d0ab8e73fc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.bilibili.com/video/BV1Ee411T74n/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=cdbbedc88ac17f2589c268d0ab8e73fc&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;预备工具&quot;&gt;&lt;a href=&quot;#预备工具&quot; class=&quot;headerlink&quot; title=&quot;预备工具&quot;&gt;&lt;/a&gt;预备工具&lt;/h2&gt;&lt;p&gt;1matlab&lt;br&gt;2spm12&lt;br&gt;3dpabi（提取ROIs）&lt;br&gt;4AAL1/2/3模板&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Tools" scheme="http://JavaSsun.github.io/tags/Tools/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>8-7-FSL软件使用</title>
    <link href="http://javassun.github.io/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/"/>
    <id>http://javassun.github.io/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/</id>
    <published>2023-10-20T07:17:38.000Z</published>
    <updated>2024-05-09T07:10:00.560Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p>全名是： <strong>F</strong>MRIB’s <strong>S</strong>oftware <strong>L</strong>ibrary - FMRIB 是 英国牛津大学脑功能磁共振成像中心，FSL 则是他们开发的一个软件库。 - 由 Stephen Smith 教授开发，发布于 2000年 - 适用于所有操作系统 - 用于结构 MRI、功能 MRI（任务、静息）、扩散 MRI的分析 - MRI, CT数据的预处理和分析 - MRI, CT数据的查看。</p><a id="more"></a><p><a href="https://blog.csdn.net/qq_39653816/article/details/126372128" target="_blank" rel="noopener">https://blog.csdn.net/qq_39653816/article/details/126372128</a></p><p><a href="https://zhuanlan.zhihu.com/p/430898301" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/430898301</a></p><p><a href="https://fsl.fmrib.ox.ac.uk/fslcourse/2019_Beijing/lectures/reg.pdf" target="_blank" rel="noopener">https://fsl.fmrib.ox.ac.uk/fslcourse/2019_Beijing/lectures/reg.pdf</a></p><p><a href="https://blog.csdn.net/qq_36421001/article/details/119775745" target="_blank" rel="noopener">https://blog.csdn.net/qq_36421001/article/details/119775745</a></p><p><a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET" target="_blank" rel="noopener">https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET</a></p><p><a href="https://space.bilibili.com/542601735/channel/seriesdetail?sid=681057" target="_blank" rel="noopener">https://space.bilibili.com/542601735/channel/seriesdetail?sid=681057</a></p><p><a href="https://www.bilibili.com/video/BV11V411k7oe/?spm_id_from=333.788.recommend_more_video.-1&vd_source=cdbbedc88ac17f2589c268d0ab8e73fc" target="_blank" rel="noopener">https://www.bilibili.com/video/BV11V411k7oe/?spm_id_from=333.788.recommend_more_video.-1&amp;vd_source=cdbbedc88ac17f2589c268d0ab8e73fc</a></p><p><a href="https://blog.csdn.net/u014264373/category_11464520.html?spm=1001.2014.3001.5482" target="_blank" rel="noopener">https://blog.csdn.net/u014264373/category_11464520.html?spm=1001.2014.3001.5482</a></p><p>界面如下</p><p><img src="/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/F59sAC3Usol9F9rt3tZBBw00XhYStpHZAQoZIAiCoLo.png" alt="image"></p><h3 id="BET-Brain-Extraction-Tools-大脑图像提取-去头骨"><a href="#BET-Brain-Extraction-Tools-大脑图像提取-去头骨" class="headerlink" title="BET - Brain Extraction Tools 大脑图像提取/去头骨"></a>BET - Brain Extraction Tools 大脑图像提取/去头骨</h3><p>普通扫描的大脑图像包含非常多的组织，如图所示</p><p><img src="/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/MkTgyQItH7O8KpRsLu10doc_9U3Mo2tQri8tZ26JSGs.png" alt="image"></p><p><img src="/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/ShRVH7_-MmxKTttgmPFZSGMQzk_q_dvWhMppAtUDLIQ.png" alt="image"></p><p>除了大脑组织以外，还包括皮肤，头骨，眼球，嘴巴，喉腔等解剖结构，这些结构会影响我们对大脑的分析。因此，希望对脑组织和非脑组织进行自动分割。</p><p>BET从整个头部的图像中删除非脑组织。如果有质量良好的T1和T2输入图像，他还可以估计颅骨内外表面和头皮外表面。</p><p>大脑和非大脑组织分割、配准等预处理步骤。</p><h3 id="SUSAN-noise-reduction-非线性降噪"><a href="#SUSAN-noise-reduction-非线性降噪" class="headerlink" title="SUSAN noise reduction 非线性降噪"></a>SUSAN noise reduction 非线性降噪</h3><p>SUSAN降噪使用非线性滤波来降低图像（2D或3D）中的噪声，同时保留底层结构。他通过使用具有相似强度的局部体素平均值来代替某一体素。</p><h3 id="FAST-FMRIB’s-Automated-Segmentation-Tool-组织自动分割"><a href="#FAST-FMRIB’s-Automated-Segmentation-Tool-组织自动分割" class="headerlink" title="FAST - FMRIB’s Automated Segmentation Tool 组织自动分割"></a>FAST - FMRIB’s Automated Segmentation Tool 组织自动分割</h3><p>FAST（FMRIB的自动分割工具）将大脑的3D图像分割成不同的组织类型（灰质、白质、脑脊液等），同时校正空间强度变化（也称为偏置场或射频不均匀性）。该方法基于隐马尔可夫随机模型和相关的期望值最大化算法。整个过程是完全自动化的，还可以产生偏场校正输入图像和概率和/部分体积组织分割。与大多数基于有限混合模型的方法相比，该方法对噪声敏感，具有较强的鲁棒性和可靠性。</p><h3 id="MELODIC-ICA-Multivariate-Exploratory-Linear-Optimize-Decomposition-into-Independent-Components"><a href="#MELODIC-ICA-Multivariate-Exploratory-Linear-Optimize-Decomposition-into-Independent-Components" class="headerlink" title="MELODIC ICA - Multivariate Exploratory Linear Optimize Decomposition into Independent Components"></a>MELODIC ICA - Multivariate Exploratory Linear Optimize Decomposition into Independent Components</h3><p>MELODIC 3.0 使用独立成分分析（ICA），将多=单个或多个4D数据分解成不同的空间和时间成分。对于ICA组（ICA Group）分析，MELODIC要么使用张量独立分量分析（TICA，其中数据被分解成空间图（Spatial maps）、时间序列（time courses）和被试/会话（subject/session modes）模式），要么使用更简单的时间连接方法。MELODIC可以识别不同的激活和伪成分，而无需指定任何明确的时间序列模型。</p><h3 id="FDT-FMRIB’s-Diffusion-Toolbox"><a href="#FDT-FMRIB’s-Diffusion-Toolbox" class="headerlink" title="FDT - FMRIB’s Diffusion Toolbox"></a>FDT - FMRIB’s Diffusion Toolbox</h3><p>FDT是一款用于分析扩散加权图像（DWI）的软件工具。</p><p>FDT包括数据预处理、局部扩散建模和纤维追踪成像。FDT的每个阶段都是分开运行的。用户界面提供的主要功能包括：</p><p>Eddy current &amp; motion correction / Outlier detecetion</p><p>用于涡流校正、运动校正和奇异值识别</p><p>BEDPOSTX - 用于扩散参数的局部建模</p><p>PROBTRACKX - 用于纤维追踪成像和基于连接的分割</p><p>dtifit - 用于扩散张量的局部拟合</p><h3 id="POSSUM-Physics-Oriented-Simulated-Scanner-for-Understanding-MRI"><a href="#POSSUM-Physics-Oriented-Simulated-Scanner-for-Understanding-MRI" class="headerlink" title="POSSUM - Physics-Oriented Simulated Scanner for Understanding MRI"></a>POSSUM - Physics-Oriented Simulated Scanner for Understanding MRI</h3><p>POSSUM是一款能够生成逼真的模拟MRI和FMRI图像或时间序列的软件工具。POSSUM包括用于脉冲序列生成、信号生成、噪声添加和图像重建的工具。</p><h3 id="FSLeyes-FSLView"><a href="#FSLeyes-FSLView" class="headerlink" title="FSLeyes/FSLView"></a>FSLeyes/FSLView</h3><p>交互式显示工具</p><p><img src="/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/DHO6BtcsWqayyQ3hapuVRlT7Ovl_lRic_LV4SgOXkXI.png" alt="image"></p><p>从左往右:矢状面(Sagittal) 冠状面(Coronal) 横断面(Axial)</p><p><img src="/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/zzvLeRIjuIL-9NuG5l3jlLqx5hSSZ0YzSZ0UwiQU-os.png" alt="image"></p><p>Axial：又名横断面，transverse<br>Coronal：又名冠状面，<br>Sagittal：矢状面，如同一个箭矢劈开成左右两半</p><p><img src="/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/Xd9koAkiUhwLdvmSGjil32_1hIKepDxQ44sNyQzBal8.png" alt="image"></p><h3 id="FSL实用命令"><a href="#FSL实用命令" class="headerlink" title="FSL实用命令"></a>FSL实用命令</h3><p>查看影像基本信息</p><p>fslinfo *.nii.gz</p><p>查看影像更加详细的信息</p><p>选项参数 -x，以XML格式输出</p><p>Don’t worry if you don’t know what every field means.</p><p>fslhd *.nii.gz</p><p>各种统计量</p><p>fslstats *.nii.gz -m -M</p><p>影像文件分割</p><p>fslsplit *.nii.gz target_folder</p><p>影像文件合并</p><p>fslmerge -t target_folder</p><p>影像剪切、尺寸调整</p><p>fslroi *.nii.gz *_resize.nii.gz -5 101 -5 119 -5 101</p><p>数字自己设置</p><p>fsl数学工具</p><p>fslmaths</p><p>fslutils</p><p>fslcpgeom - 将标题信息的某些部分（图像尺寸、体素尺寸、体素尺寸单位字符串、图像方向/）从一个图像复制到另一个图像</p><p>fslinfo - 报告 Nifti 数据的头文件信息</p><p>fslmaths - 简单但功能强大的程序，允许对图像进行数学处理</p><p>fslmerge - 合并多个图像文件</p><p>fslroi - 从图像中提取感兴趣区域 (ROI)</p><p>fslslice - 将 3D 文件拆分为许多 2D 文件（沿 z 轴）</p><p>fslsplit - 将一个 4D 文件分割成许多 3D 文件</p><p>fslorient - 报告图像的采集方向信息</p><h3 id="数据集性别-年龄分布"><a href="#数据集性别-年龄分布" class="headerlink" title="数据集性别/年龄分布"></a>数据集性别/年龄分布</h3><table><thead><tr><th>Dataset</th><th>Male</th><th>Female</th><th>Age_Round</th><th>Mean_Age</th><th>Count_Number</th><th>MMSE</th><th>CDR</th></tr></thead><tbody><tr><td>AD</td><td>73</td><td>77</td><td>56 ~ 93</td><td>77.01 ± 7.44</td><td>150</td><td></td><td></td></tr><tr><td>MCI</td><td>75</td><td>75</td><td>55 ~ 90</td><td>75.4 ± 7.71</td><td>150</td><td></td><td></td></tr><tr><td>NC</td><td>71</td><td>79</td><td>61 ~ 91</td><td>77.13 ± 5.37</td><td>150</td><td></td><td></td></tr></tbody></table><h3 id="数据批处理"><a href="#数据批处理" class="headerlink" title="数据批处理"></a>数据批处理</h3><p>#!/bin/bash 此脚本由bash进行解释，bash是一种命令解释器</p><p>cd change directory的缩写，切换路径</p><p>$ 变量名的起始</p><p>echo 输出字符串</p><p>mkdir 创建文件夹</p><p>ls 列出文件及目录</p><p>BET.sh</p><figure class="highlight plain"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">baseADDir&#x3D;&quot;&#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;shr&#x2F;AD&#x2F;ADNI-Datasets&#x2F;AD&#x2F;origin&#x2F;&quot;</span><br><span class="line">cd $baseADDir</span><br><span class="line">echo ~~~~~~AD-BET-Started~~~~~~</span><br><span class="line">niiList&#x3D;&#96;ls *.nii&#96;</span><br><span class="line">for nii in $niiList;do</span><br><span class="line">    echo $nii</span><br><span class="line">    bet2 $nii  $&#123;nii%.*&#125;_brain -f 0.5 -g 0</span><br><span class="line">done</span><br><span class="line">echo ~~~~~~AD-BET-Finshed~~~~~~</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">baseCNDir&#x3D;&quot;&#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;shr&#x2F;AD&#x2F;ADNI-Datasets&#x2F;CN&#x2F;origin&#x2F;&quot;</span><br><span class="line">cd $baseCNDir</span><br><span class="line">echo ~~~~~~CN-BET-Started~~~~~~</span><br><span class="line">niiList&#x3D;&#96;ls *.nii&#96;</span><br><span class="line">for nii in $niiList;do</span><br><span class="line">    echo $nii</span><br><span class="line">    bet2 $nii  $&#123;nii%.*&#125;_brain -f 0.5 -g 0</span><br><span class="line">done</span><br><span class="line">echo ~~~~~~CN-BET-Finshed~~~~~~</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">baseMCIDir&#x3D;&quot;&#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;shr&#x2F;AD&#x2F;ADNI-Datasets&#x2F;MCI&#x2F;origin&#x2F;&quot;</span><br><span class="line">cd $baseMCIDir</span><br><span class="line">echo ~~~~~~MCI-BET-Started~~~~~~</span><br><span class="line">niiList&#x3D;&#96;ls *.nii&#96;</span><br><span class="line">for nii in $niiList;do</span><br><span class="line">    echo $nii</span><br><span class="line">    bet2 $nii  $&#123;nii%.*&#125;_brain -f 0.5 -g 0</span><br><span class="line">done</span><br><span class="line">echo ~~~~~~MCI-BET-Finshed~~~~~~</span><br></pre></td></tr></table></figure><p>sh BET.sh</p><p>FLIRT</p><figure class="highlight plain"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">baseADDir&#x3D;&quot;&#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;shr&#x2F;AD&#x2F;ADNI-Datasets&#x2F;AD&#x2F;origin&#x2F;&quot;</span><br><span class="line">cd $baseADDir</span><br><span class="line">echo ~~~~~~AD-FLIRT-Started~~~~~~</span><br><span class="line">niiList&#x3D;&#96;ls *.nii.gz&#96;</span><br><span class="line">for nii in $niiList;do</span><br><span class="line">    echo $nii</span><br><span class="line">    flirt -in $nii -ref &#x2F;usr&#x2F;local&#x2F;fsl&#x2F;data&#x2F;standard&#x2F;MNI152_T1_2mm_brain -out $&#123;nii%.nii.gz*&#125;_FLIRT \</span><br><span class="line">          -omat $&#123;nii%.nii.gz*&#125;_FLIRT.mat \</span><br><span class="line">          -bins 256 -cost corratio \</span><br><span class="line">          -searchrx -90 90 -searchry -90 90 -searchrz -90 90 \</span><br><span class="line">          -dof 12  -interp trilinear</span><br><span class="line">done</span><br><span class="line">echo ~~~~~~AD-FLIRT-Finshed~~~~~~</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">baseCNDir&#x3D;&quot;&#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;shr&#x2F;AD&#x2F;ADNI-Datasets&#x2F;CN&#x2F;origin&#x2F;&quot;</span><br><span class="line">cd $baseCNDir</span><br><span class="line">echo ~~~~~~CN-FLIRT-Started~~~~~~</span><br><span class="line">niiList&#x3D;&#96;ls *.nii.gz&#96;</span><br><span class="line">for nii in $niiList;do</span><br><span class="line">    echo $nii</span><br><span class="line">    flirt -in $nii -ref &#x2F;usr&#x2F;local&#x2F;fsl&#x2F;data&#x2F;standard&#x2F;MNI152_T1_2mm_brain -out $&#123;nii%.nii.gz*&#125;_FLIRT \</span><br><span class="line">          -omat $&#123;nii%.nii.gz*&#125;_FLIRT.mat \</span><br><span class="line">          -bins 256 -cost corratio \</span><br><span class="line">          -searchrx -90 90 -searchry -90 90 -searchrz -90 90 \</span><br><span class="line">          -dof 12  -interp trilinear</span><br><span class="line">done</span><br><span class="line">echo ~~~~~~CN-FLIRT-Finshed~~~~~~</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">baseMCIDir&#x3D;&quot;&#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;shr&#x2F;AD&#x2F;ADNI-Datasets&#x2F;MCI&#x2F;origin&#x2F;&quot;</span><br><span class="line">cd $baseMCIDir</span><br><span class="line">echo ~~~~~~MCI-FLIRT-Started~~~~~~</span><br><span class="line">niiList&#x3D;&#96;ls *.nii.gz&#96;</span><br><span class="line">for nii in $niiList;do</span><br><span class="line">    echo $nii</span><br><span class="line">    flirt -in $nii -ref &#x2F;usr&#x2F;local&#x2F;fsl&#x2F;data&#x2F;standard&#x2F;MNI152_T1_2mm_brain -out $&#123;nii%.nii.gz*&#125;_FLIRT \</span><br><span class="line">          -omat $&#123;nii%.nii.gz*&#125;_FLIRT.mat \</span><br><span class="line">          -bins 256 -cost corratio \</span><br><span class="line">          -searchrx -90 90 -searchry -90 90 -searchrz -90 90 \</span><br><span class="line">          -dof 12  -interp trilinear</span><br><span class="line">done</span><br><span class="line">echo ~~~~~~MCI-FLIRT-Finshed~~~~~~</span><br></pre></td></tr></table></figure><p>sh FLIRT.sh</p><h3 id="将-nii-nii-gz-文件转化为-png-jpg"><a href="#将-nii-nii-gz-文件转化为-png-jpg" class="headerlink" title="将.nii(.nii.gz)文件转化为.png(jpg)"></a>将.nii(.nii.gz)文件转化为.png(jpg)</h3><p>工具命令: fslslice - 将 3D 文件拆分为许多 2D 文件（沿 z 轴）</p><p>代码:</p><figure class="highlight plain"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import os #遍历文件夹</span><br><span class="line">import nibabel as nib</span><br><span class="line">import imageio #转换成图像</span><br><span class="line"></span><br><span class="line">def nii_to_image(niifile):</span><br><span class="line">    filenames &#x3D; os.listdir(filepath)  #读取nii文件</span><br><span class="line">    slice_trans &#x3D; []</span><br><span class="line"></span><br><span class="line">    for f in filenames:</span><br><span class="line">        #开始读取nii文件</span><br><span class="line">        img_path &#x3D; os.path.join(filepath, f)</span><br><span class="line">        img &#x3D; nib.load(img_path)  #读取nii</span><br><span class="line">        img_fdata &#x3D; img.get_fdata()</span><br><span class="line">        fname &#x3D; f.replace(&#39;.nii&#39;, &#39;&#39;) #去掉nii的后缀名</span><br><span class="line">        img_f_path &#x3D; os.path.join(imgfile, fname)</span><br><span class="line">        # 创建nii对应图像的文件夹</span><br><span class="line">        if not os.path.exists(img_f_path):</span><br><span class="line">            os.mkdir(img_f_path)  #新建文件夹</span><br><span class="line"></span><br><span class="line">        #开始转换图像</span><br><span class="line">        (x,y,z) &#x3D; img.shape</span><br><span class="line">        for i in range(z):   #是z的图象序列</span><br><span class="line">            slice &#x3D; img_fdata[i, :, :]  #选择哪个方向的切片自己决定</span><br><span class="line">            imageio.imwrite(os.path.join(img_f_path, &#39;&#123;&#125;.png&#39;.format(i)), slice)</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    filepath &#x3D; &#39;D:&#x2F;feiyan&#x2F;COVID-19-CT-Seg_20cases&#39;</span><br><span class="line">    imgfile &#x3D; &#39;D:&#x2F;feiyan&#x2F;covid19-ct-seg-png&#39;</span><br><span class="line">    nii_to_image(filepath)</span><br></pre></td></tr></table></figure><h3 id="数据处理一般步骤"><a href="#数据处理一般步骤" class="headerlink" title="数据处理一般步骤"></a>数据处理一般步骤</h3><p>头动校正</p><p>MIPAV 进行 AC-PC校正</p><p>BET颅骨剥离</p><p>配准MNI_152</p><p>平滑处理</p><p>224x224x3</p><p>FAST 组织分割 灰质、白质、脑脊液</p><p>提取灰质图像进行切片预处理/直接对横、冠、矢进行切割</p><p>针对sMRI</p><p>* BET颅骨剥离</p><p>* Linear(FLIRT) 配准到MNI_152</p><p>* 图像平滑 6x6x6</p><p>* FAST 组织类型分割,分割出灰质、白质、脑脊液(对灰质图像作进一步体积/面积处理)</p><p>* 省去组织类型分割,图像平滑结束后直接对横断面/矢状面/冠状面进行切片处理(3D—-&gt;2D)</p><h3 id="针对切片"><a href="#针对切片" class="headerlink" title="针对切片"></a>针对切片</h3><p>计算所有MRI切片的熵，并按熵大小对它们进行降序排列，仅选取信息熵较大的sMRI切片用于训练CNN模型，从而增强了模型的整体稳健性.</p><p>为了扩充数据集，对每位受试者的切片图像进行筛选扩充。一种简单的方法是随机选择多张图像，但这样的选择方法可能会遗漏一些关键信息。采用Hon等人提出的图像熵选取切片的方法，该方法按照图像中包含信息的多少即熵的大小，将切片从大到小进行排列，对每位受试者的MRI切片，选取熵值较高的前32个，这样既有利于扩充数据集，也有利于将信息少的图像排除在外.</p><h3 id="分类实验"><a href="#分类实验" class="headerlink" title="分类实验"></a>分类实验</h3><p>* AD-MCI</p><p>* AD-NC</p><p>* NC-MCI</p><p>* AD-MCI-NC</p><h3 id="已有算法"><a href="#已有算法" class="headerlink" title="已有算法"></a>已有算法</h3><p><strong>每两个算法是一篇大论文中提出的两个小创新点.</strong></p><h4 id="基于深度神经网络的阿尔兹海默病分类算法研究-曲阜师范大学-计算机学院-崔秀明"><a href="#基于深度神经网络的阿尔兹海默病分类算法研究-曲阜师范大学-计算机学院-崔秀明" class="headerlink" title="基于深度神经网络的阿尔兹海默病分类算法研究-曲阜师范大学-计算机学院-崔秀明"></a>基于深度神经网络的阿尔兹海默病分类算法研究-曲阜师范大学-计算机学院-崔秀明</h4><p>基于迁移学习和深度残差网络的阿尔兹海默病分类算法</p><p>根据CNN的参数共享性，引入迁移学习的思想，将在ImageNet中预训练好的ResNet/DenseNet模型迁移至MRI数据集中进行微调，从而替代从头开始训练一个全新的模型.另外训练一个与深度ResNet一样大的CNN需要巨大的计算资源，并且需要数周的时间才能训练。因此提出了基于迁移学习和深度残差网络的阿尔兹海默病分类算法，该算法引入迁移学习解决了可用医学图像样本数量少的问题，缩短了CNN模型的训练时间；引入信息熵的概念用于选择训练集，增强了模型的整体稳健性。</p><p><img src="/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/OF7xEiLRR55M0HmbHIwaPVVvA9KoaR9jjJPY2oRRgK4.png" alt="image"></p><p>基于深层特征和非线性降维的阿尔兹海默病分类算法</p><p>医学图像存在一个固有的劣势，就是高维非线性，现存方法也曾尝试了使用降维方法对其进行降维，但是由于数据的非线性特性使得在降维过程中产生了很多损失，导致最后的分类效果不理想；另外，前人所做工作中使用的降维方法的算法复杂度非常高，浪费计算成本。因此，提出了基于深层特征和非线性降维的阿尔兹海默病分类算法，在算法中引入了非线性降维方法LargeVis，减少了线性降维方法在降维过程中损失的信息，并大大降低了计算成本。</p><p><img src="/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/HCLCGc6xEIdDdATe_JrMHxgjg43wxWzmXKwJ6_hBwvk.png" alt="image"></p><h4 id="基于卷积神经网络的阿尔茨海默病分类算法研究-曲阜师范大学-计算机学院-刘汉磊"><a href="#基于卷积神经网络的阿尔茨海默病分类算法研究-曲阜师范大学-计算机学院-刘汉磊" class="headerlink" title="基于卷积神经网络的阿尔茨海默病分类算法研究-曲阜师范大学-计算机学院-刘汉磊"></a>基于卷积神经网络的阿尔茨海默病分类算法研究-曲阜师范大学-计算机学院-刘汉磊</h4><p>基于特征重构和卷积神经网络的AD分类算法</p><p>基于先验知识90个ROI的灰质体积作为特征</p><p>将预处理好的MRI数据使用EDLT方法进行特征重构，构造了一个层数较浅的卷积神经网络结构，并利用迁移学习进行预训练，在ADNI数据集上进行了训练和测试评估。结果显提方法要比单纯使用特征数据进行分类的传统机器学习方法的分类效果有所提高，表明使用特征重构的方法能够获得有意义的分类效果，迁移学习的使用能够降低在小样本数据集中的过拟合风险，也降低了计算成本。</p><p>基于迁移学习和密集连接网络的阿尔茨海默病分类算法</p><h4 id="基于先验知识90个ROI的灰质体积作为特征"><a href="#基于先验知识90个ROI的灰质体积作为特征" class="headerlink" title="基于先验知识90个ROI的灰质体积作为特征"></a>基于先验知识90个ROI的灰质体积作为特征</h4><p>采用高斯滤波器进行图像增强，使用HEICA进行灰质分割，对AD、NC、MCI的三分类任务和两两分类任务进行了实验，实验数据基于ADNI数据库。结果显示，迁移学习的效果优于从头训练的效果，使用HEICA进行分割的效果优于未使用的效果。表明了在小样本数据集上使用迁移学习的必要性，以及使用图像增强和HEICA方法的有效性。</p><p><img src="/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/kwyIOEVcQ8Fk24Yf7nIu19iqhBPfo6476R2SLENqOGU.png" alt="image"></p><p>这个作者为了训练深度神经网络数据，使用PyTorch来进行训练和测试，GPU为英伟达精视GTX 1070，采用帕斯卡架构，16nm制程工艺，单精度浮点数达到了6.5Tflops，显存容量8GB GDDR5，核心频率为1683MHz，显存频率8000MHz</p><p><strong>医学图像的小样本问题和图像质量不高的问题，一直是研究人员进行医学图像分类的困扰。引入了高斯滤波器进行图像增强，使用HEICA进行灰质图像分割，得到了较为清晰的灰质图像；引入信息熵的概念用于选择切片图像，以增加数据集样本数量.</strong></p><h4 id="基于迁移学习的阿尔茨海默病早期诊断算法研究-曲阜师范大学-计算机学院-刘永林"><a href="#基于迁移学习的阿尔茨海默病早期诊断算法研究-曲阜师范大学-计算机学院-刘永林" class="headerlink" title="基于迁移学习的阿尔茨海默病早期诊断算法研究-曲阜师范大学-计算机学院-刘永林"></a>基于迁移学习的阿尔茨海默病早期诊断算法研究-曲阜师范大学-计算机学院-刘永林</h4><p>基于判别式迁移特征学习的AD早期诊断算法</p><p>将每个受试者灰质体积配准到AAL模板上,选择ALL模板中90个自动标记的ROI,计算每个ROI的体积作为特征</p><p><img src="/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/HlfAn5s6Lngd14Qmr3J5j5Galh9OM8oxkyEOwEPjl2Y.png" alt="image"></p><p>基于<strong>集成迁移学习的AD早期诊断算法</strong></p><p><img src="/2023/10/20/8-7-FSL%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/dQBLz5At-lKBE0vdBIidFbJG5nPAf_IP-ffQ0UCFUfE.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;全名是： &lt;strong&gt;F&lt;/strong&gt;MRIB’s &lt;strong&gt;S&lt;/strong&gt;oftware &lt;strong&gt;L&lt;/strong&gt;ibrary - FMRIB 是 英国牛津大学脑功能磁共振成像中心，FSL 则是他们开发的一个软件库。 - 由 Stephen Smith 教授开发，发布于 2000年 - 适用于所有操作系统 - 用于结构 MRI、功能 MRI（任务、静息）、扩散 MRI的分析 - MRI, CT数据的预处理和分析 - MRI, CT数据的查看。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Tools" scheme="http://JavaSsun.github.io/tags/Tools/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>8-6-FreeSurfer软件使用</title>
    <link href="http://javassun.github.io/2023/10/16/8-6-FreeSurfer%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/"/>
    <id>http://javassun.github.io/2023/10/16/8-6-FreeSurfer%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/</id>
    <published>2023-10-16T09:17:38.000Z</published>
    <updated>2024-05-09T07:08:21.746Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p><a href="https://surfer.nmr.mgh.harvard.edu/fswiki/rel7downloads" target="_blank" rel="noopener">https://surfer.nmr.mgh.harvard.edu/fswiki/rel7downloads</a><br><a href="https://blog.csdn.net/Y000077/article/details/122614510" target="_blank" rel="noopener">https://blog.csdn.net/Y000077/article/details/122614510</a><br>Ubuntu 20 64 位 许可证<br><a href="https://www.yuque.com/attachments/yuque/0/2024/txt/22829897/1711445891856-18f9b254-6981-4bd4-b589-48b87337e695.txt" target="_blank" rel="noopener">📎license.txt</a></p><a id="more"></a><h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><p>freesurfer一共有31个处理步骤，使用recon-all可完成全部处理步骤</p><p>由于 vi ~/.bashrc 中</p><p>export SUBJECTS_DIR=/home/pugongying/data/Brain/MRI</p><p>所以 -s 指定到SUBJECTS_DIR这里,</p><figure class="highlight plain"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">recon-all -i &#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;shr&#x2F;AD&#x2F;ADNI-Datasets&#x2F;AD&#x2F;origin&#x2F;ADNI_002_S_0619_I120964.nii -s &#x2F;home&#x2F;pugongying&#x2F;data&#x2F;Brain&#x2F;MRI&#x2F; -autorecon1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># *.nii 待处理nii图</span><br><span class="line"></span><br><span class="line"># -s &#x2F;home&#x2F;pugongying&#x2F;data&#x2F;Brain&#x2F;MRI&#x2F;为处理后的存放的文件夹名字（处理结束后自动生成）</span><br><span class="line"></span><br><span class="line"># -all 走完31个步骤,经测验,一个nii图像会大概走1个小时</span><br><span class="line"></span><br><span class="line"># --autorecon1</span><br></pre></td></tr></table></figure><p><strong>recon-all 全部步骤</strong><br>每一步的输入输出和参数可参考：<a href="https://read.douban.com/reader/column/594403/chapter/3949428/?dcs=chapters&dcm=chapter-list" target="_blank" rel="noopener">FreeSurfer核心命令之recon-all - FreeSurfer使用手册 - 秋月斋人 | 豆瓣阅读</a><br>01. 运动校正与确认<br>02. NU (非均匀强度标准化处理)<br>03. Talairach 变换计算<br>04. 强度标准化1<br>05. 去除脑壳<br>06. EM登记 (线性体积登记)<br>07. CA 强度标准化<br>08. CA 非线性体积登记<br>09. 去除颈部<br>10. 脑壳LTA<br>11. CA标记 (体积标记, 如Aseg)和统计<br>12. 强度标准化2 (控制点开始)<br>13. 白质分割<br>14. 白质ASeg编辑<br>15. 填充(开始白质编辑)<br>16. Tessellation细分曲面技术 (开始每个脑半球的操作)<br>17. 平滑1<br>18. 胀平1<br>19. QSphere<br>20. 自动化局部解剖修复<br>21. 最终的曲面 (从这里开始编辑软脑膜)<br>22. 平滑2<br>23. 胀平2<br>24. 球形映射<br>25. 球形登记<br>26. 球形登记，对侧半球<br>27. Subject平均曲率映射<br>28. 皮质划分 - Desikan_Killian和Christophe 分类<br>29. 皮质划分统计<br>30. 皮质色带覆盖<br>31. 皮质划分到aseg映射<br><strong>分步骤处理</strong><br>语句 对应操作<br>-autorecon1 完成步骤1-5<br>等等  </p><p><strong>颅骨剥离与仿射对齐</strong><br>如果是需要做颅骨剥离和对齐，可以用下面这段代码批量处理，将如下代码存为freesurfer_preprocessing.py文件，在终端输入 python freesurfer_preprocessing.py ，回车即可  </p><p>每次<br>终端更改<br>vi ~/.bashrc<br>SUBJECT_DIR=”/home/pugongying/data/Brain/MRI/CN/“<br>source ~/.bashrc  </p><p>代码中更改<br>path =r”/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin/“<br>SUBJECT_DIR=”/home/pugongying/data/Brain/MRI/CN/“  </p><p>path =r”/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin/“<br>SUBJECT_DIR=”/home/pugongying/data/Brain/MRI/MCI/“  </p><figure class="highlight plain"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line"></span><br><span class="line"># 数据读取目录</span><br><span class="line">path &#x3D;r&quot;&#x2F;home&#x2F;pugongying&#x2F;data&#x2F;jupyterLab&#x2F;shr&#x2F;AD&#x2F;ADNI-Datasets&#x2F;AD&#x2F;origin&#x2F;&quot; </span><br><span class="line"># 结果保存目录</span><br><span class="line">SUBJECT_DIR &#x3D; &quot;&#x2F;home&#x2F;pugongying&#x2F;data&#x2F;Brain&#x2F;MRI&#x2F;AD&#x2F;&quot;</span><br><span class="line"># 读取path下的nii文件</span><br><span class="line">images &#x3D; glob.glob(os.path.join(path, &quot;*.nii&quot;))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 调用freesurfer的环境配置命令</span><br><span class="line">a &#x3D; &quot;export FREESURFER_HOME&#x3D;&#x2F;home&#x2F;pugongying&#x2F;data&#x2F;freesurfer;&quot;</span><br><span class="line">b &#x3D; &quot;source $FREESURFER_HOME&#x2F;SetUpFreeSurfer.sh;&quot;</span><br><span class="line">c &#x3D; &quot;export&quot; + SUBJECT_DIR+&quot;;&quot;</span><br><span class="line"></span><br><span class="line">for image in images:</span><br><span class="line">    # 将文件路径和文件名分割</span><br><span class="line">    filename &#x3D; os.path.split(image)[1]</span><br><span class="line"></span><br><span class="line">    # 将文件名和扩展名分开.如果为.nii.gz,则认为扩展名是.gz|</span><br><span class="line">    filename &#x3D; os.path.splitext(filename)[0]</span><br><span class="line"></span><br><span class="line">    # 根据扩展名的不同,只保留文件名即可,这里需要作出修改</span><br><span class="line">    filename &#x3D; filename[:15]</span><br><span class="line">    print(filename)</span><br><span class="line"></span><br><span class="line">    # cur_path &#x3D; os.path.join(path, filename) # 存原始目录</span><br><span class="line">    # cur_path &#x3D; os.path.join(path, filename)</span><br><span class="line">    cur_path &#x3D; os.path.join(SUBJECT_DIR, filename)</span><br><span class="line"></span><br><span class="line">    # print(&quot;filename: &quot;, cur_path)</span><br><span class="line">    # freesurfer环境配置、颅骨去除、未仿射对齐mpz转nii、仿射对齐、仿射对齐mpz转nii.gz格式</span><br><span class="line">    # recon-all是数据开始处理的命令， -parallels指并行处理，-autorecon1 -subjid指只使用recon-all的前五步：运动校正、非均匀强度归一化、Talairach变换、强度归一化，去颅骨</span><br><span class="line">    # mri_convert是进行格式转换，从mgz转到nii.gz，只是为了方便查看</span><br><span class="line">    # --apply_transform：仿射对齐操作</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cmd &#x3D; a + b + c \</span><br><span class="line">          + &quot;recon-all -parallel -i &quot; + image + &quot; -autorecon1 -subjid &quot; + cur_path + &quot;&amp;&amp;&quot; \</span><br><span class="line">          + &quot;mri_convert &quot; + cur_path + &quot;&#x2F;mri&#x2F;brainmask.mgz &quot; \</span><br><span class="line">                           + cur_path + &quot;&#x2F;mri&#x2F;&quot; + filename + &quot;_brainmask.nii.gz;&quot;\</span><br><span class="line">          + &quot;mri_convert &quot; + cur_path + &quot;&#x2F;mri&#x2F;brainmask.mgz --apply_transform &quot; \</span><br><span class="line">                           + cur_path + &quot;&#x2F;mri&#x2F;transforms&#x2F;talairach.xfm -o &quot; \</span><br><span class="line">                           + cur_path + &quot;&#x2F;mri&#x2F;brainmask_affine.mgz&amp;&amp;&quot; \</span><br><span class="line">          + &quot;mri_convert &quot; + cur_path + &quot;&#x2F;mri&#x2F;brainmask_affine.mgz &quot; \</span><br><span class="line">                           + cur_path + &quot;&#x2F;mri&#x2F;&quot;+filename+&quot;_affine.nii.gz;&quot;</span><br><span class="line">    # print(&quot;cmd:\n&quot;,cmd)</span><br><span class="line">    os.system(cmd)</span><br></pre></td></tr></table></figure><p>完成一个后，会在SUBJECTS_DIR目录下生成一个以原图名称命名的文件夹</p><p><img src="/2023/10/16/8-6-FreeSurfer%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/tx5qhJ6sQlSPnMi2kOOLwP-8mD6pXhxL85laFYwOuvs.png" alt="image"></p><p> 文件夹的子目录mri中存放的是完成预处理的结果</p><p><img src="/2023/10/16/8-6-FreeSurfer%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/F83aHr6AcssQ64G_1HwrV1RgsPCo1FEpjW5rqZXYbuQ.png" alt="image"></p><p>剥离颅骨结果：brainmask.mgz</p><p>仿射校正结果：brainmask_affine.mgz</p><p>剥离颅骨转成nii结果：ADNI_011_S_0003_brainmask.nii.gz</p><p>仿射校正转成nii结果：ADNI_011_S_0003_brainmask_affine.nii.gz</p><p><img src="/2023/10/16/8-6-FreeSurfer%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/lU4f11B70cHZi74OnHeQwHPpSKK92Tz9eD5Fr1Luj0c.png" alt="image"></p><h3 id="使用Fsleyes查看效果图"><a href="#使用Fsleyes查看效果图" class="headerlink" title="使用Fsleyes查看效果图"></a>使用Fsleyes查看效果图</h3><p><img src="/2023/10/16/8-6-FreeSurfer%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/LNNrZdra-WuD73cujQOlw_AmO4ceHxZ_kX5vcQmt51Q.png" alt="image"></p><p>Ububtu</p><p>ctrl + shift + alt +R 开始录屏</p><p>ctrl + shift + alt + R 再次按，结束录屏</p><p><a href="http://t.zoukankan.com/lulin1-p-7472504.html" target="_blank" rel="noopener">http://t.zoukankan.com/lulin1-p-7472504.html</a></p><p>最近在github中添加项目实现效果时需要用到gif图，在网上搜了一些工具和教程，会发现windows系统比ubuntu多很多，经过实际验证以下这种方法可以实现gif图的录制与制作，具体方法如下</p><p>１、命令行安装软件：</p><figure class="highlight plain"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install kazam sudo apt-get install  mplayer</span><br></pre></td></tr></table></figure><p>2、使用 kazam 来录制视频：</p><p>按一下键盘的 win 键（也就是一个windows的图标的键），入后输入 kazam，点击该软件，就可以通过它来录制视频了。该软件<strong>可以截图</strong>也<strong>可以录制 mp4 格式</strong>的视频。</p><p>３、将mp4格式转化为gif：</p><p>这个过程分为两步：（1）将mp4格式转化为 jpg 格式的图片; （2）将生成的 jpg 格式的图片转化为 gif 格式的图片。</p><p><em>1.1</em> 在终端下切换到刚刚存放的mp4格式的地方，然后在该文件夹下<strong>创建一个tabs文件夹</strong>用以存放等下生成的 jpg 图片。</p><p>转换为jpg： 输入命令：</p><p>mplayer -ao null editor.mp4 -vo jpeg:outdir=./tabs</p><p>上面命令大致意思是将刚刚生成的 editor.mp4 在 tabs文件夹中生成 jpg 图片。</p><p> <em>2.2</em> 将tabs文件夹中的 jpg 格式的图片转化为 gif 格式的图片：</p><p>convert ./tabs/*.jpg editor.gif</p><p>在当前目录下生成 editor.gif 。这时就已经是 gif 格式的图片了。</p><p>这种方法可以实现gif图，但要经历 <strong><em>录制mp4格式视频</em></strong> <strong><em>－&gt;</em></strong> <strong><em>mp4格式视频转(十几张甚至更多)jpg格式图片</em></strong> <strong><em>－&gt;</em></strong> <strong><em>jpg格式图片转gif格式</em></strong> 。 可以看到这种方法虽然可以实现但是有些麻烦，以后遇到更好的方法会进行更新。</p><p><a href="https://cloudconvert.com/mp4-to-gif" target="_blank" rel="noopener">https://cloudconvert.com/mp4-to-gif</a></p><p><a href="https://convertio.co/zh/mp4-gif/" target="_blank" rel="noopener">https://convertio.co/zh/mp4-gif/</a></p><p><a href="https://www.aconvert.com/cn/video/mp4-to-gif/" target="_blank" rel="noopener">https://www.aconvert.com/cn/video/mp4-to-gif/</a></p><p><img src="/2023/10/16/8-6-FreeSurfer%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/Rg-0NplxWjTp9ftw4g-tE9-VcqGB01sg9zMqgHf43ZM.gif" alt="image"></p><h3 id="检验质量"><a href="#检验质量" class="headerlink" title="检验质量"></a>检验质量</h3><p>使用fsl文件去抽查数据,然后进行分割(3D—&gt;2D)</p><p>直接用代码进行切片，见实验/Slice</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://surfer.nmr.mgh.harvard.edu/fswiki/rel7downloads&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://surfer.nmr.mgh.harvard.edu/fswiki/rel7downloads&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/Y000077/article/details/122614510&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://blog.csdn.net/Y000077/article/details/122614510&lt;/a&gt;&lt;br&gt;Ubuntu 20 64 位 许可证&lt;br&gt;&lt;a href=&quot;https://www.yuque.com/attachments/yuque/0/2024/txt/22829897/1711445891856-18f9b254-6981-4bd4-b589-48b87337e695.txt&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;📎license.txt&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Tools" scheme="http://JavaSsun.github.io/tags/Tools/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>8-5-SPM软件使用</title>
    <link href="http://javassun.github.io/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/"/>
    <id>http://javassun.github.io/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/</id>
    <published>2023-10-10T09:17:38.000Z</published>
    <updated>2024-05-09T07:05:33.314Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p><a href="https://www.bilibili.com/video/BV1D54y1Y7Ca/?spm_id_from=pageDriver&vd_source=af160cbe43a365e4f56321b03888e798" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1D54y1Y7Ca/?spm_id_from=pageDriver&amp;vd_source=af160cbe43a365e4f56321b03888e798</a></p><h2 id="1-时间矫正"><a href="#1-时间矫正" class="headerlink" title="1-时间矫正"></a><strong>1-时间矫正</strong></h2><p>1:max_num，max_num可由下面给出。  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/61oNOThM29xYcyl9InETol7S_pfymyKe7jNhWrpRyPM.png" alt="image"></p><a id="more"></a><p>Number of Slices: 40  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/eOrd5NzGtvG0zLiIiODzlMD15t3VFUIhg3a6ug1l8uU.png" alt="image"></p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/wJPiH7V1fZ5Kmbt8IP45vM_bOu9JTQAbFCS1IjFkdyA.png" alt="image"></p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/pa2uvU0N5PceTnSJNP5k2rf7zrXsjfvT06sqnIHg0f4.webp" alt="image"></p><p>使用Display查看我们经过时间矫正后的nii  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/npgXf6cEf1qSWGBJ1aFuToY3MfvJUdg3n8HbesXCFZw.png" alt="image"></p><p>将上述Batch操作记录为代码，防止人工重复点击应用于其他文件时出错  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/4_3TdIL_QpcvtoXcMraDgw9QaNtw6bJ9N9rqpm5T_zw.png" alt="image"></p><p>slice_timing中保留了我们设定的参数，如TR,TA，Slice Numbers等  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/Z1SxiP46dzPx7pbbkwiRQRRli73JgPcPU_So2eIjQzY.png" alt="image"></p><p>再次运行，以脚本方式  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/o8R0U1I_YO8qHww6ph36o32ylvh7Cpbl58JLktZy5Us.png" alt="image"></p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/bvUZhSggiD-rG9fxLcM6Uv1Cw-mYNGmuRNNNCHmaGQw.webp" alt="image"></p><h2 id="2-头动矫正（Realign）"><a href="#2-头动矫正（Realign）" class="headerlink" title="2-头动矫正（Realign）"></a><strong>2-头动矫正（Realign）</strong></h2><p>将我们收集到的TR对齐到某一个全脑上去。可以是第一个全脑、中间的全脑、最后一个全脑或者平均全脑等。<br>总之就是对齐收集到的数据，在对齐过程中，会分别算出来移动的方向和距离（如何对齐的？）。会形成一个日志文件，记录了如何将当前图像移动到标准像上面，（往左移动了多少，旋转了多少等等具体的操作）。<br>即：<strong>头动参数</strong><br><strong>●Estimate：只是计算了头动参数，并没有真正移动头像，会把头动参数写到源文件nii的头文件中，源文件虽然没有改变头动位置，但源文件的修改日期依然是应用过Estimate操作后的新时间。</strong>  </p><p><strong>●Reslice：算出来了头动参数后，点击此选项，真正对头动进行处理</strong>  </p><p><strong>●Est&amp;Res：将上述两步联合起来，即评估要移动的参数，又对头像进行处理。（√）</strong>  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/qVGbAOUoLYKSjJD_EzumG8w-Gt8yl-qYV653OAupV_0.png" alt="image"></p><p>使用经过时间矫正之后的数据，即以a开头的sub，SPM中session的含义与run雷同，还是创建3个Session  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/ItE7C0_A0e-BrJdZ8b5HGRsuzVmCibWqemxDH0HnMTI.webp" alt="image"></p><p>选定好之后。开始运行，下面的那些参数如果不知道含义，可以不用管，SPM已经把最佳参数设定为默认值了。  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/SZ1o6wL3J4lqMrCPNNnuT-K9eUUCKzRvTfrHQY8plu4.webp" alt="image"></p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/oiI2PIkFi0lVlRYQS-mFhQZFbTP1Ujp93-bOACMX_GE.png" alt="image"></p><p>会在目录中生成ps结尾的文件，SPM-Graphics窗口会有评估报告。</p><p><strong>平移</strong>一般严格的话会要求不超过2个体素或者1个体素。</p><p><strong>旋转</strong>一般旋转角度和移动mm之间会有一个映射关系。  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/RtdLDhyO7E8Fl14gvJuF4LcepcZUk-kTF6E4pD8iYn8.png" alt="image"></p><p>会生成3个r开头的文件，作为结果输出，<strong>还会生成三个rp*.txt文件，此文件记录了头动参数</strong>。<br>rp：一般会有<strong>平移：x/y/z/ 旋转：pitch/roll/yaw 6个参数，可以放到最后的线性模型中，作为一个回归因子使用</strong>。</p><h2 id="3-Segment"><a href="#3-Segment" class="headerlink" title="3-Segment"></a><strong>3-Segment</strong></h2><p><a href="https://blog.csdn.net/yufei0413/article/details/105220142/" target="_blank" rel="noopener">https://blog.csdn.net/yufei0413/article/details/105220142/</a><br><a href="https://blog.csdn.net/sophia2023/article/details/109025806" target="_blank" rel="noopener">https://blog.csdn.net/sophia2023/article/details/109025806</a><br>在SPM里面做segment一般是为了空间配准而做的，这样它分离出灰质白质后帮助后一步的配准。教程只是采用了一般工具采用的配准方法，也就是直接配准，因为segment并不是必须要做的。所以看需求，这个并没有一定的规程，你可以对比两种方法得到的配准的结果，然后看哪种效果更好一些。  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/lqHfCTWlgeq0YYvlXhaMOWi4YTQIkvoW2fL51xfJ4y8.png" alt="image"></p><h2 id="4-空间配准"><a href="#4-空间配准" class="headerlink" title="4-空间配准"></a><strong>4-空间配准</strong></h2><p>空间配准包括两步：<br>●将功能像配准到当前被适的结构像上<br>●配准当前被适的结构像和标准空间，通过配准矩阵应用到所有的功能像上<br>最后得到的功能像都是已经配准到标准空间的功能像。<br>即：将功能像配准到结构像上去，再将结构像配准到标准空间上去，，，，<br>另一种思路：将结构像配准到功能像上去，然后再把结构像配准到标准空间上去，再应用矩阵到功能像上去。<br><strong>Coregister：将功能像配准到结构像上去</strong><br><strong>Normalise：将结构像配准到标准空间上去</strong><br>同理：Estimate仅仅是计算出来转换矩阵，Reslice是真正应用到图像上。<br>因为此处需要将两步联合起来，所以Coregister仅仅需要计算出转换矩阵即可，等到Normalise再正式一并进行配准，防止重复计算（并且能少动一次就少动一次，因为涉及到转换，存在差值问题）。所以Coregister选择 Estimate，Normalise选择 Est&amp;Write。</p><h3 id="4-1-Coregister功能像配准到结构像"><a href="#4-1-Coregister功能像配准到结构像" class="headerlink" title="4-1 Coregister功能像配准到结构像"></a><strong>4-1 Coregister功能像配准到结构像</strong></h3><p>Reference Image：结构像，即保持不动的参考像<br>Source Image：功能像，即要配准到结构像上的功能像，此处要计算转换矩阵，以mean为代表  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/Q3ioStJc2uEOnSiXQLB-Pv1mgpmjoUSYvzS7ryhYWSE.png" alt="image"></p><p>上面计算出来的矩阵应用到Other Image上来，即剩下的所有功能像。  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/TJNCa4Ik1loddR9si3MEHGeaKmacEOL3CDQpSj226XI.webp" alt="image"></p><p>此处不会有前缀输出等标识，因为仅仅是评估计算转换矩阵到源文件的头文件中。运行该batch  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/qF6pC6JinQMzEhxWcWZHbiIKVeH5WuwatgCgU2_QRXA.png" alt="image"></p><p>此处会有一个临时的结果，方便查看，如下图  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/YRSYZYoDeXf0IEx_qIebJ4YamPF3MzIPNGBleABKnvg.png" alt="image"></p><h3 id="4-2-Normalise结构像配准到标准空间上"><a href="#4-2-Normalise结构像配准到标准空间上" class="headerlink" title="4-2 Normalise结构像配准到标准空间上"></a><strong>4-2 Normalise结构像配准到标准空间上</strong></h3><p>Data中生成新的Subject，Image to Align 即选择将那些图像配准到标准空间上去。<br>Image to Write 即选择要转换的功能像。此处先选择平均像，为了早点出效果，剩下的选择 ^ra.*，1:590的像  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/01DdD2acr4-B8_SnqKhlA7QvYaPwz9jrtLD7HSMHKCo.webp" alt="image"></p><p>3个run是1700，再加上一个mean像，即1771个像。剩下的默认即可，开始运行。生成的结果以W开头  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/2ETkVAEYGd-u0dTQyxWgrtrQ4wza-DlXY7hOGJUDwC4.png" alt="image"></p><p>经过一段时间后，可以看出mean被配准出来，等到所有转换完太浪费时间，尝试查看mean配准后的像  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/-4miF5n9S-5qojHymtmBMx6_NTSiW2mHqF3pWMz6pKI.png" alt="image"></p><p>选择SPM中的Check Reg，选择两个图像查看，一个是wmean的 配准到标准空间后的像，一个是SPM12中canonical路径下avg152T1.nii.1 这个标准像。  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/S0h1PpyfpBl-gDF3McRjUC1ypPxHIe_2t3CgJP5WQ4M.png" alt="image"></p><p>下面就是配准过之后的像，可以进行查看，下面是结构像，上面是功能像。  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/_s2SosqtaDLm6c1n4AsGDoBvX9Rk5GwHUn_jHBcenW4.webp" alt="image"></p><p>配准完成后生成5个文件，4个w开头的文件，1个y开头的文件，这是一个spm的normalise的estimate生成的y_*.nii文件中的数据是什么含义呢，映射矩阵，每一个体素对应的转移到新空间的向量，比如原图像是1，转换后的图像是12，那么这个y就是用来表示这个转换关系的向量，+11。  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/5LhGEK13RpR-RqSs5q-WG65-qyMm0SHxaJ_kAIAMfwA.png" alt="image"></p><h2 id="5-空间平滑"><a href="#5-空间平滑" class="headerlink" title="5-空间平滑"></a><strong>5-空间平滑</strong></h2><h3 id="5-1-什么是高斯核呢？"><a href="#5-1-什么是高斯核呢？" class="headerlink" title="5-1 什么是高斯核呢？"></a><strong>5-1 什么是高斯核呢？</strong></h3><p><a href="https://matthew-brett.github.io/teaching/smoothing_intro.html" target="_blank" rel="noopener">https://matthew-brett.github.io/teaching/smoothing_intro.html</a><br>我们在做空间平滑时用到的函数的形状，此处是高斯正态分布的曲线。<br>FWHM: the Full Width at Half Maximum.<br>FWHM是在曲线最高点一半位置处的宽度。如下图最高点是0.4，即0.2出的x轴宽度。  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/TAjmNoGc0jIyfXgb6Qwpo-fPT6vIwb69cGLM9iW4y-o.png" alt="image"></p><p>在SPM12中默认是立体的8x8x8，一般来说默认的已经过于平滑了，可以选择6x6x6，当然也可以自己根据任务选择。总体上是对脑图像中感兴趣的脑区非常小的话，不建议做过高的平滑，甚至推荐不做平滑。</p><h3 id="5-2-具体步骤"><a href="#5-2-具体步骤" class="headerlink" title="5-2 具体步骤"></a><strong>5-2 具体步骤</strong></h3><p>做过配准后的像是以wr开头，此处选择^wr.*，1:1000  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/ccJR5LxOchw-2S_lIKK9XryRYCxK0jn7JBapevdKokM.webp" alt="image"></p><p>做空间平滑一个很重要的参数是高斯核是多大，即FWHM 默认是888，可以是666。</p><p>平滑过后的图像以s为前缀  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/oKOWpavzLRytm-PMz77u382YU2U4Ju6AMWWgA_4_Rqg.png" alt="image"></p><p>平滑结束后，查看平滑前后的差别。选择SPM12中的Check Reg，选择wrasub-01和srasub-01做对比。<br>上面是平滑之前的，下面是平滑之后的  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/s_w6PVkBXLQJAhPV4nUm_12WaME4snnDUUC9UPzkIm0.webp" alt="image"></p><h2 id="6-文件名变更方式"><a href="#6-文件名变更方式" class="headerlink" title="6-文件名变更方式"></a><strong>6-文件名变更方式</strong></h2><p>sub—–&gt; asub—–&gt;rasub—–&gt;wrasub—–&gt;swrasub </p><p>原图–&gt;时间矫正—&gt;头动矫正—&gt;空间配准—-&gt;平滑处理  </p><p><img src="/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/FD2pXwt8WjW9IbwhkNqHX0tFFD2jOVBwpyM9op2qD8I.png" alt="image"></p><h2 id="7-评论区"><a href="#7-评论区" class="headerlink" title="7-评论区"></a><strong>7-评论区</strong></h2><p>配准到MNI空间是采用normalise  </p><p>spm的normalise的estimate生成的y_*.nii文件中的数据是什么含义呢？<br>映射矩阵，每一个体素对应的转移到新空间的向量。它是一个向量，比如原图像是1，转换后的图像是12，那么这个y就是用来表示这个转换关系的向量，+11。  </p><p>segment在normalization 之前做  </p><p>up主，我现在的adni数据库的 fmri数据没有结构像文件啊，我该怎么办？<br>和文件格式没有关系，读一下他们的文档，看看结构像从哪里下载。  </p><p>只有nii文件怎么看slice order<br><a href="https://en.wikibooks.org/wiki/SPM/Slice_Timing#Slice_Order" target="_blank" rel="noopener">https://en.wikibooks.org/wiki/SPM/Slice_Timing#Slice_Order</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1D54y1Y7Ca/?spm_id_from=pageDriver&amp;vd_source=af160cbe43a365e4f56321b03888e798&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.bilibili.com/video/BV1D54y1Y7Ca/?spm_id_from=pageDriver&amp;amp;vd_source=af160cbe43a365e4f56321b03888e798&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-时间矫正&quot;&gt;&lt;a href=&quot;#1-时间矫正&quot; class=&quot;headerlink&quot; title=&quot;1-时间矫正&quot;&gt;&lt;/a&gt;&lt;strong&gt;1-时间矫正&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;1:max_num，max_num可由下面给出。  &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/10/10/8-5-SPM%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/61oNOThM29xYcyl9InETol7S_pfymyKe7jNhWrpRyPM.png&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Tools" scheme="http://JavaSsun.github.io/tags/Tools/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>8-4-MRI预处理</title>
    <link href="http://javassun.github.io/2023/09/16/8-4-MRI%E9%A2%84%E5%A4%84%E7%90%86/"/>
    <id>http://javassun.github.io/2023/09/16/8-4-MRI%E9%A2%84%E5%A4%84%E7%90%86/</id>
    <published>2023-09-16T04:17:38.000Z</published>
    <updated>2024-05-09T07:04:08.499Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97<br>参考知网</p><p>●基于耦合的卷积-图卷积神经网络的阿尔茨海默病的磁共振诊断  </p><p>ADNI Series<br>1、【ADNI】数据预处理（1）SPM，CAT12<br>2、【ADNI】数据预处理（2）获取 subject slices<br>3、【ADNI】数据预处理（3）CNNs<br>4、【ADNI】数据预处理（4）Get top k slices according to CNNs<br>5、【ADNI】数据预处理（5）Get top k slices (pMCI_sMCI) according to CNNs<br>6、【ADNI】数据预处理（6）ADNI_slice_dataloader ||| show image  </p><a id="more"></a><p> <strong>脑图像预处理软件及参考资料</strong><br>SPM：<a href="https://www.fil.ion.ucl.ac.uk/spm/software/download/spmreg.php" target="_blank" rel="noopener">https://www.fil.ion.ucl.ac.uk/spm/software/download/spmreg.php</a><br>MatLab：<br>官网：<a href="https://ww2.mathworks.cn/en/products/matlab.html" target="_blank" rel="noopener">https://ww2.mathworks.cn/en/products/matlab.html</a><br>破解版：<a href="https://zaiyis.blog.csdn.net/article/details/123936220" target="_blank" rel="noopener">https://zaiyis.blog.csdn.net/article/details/123936220</a><br>破解版教程若失效，可看个人语雀中的MatLab安装教程<br>CAT：<a href="http://www.neuro.uni-jena.de/cat/index.html#DBM" target="_blank" rel="noopener">http://www.neuro.uni-jena.de/cat/index.html#DBM</a><br><a href="http://www.neuro.uni-jena.de/cat/index.html#DOWNLOAD" target="_blank" rel="noopener">http://www.neuro.uni-jena.de/cat/index.html#DOWNLOAD</a>  </p><p><img src="/2023/09/16/8-4-MRI%E9%A2%84%E5%A4%84%E7%90%86/vwbN2FKmegKLv88UHk-9ZaEj_Dhlfgo2QVAFVoNs6Is.png" alt="image"></p><p>MRIcro：<a href="https://people.cas.sc.edu/rorden/mricro/mricro.html#Installation" target="_blank" rel="noopener">https://people.cas.sc.edu/rorden/mricro/mricro.html#Installation</a><br><a href="https://blog.csdn.net/yufei0413/article/details/105220142/" target="_blank" rel="noopener">https://blog.csdn.net/yufei0413/article/details/105220142/</a><br><a href="https://blog.csdn.net/sophia2023/article/details/109025806" target="_blank" rel="noopener">https://blog.csdn.net/sophia2023/article/details/109025806</a><br><a href="https://www.likecs.com/show-203470671.html" target="_blank" rel="noopener">https://www.likecs.com/show-203470671.html</a><br><a href="https://blog.csdn.net/qq_44846512/article/details/112471568" target="_blank" rel="noopener">https://blog.csdn.net/qq_44846512/article/details/112471568</a><br><a href="https://github.com/bbanddd/ADDL/blob/master/docs/%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.md" target="_blank" rel="noopener">https://github.com/bbanddd/ADDL/blob/master/docs/%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.md</a>  </p><p>FSL：<a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FslInstallation/Windows" target="_blank" rel="noopener">https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FslInstallation/Windows</a>  </p><p>SPM-B站：<a href="https://www.bilibili.com/video/BV19f4y1z71A/?spm_id_from=333.788&vd_source=af160cbe43a365e4f56321b03888e798" target="_blank" rel="noopener">https://www.bilibili.com/video/BV19f4y1z71A/?spm_id_from=333.788&amp;vd_source=af160cbe43a365e4f56321b03888e798</a>  </p><p><strong>数据预处理流程方案1</strong><br>一、<strong>格式转换</strong>：DICOM 是目前神经影像采集重建后存储的通用数据格式，从ADNI数据集中采集到的MRI 和PET 原始图像可能为DICOM 格式。为了获得便于后续操做的数据格式：NIfTI，扩展名为.nii。图像预处理须要使用FSL、SPM 等工具对采集到的图像完成从DICOM 到NIfTI 数据格式的转换。  </p><p>二、<strong>校订</strong>：校订步骤操做主要是前连合(AC)-后连合(PC)校订。咱们使用MIPAV 软件进行AC–PC 校订, 重采样图像采用标准的256×256×256 模式,以后使用N3 算法去校订非均匀的组织强度。经过AC–PC 校订校订以后的图像，咱们还需实施头骨剥离、小脑切除操做。  </p><p>三、<strong>头骨去除和小脑切除</strong>：MRI 和PET 的原始图像中都包含着一些非脑结构，好比头骨等。为避免增长运算量，也避免影像后续预处理，影响实验结果，须要在图像预处理操做中将图像中的头骨等非脑结构移除。本文采用<strong>SPM 工具中的CAT12 工具包完成去除头骨的操做</strong>。  </p><p>四、<strong>异源图像配准</strong>：这一预处理操做步用来完成异源影像数据的配准，如：<strong>MRI 的T1 回波时间图像和T2 回波时间图像配准</strong>、MRI 与PET 配准。因为待配准的图像属于不一样类的数据差别很大，因此咱们采用更准确、鲁棒的基于互信息的配准算法完成这一操做，最小二乘法已经再也不适用。  </p><p>五、<strong>图像分割</strong>：在MRI 图像处理时，有时只关注某些特定区域的状态，这就须要根据大脑的解剖结构将目标部位的组织提取出来。在预处理流程中，咱们将MRI 按脑灰质、白质、脑脊液结构分割成为3 个不一样的图像，再进行单独或联合分析。这是由于这三个组织在大脑中有着不一样的功能，在受到AD 或MCI 影响后也有不一样的形态学的改变，须要各自提取特征。所以这一步骤须要用到图像分割算法。  </p><p>六、<strong>标准化</strong>：<strong>标准化是将前面预处理流程的图像配准到标准脑模版空间MNI(Montreal Neurological Institute)上，统一全部图像的坐标空间</strong>。MNI 空间是基于大量的正常被试的MRI 扫描平均获得的新的标准脑，是大脑图像标准化经常使用到的模版。标准化用到的算法是非刚体配准算法，包括仿射变换与非线性变换等。  </p><p>七、<strong>平滑处理</strong>：在完成上述一系列处理后，还须要将图像作一次平滑处理，<strong>以抑制功能像的噪声，提升信噪比，减小各图像间仍残余的解剖结构或功能上的不一样</strong>。一般，平滑处理采用的函数是高斯核（标准方差）函数。此外，根据经验和实践尝试，咱们使用64×64×64 的像素立方体对灰质密度图像和PET 图像进行下采样，这种处理能够节约运算时间和内存消耗，并且没有损失分类精度。  </p><p><strong>数据预处理流程方案2（采纳）</strong><br><strong>1-数据集</strong><br><strong>数据源</strong>：ADNI数据库中下载<strong>AD、MCI、NC</strong>组受试者<strong>T1权重</strong>的<strong>MRI数据。</strong><br>受试者年龄大都在65<del>83之间</del><br><del>●**NC组：A人，男?人，女?人，年龄aa</del>bb岁，平均(a.aa<strong>±</strong>b.bb****)岁**<br>●<strong>AD组：B人，男?人，女?人，年龄aa~bb岁，平均(a.aa</strong>±<strong>b.bb**</strong>)岁**<br>●<strong>MCI组：C人，男?人，女?人，年龄aa~bb岁，平均(a.aa</strong>±<strong>b.bb**</strong>)岁**<br><strong>2-预处理</strong><br>从ADNI数据库下载(A+B+C)名受试者的MRI数据，每名受试者只有唯一的MRI数据。<br><strong>SPM-CAT12</strong>对MRI进行以下操作<br>●<strong>格式转换</strong>（如果需要的话）<br>●<strong>时间矫正</strong>（如果需要的话）<br><strong>●头动矫正</strong><br><strong>●颅骨剥离</strong><br><strong>●配准到Template_MNI152标准模板空间</strong><br><strong>●图像平滑(平滑核大小大小为6像素x6像素x6像素)</strong><br>除平滑核大小外其余均使用CAT12中的默认参数<br>经过上述处理后的图像大小均为**121像素×145像素×121像素(此处仅为参考)**，空间分辨率为1.5 mm，3组受试者处理前后图像对比见下图。  </p><p><img src="/2023/09/16/8-4-MRI%E9%A2%84%E5%A4%84%E7%90%86/Ck3YT6J80_d_lk-JCd_kfORyQs7K-K1rB7GDqJ4XqXE.png" alt="image"></p><p><img src="/2023/09/16/8-4-MRI%E9%A2%84%E5%A4%84%E7%90%86/4V2ijo14Y58-pXhBu8AAXMFzN_wNvX1WH4NmKJRvGOI.png" alt="image"></p><p><img src="/2023/09/16/8-4-MRI%E9%A2%84%E5%A4%84%E7%90%86/1YaT_rFM19agzQr76PaCtHwSClI7H4OyyHCVVYpBl2g.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;br&gt;参考知网&lt;/p&gt;
&lt;p&gt;●基于耦合的卷积-图卷积神经网络的阿尔茨海默病的磁共振诊断  &lt;/p&gt;
&lt;p&gt;ADNI Series&lt;br&gt;1、【ADNI】数据预处理（1）SPM，CAT12&lt;br&gt;2、【ADNI】数据预处理（2）获取 subject slices&lt;br&gt;3、【ADNI】数据预处理（3）CNNs&lt;br&gt;4、【ADNI】数据预处理（4）Get top k slices according to CNNs&lt;br&gt;5、【ADNI】数据预处理（5）Get top k slices (pMCI_sMCI) according to CNNs&lt;br&gt;6、【ADNI】数据预处理（6）ADNI_slice_dataloader ||| show image  &lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Tools" scheme="http://JavaSsun.github.io/tags/Tools/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>8-3-UNet提取海马体</title>
    <link href="http://javassun.github.io/2023/09/10/8-3-%E6%B5%B7%E9%A9%AC%E4%BD%93%E6%8F%90%E5%8F%96/"/>
    <id>http://javassun.github.io/2023/09/10/8-3-%E6%B5%B7%E9%A9%AC%E4%BD%93%E6%8F%90%E5%8F%96/</id>
    <published>2023-09-10T15:17:38.000Z</published>
    <updated>2024-05-09T07:01:55.779Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><h2 id="1-横截面选取"><a href="#1-横截面选取" class="headerlink" title="1-横截面选取"></a><strong>1-横截面选取</strong></h2><p>Axial：又名横断面，transverseCoronal：又名冠状面，Sagittal：矢状面，如同一个箭矢劈开成左右两半</p><p><img src="/2023/09/10/8-3-%E6%B5%B7%E9%A9%AC%E4%BD%93%E6%8F%90%E5%8F%96/NFOZIMP_Ui4LAdS-bwIwPvDtwr6lbRf33xuAmdzInhE.png" alt="image"></p><a id="more"></a><p>这种图就是横断面Axial</p><p><img src="/2023/09/10/8-3-%E6%B5%B7%E9%A9%AC%E4%BD%93%E6%8F%90%E5%8F%96/ssw046JSMs_A-9qcC93pslYsXeTARjMgGI4nVRZSZk0.png" alt="image"></p><p>nii_process-origin.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy, numpy, shutil, os, nibabel, glob</span><br><span class="line"><span class="keyword">import</span> sys, getopt</span><br><span class="line"><span class="keyword">import</span> imageio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切片 矢状面进行切片（start=80, end=110 total 30）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">niito2D_A_batch</span><span class="params">(nii_file, slice_dim, parent_folder)</span>:</span></span><br><span class="line">    </span><br><span class="line">    outputfile = os.path.join(nii_file.split(<span class="string">"/"</span>)[<span class="number">-1</span>][: <span class="number">15</span>], slice_dim)</span><br><span class="line">    outputfile = os.path.join(parent_folder, outputfile)       <span class="comment">#输出文件夹</span></span><br><span class="line"></span><br><span class="line">    image_array = nibabel.load(nii_file).get_data() <span class="comment">#数据读取</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># set destination folder</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(outputfile):</span><br><span class="line">        os.makedirs(outputfile)   <span class="comment">#不存在输出文件夹则新建</span></span><br><span class="line"></span><br><span class="line">    slice_start = <span class="number">80</span> <span class="comment">#从第几个切片开始</span></span><br><span class="line">    slice_end = <span class="number">110</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterate through slices</span></span><br><span class="line">    <span class="keyword">for</span> current_slice <span class="keyword">in</span> range(slice_start, slice_end):</span><br><span class="line">        <span class="comment"># alternate slices</span></span><br><span class="line">        <span class="comment"># [A,B,C]: A 矢状面 B 冠状面 C 横断面</span></span><br><span class="line">                </span><br><span class="line">        data = image_array[:, :, current_slice] </span><br><span class="line">        <span class="comment">#切片命名 </span></span><br><span class="line">        <span class="comment"># /home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin/ADNI_002_S_0619_I120964.nii</span></span><br><span class="line">        <span class="comment"># /home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin/ADNI_002_S_061081.png</span></span><br><span class="line">        image_name = nii_file[:<span class="number">-12</span>] +<span class="string">"_"</span> <span class="string">"&#123;:0&gt;3&#125;"</span>.format(str(current_slice + <span class="number">1</span>)) + <span class="string">".png"</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#保存</span></span><br><span class="line">        imageio.imwrite(image_name, data)</span><br><span class="line">        src = image_name</span><br><span class="line">        shutil.move(src, outputfile)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 切片 冠状面进行切片（start=80, end=120 total 40）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">niito2D_B_batch</span><span class="params">(nii_file, slice_dim, parent_folder)</span>:</span></span><br><span class="line">    </span><br><span class="line">    outputfile = os.path.join(nii_file.split(<span class="string">"/"</span>)[<span class="number">-1</span>][: <span class="number">15</span>], slice_dim)</span><br><span class="line">    outputfile = os.path.join(parent_folder, outputfile)       <span class="comment">#输出文件夹</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    image_array = nibabel.load(nii_file).get_data() <span class="comment">#数据读取</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># set destination folder</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(outputfile):</span><br><span class="line">        os.makedirs(outputfile)   <span class="comment">#不存在输出文件夹则新建</span></span><br><span class="line"></span><br><span class="line">    slice_start = <span class="number">80</span> <span class="comment">#从第几个切片开始</span></span><br><span class="line">    slice_end = <span class="number">120</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterate through slices</span></span><br><span class="line">    <span class="keyword">for</span> current_slice <span class="keyword">in</span> range(slice_start, slice_end):</span><br><span class="line">        <span class="comment"># alternate slices</span></span><br><span class="line">        <span class="comment"># [A,B,C]: A 矢状面 B 冠状面 C 横断面</span></span><br><span class="line">                </span><br><span class="line">        data = image_array[:, current_slice, :] </span><br><span class="line">        <span class="comment">#切片命名 </span></span><br><span class="line">        <span class="comment"># /home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin/ADNI_002_S_0619_I120964.nii</span></span><br><span class="line">        <span class="comment"># /home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin/ADNI_002_S_061081.png</span></span><br><span class="line">        image_name = nii_file[:<span class="number">-12</span>] +<span class="string">"_"</span> <span class="string">"&#123;:0&gt;3&#125;"</span>.format(str(current_slice + <span class="number">1</span>)) + <span class="string">".png"</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#保存</span></span><br><span class="line">        imageio.imwrite(image_name, data)</span><br><span class="line">        src = image_name</span><br><span class="line">        shutil.move(src, outputfile)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 切片 横断面进行切片（start=100, end=130 total 30）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">niito2D_C_batch</span><span class="params">(nii_file, slice_dim, parent_folder)</span>:</span></span><br><span class="line">    </span><br><span class="line">    outputfile = os.path.join(nii_file.split(<span class="string">"/"</span>)[<span class="number">-1</span>][: <span class="number">15</span>], slice_dim)</span><br><span class="line">    outputfile = os.path.join(parent_folder, outputfile)       <span class="comment">#输出文件夹</span></span><br><span class="line">    </span><br><span class="line">    image_array = nibabel.load(nii_file).get_data() <span class="comment">#数据读取</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># set destination folder</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(outputfile):</span><br><span class="line">        os.makedirs(outputfile)   <span class="comment">#不存在输出文件夹则新建</span></span><br><span class="line"></span><br><span class="line">    slice_start = <span class="number">100</span> <span class="comment">#从第几个切片开始</span></span><br><span class="line">    slice_end = <span class="number">130</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterate through slices</span></span><br><span class="line">    <span class="keyword">for</span> current_slice <span class="keyword">in</span> range(slice_start, slice_end):</span><br><span class="line">        <span class="comment"># alternate slices</span></span><br><span class="line">        <span class="comment"># [A,B,C]: A 矢状面 B 冠状面 C 横断面</span></span><br><span class="line">                </span><br><span class="line">        data = image_array[current_slice, :, :] </span><br><span class="line">        <span class="comment">#切片命名 </span></span><br><span class="line">        <span class="comment"># /home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin/ADNI_002_S_0619_I120964.nii</span></span><br><span class="line">        <span class="comment"># /home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin/ADNI_002_S_061081.png</span></span><br><span class="line">        image_name = nii_file[:<span class="number">-12</span>] +<span class="string">"_"</span> <span class="string">"&#123;:0&gt;3&#125;"</span>.format(str(current_slice + <span class="number">1</span>)) + <span class="string">".png"</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#保存</span></span><br><span class="line">        imageio.imwrite(image_name, data)</span><br><span class="line">        src = image_name</span><br><span class="line">        shutil.move(src, outputfile)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">AD_Brain_Affine_list = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin/*.nii"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> AD_Brain_Affine_list:</span><br><span class="line">    <span class="comment"># niito2D_A_batch(i, "slice_A", "/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices/")</span></span><br><span class="line">    <span class="comment"># niito2D_B_batch(i, "slice_B", "/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices/")</span></span><br><span class="line">    niito2D_C_batch(i, <span class="string">"slice_C"</span>, <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices/"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">CN_Brain_Affine_list = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin/*.nii"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> CN_Brain_Affine_list:</span><br><span class="line">    <span class="comment"># niito2D_A_batch(i, "slice_A", "/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices/")</span></span><br><span class="line">    <span class="comment"># niito2D_B_batch(i, "slice_B", "/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices/")</span></span><br><span class="line">    niito2D_C_batch(i, <span class="string">"slice_C"</span>, <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices/"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">MCI_Brain_Affine_list = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin/*.nii"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> MCI_Brain_Affine_list:</span><br><span class="line">    <span class="comment"># niito2D_A_batch(i, "slice_A", "/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices/")</span></span><br><span class="line">    <span class="comment"># niito2D_B_batch(i, "slice_B", "/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices/")</span></span><br><span class="line">    niito2D_C_batch(i, <span class="string">"slice_C"</span>, <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices/"</span>)</span><br></pre></td></tr></table></figure><h2 id="2-同组内混合"><a href="#2-同组内混合" class="headerlink" title="2-同组内混合"></a>2-同组内混合</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">slices_AD_C = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices/*/slice_C/*.png"</span>)</span><br><span class="line">target_AD_C = <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C/"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> slices_AD_C:</span><br><span class="line">    <span class="comment"># shutil.copy(i, target_AD_C)</span></span><br><span class="line"></span><br><span class="line">print(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C/*.png"</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">slices_CN_C = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices/*/slice_C/*.png"</span>)</span><br><span class="line">target_CN_C = <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C/"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> slices_CN_C:</span><br><span class="line">    <span class="comment"># shutil.copy(i, target_CN_C)</span></span><br><span class="line"></span><br><span class="line">print(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C/*.png"</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">slices_MCI_C = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices/*/slice_C/*.png"</span>)</span><br><span class="line">target_MCI_C = <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C/"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> slices_MCI_C:</span><br><span class="line">    <span class="comment"># shutil.copy(i, target_MCI_C)</span></span><br><span class="line"></span><br><span class="line">print(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C/*.png"</span>)))</span><br></pre></td></tr></table></figure><h2 id="3-横截面-Axial进行方位校正，以便海马体的提取"><a href="#3-横截面-Axial进行方位校正，以便海马体的提取" class="headerlink" title="3-横截面 Axial进行方位校正，以便海马体的提取"></a>3-横截面 Axial进行方位校正，以便海马体的提取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> imageio</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">slices_AD_C = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C/*.png"</span>)</span><br><span class="line">target_AD_C = <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD/"</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> slices_AD_C:</span><br><span class="line">    img = cv2.imread(i)</span><br><span class="line">    img = cv2.rotate(img, cv2.ROTATE_180)</span><br><span class="line">    img_name = i.split(<span class="string">"/"</span>)[<span class="number">-1</span>]</span><br><span class="line">    imageio.imwrite(img_name, img)</span><br><span class="line">    shutil.move(img_name, target_AD_C)</span><br><span class="line"></span><br><span class="line">print(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD/*.png"</span>)))</span><br><span class="line">    </span><br><span class="line">slices_CN_C = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C/*.png"</span>)</span><br><span class="line">target_CN_C = <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD/"</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> slices_CN_C:</span><br><span class="line">    img = cv2.imread(i)</span><br><span class="line">    img = cv2.rotate(img, cv2.ROTATE_180)</span><br><span class="line">    img_name = i.split(<span class="string">"/"</span>)[<span class="number">-1</span>]</span><br><span class="line">    imageio.imwrite(img_name, img)</span><br><span class="line">    shutil.move(img_name, target_CN_C)</span><br><span class="line"></span><br><span class="line">print(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD/*.png"</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">slices_MCI_C = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C/*.png"</span>)</span><br><span class="line">target_MCI_C = <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD/"</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> slices_MCI_C:</span><br><span class="line">    img = cv2.imread(i)</span><br><span class="line">    img = cv2.rotate(img, cv2.ROTATE_180)</span><br><span class="line">    img_name = i.split(<span class="string">"/"</span>)[<span class="number">-1</span>]</span><br><span class="line">    imageio.imwrite(img_name, img)</span><br><span class="line">    shutil.move(img_name, target_MCI_C)</span><br><span class="line"></span><br><span class="line">print(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD/*.png"</span>)))</span><br></pre></td></tr></table></figure><h2 id="4-UNet进行海马体分割"><a href="#4-UNet进行海马体分割" class="headerlink" title="4-UNet进行海马体分割"></a>4-UNet进行海马体分割</h2><h3 id="搭建UNet"><a href="#搭建UNet" class="headerlink" title="搭建UNet"></a>搭建UNet</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.dataset <span class="keyword">import</span> random_split</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MRIDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, url, transform=None)</span>:</span></span><br><span class="line">        self.imgs = glob.glob(os.path.join(url, <span class="string">"img/*.jpg"</span>))</span><br><span class="line">        self.transform = transform</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">augment</span><span class="params">(self, img, flip)</span>:</span></span><br><span class="line">        <span class="comment"># flip = 1 水平翻转</span></span><br><span class="line">        <span class="comment"># flip = 2 垂直翻转</span></span><br><span class="line">        <span class="comment"># flip = 3 同时进行水平翻转和垂直翻转</span></span><br><span class="line">        img_flipped = cv2.flip(img, flip)</span><br><span class="line">        <span class="keyword">return</span> img_flipped</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 通过索引获取原图和标签的URL</span></span><br><span class="line">        img_url = self.imgs[index]</span><br><span class="line">        label_left_url = img_url.replace(<span class="string">"img"</span>, <span class="string">"label"</span>).replace(<span class="string">"ACPC"</span>, <span class="string">"L"</span>)</span><br><span class="line">        label_right_url = img_url.replace(<span class="string">"img"</span>, <span class="string">"label"</span>).replace(<span class="string">"ACPC"</span>, <span class="string">"R"</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 通过cv2库读取图像</span></span><br><span class="line">        image = cv2.imread(img_url)</span><br><span class="line">        label_left = cv2.imread(label_left_url)</span><br><span class="line">        label_right = cv2.imread(label_right_url)</span><br><span class="line">        </span><br><span class="line">                </span><br><span class="line">        width = <span class="number">224</span></span><br><span class="line">        height = <span class="number">224</span></span><br><span class="line">        image = cv2.resize(image,(width,height))</span><br><span class="line">        label_left = cv2.resize(label_left,(width,height))</span><br><span class="line">        label_right = cv2.resize(label_right,(width,height))</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        bImg, gImg, rImg = cv2.split(image)</span><br><span class="line">        image = cv2.merge([bImg,gImg,rImg])</span><br><span class="line">        </span><br><span class="line">        blabel_left, glabel_left, rlabel_left = cv2.split(label_left)</span><br><span class="line">        label_left = cv2.merge([blabel_left,glabel_left,rlabel_left])</span><br><span class="line">        </span><br><span class="line">        blabel_right, glabel_right, rlabel_right = cv2.split(label_right)</span><br><span class="line">        label_right = cv2.merge([blabel_right,glabel_right,rlabel_right])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 合并左右海马体</span></span><br><span class="line">        label = cv2.addWeighted(label_left,<span class="number">1</span>,label_right,<span class="number">1</span>,<span class="number">0.2</span>) </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定位到转灰度时图片要为三通道，否则报错，在转灰度前，加上如下代码将图转为三通道即可</span></span><br><span class="line">        <span class="comment"># 采用CV_BGR2GRAY,  转换公式Gray = 0.1140B + 0.5870G + 0.2989*R</span></span><br><span class="line">        <span class="comment"># image = cv2.merge([image,image,image])</span></span><br><span class="line">        <span class="comment"># label = cv2.merge([label,label,label])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 转换为灰度图：3通道转换为1通道</span></span><br><span class="line">        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line">        label = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 修正标签，将海马体部分像素设置为1，非海马体部分设置为0</span></span><br><span class="line">        <span class="keyword">if</span> label.max()&gt;<span class="number">1</span>:</span><br><span class="line">            label = label/<span class="number">255</span></span><br><span class="line">        label[label&gt;=<span class="number">0.5</span>] = <span class="number">1</span></span><br><span class="line">        label[label&lt;<span class="number">0.5</span>] = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 进行随机的数据增强</span></span><br><span class="line">        flip = random.choice([<span class="number">-1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">        <span class="keyword">if</span> flip != <span class="number">2</span>:</span><br><span class="line">            image = self.augment(image, flip)</span><br><span class="line">            label = self.augment(label, flip)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 转换数据</span></span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">            label = self.transform(label)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.imgs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvUnit</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(ConvUnit, self).__init__()</span><br><span class="line">        self.unit = nn.Sequential(</span><br><span class="line">            <span class="comment"># 保持图像大小</span></span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            <span class="comment"># 常用于卷积网络中卷积操作之后，进行数据的归一化处理(防止梯度消失或爆炸)</span></span><br><span class="line">            <span class="comment"># 使得数据在进行Relu之前不会因为数据过大而导致网络性能不稳定</span></span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            <span class="comment"># inplace=True, 地址传递，会改变输入数据的值,节省反复申请与释放内存的空间与时间</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">             <span class="comment"># 保持图像大小</span></span><br><span class="line">            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.unit(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DownSampling</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(DownSampling, self).__init__()</span><br><span class="line">        self.layer = nn.Sequential(</span><br><span class="line">            <span class="comment"># 最大池化，将图像大小变为原来的 1/2</span></span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            <span class="comment"># 卷积单元进行卷积操作</span></span><br><span class="line">            ConvUnit(in_channels, out_channels)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.layer(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UpSampling</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(UpSampling, self).__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 上采样层，将通道数变为1/2是为了在concat后保持通道数不变</span></span><br><span class="line">        self.layer = nn.ConvTranspose2d(in_channels, in_channels//<span class="number">2</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">       </span><br><span class="line">        <span class="comment"># 卷积单元</span></span><br><span class="line">        self.conv = ConvUnit(in_channels, out_channels)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, r)</span>:</span></span><br><span class="line">        <span class="comment"># 对x进行上采样，同时通道数减半</span></span><br><span class="line">        x = self.layer(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将x与r在通道维度连接，恢复原本通道数</span></span><br><span class="line">        x = torch.cat((x, r), dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(UNet, self).__init__()</span><br><span class="line">        <span class="comment"># 输入层</span></span><br><span class="line">        self.conv = ConvUnit(in_channels, <span class="number">64</span>)</span><br><span class="line">        <span class="comment"># 定义四个下采样层和四个上采样层</span></span><br><span class="line">        self.D1 = DownSampling(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">        self.D2 = DownSampling(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.D3 = DownSampling(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">        self.D4 = DownSampling(<span class="number">512</span>, <span class="number">1024</span>)</span><br><span class="line">        self.U1 = UpSampling(<span class="number">1024</span>, <span class="number">512</span>)</span><br><span class="line">        self.U2 = UpSampling(<span class="number">512</span>, <span class="number">256</span>)</span><br><span class="line">        self.U3 = UpSampling(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.U4 = UpSampling(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        <span class="comment"># 输出层，输出图像像素保持在0～1以进行二分类</span></span><br><span class="line">        self.out = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># U-NET的左半部分</span></span><br><span class="line">        L1 = self.conv(x)</span><br><span class="line">        L2 = self.D1(L1)</span><br><span class="line">        L3 = self.D2(L2)</span><br><span class="line">        L4 = self.D3(L3)</span><br><span class="line">        Bottom = self.D4(L4)</span><br><span class="line">        <span class="comment"># U-NET的右半部分</span></span><br><span class="line">        R1 = self.U1(Bottom, L4)</span><br><span class="line">        R2 = self.U2(R1, L3)</span><br><span class="line">        R3 = self.U3(R2, L2)</span><br><span class="line">        R4 = self.U4(R3, L1)</span><br><span class="line">        <span class="keyword">return</span> self.out(R4)</span><br></pre></td></tr></table></figure><h3 id="模型对ADNI-Datasets-方向校正后的横截面数据作海马体预测提取"><a href="#模型对ADNI-Datasets-方向校正后的横截面数据作海马体预测提取" class="headerlink" title="模型对ADNI-Datasets 方向校正后的横截面数据作海马体预测提取"></a>模型对ADNI-Datasets 方向校正后的横截面数据作海马体预测提取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line">print(<span class="string">"AD: "</span> + str(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD/*.png"</span>))))</span><br><span class="line">print(<span class="string">"CN: "</span> + str(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD/*.png"</span>))))</span><br><span class="line">print(<span class="string">"MCI: "</span>+ str(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD/*.png"</span>))))</span><br><span class="line"></span><br><span class="line">print(<span class="string">"AD: "</span> + str(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD_hs/*.png"</span>))))</span><br><span class="line">print(<span class="string">"CN: "</span> + str(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD_hs/*.png"</span>))))</span><br><span class="line">print(<span class="string">"MCI: "</span>+ str(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD_hs/*.png"</span>))))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MRI_3_class_Dataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, url,  transform=None)</span>:</span></span><br><span class="line">        self.imgs = glob.glob(url)</span><br><span class="line">        self.transform = transform</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">augment</span><span class="params">(self, img, flip)</span>:</span></span><br><span class="line">        <span class="comment"># flip = 1 水平翻转</span></span><br><span class="line">        <span class="comment"># flip = 2 垂直翻转</span></span><br><span class="line">        <span class="comment"># flip = 3 同时进行水平翻转和垂直翻转</span></span><br><span class="line">        img_flipped = cv2.flip(img, flip)</span><br><span class="line">        <span class="keyword">return</span> img_flipped</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 通过索引获取原图和标签的URL</span></span><br><span class="line">        img_url = self.imgs[index]</span><br><span class="line">       </span><br><span class="line">        <span class="comment"># 通过cv2库读取图像</span></span><br><span class="line">        image = cv2.imread(img_url)</span><br><span class="line">                </span><br><span class="line">        width = <span class="number">224</span></span><br><span class="line">        height = <span class="number">224</span></span><br><span class="line">        image = cv2.resize(image,(width,height))</span><br><span class="line">        </span><br><span class="line">        bImg, gImg, rImg = cv2.split(image)</span><br><span class="line">        image = cv2.merge([bImg,gImg,rImg])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定位到转灰度时图片要为三通道，否则报错，在转灰度前，加上如下代码将图转为三通道即可</span></span><br><span class="line">        <span class="comment"># 采用CV_BGR2GRAY,  转换公式Gray = 0.1140B + 0.5870G + 0.2989*R</span></span><br><span class="line">        <span class="comment"># image = cv2.merge([image,image,image])</span></span><br><span class="line">        <span class="comment"># label = cv2.merge([label,label,label])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 转换为灰度图：3通道转换为1通道</span></span><br><span class="line">        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 进行随机的数据增强</span></span><br><span class="line">        <span class="comment"># flip = random.choice([-1, 0, 1, 2])</span></span><br><span class="line">        <span class="comment"># if flip != 2:</span></span><br><span class="line">        <span class="comment">#     image = self.augment(image, flip)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 转换数据</span></span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> image</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.imgs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_mri_3_class_data</span><span class="params">(url, batch_size=<span class="number">4</span>, shuffle=True, split=None)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 实例化自定义Dataset，加载数据集</span></span><br><span class="line">    mri = MRI_3_class_Dataset(url, transform=transforms.Compose([</span><br><span class="line">        <span class="comment"># ToTensor()将shape为(H, W, C)的nump.ndarray或img转为shape为(C, H, W)的tensor，其将每一个数值归一化到[0,1]</span></span><br><span class="line">        <span class="comment"># 其归一化方法比较简单，直接除以255即可</span></span><br><span class="line">        transforms.ToTensor()</span><br><span class="line">    ]))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将数据集封装到DataLoader</span></span><br><span class="line">    data_loader = DataLoader(mri, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line">    <span class="keyword">return</span> data_loader</span><br></pre></td></tr></table></figure><p>预训练好的模型在 阿里云 Unet中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/U-NET/model_version_2/model.pth"</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">AD_Data_Loader = load_mri_3_class_data(url=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD/*.png"</span>,   batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, split=<span class="literal">None</span>)</span><br><span class="line">predict(AD_Data_Loader, model=model, pred_dir= <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD_hs"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">CN_Data_Loader = load_mri_3_class_data(url=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD/*.png"</span>,   batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, split=<span class="literal">None</span>)</span><br><span class="line">predict(CN_Data_Loader, model=model, pred_dir= <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD_hs"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">MCI_Data_Loader = load_mri_3_class_data(url=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD/*.png"</span>,   batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, split=<span class="literal">None</span>)</span><br><span class="line">predict(MCI_Data_Loader, model=model, pred_dir= <span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD_hs"</span>)</span><br></pre></td></tr></table></figure><h2 id="5-海马体候选挑选"><a href="#5-海马体候选挑选" class="headerlink" title="5-海马体候选挑选"></a>5-海马体候选挑选</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">进入命令行， cp -r origin-slices_C_CD_hs/*.png      origin-slices_C_CD_hs_</span><br><span class="line">因为使用Unet分割一次太慢，所以需要保留分割结果</span><br></pre></td></tr></table></figure><h3 id="挑选颜色均值-gt-2的L-R图片"><a href="#挑选颜色均值-gt-2的L-R图片" class="headerlink" title="挑选颜色均值&gt;2的L_R图片"></a>挑选颜色均值&gt;2的L_R图片</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> skimage</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">AD_Origin_LR_HS= glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD_hs/*_L_R.png"</span>)</span><br><span class="line">CN_Origin_LR_HS= glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD_hs/*_L_R.png"</span>)</span><br><span class="line">MCI_Origin_LR_HS= glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD_hs/*_L_R.png"</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"AD_Origin_LR_HS: "</span> + str(len(AD_Origin_LR_HS)))</span><br><span class="line">print(<span class="string">"CN_Origin_LR_HS: "</span> + str(len(CN_Origin_LR_HS)))</span><br><span class="line">print(<span class="string">"MCI_Origin_LR_HS: "</span> + str(len(MCI_Origin_LR_HS)))</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">AD_Origin_LR_HS_= glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD_hs_/*_L_R.png"</span>)</span><br><span class="line">CN_Origin_LR_HS_= glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD_hs_/*_L_R.png"</span>)</span><br><span class="line">MCI_Origin_LR_HS_= glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD_hs_/*_L_R.png"</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"AD_Origin_LR_HS_: "</span> + str(len(AD_Origin_LR_HS_)))</span><br><span class="line">print(<span class="string">"CN_Origin_LR_HS_: "</span> + str(len(CN_Origin_LR_HS_)))</span><br><span class="line">print(<span class="string">"MCI_Origin_LR_HS_: "</span> + str(len(MCI_Origin_LR_HS_)))</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">AD_Origin_HS= glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD_hs/*.png"</span>)</span><br><span class="line">CN_Origin_HS= glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD_hs/*.png"</span>)</span><br><span class="line">MCI_Origin_HS= glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD_hs/*.png"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">"AD_Origin_HS: "</span> + str(len(AD_Origin_HS)))</span><br><span class="line">print(<span class="string">"CN_Origin_HS: "</span> + str(len(CN_Origin_HS)))</span><br><span class="line">print(<span class="string">"MCI_Origin_HS: "</span> + str(len(MCI_Origin_HS)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历 AD-CN-MCI数据集，白点出现超过 才可以留存</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_candidate_first</span><span class="params">(url)</span>:</span></span><br><span class="line">    labels = glob.glob(url)</span><br><span class="line">    <span class="keyword">for</span> candidate_label <span class="keyword">in</span> labels:</span><br><span class="line">        <span class="comment"># 对图片进行判断，图片平均值&gt;1(实际平均值要为0，此处提供的图片全黑为1)，就是全黑，否则就是有白点</span></span><br><span class="line">        origin_image = candidate_label.replace(<span class="string">"_L_R"</span>, <span class="string">""</span>)</span><br><span class="line">        <span class="keyword">if</span> (np.mean(cv2.imread(candidate_label))) &gt;<span class="number">2</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            os.remove(candidate_label)</span><br><span class="line">            os.remove(origin_image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">select_candidate_first(url=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD_hs_/*_L_R.png"</span>)</span><br><span class="line">select_candidate_first(url=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD_hs_/*_L_R.png"</span>)</span><br><span class="line">select_candidate_first(url=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD_hs_/*_L_R.png"</span>)</span><br><span class="line"></span><br><span class="line">test_image = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD_hs_/*_L_R.png"</span>)</span><br><span class="line">test_image.sort()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line"></span><br><span class="line">k = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> test_image:</span><br><span class="line">    </span><br><span class="line">    image_mean_score = np.mean(cv2.imread(i))</span><br><span class="line">    print(str(i[<span class="number">-7</span>:<span class="number">-4</span>]) +<span class="string">" : "</span> +  str(image_mean_score))</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">10</span>,<span class="number">6</span>,k)</span><br><span class="line">    plt.title(image_mean_score)</span><br><span class="line">    plt.imshow(Image.open(i))</span><br><span class="line">    plt.legend()</span><br><span class="line">    </span><br><span class="line">    k = k+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test_image = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD_hs_/*_L_R.png"</span>)</span><br><span class="line">test_image.sort()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line"></span><br><span class="line">k = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> test_image:</span><br><span class="line">    </span><br><span class="line">    image_mean_score = np.mean(cv2.imread(i))</span><br><span class="line">    print(str(i[<span class="number">-7</span>:<span class="number">-4</span>]) +<span class="string">" : "</span> +  str(image_mean_score))</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">10</span>,<span class="number">6</span>,k)</span><br><span class="line">    plt.title(image_mean_score)</span><br><span class="line">    plt.imshow(Image.open(i))</span><br><span class="line">    plt.legend()</span><br><span class="line">    </span><br><span class="line">    k = k+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test_image = glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD_hs_/*_L_R.png"</span>)</span><br><span class="line">test_image.sort()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line"></span><br><span class="line">k = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> test_image:</span><br><span class="line">    </span><br><span class="line">    image_mean_score = np.mean(cv2.imread(i))</span><br><span class="line">    print(str(i[<span class="number">-7</span>:<span class="number">-4</span>]) +<span class="string">" : "</span> +  str(image_mean_score))</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">10</span>,<span class="number">6</span>,k)</span><br><span class="line">    plt.title(image_mean_score)</span><br><span class="line">    plt.imshow(Image.open(i))</span><br><span class="line">    plt.legend()</span><br><span class="line">    </span><br><span class="line">    k = k+<span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="融合图片-将左右海马体融合到原图上"><a href="#融合图片-将左右海马体融合到原图上" class="headerlink" title="融合图片,将左右海马体融合到原图上"></a>融合图片,将左右海马体融合到原图上</h3><ul><li>融合后原图放在origin-slices_C_CD_hs_Mix中</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">concat_iamge_hippocampus</span><span class="params">(url, target)</span>:</span></span><br><span class="line">    labels = glob.glob(url)</span><br><span class="line">    <span class="keyword">for</span> candidate_label <span class="keyword">in</span> labels:</span><br><span class="line">        candidate_hs_image = cv2.imread(candidate_label)</span><br><span class="line">        origin_img = candidate_label.replace(<span class="string">"_L_R"</span>, <span class="string">""</span>)</span><br><span class="line">        origin_img_img = origin_img.split(<span class="string">"/"</span>)[<span class="number">-1</span>]</span><br><span class="line">        img = cv2.imread(origin_img)</span><br><span class="line">        main_concat = cv2.addWeighted(img[:,:,:], <span class="number">1</span>, candidate_hs_image[:,:,:], <span class="number">1</span>, <span class="number">0.2</span>)</span><br><span class="line">        cv2.imwrite(os.path.join(target, origin_img_img), main_concat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">concat_iamge_hippocampus(url=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD_hs_/*_L_R.png"</span>, target=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD_hs_Mix"</span>)</span><br><span class="line">print(<span class="string">"AD_Origin_Mix: "</span> + str(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/AD/origin-slices_C_CD_hs_Mix/*.png"</span>))))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">concat_iamge_hippocampus(url=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD_hs_/*_L_R.png"</span>, target=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD_hs_Mix"</span>)</span><br><span class="line">print(<span class="string">"CN_Origin_Mix: "</span> + str(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/CN/origin-slices_C_CD_hs_Mix/*.png"</span>))))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">concat_iamge_hippocampus(url=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD_hs_/*_L_R.png"</span>, target=<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD_hs_Mix"</span>)</span><br><span class="line">print(<span class="string">"MCI_Origin_Mix: "</span> + str(len(glob.glob(<span class="string">"/home/pugongying/data/jupyterLab/shr/AD/ADNI-Datasets/MCI/origin-slices_C_CD_hs_Mix/*.png"</span>))))</span><br></pre></td></tr></table></figure><h2 id="6-补充AD-MCI"><a href="#6-补充AD-MCI" class="headerlink" title="6-补充AD-MCI"></a>6-补充AD-MCI</h2><p>AD_Origin_Mix: 178</p><p>CN_Origin_Mix: 352</p><p>MCI_Origin_Mix: 215</p><p><img src="/2023/09/10/8-3-%E6%B5%B7%E9%A9%AC%E4%BD%93%E6%8F%90%E5%8F%96/Db_MPpOlliGh1VeRhpFLPZykHxcNxeD5eqwtitenMiw.webp" alt="image"></p><p>所以需要再多下载AD和MCI 进行补充</p><p>补充后：</p><p>AD_Origin_Mix: 300</p><p>CN_Origin_Mix: 500</p><p>MCI_Origin_Mix: 380</p><hr><h3 id="FSL左右海马体分割-freesurfer合并"><a href="#FSL左右海马体分割-freesurfer合并" class="headerlink" title="FSL左右海马体分割+freesurfer合并"></a>FSL左右海马体分割+freesurfer合并</h3><p><a href="https://blog.csdn.net/qq_38851184/article/details/124452709" target="_blank" rel="noopener">https://blog.csdn.net/qq_38851184/article/details/124452709</a></p><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>需要分割出海马体。可借鉴方法：<a href="https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6&spm=1001.2101.3001.7020" target="_blank" rel="noopener">深度</a>学习（UNet分割），形态学上的开闭，fsl中的分割。<br>使用fsl种的分割时需要注意，fsl分割分为左海马和右海马<br>方法：使用fsl中的first命令进行分割。<br>先在终端输入first查看需要输入的参数：</p><p><img src="/2023/09/10/8-3-%E6%B5%B7%E9%A9%AC%E4%BD%93%E6%8F%90%E5%8F%96/vpFKhZw6SAmZ76pYyfDAlzA2x5oynngkzZawEOZPY2c.png" alt="image"></p><p>可以看到-i 要从哪个文件进行提取， -k输出分割文件名称，-m 分割的标准文件（*.bmv），-l</p><p>做flirt时的变换矩阵。</p><p>关于*.bmv文件：fsl自带的，在fsl安装目录data/first下面：</p><p><img src="/2023/09/10/8-3-%E6%B5%B7%E9%A9%AC%E4%BD%93%E6%8F%90%E5%8F%96/ToCC18E2iZ4Ck14W3WGwa3e1BATVfuKxRj7BKflnswY.png" alt="image"></p><p>关于这两个文件夹有什么区别不清楚，但是海马在选中的文件夹中。</p><h4 id="bash直接运行"><a href="#bash直接运行" class="headerlink" title="bash直接运行"></a>bash直接运行</h4><p>flirt的变换矩阵即subjmat.mat,该文件在做配准的时候是需要用参数进行输出的，但是直接使用命令是默认不输出</p><p>命令：first -i subj.nii -l subjmat.mat -m L_Hipp_bin.bmv -k l_hippo.nii</p><p>同样的方法生成右海马：</p><p>first -i subj.nii -l subjmat.mat -m R_Hipp_bin.bmv -k r_hippo.nii</p><p>使用freesurfer中的mri_concat命令将左海马和右海马合并成整个海马体：</p><p>mri_concat –combine l_hippo.nii r_hippo.nii –o hippo.nii</p><p>得到hippo.nii就是海马文件：</p><p><img src="/2023/09/10/8-3-%E6%B5%B7%E9%A9%AC%E4%BD%93%E6%8F%90%E5%8F%96/PG-qKR1VJb1vaNOXL8Yh7iAIBddDD4RX1au894OKUPE.png" alt="image"></p><h4 id="python-nipype实现"><a href="#python-nipype实现" class="headerlink" title="python+nipype实现"></a>python+nipype实现</h4><p>分割成左右海马体+合并代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">from</span> PyQt5 <span class="keyword">import</span> QtWidgets</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QMessageBox</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hippoSeg</span><span class="params">(in_file, out_file, out_path)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">segmentation hippocampus, and show the messagebox.</span></span><br><span class="line"><span class="string">    :param in_file: subj-T1.nii</span></span><br><span class="line"><span class="string">    :param out_file: hippo.nii</span></span><br><span class="line"><span class="string">    :param out_path: /home/xxx/Desktop/test</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    l_hippo = os.path.join(out_path, <span class="string">'L_Hipp_bin.bmv'</span>)</span><br><span class="line">    r_hippo = os.path.join(out_path, <span class="string">'R_Hipp_bin.bmv'</span>)</span><br><span class="line"></span><br><span class="line">    mat_file = os.path.join(out_path, <span class="string">'reg.mat'</span>) <span class="comment"># 配准时输出的矩阵</span></span><br><span class="line">    l_hippo_out = os.path.join(out_path, <span class="string">'l_hippo.nii.gz'</span>)</span><br><span class="line">    r_hippo_out = os.path.join(out_path, <span class="string">'r_hippo.nii.gz'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">   <span class="string">''' 分割左海马体 '''</span></span><br><span class="line">        l_hippo_cmd = <span class="string">'first -i &#123;0&#125; -l &#123;1&#125; -m &#123;2&#125; -k &#123;3&#125;'</span>.format(in_file, mat_file, l_hippo, l_hippo_out)</span><br><span class="line">        <span class="comment"># 因为是连接的远程环境，所以每次使用fsl中的命令需要重新inport一下，感觉有点繁琐。</span></span><br><span class="line">        l_cmdline = <span class="string">'export FSLDIR=/etc/fsl/5.0 &amp;&amp; source $FSLDIR/fsl.sh &amp;&amp; &#123;0&#125;'</span>.format(l_hippo_cmd)</span><br><span class="line">        task = subprocess.run(l_cmdline, shell=<span class="literal">True</span>, stdout=subprocess.PIPE)</span><br><span class="line">    <span class="keyword">except</span> BaseException <span class="keyword">as</span> err:</span><br><span class="line">        print(<span class="string">'err\n'</span>, err)</span><br><span class="line">        QMessageBox.information(QtWidgets.QWidget(), <span class="string">'messagebox'</span>, <span class="string">'left hippocampus segmentation error, see log file'</span>,</span><br><span class="line">                                QMessageBox.Yes)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">    <span class="string">''' 分割右海马体 '''</span></span><br><span class="line">        r_hippo_cmd = <span class="string">'first -i &#123;0&#125; -l &#123;1&#125; -m &#123;2&#125; -k &#123;3&#125;'</span>.format(in_file, mat_file, r_hippo, r_hippo_out)</span><br><span class="line">        r_cmdline = <span class="string">'export FSLDIR=/etc/fsl/5.0 &amp;&amp; source $FSLDIR/fsl.sh &amp;&amp; &#123;0&#125;'</span>.format(r_hippo_cmd)</span><br><span class="line">        task = subprocess.run(r_cmdline, shell=<span class="literal">True</span>, stdout=subprocess.PIPE)</span><br><span class="line">    <span class="keyword">except</span> BaseException <span class="keyword">as</span> err:</span><br><span class="line">        print(<span class="string">'err\n'</span>, err)</span><br><span class="line">        QMessageBox.information(QtWidgets.QWidget(), <span class="string">'messagebox'</span>, <span class="string">'right hippocampus segmentation error, see log file'</span>,</span><br><span class="line">                                QMessageBox.Yes)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">    <span class="string">''' 左右海马体联合 '''</span></span><br><span class="line">    <span class="comment"># 这条命令可以换成nipype包中的API接口，这里偷懒没有换。</span></span><br><span class="line">        concat_cmd = <span class="string">'mri_concat --combine &#123;0&#125; &#123;1&#125; --o &#123;2&#125;'</span>.format(os.path.join(out_path, l_hippo_out), </span><br><span class="line">                                                                   os.path.join(out_path, r_hippo_out),</span><br><span class="line">                                                                   os.path.join(out_path, out_file))</span><br><span class="line">         <span class="string">''' 同样需要export一下freesurfer '''</span></span><br><span class="line">        merge_cmdline = <span class="string">'export FREESURFER_HOME=/usr/local/freesurfer &amp;&amp; source $FREESURFER_HOME/SetUpFreeSurfer.sh &amp;&amp;  &#123;0&#125;'</span>.format(concat_cmd)</span><br><span class="line">        print(<span class="string">'start merge'</span>)</span><br><span class="line">        task = subprocess.run(merge_cmdline, shell=<span class="literal">True</span>, stdout=subprocess.PIPE)</span><br><span class="line">        print(<span class="string">'finished!'</span>)</span><br><span class="line">        QMessageBox.information(QtWidgets.QWidget(), <span class="string">'messagebox'</span>, <span class="string">'finished hippocampus '</span>,</span><br><span class="line">                                QMessageBox.Yes)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">except</span> BaseException <span class="keyword">as</span> err:</span><br><span class="line">        print(<span class="string">'err\n'</span>, err)</span><br><span class="line">        QMessageBox.warning(QtWidgets.QWidget(), <span class="string">'messagebox'</span>, <span class="string">'hippocampus merge error, see log file'</span>,</span><br><span class="line">                                QMessageBox.Yes)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">first -i ADNI_002_S_0619_affine.nii.gz -l subject.mat -m /usr/local/fsl/data/first/models_317_bin/L_Hipp_bin.bmv -k l_hippo.nii</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;h2 id=&quot;1-横截面选取&quot;&gt;&lt;a href=&quot;#1-横截面选取&quot; class=&quot;headerlink&quot; title=&quot;1-横截面选取&quot;&gt;&lt;/a&gt;&lt;strong&gt;1-横截面选取&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Axial：又名横断面，transverseCoronal：又名冠状面，Sagittal：矢状面，如同一个箭矢劈开成左右两半&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/09/10/8-3-%E6%B5%B7%E9%A9%AC%E4%BD%93%E6%8F%90%E5%8F%96/NFOZIMP_Ui4LAdS-bwIwPvDtwr6lbRf33xuAmdzInhE.png&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>8-2-ADNI论文数据预处理</title>
    <link href="http://javassun.github.io/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/"/>
    <id>http://javassun.github.io/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</id>
    <published>2023-09-02T15:17:38.000Z</published>
    <updated>2024-05-09T07:22:28.980Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><h2 id="1-基于深度神经网络的阿尔兹海默病分类算法研究"><a href="#1-基于深度神经网络的阿尔兹海默病分类算法研究" class="headerlink" title="1: 基于深度神经网络的阿尔兹海默病分类算法研究"></a>1: 基于深度神经网络的阿尔兹海默病分类算法研究</h2><p>曲阜师范大学-计算机学院-崔秀明</p><h3 id="1-数据集预处理"><a href="#1-数据集预处理" class="headerlink" title="1-数据集预处理"></a>1-数据集预处理</h3><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/TwTn80zU_EF9XwEHozZcr-zBV3MAQdkjg1MsGS8fzZ0.png" alt="image"></p><a id="more"></a><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/fwZHoqqmF9msI00MzeFeXcq0C4caHIuCpzoK1kRcK6I.png" alt="image"></p><h3 id="2-算法"><a href="#2-算法" class="headerlink" title="2-算法"></a>2-算法</h3><p><strong>基于迁移学习和深度残差网络的阿尔兹海默病分类算法</strong></p><p>首先，本文根据CNN的参数共享性，引入迁移学习的思想，将在ImageNet中预训练好的ResNet模型迁移至本文中的sMRI数据集中进行微调，从而替代从头开始训练一个全新的模型。此外，还计算了所有s MRI切片的熵，并按熵大小对它们进行降序排列，仅选取信息熵较大的sMRI切片用于训练CNN模型，从而增强了模型的整体稳健性。最后基于挑选出的sMRI切片进行了AD/MCI、AD/NC、NC/MCI与AD/MCI/NC的分类实验，结果表明，该算法在可用性较小的医学图像数据集中取得了较好的分类结果，同时缩短了CNN模型的训练时间。</p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/OF7xEiLRR55M0HmbHIwaPVVvA9KoaR9jjJPY2oRRgK4.png" alt="image"></p><p><strong>基于深层特征和非线性降维的阿尔兹海默病分类算法</strong></p><p>首先，本文根据CNN的参数共享性，引入迁移学习的思想，将在ImageNet中预训练好的ResNet模型迁移至本文中的sMRI数据集中进行微调，从而替代从头开始训练一个全新的模型。此外，还计算了所有s MRI切片的熵，并按熵大小对它们进行降序排列，仅选取信息熵较大的sMRI切片用于训练CNN模型，从而增强了模型的整体稳健性。最后基于挑选出的sMRI切片进行了AD/MCI、AD/NC、NC/MCI与AD/MCI/NC的分类实验，结果表明，该算法在可用性较小的医学图像数据集中取得了较好的分类结果，同时缩短了CNN模型的训练时间。</p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/HCLCGc6xEIdDdATe_JrMHxgjg43wxWzmXKwJ6_hBwvk.png" alt="image"></p><h3 id="3-创新点"><a href="#3-创新点" class="headerlink" title="3-创新点"></a>3-创新点</h3><p>本文主要提出了<strong>两个基于深度神经网络的AD分类算法</strong>。</p><ul><li><strong>提出基于迁移学习和深度残差网络的阿尔兹海默病分类算法</strong>。在现实生活中，医学图像与自然图像的获取方式不同，使得医学图像的获取途径很狭窄，并且医学图像的图像质量不是很高，因此导致了用于阿尔兹海默病分类的医学图像可用性相对较小，不足以充分训练CNN网络。另外训练一个与深度ResNet一样大的CNN需要巨大的计算资源，并且需要数周的时间才能训练。因此提出了基于迁移学习和深度残差网络的阿尔兹海默病分类算法，该算法引入迁移学习解决了可用医学图像样本数量少的问题，缩短了CNN模型的训练时间；引入信息熵的概念用于选择训练集，增强了模型的整体稳健性。</li><li><strong>提出基于深层特征和非线性降维的阿尔兹海默病分类算法</strong>。医学图像存在一个固有的劣势，就是高维非线性，现存方法也曾尝试了使用降维方法对其进行降维，但是由于数据的非线性特性使得在降维过程中产生了很多损失，导致最后的分类效果不理想；另外，前人所做工作中使用的降维方法的算法复杂度非常高，浪费计算成本。因此，提出了基于深层特征和非线性降维的阿尔兹海默病分类算法，在算法中引入了非线性降维方法LargeVis，减少了线性降维方法在降维过程中损失的信息，并大大降低了计算成本。</li></ul><h3 id="4-展望"><a href="#4-展望" class="headerlink" title="4-展望"></a>4-展望</h3><p>（1）本文实验中使用的都是2D CNN结构的变体，考虑到MRI数据集都是三维医学影像，未来可以尝试使用三维卷积神经网络（3D CNN）对上述数据集进行训练。</p><p>（2）本文在sMRI图像投入到实际应用之前，进行了一系列标准化的预处理流程，并未完全实现自动化提取特征。虽然sMRI数据在经过预处理后，在训练DNN时可以加快模型训练的收敛速度，降低对数据训练的需求，提高模型性能。但是神经影像数据的预处理步骤比较繁琐，因此，如何使用未经预处理的sMRI数据进行模型训练并获得良好的效果是未来需要研究的地方。</p><h2 id="2-基于卷积神经网络的阿尔茨海默病分类算法研究"><a href="#2-基于卷积神经网络的阿尔茨海默病分类算法研究" class="headerlink" title="2: 基于卷积神经网络的阿尔茨海默病分类算法研究"></a>2: 基于卷积神经网络的阿尔茨海默病分类算法研究</h2><p>      曲阜师范大学-计算机学院-刘汉磊</p><p>国内外专家学者使用比较成熟的方法都是以传统机器学习为主要算法进行AD、MCI和NC的分类和诊断，此类方法通常包含三个基本组成部分[26]：<strong>一是感兴趣区域（Re-gions of Interests，ROIs）的预先确定</strong>，<strong>二是图像特征的提取，三是分类模型的构建</strong>。根据结构磁共振成像（structure MRI，sMRI）中用于后续特征提取和分类器构建的ROI的尺度不同，可以将这些方法细分为<strong>基于体素、区域和Patch（内核kernel每次查看图像的一小块）级别的形态模式分析方法</strong></p><h3 id="1-数据集预处理-1"><a href="#1-数据集预处理-1" class="headerlink" title="1-数据集预处理"></a>1-数据集预处理</h3><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/kJBwqT29qC1i5zV2AmhBJ8YywmTUJxA6Kpg7PbYVW94.png" alt="image"></p><h3 id="2-算法-1"><a href="#2-算法-1" class="headerlink" title="2-算法"></a>2-算法</h3><p><strong>基于特征重构和卷积神经网络的AD分类算法</strong></p><p>将预处理好的MRI数据使用EDLT方法进行特征重构，构造了一个层数较浅的卷积神经网络结构，并利用迁移学习进行预训练，在ADNI数据集上进行了训练和测试评估。结果显示，所提方法要比单纯使用特征数据进行分类的传统机器学习方法的分类效果有所提高，表明使用特征重构的方法能够获得有意义的分类效果，迁移学习的使用能够降低在小样本数据集中的过拟合风险，也降低了计算成本。</p><p><strong>基于迁移学习和密集连接网络的阿尔茨海默病分类算法</strong></p><p>采用高斯滤波器进行图像增强，使用HEICA进行灰质分割，对AD、NC、MCI的三分类任务和两两分类任务进行了实验，实验数据基于ADNI数据库。结果显示，迁移学习的效果优于从头训练的效果，使用HEICA进行分割的效果优于未使用的效果。表明了在小样本数据集上使用迁移学习的必要性，以及使用图像增强和HEICA方法的有效性。</p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/kwyIOEVcQ8Fk24Yf7nIu19iqhBPfo6476R2SLENqOGU.png" alt="image"></p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/7y89B5oqGWBfVX-RUiDaq1gO0lYmI9QA5qQrh74sCuI.png" alt="image"></p><p>因为sMRI数据是由多张2D切片构成，每位受试者的NIFTI（Neuroimaging Informatics Technology Initiative）格式图像都包括256张切片。为了扩充数据集，我们选择对每位受试者的切片图像进行筛选扩充。一种简单的方法是随机选择多张图像，但这样的选择方法可能会遗漏一些关键信息。我们采用Hon等人[94]提出的图像熵选取切片的方法，该方法按照图像中包含信息的多少即熵的大小，将切片从大到小进行排列，我们对每位受试者的sMRI切片，选取熵值较高的前32个，这样既有利于扩充数据集，也有利于将信息少的图像排除在外。</p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/b_B_i8i_n7tOH0wx0hQ_VPieg5oLwrPHucLLfMfOBKc.png" alt="image"></p><p>使用MATLAB R2017a进行<strong>切片，颅骨剥离和图像分割</strong>。为了训练深度神经网络数据，我们使用PyTorch来进行训练和测试，GPU为英伟达精视GTX 1070，采用帕斯卡架构，16nm制程工艺，单精度浮点数达到了6.5Tflops，显存容量8GB GDDR5，核心频率为1683MHz，显存频率8000MHz</p><h3 id="3-创新点-1"><a href="#3-创新点-1" class="headerlink" title="3-创新点"></a>3-创新点</h3><p>本文提出了两种基于卷积神经网络的AD分类算法。</p><ul><li><strong>基于特征重构和卷积神经网络的阿尔茨海默病分类算法</strong>。针对基于先验知识、使用标准处理流程获得的sMRI灰质体积一维张量数据，我们提出一种基于特征重构的CNN方法。首先使用EDLT方法将一维张量特征数据转换为合成矩阵形式，在数据中创建“人工相关性”，并对合成矩阵数据通过使用翻转和裁剪进行数据增强。同时针对小样本数据集的特点，我们构造了浅层卷积神经网络架构，于源域SVHN上预训练，然后迁移至目标域中进行微调。针对此算法，我们在796名受试者数据上进行训练和测试，结果表明该算法具有实际可行性，分类效果较好。<strong>当前针对AD分类问题，研究人员使用比较成熟的技术是将人工提取特征放入传统机器学习分类器中进行分类训练。而将数值化的图像特征用作CNN的输入来进行分类这方面的工作并不多。本文引入特征重构方法，将一维灰质数据重构为二维矩阵，构造了适合于小样本数据集的浅层CNN，在SVHN数据集上进行预训练，并迁移至重构数据集上进行学习，通过进行对比实验以及同其他文献中方法的比较，证明了该方法的科学性和有效性。</strong></li></ul><ul><li><strong>基于迁移学习和密集连接网络的阿尔茨海默病分类算法</strong>。对于医学图像数据而言，图像中表达的信息比将信息量化为数据后的要全面。在本算法中，我们使用的是MRI数据。在预处理中，为了在颅骨剥离之前减少图像噪点，我们使用了高斯滤波器进行图像增强，在灰质分割时采用了HEICA的方法，使得灰质分割紧凑型强。分类所使用的框架为在ImageNet上预训练的DenseNet-BC网络，在迁移至目标域后，对其全连接层进行重新训练，其它层进行微调。切片图像选择我们使用了图像熵的办法，选取了每位受试者图像熵前32位的切片，这样有利于选择包含较多信息的图像进行训练，较少信息的图像排除在外，减少信息冗余。通过训练和测试，对比从头训练的网络和未进行图像增强的网络，发现所提算法的分类效果较好。<strong>医学图像的小样本问题和图像质量不高的问题，一直是研究人员进行医学图像分类的困扰。本文引入了高斯滤波器进行图像增强，使用HEICA进行灰质图像分割，得到了较为清晰的灰质图像；引入信息熵的概念用于选择切片图像，以增加数据集样本数量；选择DenseNet-BC网络作为分类模型，对其在ImageNet数据集上进行预训练，缩短了网络训练时间，降低了过拟合风险，通过进行对比实验以及同其他文献中方法的比较，证明了该方法的分类有效性。</strong></li></ul><h3 id="4-展望-1"><a href="#4-展望-1" class="headerlink" title="4-展望"></a>4-展望</h3><p>（1）多模态集成学习问题。本文中仅使用了sMRI数据，但多种诊断数据的结合，是提高疾病诊断正确率的方法之一。接下来可以结合fMRI、PET以及基因检测数据，进行集成学习，为AD分类提供更多信息，获得更好的分类结果。</p><p>（2）图像预处理问题。第四章中用到的sMRI数据，是经过一系列图像预处理步骤得到的，但是这些流程并不能在全自动的情况下进行，对于医生实际操作是一个挑战，下一步的工作就是将预处理步骤集成，使之处理起来更加方便。</p><p>（3）对于算法一中构建的浅层卷积神经网络，可以进一步去比较不同卷积层数以及不同卷积核的大小所引起的性能的差异，由此确定出更加适合的CNN架构。</p><h2 id="3-基于迁移学习的阿尔茨海默病早期诊断算法研究"><a href="#3-基于迁移学习的阿尔茨海默病早期诊断算法研究" class="headerlink" title="3: 基于迁移学习的阿尔茨海默病早期诊断算法研究"></a>3: 基于迁移学习的阿尔茨海默病早期诊断算法研究</h2><p>曲阜师范大学-计算机学院-刘永林</p><p>轻度认知障碍（Mild Cognitive Impairmen,MCI）是一种认知性疾病，是AD的前驱阶段。研究表明，由MCI到AD的转化率已经高达10％到15％，这明显高于认知健康受试者1%到2%的转化率。<strong>在MCI患者中发现有一些MCI患者会转为AD，也会有其他的MCI患者保持稳定或甚至出现逆转，恢复至正常的状态</strong>。因此，<strong>将前者称为MCI转换（MCIconvert,MCIc），后者称为MCI非转换（MCInon-convert,MCInc），并将MCInc和MCIc之间的差异用于AD的早期检测</strong>。尽管现在医疗系统中治疗AD的药物十分有限，但早期的发现和治疗还是有助于减缓疾病的进展。因此，针对MCI开展预防和治疗对延缓痴呆发病，提高患者的生活质量具有重要作用</p><h3 id="1-数据集预处理-2"><a href="#1-数据集预处理-2" class="headerlink" title="1-数据集预处理"></a>1-数据集预处理</h3><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/KahZimcooT86mLjvO77KYi_iYTXVNUadTnKJExwCsHo.png" alt="image"></p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/Bd3bKxLX-zRl4AGo8Esx7RMXrJeou1c-wthIMjJM15E.png" alt="image"></p><h3 id="2-算法-2"><a href="#2-算法-2" class="headerlink" title="2-算法"></a>2-算法</h3><p><strong>基于判别式迁移特征学习的AD早期诊断算法</strong></p><p>基于判别式迁移特征学习的AD早期诊断模型主要包括三个步骤：数据预处理和特征提取，基于判别式迁移特征学习（DTFL）算法和SVM的分类预测。本章AD诊断算法框架如图3.1所示。</p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/HlfAn5s6Lngd14Qmr3J5j5Galh9OM8oxkyEOwEPjl2Y.png" alt="image"></p><p><strong>基于集成迁移学习的AD早期诊断算法</strong></p><p>基于集成迁移学习的AD早期诊断模型主要包括三个步骤：数据预处理与特征提取、基于JDA的特征学习和基于集成学习的分类预测。本章结构框架图如图4.1所示。</p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/dQBLz5At-lKBE0vdBIidFbJG5nPAf_IP-ffQ0UCFUfE.png" alt="image"></p><h3 id="3-创新点-2"><a href="#3-创新点-2" class="headerlink" title="3-创新点"></a>3-创新点</h3><p>(1)<strong>提出了基于判别式迁移特征学习的AD早期诊断算法</strong></p><p>为充分利用辅助学习领域的相关知识，依据目标域（即MCI组）与辅助域（AD和NC组）数据的相关性合源域与目标域之间的分布差异，提出了TCA特征迁移算法；但是TCA算法中领域间分布差异度量方法忽略了各领域样本类别与样本特征之间的相关性，通过添加基于类内类间散度矩阵的判别优化项，来更好的使用样本之间的判别性信息，提出了基于判别式迁移特征学习（DTFL）的AD诊断算法，来实现样本领域间知识的迁移，提高样本类别的可分性。实验结果表明，从五个性能指标方面对分类结果进行分析，DTFL算法比其他对比方法都获得了更好的分类性能。</p><p>(2)<strong>提出了基于集成迁移学习的AD早期诊断算法</strong></p><p>针对TCA特征迁移算法对样本的结构信息与标签信息利用不足的情况，采用了基于联</p><p>合分布自适应（JDA）的特征迁移算法，来缩小样本领域间的边缘分布差异与条件分布差</p><p>异，提取样本数据领域间的共享特征，实现数据领域间知识的迁移；同时，为了获得更为</p><p>精确的AD分类性能，提出将GBDT、XGBoost和Adaboost作为三个基分类器，利用特征子</p><p>集训练得到基分类器，通过对多个基分类器加权投票方法的集成输出得到最终的分类结</p><p>果，并且在标准数据集ADNI上验证了本文提出的集成迁移学习方法的有效性。结果表明，</p><p>基于集成迁移学习的AD早期诊断算法在AD分类研究中获得的较好的分类性能。</p><h3 id="4-展望-2"><a href="#4-展望-2" class="headerlink" title="4-展望"></a>4-展望</h3><p>（1）本文提出的迁移学习AD早期诊断算法是基于来自ADNI数据库的单模态（即MRI）数据，用AD和NC为单个辅助领域，来识别MCIc和MCInc患者。但是，在ADNI数据库中，许多受试者都具有多模态生物标志物。依据迁移学习的原理，只要这些多领域的学习任务与目标领域的学习任务具有相关性，就可以利用多个辅助领域知识进行迁移学习，如其他痴呆类型（血管性痴呆）的数据。在未来的工作中，我们可以研究添加多模态样本数据和多辅助域数据进一步改善算法的分类性能。</p><p>（2）迁移学习方法在测量源域与目标域之间的差异性度量方面，应该进一步研究和度量源数据集和目标数据集之间的局部差异程度，根据度量结果再选择合适的方法进行迁移学习。例如，如果差异较小，可以考虑基于样本的迁移，如果差异较大，则采用基于特征的方式或者只使用目标样本来优化，避免出现负迁移现象。</p><h2 id="4-基于耦合的卷积-图卷积神经网络的阿尔茨海默病的磁共振诊断方法"><a href="#4-基于耦合的卷积-图卷积神经网络的阿尔茨海默病的磁共振诊断方法" class="headerlink" title="4: 基于耦合的卷积-图卷积神经网络的阿尔茨海默病的磁共振诊断方法"></a>4: 基于耦合的卷积-图卷积神经网络的阿尔茨海默病的磁共振诊断方法</h2><p>南方医科大学-生物医学工程学院-李青峰</p><p>   针对已有方法<strong>未利用大脑拓扑信息的问题，提出基于耦合的卷积-图卷积神经网络的疾病诊断模型</strong>，以实现对阿尔茨海默病及其前驱症状的精确诊断，为临床提供可靠的辅助诊断信息。</p><p>   方法根据ADNI数据库提供的信息，<strong>将MMSE评分在20**</strong>26分、同时CDR评分为0.5或1的被试的疾病标签标记为AD组；将MMSE评分在24<strong>**30分且CDR评分为0、无抑郁症状、无认知障碍、无焦虑症状的被试疾病标签标记为NC组。</strong>本文提出一种耦合的卷积-图卷积神经网络（CCGCN）模型，<strong>以组间比较获取的疾病相关区域作为输入，利用卷积神经网络，从大脑磁共振图像的不同区域提取疾病相关的特征，再使用图卷积网络，结合提取到的特征，对区域间拓扑结构进行建模，并在图卷积网络中嵌入图池化操作，从而自适应地学习大脑拓扑结构与疾病诊断任务之间的内在联系</strong>。利用ADNI数据集，获得CCGCN模型对阿尔茨海默病及其前驱症状的疾病诊断准确率、灵敏度和特异度，并进行模型结构的消融实验。</p><p>   结果该模型在阿尔茨海默病的诊断任务上取得了92.5%的准确率、88.1%的灵敏度和96.0%的特异度，诊断精度优于目前最先进的方法；同时在区分进行型轻度认知障碍患者和稳定型轻度认知障碍患者的任务上取得了79.8%的准确率、55.3%的灵敏度和83.7%的特异度；消融实验的结果显示了CCGCN模型各组成成分的有效性。结论基于耦合的卷积-图卷积神经网络的疾病诊断模型利用了原始图像的结构和拓扑信息，相比现有方法可以提供更加精确的阿尔茨海默病诊断结果，有望将其应用于临床的辅助诊断中。</p><p>目前取得较好效果的<strong>基于深度学习的AD诊断策略基本包括两步</strong>：<strong>从局部图像块提取特征；再将提取到的特征简单组合，进行进一步特征处理</strong>。但是，目前这些诊断策略的<strong>共同缺点是忽略不同图像块之间的拓扑关系</strong>。AD患者相比正常认知人群，其大脑sMRI中的图像块提取位置之间的空间位置关系必然是不同的。因此，<strong>这种拓扑结构可以提供大脑的结构信息，与图像的局部纹理信息结合，可以为AD的诊断提供更加可靠的依据</strong>。</p><h3 id="1-数据集预处理-3"><a href="#1-数据集预处理-3" class="headerlink" title="1-数据集预处理"></a>1-数据集预处理</h3><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/woTZzMuH_RY-MRI48F7tQ5AXR2fyB26OSc0CHEipyjM.png" alt="image"></p><p>包括ADNI-1和ADNI-2数据集。根据ADNI数据库提供的信息［5］，MMSE［23］评分在20<del>26分、同时CDR［24］评分为0.5或1的被试的疾病标签标记为AD组；MMSE评分在24</del>30分且CDR评分为0、无抑郁症状、无认知障碍、无焦虑症状的被试疾病标签标记为NC组；参考已有研究［2］的方法，根据MCI受试者是否会在首次扫描之后36月内转化为AD，进一步将ADNI-1和ADNI-2数据集中的MCI被试划分为稳定型MCI（即sMCI）和进行型MCI（pMCI）。</p><p>ADNI-1数据集中共有199例AD，167例pMCI，226例sMCI和229例NC被试；ADNI-2数据集中共有159例AD，38例pMCI，239例sMCI和200例NC被试，需注意的是，同时在ADNI-1和ADNI-2数据集中出现的被试已从ADNI-2数据集中移除。取以上被试的T1磁共振图像，作为实验数据。ADNI-1中的数据由1.5 T磁共振扫描仪获取，而ADNI-2的数据由3 T扫描仪获取。上述数据集中的被试分布见表1。</p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/vDunP5to9dwe_vYelhb2ecipoolhjScNjWqQ4oqo3Y4.png" alt="image"></p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/Nb4LR5M7eurBft9IaHdMOhYNpTcg60SlFZKyiaeypro.png" alt="image"></p><h3 id="2-算法-3"><a href="#2-算法-3" class="headerlink" title="2-算法"></a>2-算法</h3><p><strong>基于耦合的卷积-图卷积神经网络的阿尔茨海默病的磁共振诊断方法</strong></p><p>该模型主要有两个组成部分：<strong>图像块层级特征提取网络</strong>、<strong>b-GCN</strong></p><ul><li>图像块层级特征提取网络：其作用是从对应的图像块中提取特征，其内部结构如图2。网络的输入为两个同尺寸不同尺度的图像块（如前述），输出为标签相关特征向量。为生成标签相关特征，网络对输入图像块采用7个卷积层进行特征提取，其中每个卷积层后均加入批标准化操作和线性整流单元（ReLU）。网络的层间连接采用残差连接［11］（以跳层连接和特征图相加实现）和密集连接［12］（以特征图复制和按通道连接实现），以促进层间特征交流，避免优化过程中的梯度消失，增强网络的特征提取能力。最后一个卷积层的输出特征图经全局平均池化层［13］压缩为向量，再有全连接层对特征进行进一步的整合处理，最终输出与疾病标签相关的特征向量（本实验每个图像块上提取到的特征向量的维度定义为128维）。</li><li>b-GCN：利用上文提到的特征点空间结构，可以构造图结构G（V,E），其中V为图结构的节点集合，E为图结构的节点间边的集合。将特征点定义为图的节点，节点间欧式距离值定义为图的边，每个特征点（记为k，特征点共有K=30个）处的图像块提取到的μ维特征向量（μ=128）定义为相应的节点处的特征向量λ^k</li></ul><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/HA5jauCO1vXtU3RzSRcIQ6uklqhXXJy8mmo_inTY-Lw.png" alt="image"></p><p><strong>模型架构</strong></p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/OkkezY9pShhL4eTnrZZk7MKIk37UW1jkTDqZMQQ7heI.png" alt="image"></p><h3 id="3-训练方法"><a href="#3-训练方法" class="headerlink" title="3-训练方法"></a>3-训练方法</h3><p>我们以一种部分-整体策略来训练CCGCN模型，利用从不同特征点位置提取的图像块，首先单独训练每个图像块层级特征提取网络。当图像块层级特征提取网络训练至收敛后，对于每个输入图像，可从图像上每个特征点对应的图像块上获取疾病标签相关的特征向量。接下来，利用这些特征向量，对全脑层级图卷积神经网络进行训练。以上的预训练过程的目的是降低接下来对CCGCN模型进行端到端训练的难度。在预训练结束后，利用预训练得到的参数来初始化CCGCN模型的相应参数，对整个模型执行端到端的训练，以促进各部分间特征交流，避免模型各个组成部分参数的局部最优。训练中，模型的优化采用自适应矩估计方法［16］，使用Focal loss［17］作为损失函数，学习率设为10-4。</p><h3 id="4-创新点"><a href="#4-创新点" class="headerlink" title="4-创新点"></a>4-创新点</h3><p>在我们提出的CCGCN模型中，以图卷积神经网络对大脑拓扑结构进行建模，并以此为依据，对卷积神经网络提取到的特征进行进一步处理，可以实现诊断性能的进一步提升。</p><p>将卷积神经网络与图卷积神经网路耦合为一个整体，利用卷积神经网络对局部图像块特征进行抽取、处理，再利用图卷积神经网络，以大脑的空间拓扑结构为依据，对卷积神经网络抽取到的特征进行进一步处理。实验证明本文方法可以提高AD及其前驱症状的诊断效果，且有较好的稳定性，为临床实现AD及其前驱症状的计算机辅助诊断提出了一种新的方法。</p><p>相比传统特征提取方法，作为一种自适应特征提取方法，深度学习可以分层次地从原始数据空间提取、融合特征，从而获得对于目标任务的更好的特征表示。大脑sMRI中疾病相关的特征，相对整幅图像而言非常稀疏，因此必须通过预定位，找到疾病影响最为显著的区域，进而使用神经网络（如CNN）在此区域进行特征提取。</p><p><strong>然而，上述处理方法，相当于将完整的大脑图像视为局部图像块的组合，而忽略了这些图像快的空间位置分布状态，即全脑的拓扑结构，与疾病标签之间的关联</strong>。为解决这一问题，更好地利用原始图像所提供的信息，从而获得更好的疾病预测结果，我们将卷积神经网络与图卷积神经网路耦合为一个整体，利用卷积神经网络对局部图像块特征进行抽取、处理，再利用图卷积神经网络，以大脑的空间拓扑结构为依据，对卷积神经网络抽取到的特征进行进一步处理。实验证明本文方法可以提高AD及其前驱症状的诊断效果，且有较好的稳定性，为临床实现AD及其前驱症状的计算机辅助诊断提出了一种新的方法。</p><h3 id="5-展望"><a href="#5-展望" class="headerlink" title="5-展望"></a>5-展望</h3><p>本文提出的方法旨在对疾病标签进行预测，而未考虑其他因素（如年龄、性别、MMSE、CDR-SB等与疾病标签之间的内在联系。作为一种可行方案，未来将在模型结构中嵌入多任务策略，自适应地学习其他因素与疾病标签之间的关系，为进一步提升疾病标签预测任务的精度和稳定性提供一种方法。由于阿尔茨海默病及其前驱症状与多种生理指标相关，如糖代谢、脑功能连接等［25-26］，而T1 sMRI主要提供脑的结构信息，增加其他成像模态，如静息态功能磁共振成像、正电子发射计算机断层成像以及扩散张量成像等，可以为疾病诊断提供更多信息，从而进一步提升诊断精度和稳定性。</p><p>实现了病变区域定位任务和疾病诊断任务的联合优化的文献：</p><ul><li>Lian C,Liu M,Zhang J,et al.Hierarchical fully convolutional network for joint atrophy localization and alzheimer’s disease diagnosis using structural MRI［J］.IEEE Transactions Pattern Analysis Machine Intellig,2018,39(2):1-10.</li><li>Li Q,Xing X,Sun Y,et al.Novel iterative attention focusing strategy for joint pathology localization and prediction of MCI progression［M］.Springer:Med Image Comp Assisted Intervent, 2019:307-15.</li></ul><h2 id="5-基于脑部特异子结构分析的阿尔兹海默症分类"><a href="#5-基于脑部特异子结构分析的阿尔兹海默症分类" class="headerlink" title="5: 基于脑部特异子结构分析的阿尔兹海默症分类"></a>5: 基于脑部特异子结构分析的阿尔兹海默症分类</h2><p>四川大学-电子信息学院-印彪</p><p><strong>阿尔兹海默症与脑部子结构的形态学密切相关</strong>，现有研究通常是<strong>直接选取海马体、杏仁体等医学分析上具有特异性的子结构进行探究，并没有全面地去进行特异性子结构筛选</strong>。为了探究AD与子结构特异性之间的相关性，主要做了以下2个方面的工作:：**(1)提取脑部子结构的体积信息作为特征向量进行分类，并且通过机器学习决策树输出对分类起决定性作用的子结构<strong>。(2)以Res Net－3D为基础构建了网络，引入注意力子模块，过滤MRI图像中的冗余信息，同时将机器学习提取的特异性子结构的体积信息与高维特征信息进行融合，再进行分类。选用ADNI公开数据集上765名患者(正常(Cognitively Normal，CN)358名、AD患者407名)不同时期的2 294个脑部MRI图像进行了实验验证。实验结果表明，</strong>决策树中对分类起主要作用的子结构为海马体、杏仁体和鼻内嗅皮层这三个区域**，提出的方法，优于其他5种当前方法，可以作为一种很有前景的AD辅助诊断方法。</p><p>根据已有的工作，AD分类方法大致可以分为3类:</p><ul><li><strong>基于体素</strong></li><li><strong>基于感兴趣区域(ROI)</strong></li><li><strong>基于区域块的（Patch）</strong></li></ul><p>在基于<strong>体素</strong>的方法中，简单地通过统计或选择体素来提取特征。Ju等人［13］提出利用深度学习结合脑网络和临床相关文本信息对阿尔茨海默病进行早期诊断。然而，基于体素的特征通常具有更高的维数和噪声，这可能与疾病无关。因此，需要通过平滑、降采样和特征选择等技术来降低基于体素的特征的维数，以提高分类器的效率。</p><p>[13] JU Ronghui，HU Chenhui，ZHOU Pan，et al．Early diagnosis of Alzheimer’s disease based on resting－state brain netw orks and deep learning［J］．IEEE/ACM Transactions on Computational Biology and Bioinformatics，2017，16(1):244－257</p><p>在基于<strong>ROI</strong>的方法中，将大脑MRI图像分割成不同的组织ROI，然后使用基于ROI的特征向量或这些ROI之间的关系向量来描述MRI图像对AD患者进行分类。Ahmed等人［17］开发了一种利用海马视觉特征进行AD识别的自动分类框架。</p><p>[17] AHMED O B，BENOIS－PINEAU J，ALLARD M，et al．Classification of Alzheimer’s disease subjects from MRI using hippocampal visual features［J］．M ultimedia Tools and Applications，2015，74(4): 1249－1266．</p><p>本文做的主要贡献如下:</p><p>(1)基于机器学习，提取在阿尔兹海默症诊断过程中起决定性因素的特征子结构。</p><p>(2)将特征子结构的体积信息与深度学习分类网络的高维信息融合，同时增加注意力模块，过滤MRI冗余信息。</p><h3 id="1-数据集预处理-4"><a href="#1-数据集预处理-4" class="headerlink" title="1-数据集预处理"></a>1-数据集预处理</h3><p>在ADNI数据集上均匀选取765名受试者及其MRI脑部影像2 294个;其中AD的受试者为407人，CN的受试者为358人;对于脑部MRI，AD占有1 223例，CN占有1 071例。研究根据受试者年龄、简易精神状态检查表(mini-mental state examination，MMSE)、临床痴呆评定量表(Clinical Dementia Rating，CDR)、临床痴呆综合汇总评定量表(CDR Sum Boxes，CDR－SB)的均值和方差，将受试者按照7:3的比例，均匀划分成训练集和测试集，其数据分布见表1。</p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/cPkTRdc8YOkGGZp47DvyciF2sV3BMo_fk_pxB3feWQk.png" alt="image"></p><p>本文提取脑部子结构采用的是Huo等人［21］的<strong>基于空间块地图的三维全脑分割网络</strong>，该方法<strong>将脑部MRI分成27个独立的块，然后通过3D完全卷积网络对高分辨率的MRI块进行全脑分割，每个网络学习固定空间中的分割信息，最后将分割后的子块融合，还原整个脑部MRI，完成全脑子结构分割</strong>。该方法可以<strong>将脑部分割成132个子结构</strong>，与多图谱分割的方法相比具有较好的分割性能，同时将计算时间从原来的30 h缩短到了15 min。</p><p>[21] 3D Whole Brain Segmentation using Spatially Localized Atlas Network Tiles</p><p>首先，<strong>对MRI图像进行MNI空间仿射配准</strong>，<strong>将配准后的MRI影像进行N4偏置场校正、强度归一化</strong>。然后，<strong>将预处理后的图像送入分割网络中，进行脑部子结构的分割与融合，得到分割后脑部子结构的掩模MRI</strong>。最后，<strong>将分割后的掩模文件反配准到原始空间，得到原始掩模</strong>。</p><h3 id="2-算法-4"><a href="#2-算法-4" class="headerlink" title="2-算法"></a>2-算法</h3><p>网络的主体是以3D ResNet进行的改进。过程中主要对3D ResNet的残差模块进行了修改，引入了残差注意力模块，减少了图像的冗余信息。</p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/82E7VkNmjSgEwda21jdJYvGu-dm4O2ioFPwiDKXvOWw.png" alt="image"></p><p>对于阿尔兹海默症分类的体积特异性子结构、对<strong>阿尔兹海默症诊断起决定性作用的子结构为海马体、杏仁体和鼻内嗅区</strong>，说明了在阿尔兹海默症患病的过程中，脑部子结构体积会存在相应的变化。<strong>深度学习将机器学习提取出来的特征子结构体积信息加入网络中进行特征的融合，进一步提高了分类的准确率，同时加入了注意力模块，去除了MRI影像中的冗余信息，提高了二分类的准确率。</strong></p><h2 id="6-基于双线性卷积神经网络模型的阿尔茨海默病自动诊断"><a href="#6-基于双线性卷积神经网络模型的阿尔茨海默病自动诊断" class="headerlink" title="6: 基于双线性卷积神经网络模型的阿尔茨海默病自动诊断"></a>6: 基于双线性卷积神经网络模型的阿尔茨海默病自动诊断</h2><p>贵州医科大学-大健康学院-曾雷雷</p><h3 id="1-数据集预处理-5"><a href="#1-数据集预处理-5" class="headerlink" title="1-数据集预处理"></a>1-数据集预处理</h3><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/idX4jDryLX6fHSdCk-DyIvgBviKsCM4Buwx5a2fifoc.png" alt="image"></p><h3 id="2-算法-5"><a href="#2-算法-5" class="headerlink" title="2-算法"></a>2-算法</h3><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/eVUmLHJdku3WWS21c2SIwqLX3yaAfk36VDH5Hm0FRiw.png" alt="image"></p><h2 id="7-基于卷积神经网络的阿尔茨海默病-MRI影像辅助诊断研究"><a href="#7-基于卷积神经网络的阿尔茨海默病-MRI影像辅助诊断研究" class="headerlink" title="7: 基于卷积神经网络的阿尔茨海默病 MRI影像辅助诊断研究"></a>7: 基于卷积神经网络的阿尔茨海默病 MRI影像辅助诊断研究</h2><p>长春工业大学-计算机科学与工程学院-季鸿坤</p><p><img src="/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/yQLyfFC8etrF8VDudL9DmH_dHRgqqU1xnsmLlCSQhiA.png" alt="image"></p><h3 id="1-数据集预处理-6"><a href="#1-数据集预处理-6" class="headerlink" title="1-数据集预处理"></a>1-数据集预处理</h3><p>MRI成像及ADNI简介-MRI影像预处理：<a href="https://www.yuque.com/miluhuimilu/dglai6/hn81cf" target="_blank" rel="noopener">https://www.yuque.com/miluhuimilu/dglai6/hn81cf</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;h2 id=&quot;1-基于深度神经网络的阿尔兹海默病分类算法研究&quot;&gt;&lt;a href=&quot;#1-基于深度神经网络的阿尔兹海默病分类算法研究&quot; class=&quot;headerlink&quot; title=&quot;1: 基于深度神经网络的阿尔兹海默病分类算法研究&quot;&gt;&lt;/a&gt;1: 基于深度神经网络的阿尔兹海默病分类算法研究&lt;/h2&gt;&lt;p&gt;曲阜师范大学-计算机学院-崔秀明&lt;/p&gt;
&lt;h3 id=&quot;1-数据集预处理&quot;&gt;&lt;a href=&quot;#1-数据集预处理&quot; class=&quot;headerlink&quot; title=&quot;1-数据集预处理&quot;&gt;&lt;/a&gt;1-数据集预处理&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2023/09/02/8-2-ADNI%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/TwTn80zU_EF9XwEHozZcr-zBV3MAQdkjg1MsGS8fzZ0.png&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="论文" scheme="http://JavaSsun.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="Tools" scheme="http://JavaSsun.github.io/tags/Tools/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>8-1-数据预处理工具</title>
    <link href="http://javassun.github.io/2023/08/05/8-1-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/"/>
    <id>http://javassun.github.io/2023/08/05/8-1-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/</id>
    <published>2023-08-05T14:17:38.000Z</published>
    <updated>2024-05-09T06:57:41.420Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><ul><li><strong>Matlab</strong></li><li>SPM12 <a href="https://www.fil.ion.ucl.ac.uk/spm/software/download/" target="_blank" rel="noopener">https://www.fil.ion.ucl.ac.uk/spm/software/download/</a></li><li>Dpabi <a href="http://rfmri.org/dpabi" target="_blank" rel="noopener">http://rfmri.org/dpabi</a></li><li>BrainNetViewer <a href="https://www.nitrc.org/projects/bnv/" target="_blank" rel="noopener">https://www.nitrc.org/projects/bnv/</a></li><li>gretna <a href="https://www.nitrc.org/projects/gretna/" target="_blank" rel="noopener">https://www.nitrc.org/projects/gretna/</a></li><li>AAL <a href="https://www.gin.cnrs.fr/en/tools/aal/" target="_blank" rel="noopener">https://www.gin.cnrs.fr/en/tools/aal/</a> <a href="https://www.oxcns.org/aal3.html" target="_blank" rel="noopener">https://www.oxcns.org/aal3.html</a><a id="more"></a><a href="https://search.kg.ebrains.eu/instances/Dataset/f8758eda-483e-45fe-8a88-a1fc806dde18" target="_blank" rel="noopener">https://search.kg.ebrains.eu/instances/Dataset/f8758eda-483e-45fe-8a88-a1fc806dde18</a></li></ul><p><a href="https://blog.csdn.net/txapples/article/details/108471097" target="_blank" rel="noopener">https://blog.csdn.net/txapples/article/details/108471097</a></p><h3 id="创建每个步骤对应的文件夹"><a href="#创建每个步骤对应的文件夹" class="headerlink" title="创建每个步骤对应的文件夹"></a>创建每个步骤对应的文件夹</h3><figure class="highlight plain"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">## 在每个subject下面提前创建每个步骤对应的文件夹</span><br><span class="line"># * 2.NiFTI</span><br><span class="line"># * 3.SliceTime</span><br><span class="line"># * 4.Realignment</span><br><span class="line"># * 5.Normalize</span><br><span class="line"># * 6.Smooth</span><br><span class="line"># * 7.Co-register</span><br><span class="line"># * 8.ROI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import shutil</span><br><span class="line">import glob</span><br><span class="line"></span><br><span class="line"># 原始的dcm文件每个subject有6720个dicom,少了，则是网络中断，需要重新下载</span><br><span class="line">prefix_dir &#x3D; &quot;&#x2F;home&#x2F;pugongying&#x2F;data&#x2F;Brain&#x2F;fMRI-Test&#x2F;ADNI&#x2F;&quot;</span><br><span class="line">nifti_folder_name &#x3D; &quot;2.NiFTI&quot;</span><br><span class="line">sliceTime_folder_name &#x3D; &quot;3.SliceTime&quot;</span><br><span class="line">realignment_folder_name &#x3D; &quot;4.Realignment&quot;</span><br><span class="line">normalize_folder_name &#x3D; &quot;5.Normalize&quot;</span><br><span class="line">smooth_folder_name &#x3D; &quot;6.Smooth&quot;</span><br><span class="line">co_register_folder_name &#x3D; &quot;7.Co-register&quot;</span><br><span class="line">ROI_folder_name &#x3D; &quot;8.ROI&quot;</span><br><span class="line"></span><br><span class="line">folders &#x3D; glob.glob(os.path.join(prefix_dir, &quot;*&#x2F;Resting_State_fMRI&#x2F;*&quot;))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for folder in folders:</span><br><span class="line">    if not os.path.exists(os.path.join(folder, nifti_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, nifti_folder_name))</span><br><span class="line"></span><br><span class="line">    if not os.path.exists(os.path.join(folder, sliceTime_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, sliceTime_folder_name))</span><br><span class="line"></span><br><span class="line">    if not os.path.exists(os.path.join(folder, realignment_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, realignment_folder_name))</span><br><span class="line"></span><br><span class="line">    if not os.path.exists(os.path.join(folder, normalize_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, normalize_folder_name))</span><br><span class="line"></span><br><span class="line">    if not os.path.exists(os.path.join(folder, smooth_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, smooth_folder_name))</span><br><span class="line"></span><br><span class="line">    if not os.path.exists(os.path.join(folder, co_register_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, co_register_folder_name))</span><br><span class="line"></span><br><span class="line">    if not os.path.exists(os.path.join(folder, ROI_folder_name)):</span><br><span class="line">        os.makedirs(os.path.join(folder, ROI_folder_name))</span><br><span class="line"></span><br><span class="line">glob.glob(os.path.join(prefix_dir, &quot;*&#x2F;Resting_State_fMRI&#x2F;*&#x2F;*&quot;))</span><br></pre></td></tr></table></figure><h3 id="提取配准后的文件到7-Co-register文件夹"><a href="#提取配准后的文件到7-Co-register文件夹" class="headerlink" title="提取配准后的文件到7.Co-register文件夹"></a>提取配准后的文件到7.Co-register文件夹</h3><figure class="highlight plain"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">## 提取配准后的文件到7.Co-register文件夹</span><br><span class="line"># * 140个文件&#x2F;人</span><br><span class="line"># * rswras</span><br><span class="line"></span><br><span class="line">base_dir &#x3D; &quot;&#x2F;home&#x2F;pugongying&#x2F;data&#x2F;Brain&#x2F;fMRI-Test&#x2F;ADNI&#x2F;*&quot;</span><br><span class="line">base_folders &#x3D; (glob.glob(base_dir))</span><br><span class="line">for base_folder in base_folders:</span><br><span class="line">    co_register_tmp_list &#x3D; glob.glob(os.path.join(base_folder, &quot;Resting_State_fMRI&#x2F;*&#x2F;2.NiFTI&#x2F;rswras*.nii&quot;))</span><br><span class="line">    dst_folders &#x3D; glob.glob(os.path.join(base_folder, &quot;Resting_State_fMRI&#x2F;*&#x2F;7.Co-register&#x2F;&quot;))[0]</span><br><span class="line">    for co_register_tmp in co_register_tmp_list:</span><br><span class="line">        shutil.copy(co_register_tmp, dst_folders)</span><br></pre></td></tr></table></figure><p><strong>Dpabi提取ROI信号</strong></p><p><img src="/2023/08/05/8-1-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/NSM9dxbLC6Jv6e9rY707OxhmJYXzQzn6nSl2sldMDHM.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Matlab&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;SPM12 &lt;a href=&quot;https://www.fil.ion.ucl.ac.uk/spm/software/download/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.fil.ion.ucl.ac.uk/spm/software/download/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Dpabi &lt;a href=&quot;http://rfmri.org/dpabi&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://rfmri.org/dpabi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;BrainNetViewer &lt;a href=&quot;https://www.nitrc.org/projects/bnv/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.nitrc.org/projects/bnv/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;gretna &lt;a href=&quot;https://www.nitrc.org/projects/gretna/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.nitrc.org/projects/gretna/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;AAL &lt;a href=&quot;https://www.gin.cnrs.fr/en/tools/aal/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.gin.cnrs.fr/en/tools/aal/&lt;/a&gt; &lt;a href=&quot;https://www.oxcns.org/aal3.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.oxcns.org/aal3.html&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
    
      <category term="Tools" scheme="http://JavaSsun.github.io/tags/Tools/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>7-2-GNN For AD</title>
    <link href="http://javassun.github.io/2023/07/25/7-2-GNN-For-AD/"/>
    <id>http://javassun.github.io/2023/07/25/7-2-GNN-For-AD/</id>
    <published>2023-07-25T14:17:38.000Z</published>
    <updated>2024-05-09T07:22:20.815Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p><img src="/2023/07/25/7-2-GNN-For-AD/eoU98wMNr9k7Zd36NUkPlfXEbJotoTjFSFmZYL1eEAo.png" alt="image"></p><a id="more"></a><h2 id="参考文献（17篇）"><a href="#参考文献（17篇）" class="headerlink" title="参考文献（17篇）"></a>参考文献（17篇）</h2><p>[143] C. R. Jack Jr, M. A. Bernstein, N. C. Fox, P. Thompson, G. Alexander,D. Harvey, B. Borowski, P. J. Britson, J. L. Whitwell, C. Wardet al.,“The alzheimer’s disease neuroimaging initiative (adni): Mri methods,”J. Magn. Reson. Imaging, vol. 27, no. 4, pp. 685–691, 2008.</p><p>[145] R. C. Petersen, P. Aisen, L. A. Beckett, M. Donohue, A. Gamst, D. J.Harvey, C. Jack, W. Jagust, L. Shaw, A. Togaet al., “Alzheimer’sdisease neuroimaging initiative (adni): clinical characterization,”Neu-rology, vol. 74, no. 3, pp. 201–209, 2010.</p><p>[152] L. A. Beckett, M. C. Donohue, C. Wang, P. Aisen, D. J. Harvey,N. Saito, and A. D. N. Initiative, “The alzheimer’s disease neuroimag-ing initiative phase 2: Increasing the length, breadth, and depth of ourunderstanding,”Alzheimer’s &amp; Dementia, vol. 11, no. 7, pp. 823–831,2015.</p><h3 id="1-Spectral-graph-convolutions-for-population-based-disease-prediction"><a href="#1-Spectral-graph-convolutions-for-population-based-disease-prediction" class="headerlink" title="1. Spectral graph convolutions for population-based disease prediction"></a>1. Spectral graph convolutions for population-based disease prediction</h3><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445252159-8bb76bd1-43f3-4878-9f35-82b7deb2716d.pdf" target="_blank" rel="noopener">📎Spectral graph convolutions for population-baseddisease prediction.pdf</a></p><p>[98] S. Parisot, S. I. Ktena, E. Ferrante, M. Lee, R. G. Moreno, B. Glocker,and D. Rueckert, “Spectral graph convolutions for population-based disease prediction,” inProc. Med. Image Comput. Comput.-Assist.Interv. (MICCAI), 2017, pp. 177–185.</p><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>      利用丰富的成像和非成像信息进行疾病预测任务，需要模型能够同时表示个体特征以及来自潜在大人群的受试者之间的数据关联。Graph为此类任务提供了自然框架，但以前的基于图形的方法侧重于成对的相似性，而没有对受试者的个人特征和特征进行建模。另一方面，仅依赖特定于对象的成像特征向量无法模拟对象之间的交互和相似性，这会降低性能。在本文中，我们引入了图形卷积网络（GCN）的新概念，将图像和非图像数据相结合，用于人群的大脑分析。<strong>我们将种群表示为一个稀疏图，其中顶点与基于图像的特征向量关联，边缘编码不典型信息</strong>。该结构用于训练部分标记图上的GCN模型，旨在从节点特征和受试者之间的成对关联推断未标记节点的类别。我们展示了该方法在具有挑战性的ADNI和ABIDE数据库上的潜力，作为在分类任务中集成上下文信息的益处的概念证明。这对预测的质量有明显的影响，导致ABIDE的准确率为69.5%（超过目前66.8%的现有技术水平），ADNI中MCI转换的准确率达77%，显著优于仅考虑单个特征的标准线性分类器。</p><h4 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/j-zlHQPL14MmFc8riX6-2BQGuAmUKUu-uGNGuPQeMbM.png" alt="image"></p><p>我们考虑一个包括成像（如静息状态MRI或结构MRI）和非成像表型数据（如年龄、性别、采集地点等）的N采集数据库。我们的目标是为每个采集分配一个标签，对应于受试者和时间点，描述对应受试者的疾病状态（如对照或患病）。为此，我们将人口表示为稀疏图G={V，E，W}，其中W是描述图连通性的邻接矩阵。顶点v∈V表示每个采集V与从图像数据中提取的C维特征向量x（v）相关联。图的边缘表示子项目之间的相似性，并包含表型信息。通过使用在标记的图顶点子集上训练的GCN，以半监督的方式完成图标记。直观地说，标签信息将在假设与高边权重连接的节点更具可比性的情况下在图形上传播。</p><p>所提出的模型需要两个关键的设计选择人群图构建：</p><p>1）描述每个样本的特征向量（v）的定义</p><p>2）图边E的定义对样本之间的相互作用进行建模。</p><p>对于ADNI数据集，我们只需使用所有138个分段大脑结构的体积。</p><h4 id="总结-amp-讨论"><a href="#总结-amp-讨论" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p>代码：<a href="https://github.com/parisots/population-gcn" target="_blank" rel="noopener">https://github.com/parisots/population-gcn</a></p><p>在本文中，我们介绍了用于基于人群的大脑分析的图卷积的新概念。我们提出了一种策略，将基于图像的患者特定信息与基于非成像的信息交互相结合，构建群体图，并使用该结构训练用于半监督群体分类的GCN。作为概念的证明，该方法在具有挑战性的ABIDE和ADNI数据库上进行了测试，分别用于从异构数据库中进行ASD分类和从纵向信息预测MCI转换。我们的实验证实了我们关于上下文成对信息对分类过程的重要性的最初假设。在所提出的半监督学习设置中，由于分布在网络上的监督损失梯度信息，在相邻矩阵上调节GCN允许学习表示，即使对于未标记的节点也是如此。这对预测的质量有明显的影响，与标准线性分类器（仅考虑单个特征）相比，ABIDE提高了4.1%，ADNI提高了10%。</p><p>这项工作可以考虑几个扩展。设计一个有效的策略来构建人口图是至关重要的，而且远非显而易见。我们的图在同一边缘包含多种类型的信息。一个有趣的扩展是使用属性图，其中两个节点之间的边设计成向量而不是标量。这将允许利用补充信息，并以不同的方式权衡某些措施的影响。还可以考虑将时间信息与纵向数据相结合。我们的特征向量目前非常简单，因为我们的主要目的是显示图形中上下文信息的影响。我们计划使用更丰富的特征向量来评估我们的方法，可能通过使用来自MRI图像的自动编码器和rs-fMRI连接网络。</p><h3 id="2-Disease-prediction-using-graph-convolutional-networks-application-to-autism-spectrum-disorder-and-alzheimer’s-disease"><a href="#2-Disease-prediction-using-graph-convolutional-networks-application-to-autism-spectrum-disorder-and-alzheimer’s-disease" class="headerlink" title="2. Disease prediction using graph convolutional networks: application to autism spectrum disorder and alzheimer’s disease"></a>2. Disease prediction using graph convolutional networks: application to autism spectrum disorder and alzheimer’s disease</h3><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445252148-a457bec5-c588-4450-98da-76687cbfe66c.pdf" target="_blank" rel="noopener">📎Disease prediction using graph convolutional networks.pdf</a></p><p>[21] S. Parisot, S. I. Ktena, E. Ferrante, M. Lee, R. Guerrero, B. Glocker,and D. Rueckert, “Disease prediction using graph convolutional networks: application to autism spectrum disorder and alzheimer’s disease,”Med. Image Anal., vol. 48, pp. 117–130, 2018.</p><p>GCNs can beused to classify subjects into healthy or AD. Parisot et al. [21]constructed a population graph by integrating subject-specificimaging (MRI) and pairwise interactions using non imaging(phenotypic) data, then fed the sparse graph to a GCN to per-form a semi-supervised node classification. Their experimentson the ADNI dataset for AD classification (conversion from(MCI) to AD) showed a high performance in comparison to anon-graph method [181]. In addition, comparing to their priorwork [98] they showed a better graph structure (combiningAPOE4 gene data and eliminating AGE information) thatcould increase the accuracy of binary classification of AD onthe ADNI dataset.</p><p>GCN可用于将受试者分类为健康或AD。Parisot等人[21]通过使用非成像（表型）数据整合受试者特异性成像（MRI）和成对相互作用构建了群体图，然后将稀疏图馈送给GCN以形成半监督节点分类。他们对AD分类的ADNI数据集（从（MCI）到AD的转换）的实验表明，其性能较高。此外，与他们之前的研究[98]相比，他们显示了更好的图形结构（结合APOE4基因数据并消除AGE信息），可以提高ADNI数据集上AD的二值分类的准确性。</p><h4 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h4><p>图被广泛用作一个自然框架，它捕捉了作为图中节点呈现的各个元素之间的交互。具体而言，在医学应用中，节点可以表示潜在大量人群（患者或健康对照）中的个体，并伴有一组特征，而图形边缘以直观的方式结合了受试者之间的关联。这意味着在疾病分类任务中同时结合丰富的成像和非成像信息以及个体受试者特征。在疾病预测的背景下，先前的基于图的监督或非监督学习方法仅关注受试者之间的成对相似性，而忽略了个体特征和特征，或者更确切地说，依赖于受试者特定的图像特征向量，而无法对它们之间的交互进行建模。在这篇论文中，我们对一个通用框架进行了全面评估，该框架利用了成像和非成像信息，可用于大规模人群的大脑分析。该框架利用图形卷积网络（GCN），并将种群呈现为稀疏图，其中其节点与基于图像的特征向量相关联，而表型信息作为边缘权重进行整合。广泛的评估探索了该框架的每个单独组成部分对疾病预测性能的影响，并将其与不同的基线进行了进一步比较。该框架的性能在两个具有不同基础数据的大型数据集ABIDE和ADNI上进行了测试，分别用于预测自闭症谱系障碍和转换为阿尔茨海默病。我们的分析表明，我们的新框架可以改进两个数据库的最新结果，ABIDE的分类准确率为70.4%，ADNI的分类准确度为80.0%。</p><h4 id="架构图-1"><a href="#架构图-1" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/zOZcIEmQ0Umj36_7zVr0_U5kTdlxXbNqwRMRe1KIEnM.png" alt="image"></p><p>我们考虑一个受试者群体，每个受试者由一组互补的、表型和人口统计信息（例如性别、年龄、获取地点）描述/关联。人群包括一组N次成像采集（本文中考虑了结构或功能MRI），N≥S，这意味着一个受试者可以与多个采集（纵向扫描）相关联。我们的目标是根据表型信息提供的成像数据预测每个受试者的状态（健康控制或疾病）。总体表示为加权稀疏图，G={V，E，W}，其中W是描述图连通性的邻接矩阵。由顶点V∈V表示的每个采集V对应于与从成像数据中提取的C维特征向量（V）相关联的对象。图的边缘为相应受试者之间的相似性建模，并纳入表型信息。我们将诊断任务建模为节点分类问题，其中我们的目标是为每个描述受试者患病（l=1）或健康状态（l=0）的图节点分配一个标签∈{0,1}。尽管我们在这项工作中专注于二进制分类，但该模型可以很容易地扩展到多类分类问题。我们采用半监督策略，其中所有节点特征以及总体图都被馈送到GCN，而在训练过程中只有图节点的子集被标记并用于优化过程。直观地说，该图充当正则化器，“鼓励”与高边权重连接的节点以提高标签传播性能的方式为过滤相邻节点的特征做出更多贡献。</p><p>主要贡献：</p><p>• 在医学成像领域引入GCN进行人群分析。</p><p>• 将受试者分类作为一个图形标记问题的新公式，整合了成像和非成像数据。</p><p>• 无缝集成已知的非成像特征，允许整合临床专业知识以提高分类性能</p><p>所提出的模型需要两个关键的设计选择人群图构建：</p><p>1）描述每个图节点/采集的特征向量的定义</p><p>2）图的连通性，即图的边S和它们的权重W，其对节点/受试者/扫描质检的相似性及其对应特征进行建模</p><p>对于ADNI数据集，我们只需使用所有138个分段大脑结构的体积。</p><h4 id="总结-amp-讨论-1"><a href="#总结-amp-讨论-1" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p>代码：<a href="https://github.com/parisots/population-gcn" target="_blank" rel="noopener">https://github.com/parisots/population-gcn</a></p><p>在本文中，我们提出了一种利用谱图卷积这一新概念的组级总体诊断方法。我们将群体建模为一个稀疏图，结合了受试者特异性数据和使用表型和其他非成像信息描述的成对交互作用。该稀疏图用于以半监督的方式训练GCN，用于节点分类、在标记节点的子集上学习并评估其余节点。我们在两个大型且具有挑战性的数据库（ABIDE和ADNI）上的实验证实了我们关于上下文成对信息对分类的重要性的初始假设，因为我们以70.4%（ABIDE）和80%（ADNI）的准确度获得了最先进的性能，对应于仅使用节点特征的分类增加了5%和9%。我们的可拓性评估分析了模型的不同组成部分，包括特征选择方法、多项式度和图构建策略。探索不同的图结构和基线，我们展示了我们的表型图公式如何产生更准确和稳定的结果，以及选择合适的表型测量来模拟成对相互作用的重要性。</p><p>在这项工作的主要局限性中，我们应该考虑将该框架推广到未知节点，例如在ABIDE案例中。由于这是一种转换学习的应用，对新的不可见领域的推广预计会导致性能下降，特别是如果训练数据集不够大，无法捕捉群体可变性。此外，ADNI图的构建方式，每个受试者的多个扫描被建模为节点并独立分类，可能会向有更多访问的受试者引入偏见。最后但并非最不重要的是，高度阶层失衡的问题构成了一种需要进一步研究的情景。在这项工作中，我们用相对平衡的数据进行了两项研究。然而，在某些类型的人口研究中（例如，全基因组预测任务Yones等人（2017）），可以发现巨大的阶级失衡比例，大约为1:10000。在未来，我们希望研究如何使用图卷积来利用可用的注释数据来简化高度类不平衡问题中的预测率。</p><h3 id="3-Tadpole-challenge-Prediction-of-longitudinal-evolution-in-alzheimer’sdisease"><a href="#3-Tadpole-challenge-Prediction-of-longitudinal-evolution-in-alzheimer’sdisease" class="headerlink" title="3. Tadpole challenge: Prediction of longitudinal evolution in alzheimer’sdisease"></a>3. Tadpole challenge: Prediction of longitudinal evolution in alzheimer’sdisease</h3><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445252624-3b870c79-a138-4b80-9470-2c36c388562e.pdf" target="_blank" rel="noopener">📎TADPOLE Challenge.pdf</a></p><p>[146] R. V. Marinescu, N. P. Oxtoby, A. L. Young, E. E. Bron, A. W. Toga,M. W. Weiner, F. Barkhof, N. C. Fox, S. Klein, D. C. Alexanderet al.,“Tadpole challenge: Prediction of longitudinal evolution in alzheimer’sdisease,”arXiv preprint arXiv:1805.03909, 2018.</p><p><a href="https://github.com/noxtoby/TADPOLE" target="_blank" rel="noopener">https://github.com/noxtoby/TADPOLE</a></p><h3 id="4-Inceptiongcn-receptive-field-aware-graph-convolutional-network-for-disease-prediction"><a href="#4-Inceptiongcn-receptive-field-aware-graph-convolutional-network-for-disease-prediction" class="headerlink" title="4. Inceptiongcn: receptive field aware graph convolutional network for disease prediction"></a>4. Inceptiongcn: receptive field aware graph convolutional network for disease prediction</h3><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445252165-97d53899-62d8-4b93-8322-5aefb0ad58c9.pdf" target="_blank" rel="noopener">📎InceptionGCN.pdf</a></p><p>[93] A. Kazi, S. Shekarforoush, S. A. Krishna, H. Burwinkel, G. Vivar,K. Kort ̈um, S.A. Ahmadi, S. Albarqouni, and N. Navab, “Inceptiongcn: receptive field aware graph convolutional network for disease prediction,” in Proc. Int. Conf. Inf. Process. Med. Imaging (IPMI),2019, pp. 73–85.</p><h4 id="摘要-2"><a href="#摘要-2" class="headerlink" title="摘要"></a>摘要</h4><p>几何深度学习为医学领域的成像和非成像模式的集成提供了一个原则性和通用性的工具。特别是图形卷积网络（GCN）已经通过利用大型多模态数据集在疾病预测、分割和矩阵完成等多种问题上进行了探索。在本文中，我们介绍了一种新的谱域结构，用于疾病预测图的深度学习。新颖之处在于定义了几何“初始模块”，它能够在卷积过程中捕获图内和图间结构异构性。我们设计了具有不同内核大小的滤波器来构建我们的架构。我们在两个公开可用的数据集上展示了我们的疾病预测结果。此外，我们在模拟数据上提供了关于常规GCN和我们提出的模型在不同输入情景下的行为的见解。</p><h4 id="架构图-2"><a href="#架构图-2" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/2zAiNd-KyDXy7D7Q3ee1c1MmdBtrjQDLUKimiIi1Tv8.png" alt="image"></p><p>传统模型在所有层中使用恒定的滤波器大小，这迫使使用固定跳数的邻居来学习每个节点的特征，而不考虑簇大小和形状。我们提出的InceptionGCN模型克服了这一限制，通过改变GC层中的滤波器大小，以产生类别可分离的输出特征。当每个类别分布具有不同的方差和/或类别严重重叠时，我们的模型的这一特性非常理想。利用这种设置，我们的目标是通过合并来自不同图形的不同关联的信息来解决疾病分类任务。我们从亲和图的构建开始详细描述了该模型，随后介绍了数学背景，并讨论了所提出的模型架构。</p><h4 id="总结-amp-讨论-2"><a href="#总结-amp-讨论-2" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p>InceptionGCN模型的潜在改进包括样本外推理（即归纳学习），这将大大提高模型的能力。另一个研究领域是将多亲和图集成到一个模型中。此外，还可以优化InceptionGCN模型结构本身，首先通过使用可学习的预处理步骤来获得邻域值，其次通过分析每个GC层中隐藏单元的数量和所需的初始模块的总数。</p><h3 id="5-Adaptive-graph-convolution-pooling-for-brain-surface-analysis"><a href="#5-Adaptive-graph-convolution-pooling-for-brain-surface-analysis" class="headerlink" title="5. Adaptive graph convolution pooling for brain surface analysis"></a>5. Adaptive graph convolution pooling for brain surface analysis</h3><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445252154-3454cf94-1820-4b6e-a14c-b398179ab148.pdf" target="_blank" rel="noopener">📎Adaptive Graph Convolution Pooling for Brain Surface Analysis.pdf</a></p><p>[45] K. Gopinath, C. Desrosiers, and H. Lombaert, “Adaptive graph convolution pooling for brain surface analysis,” inProc. Int. Conf. Inf.Process. Med. Imaging (IPMI), 2019, pp. 86–98.</p><h3 id="6-Dynamic-spectral-graph-convolution-networks-with-assistanttask-training-for-early-mci-diagnosis"><a href="#6-Dynamic-spectral-graph-convolution-networks-with-assistanttask-training-for-early-mci-diagnosis" class="headerlink" title="6. Dynamic spectral graph convolution networks with assistanttask training for early mci diagnosis"></a>6. Dynamic spectral graph convolution networks with assistanttask training for early mci diagnosis</h3><p><a href="https://sci-hub.ru/10.1007/978-3-030-32251-9_70" target="_blank" rel="noopener">https://sci-hub.ru/10.1007/978-3-030-32251-9_70</a> (第670页)</p><p>[58] X. Xing, Q. Li, H. Wei, M. Zhang, Y. Zhan, X. S. Zhou, Z. Xue, andF. Shi, “Dynamic spectral graph convolution networks with assistanttask training for early mci diagnosis,” inProc. Med. Image Comput.Comput.-Assist. Interv. (MICCAI), 2019, pp. 639–646.</p><p>Xing et al. [58] proposed a model consisting of dynamicspectral graph convolution networks (DS-GCNs) to predictearly mild cognitive impairment (EMCI), and two assistivenetworks for gender and age to provide guidance for the finalEMCI prediction. They constructed graphs using T1-weightedandfMRI images from the ADNI [143] dataset. Apart frompredicting age and gender for EMCI prediction, their modelused an LSTM which could extract temporal informationrelated to the EMCI prediction.</p><p>Xing等人[58]提出了一个由动态频谱图卷积网络（DS-GCN）组成的模型，用于预测早期轻度认知障碍（EMCI），以及两个针对性别和年龄的辅助网络，用于为最终的EMCI预测提供指导。他们使用ADNI[143]数据集的T1加权和MRI图像构建了图表。除了预测EMCI预测的年龄和性别外，他们的模型使用了LSTM，该LSTM可以提取与EMCI预测相关的时间信息。</p><h4 id="摘要-3"><a href="#摘要-3" class="headerlink" title="摘要"></a>摘要</h4><p>功能性脑连接组，也称为区域间功能连接（FC）矩阵，最近被认为提供早期轻度认知障碍 (eMCI) 的决定性标志物。 然而，在大多数现有方法中，使用了向量化静态 FC 矩阵和一些“现成的”分类器，这可能会导致两者的弃用空间和时间信息，从而危及诊断表现。 在本文中，我们提出了使用功能 MRI 进行早期 MCI 诊断的动态谱图卷积网络 (DS-GCN)。 首先，构建一个动态脑图，以便通过 fMRI 的时变相关性导出连接强度（边缘）信号，节点信号是根据 T1 MR 图像计算的。 然后，基于长短期记忆的谱图卷积网络用于处理远程时间信息动。 最后，我们提出预测每个受试者的性别和年龄作为辅助任务，这反过来捕获有用的网络特征并促进主要任务eMCI分类； 我们将此策略称为辅助任务训练。对 294 个训练对象和 74 个测试对象的实验表明，eMCI分类结果达到了 79.7% 的准确率（灵敏度为 86.5%和 73.0% 的特异性）并且优于最先进的方法。值得注意的是，所提出的方法可以进一步扩展到其他连接组学研究，其中图形是通过白质计算的纤维连接或灰质特征。</p><p>传统的 fMRI 诊断方法计算整个时间序列的功能连接矩阵（FC 矩阵），通过将 FC 矩阵重塑为特征向量来生成特征，可以使用 SVM 等分类器进行诊断。 然而，这些方法既没有考虑跨时间序列的血氧水平依赖性 (BOLD) 信号的动态，因此忽略了大脑活动的条件依赖性，也没有通过将 FC 矩阵重塑为向量来保留空间信息。 为了同时保留拓扑和时间信息，研究人员实施了 CNN和 RNN 进行分类。 然而，他们的方法仍然受到 fMRI 信号中噪声的影响，这可能会淹没与神经元活动相关的所需信号。</p><p>大脑连接网络可以用描述大脑区域及其关系的图表来描述。 图卷积网络允许在网络/图结构上实现神经网络。 研究人员通过两种方式将 GCN 用于疾病诊断，即节点分类和图分类。 节点分类将主体视为节点，在预定义的人口统计图上对它们进行分类。 图分类为每个受试者分配一个图，每个大脑区域作为一个节点。 与上述传统方法一样，它们只处理静态网络，不考虑 BOLD 信号的动态特性。</p><p>在这项研究中，我们提出了动态谱图卷积网络 (DSGCNs) 和辅助任务训练，用于使用 fMRI 进行早期 MCI 诊断。 为了解决上述问题，所提出方法的新颖性总结为三个方面：</p><p>（1）图函数连接数据的谱图卷积操作；</p><p> (2) 一个LSTM架构进一步提取与诊断相关的时间信息；</p><p> (3) 使用的两个辅助网络性别和年龄分别作为额外产出，为主要eMCI诊断任务。</p><h4 id="架构图-3"><a href="#架构图-3" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/TF6g0iVluHo0nQn_LHxhgQgq3R-QJ4E6DeoBlFDuBLc.png" alt="image"></p><p>上面是所提出的 DS-GCN 的框架。 左侧部分（A 和 B）演示了动态图是如何形成的。 每个节点上的特征由根据 T1 加权 MR 图像计算的相应 ROI 的体积定义。 时变边缘是根据滑动窗口内 BOLD 信号的相关性计算的。 在定义图之后，使用具有三个完全连接层的基于光谱图卷积的 LSTM (GC-LSTM) 层来分别预测每个患者的状态、性别和年龄。 最后，来自两个结构相同但参数不同的辅助网络（C和E）的特征图被加权并组合成诊断网络（D）的特征图，指导诊断网络的参数训练和优化。</p><p><img src="/2023/07/25/7-2-GNN-For-AD/Z4DPQG9SEJyLwFoOn_Q2USFBxw3MHnEX4w61mYXeQjw.png" alt="image"></p><p>GC-LSTM。 动态图由解剖区域之间的时变连接组成，并且使用长短期记忆 (LSTM) 单元来处理时间信息。 LSTM 已广泛用于处理循环或时间信号，它通过使用隐藏层作为状态来解决长期依赖性问题。 通过用上面介绍的图卷积替换传统 LSTM 中的矩阵乘法运算符，我们提出了一个动态图 LSTM 神经网络。</p><p>包括性别和年龄在内的人口统计信息可以帮助预测 eMCI。 与大多数现有方法不同，我们将它们用作额外输出。 这种辅助任务训练有两个优点。 首先，脑功能信号中含有大量噪声，难以进行适当的特征提取。 相关的辅助任务可以帮助深度学习模型将注意力集中在相关特征上。 性别/年龄可能与 ADNI 数据集中的诊断结果相关性较弱。 因此，简单地将性别和年龄直接添加为额外输入不一定会提高分类性能。</p><h4 id="总结-amp-讨论-3"><a href="#总结-amp-讨论-3" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p>DS-GCN（提议）：训练阶段没有使用性别和年龄预测任务。</p><p>DS-GCN + 人口统计特征（提议）：将性别和年龄作为额外输入添加到最后一个全连接层中。</p><p>DS-GCN + Assistant task training（提议）：注意性别和年龄不是作为额外的输入特征，而是作为输出。</p><p>提出了一种动态图卷积网络，用于分析 fMRI 连通性并将 eMCI 与正常对照进行分类。 此外，为了提高网络稳定性和分类性能，我们提出了一种新的辅助任务训练策略，即同时预测多个人口统计因素，以改进 eMCI 分类。 使用来自 ADNI2 的数据集，我们提出的算法表明可以将 eMCI 从 NC 中分类，准确率为 79.73%。 值得注意的是，我们提出的网络可以扩展到其他连接组学研究。</p><h3 id="7-Graph-convolutional-network-analysis-for-mild-cognitive-impairment-prediction"><a href="#7-Graph-convolutional-network-analysis-for-mild-cognitive-impairment-prediction" class="headerlink" title="7. Graph convolutional network analysis for mild cognitive impairment prediction"></a>7. Graph convolutional network analysis for mild cognitive impairment prediction</h3><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445252378-2cffb291-ecdf-464d-93e5-6ed15486c01f.pdf" target="_blank" rel="noopener">📎Graph convolutional network analysis for mild cognitive impairment prediction.pdf</a></p><p>[148] X. Zhao, F. Zhou, L. Ou-Yang, T. Wang, and B. Lei, “Graph convolutional network analysis for mild cognitive impairment prediction” inProc. IEEE Int. Symp. Biomed. Imaging (ISBI), 2019, pp. 1598–1601.</p><p>Zhao et al. [148] developed a GCN based method to predictMCI (EMCI vc NC, LMCI vs NC and LMCI vs EMCI) fromrs-fMRI. They constructed the MCI-graph using both imagingdata extracted from rsfMRI and non-imaging data includinggender and collection device information. They classified thenodes in the generated MCI-graph using GCN and Cheby-GCN and compared the results with a Ridge, a random forestclassifier and a multilayer perceptron, and demonstrated a highperformance for Cheby-GCN over those methods.</p><p>Zhao等人[148]开发了一种基于GCN的方法，用于从fMRI预测MCI（EMCI vc NC、LMCI vs NC和LMCI vs EMCI）。他们使用从rsfMRI中提取的成像数据和非成像数据（包括扫描仪和采集设备信息）构建了MCI图。他们使用GCN和Cheby-GCN对生成的MCI图中的节点进行了分类，并将结果与Ridge、随机森林分类器和多层感知器进行了比较，并证明了Cheby-GSN在这些方法上的高性能。</p><h4 id="摘要-4"><a href="#摘要-4" class="headerlink" title="摘要"></a>摘要</h4><p>轻度认知障碍（MCI）是阿尔茨海默病（AD）的早期阶段，是一种神经退行性疾病。功能连接网络（FCN）为分析大脑功能区域的连接提供了一种有效的方法。然而，大多数方法只考虑了神经成像信息，关注群体关系而不考虑受试者的个人特征，忽视了人口统计学关系。为了解决这个问题，在本文中，我们介绍了一种基于图卷积网络（GCN）的新方法，该方法将图像和其他信息结合起来用于MCI预测任务。所提出的模型能够同时代表潜在人群的个体特征和受试者之间的数据关联。具体来说，我们使用不同的收集设备和性别信息来构建称为MCI图的图，并修改卷积神经网络（CNN）来构建用于MCI预测的GCN。实验结果表明，我们提出的方法具有显著的预测性能。</p><p>轻度认知障碍（MCI）在5年内每年的转化率高达10%-15%。因此，一种用于MCI早期诊断的有效预测模型构建已成为热门话题。对于MCI识别，基于静息状态功能磁共振成像（rs fMRI）的功能连接网络（FCN）已被广泛使用。FCN被定义为解剖分离的大脑区域中神经元激活的时间依赖模式[2]。</p><p>我们使用FCN来探索丰富的大脑功能连接信息[4]作为每个受试者的特征。然而，在之前的研究中，研究人员[5]发现，不同采集设备的MCI识别精度存在差异，其发生与年龄和性别有关。同时，图论提供了解决上述问题的有效方法[6]。因此，我们将所有对象表示为稀疏图，其中顶点表示每个对象的FCN特征，边缘编码上述信息（例如，性别和收集设备）。</p><p>EMCI—LMCI—NC：数据预处理软件-GRETNA[11]软件包执行。</p><p>首先，我们将DICOM转换为NIFTI。然后移动前20个时间点，切片计时和重新排列。我们使用DARTEL进行空间归一化和去卷曲。下一步是干扰信号的回归，并使用时间滤波（0.01Hz-0.08Hz）。最后，使用基于90个ROI的成对皮尔逊相关系数计算FCN，该系数使用自动解剖标记（AAL）模板。</p><h4 id="架构图-4"><a href="#架构图-4" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/DwX9I_4bNyypu9D0XgMHeP2GVUrhRrfUv4RAArnRxzY.png" alt="image"></p><h4 id="总结-amp-讨论-4"><a href="#总结-amp-讨论-4" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/cfKnqQufTDHcWm1MH59pPEv6gJrL0aRaFiCM_QX7R_k.png" alt="image"></p><p>在本文中，我们提出了一种基于Cheby GCN的有效方法，该方法利用图像和非图像信息进行MCI预测。具体来说，我们使用不同的收集设备和性别信息构建MCI图。我们的方法提高了不同级别MCI的可分辨性。进行了大量实验以验证所提出的方法。未来，我们将研究更复杂的网络结构，并考虑基于这些网络的特征融合。我们还将尝试将我们的方法应用于临床应用。</p><h3 id="8-Cortical-graph-neural-network-for-ad-and-mci-diagnosis-and-transfer-learning-across-populations"><a href="#8-Cortical-graph-neural-network-for-ad-and-mci-diagnosis-and-transfer-learning-across-populations" class="headerlink" title="8. Cortical graph neural network for ad and mci diagnosis and transfer learning across populations"></a>8. Cortical graph neural network for ad and mci diagnosis and transfer learning across populations</h3><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445252419-7508c67d-d981-4952-881d-6eab4a488886.pdf" target="_blank" rel="noopener">📎Cortical graph neural network for ad and mci diagnosis and transfer learning across populations.pdf</a></p><p>[149] C.-Y. Wee, C. Liu, A. Lee, J. S. Poh, H. Ji, A. Qiu, A. D. N. Initiativeet al., “Cortical graph neural network for ad and mci diagnosis and transfer learning across populations,”NeuroImage: Clinical, vol. 23, p.101929, 2019.</p><p>To reduce the burden of creating a reliable population-specific classifier from scratch, generalization of classifiers toother datasets or populations, especially those with a limitedsample size, is critical. Wee et al. [149] employed a spectralgraph CNN that incorporates the cortical thickness and ge-ometry from MRI scans to identify AD. To demonstrate thegeneralisation and the feasibility to transfer classifiers learnedfrom one population to another, the authors trained on a sizablecaucasian dataset from the ADNI cohort [145], and evaluatehow well the classifier can predict the diagnosis of an Asianpopulation. To transfer the spectral graph-CNN model, themodel that worked best on the ADNI cohort’s testing set wasfine-tuned on the training set of the Asian population. Theperformance of the fine-tuned model was then assessed usingthe testing set of the Asian cohort.</p><p>为了减轻从头开始创建可靠的特定于群体的分类器的负担，将分类器推广到更大的数据集或群体，尤其是样本大小有限的数据集和群体，至关重要。Wee等人[149]使用了一种光谱图CNN，它结合了来自MRI扫描的皮质厚度和几何测量来识别AD。为了证明从一个人群中学习到的分类器转移到另一个人群的通用性和可行性，作者们在ADNI队列中的一个可扩展的高加索数据集上进行了训练[145]，并评估分类器如何预测亚洲种群的诊断。为了转移光谱图CNN模型，在ADNI队列测试集上效果最好的模型在亚洲人群的训练集上进行了微调。然后使用亚洲队列的测试集评估微调模型的性能。</p><h4 id="摘要-5"><a href="#摘要-5" class="headerlink" title="摘要"></a>摘要</h4><p>将机器学习与神经成像数据相结合，对于轻度认知障碍（MCI）和阿尔茨海默病（AD）的早期诊断具有巨大潜力。然而，目前尚不清楚在一个群体中构建的分类器如何预测其他群体的MCI/AD诊断。本研究旨在采用结合皮质厚度和几何结构的频谱图卷积神经网络，根据ADNI-2队列的3089 T1加权MRI数据识别MCI和AD，并评估其在ADNI-1队列（n=3602）和亚洲队列（n=347）中预测AD的可行性。对于ADNI-2队列，CNN图表显示对照组（CN）与AD的分类准确率为85.8%，早期MCI（EMCI）与AD之间的分类准确度为79.2%，其次是CN vs LMCI（69.3%），LMCI与AD（65.2%），EMCI与LMCI（60.9%），CN与EMCI（51.8%）。我们展示了现有深度学习方法中图形CNN的鲁棒性，如基于欧氏域的多层网络和皮层厚度的1D CNN，以及ADNI-2队列的T1加权MRI图像上的2D和3D CNN。图神经网络还预测了EMCI向AD的转化率为75%，LMCI向AD的转换率为92%。调整后的曲线图CNN进一步提供了ADNI-1队列中有前景的CN与AD分类准确率，分别为89.4%和&gt;90%。我们的研究证明了将AD/MCI分类器从一个群体转移到另一个群体的可行性。值得注意的是，在CNN中加入皮质几何结构有可能提高分类性能。</p><p>我们训练了ADNI-2数据集的CNN肿瘤厚度谱图，该数据集主要由高加索人群组成，然后转移该模型来预测ADNI-1队列和亚洲队列的AD和MCI诊断。与使用ADNI数据集子集的现有研究不同（例如，（Korolevet等人，2017）），我们使用ADNI-2队列（n=3089）的所有可用MRI扫描来训练用于痴呆分类的鲁棒频谱图CNN。然后，我们使用转移学习来评估基于CNN的光谱图AD/MCI分类器的通用性，该分类器在可大小化的高加索数据集上训练为ADNI-1队列的完整数据集和全亚洲数据集。因此，我们预计从ADNI-2数据集获得的分类器可以为ADNI-1和亚洲人群实现类似的分类精度。</p><h4 id="架构图-5"><a href="#架构图-5" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/uMz-lVhWsjDskL2DAqaQex2ietOjWXjHze00shFQzbg.png" alt="image"></p><h4 id="总结-amp-讨论-5"><a href="#总结-amp-讨论-5" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p>在本文中，我们采用了基于CNN的光谱图框架，该框架利用皮质厚度及其基础几何信息进行AD和MCI诊断以及MCI到AD转换。我们使用公开可用的ADNI-2队列中的3089次MRI扫描评估了我们框架的有效性，并展示了最先进的痴呆分类性能。光谱图CNN肿瘤厚度优于基于体素的CNN模型。此外，我们的光谱图CNN能够在样本大小不平衡的情况下实现两类的相对平衡预测。我们通过在两个类中使用平衡样本训练小批量，并使用小样本量对类进行过采样，并基于强调主要类和少数类的平衡性能的可调整边缘测量平均值确定最佳网络参数，实现了这一点。光谱图CNN还实现了MCI到AD转换的高预测精度。当将在ADNI-2共短序列上训练的光谱图CNN模型转移到亚洲队列时，与直接在亚洲队列上训练的相同模型相比，光谱图CNN始终实现了更好的分类性能。此外，对MCI受试者进行微调的训练频谱图CNN模型能够准确地从亚洲队列中识别AD受试者，这表明了将现有稳健分类器应用于新人群MCI和AD的早期诊断和预测的可行性。本研究中提出的光谱图CNN模型是相对通用的，可以应用于早期诊断大脑疾病的更多大脑成像数据。当将皮层厚度的光谱图与多模态大脑图像数据的其他分类方法相结合时，可以获得进一步的改进。</p><h3 id="9-Graph-convolutional-neural-networks-for-alzheimer’s-disease-classification"><a href="#9-Graph-convolutional-neural-networks-for-alzheimer’s-disease-classification" class="headerlink" title="9. Graph convolutional neural networks for alzheimer’s disease classification"></a>9. Graph convolutional neural networks for alzheimer’s disease classification</h3><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445252469-c48d1e16-e39a-498f-89ad-86b71665b364.pdf" target="_blank" rel="noopener">📎Graph convolutional neural networks for alzheimer’s disease classification.pdf</a></p><p>[150] T.-A. Song, S. R. Chowdhury, F. Yang, H. Jacobs, G. El Fakhri, Q. Li,K. Johnson, and J. Dutta, “Graph convolutional neural networks for alzheimer’s disease classification,” inProc. IEEE Int. Symp. Biomed.Imaging (ISBI), 2019, pp. 414–417.</p><p>Song et al. [150] built a structural connectivity graph fromDTI data from the ADNI imaging dataset and implementeda multi-class GCN classifier for the four class classificationof subjects on the AD spectrum. The receiver operatingcharacteristic (ROC) curve was compared between GCN andSVM classifiers for each class and demonstrated the capabilityof GCN over SVM (which relies on a predefined set of inputfeatures) for AD classification.</p><p>Song等人[150]从ADNI成像数据集的DTI数据构建了结构连通图，并为AD频谱上的四类受试者分类实现了多类GCN分类器。在GCN和SVM分类器之间比较了每个类别的接收器操作特性（ROC）曲线，并证明了GCN优于SVM（依赖于预定义的一组输入特征）的AD分类能力。</p><h4 id="摘要-6"><a href="#摘要-6" class="headerlink" title="摘要"></a>摘要</h4><p>图形卷积神经网络（GCNNs）旨在扩展卷积神经网络的数据表示和分类能力，该网络对在规则欧几里得域上定义的信号（例如图像和音频信号）非常有效，从而扩展到在欧几里得域定义的不规则图形结构数据。使我们能够将大脑作为一个复杂系统进行研究的图论工具在大脑连接性研究中具有重要意义。特别是，在阿尔茨海默病（AD）这一与网络功能障碍相关的神经退行性疾病中，基于图的工具对于疾病分类和分期至关重要。在这里，我们实现并测试了一个多类GCNN分类器，用于将AD频谱上的受试者基于网络分类为四类：认知正常、早期轻度认知损害、晚期轻度认知损害和AD。我们使用从扩散张量成像数据获得的结构连通图来训练和验证网络。使用接收器操作特征曲线，我们证明了GCNN分类器优于支持向量机分类器，因为它依赖于疾病类别。我们的研究结果表明，随着疾病从CN发展到AD，两种方法之间的性能差距越来越大。因此，我们证明GCNN是AD谱上受试者分期和分类的竞争工具。</p><h4 id="架构图-6"><a href="#架构图-6" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/Qxcr8KbUzUQJOzI5P4CkF6598ePWHESdU6MKa4av2SU.png" alt="image"></p><p><img src="/2023/07/25/7-2-GNN-For-AD/tqd7gXGNa8-1_9wfbsHgLpv2ULLTANeBsuLC_thP4O4.png" alt="image"></p><p>样本大脑图像（横截面图）：</p><p>（A）高分辨率T1加权解剖MR扫描</p><p>（B）扩散MR扫描</p><p>（C）原生（FreeSurfer）空间中的解剖模板</p><p>（D）具有112个解剖区域的FreeSurfer图谱</p><p>（E）通过束描记术重建的纤维束</p><p>（F）通过纤维计数计算的相邻矩阵</p><h4 id="总结-amp-讨论-6"><a href="#总结-amp-讨论-6" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p>我们已经实现并验证了用于AD频谱上的对象分类的多类GCNN分类器。我们使用基于DTI的结构连接图来训练和验证网络。ROC分析结果表明，GCNN分类器在依赖于疾病类别的边缘方面优于SVM。我们的发现表明，两种方法之间的性能差距随着疾病从CN发展到AD而增加。从技术角度来看，我们的结果很重要，因为它阐明了GCNN分类器在低样本量设置下产生高性能的潜力。作为未来的工作，我们将把这个分类器扩展到更大的数据集，测试替代损失函数，并测试各种GCNN架构和实现。</p><h3 id="10-Predicting-alzheimer’s-disease-by-hierarchical-graph-convolution-from-positron-emission-tomography-imaging"><a href="#10-Predicting-alzheimer’s-disease-by-hierarchical-graph-convolution-from-positron-emission-tomography-imaging" class="headerlink" title="10. Predicting alzheimer’s disease by hierarchical graph convolution from positron emission tomography imaging"></a>10. Predicting alzheimer’s disease by hierarchical graph convolution from positron emission tomography imaging</h3><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445252485-291939d9-9828-4df8-8113-5c2aeef5b2e7.pdf" target="_blank" rel="noopener">📎Predicting alzheimer’s disease by hierarchical graph convolution.pdf</a></p><p>[151] J. Guo, W. Qiu, X. Li, X. Zhao, N. Guo, and Q. Li, “Predicting alzheimer’s disease by hierarchical graph convolution from positron emission tomography imaging,” inProc. IEEE Int. Conf. Big Data,2019, pp. 5359–5363.</p><p>Guo et al. [151] constructed a graph from the ROI of eachsubject’s PET images from the ADNI2dataset [152], andproposed a PETNet model based on GCNs for EMCI, LMCI or NC prediction. The proposed method is computationallyinexpensive and more flexible in comparison to voxel-levelmodeling.</p><p>Guo等人[151]从ADNI2数据集[152]中每个受试者的PET图像的ROI构建了一个图，并提出了基于EMCI、LMCI的GCN或NC预测的PETNet模型。与体素级建模相比，所提出的方法计算成本低且更灵活。</p><h4 id="摘要-7"><a href="#摘要-7" class="headerlink" title="摘要"></a>摘要</h4><p>基于图像的阿尔茨海默病（AD）的早期诊断已经成为一种有效的方法，特别是通过使用正电子发射地形图（PET）等核医学成像技术。在各种文献中，已经发现PET图像可以更好地建模为在网络（非欧几里德）结构上定义的信号（例如氟倍他吡的摄取），该网络结构由其病理进展和代谢连通性的基本图形模式控制。为了有效地将深度学习框架应用于PET图像分析，以克服其对欧几里得网格的限制，我们开发了一种基于广义、基于图的CNN架构（PETNet）的3D PET图像表示和分析解决方案，该架构分析了定义在按组推断的图形结构上的PET信号。PETNet中的计算是在非欧几里得图（网络）域中定义的，因为它通过对图上的光谱滤波信号进行卷积运算和基于分层图聚类的合并运算来执行特征提取，这表明了与深度学习和其他基于机器学习的方法相比，改进的性能。</p><p>通过将从感兴趣区域（ROI）提取的PET数据定义为图节点上的信号，我们可以对图执行信号滤波和表示学习，类似于欧几里得空间中的信号滤波和特征提取（例如通过卷积滤波器）。受到Defferrard等人[18]提出的算法架构的启发，该架构从给定的图中学习局部化的光谱滤波器，并通过切比雪夫多项式逼近执行图形滤波，在这项工作中，我们开发并实现了PET图像分析框架PETNet，学习基于图形的特征和有效的分类系统，该系统可以对阿尔茨海默病进行早期诊断，即轻度认知障碍（MCI）的预测和分期。</p><h4 id="架构图-7"><a href="#架构图-7" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/hOLU-hBj427utwvsrb2hU5beSs5xhph5xzshboBoa6Y.png" alt="image"></p><p>PETNet的算法管道：</p><p>（a） 输入PET图像</p><p>（b） 提取ROI上的平均信号</p><p>（c） 在每个ROI（y轴）中跨所有对象（x轴）的提取信号的聚集</p><p>（d） 从成组信号推断出的图及其分层聚类</p><p>（e） 图卷积网络的结构，其中提取的信号和推断的图都用作输入</p><p>PETNet由四个步骤组成：包括3D PET图像（a）到基于ROI的信号转换（b），图形推断和分层聚类（d），以及用于信号到标签预测的图形卷积网络（e）</p><h4 id="总结-amp-讨论-7"><a href="#总结-amp-讨论-7" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p>PETNet的初步结果表明，与体素级建模相比，基于基于图的表示的深度学习可以为医学图像分析提供更灵活、计算成本更低的方法。这项工作的一个重要前提是，基于生物学和解剖学证据，成像数据可以更好地在可学习的图形上建模，这些证据表明，大脑物理/几何距离较远的区域的结构和功能财产可以持续相关，包括淀粉样蛋白负荷、皮层厚度和认知角色。这些财产是证据较少的自然图像，其中像素值的分布由本地控制。因此，进一步发展基于图形的分析（包括当前的PETNet框架）的关键问题是图形构造/推理，这是神经图像和医学图像分析中一个重要的、讨论得很好但仍然没有定论的话题。一种特定的收益方法是将图形推理过程纳入分类框架，以学习优化的图形定义。其他方法包括度量学习（例如，不同图形推理方法之间的权重）和多重学习也可以适用。</p><h3 id="11-Attention-guided-deep-graph-neural-network-for-longitudinal-alzheimer’s-disease-analysis"><a href="#11-Attention-guided-deep-graph-neural-network-for-longitudinal-alzheimer’s-disease-analysis" class="headerlink" title="11. Attention-guided deep graph neural network for longitudinal alzheimer’s disease analysis"></a>11. Attention-guided deep graph neural network for longitudinal alzheimer’s disease analysis</h3><p>DOI: 10.1007/978-3-030-59728-3_38 (421页)</p><p>[142] J. Ma, X. Zhu, D. Yang, J. Chen, and G. Wu, “Attention-guided deep graph neural network for longitudinal alzheimer’s disease analysis,” inProc. Med. Image Comput. Comput.-Assist. Interv. (MICCAI), 2020,pp. 387–396.</p><p>Ma et al. [142] proposed an Attention-Guided Deep GraphNeural (AGDGN) network model to derive both structuraland temporal graph features from the ADNI dataset [143].This dataset contains four classes, however due to a shortageof data to train this model, they combined CN and SMC toform the CN group, and MCI and AD to form the AD group.This resulted in a two-class classification problem. They usedan attention-guided random walk (AGRW) process to extractnoise-robust graph embeddings. Their results indicated that theidentified AD characteristics detected by the proposed modelaligned with those reported by clinical studies.</p><p>Ma等人[142]提出了一种注意力引导的深度图形神经（AGDGN）网络模型，以从ADNI数据集[143]中导出结构和时间图形特征。该数据集包含四个类，但由于训练该模型的数据不足，他们将CN和SMC组合成CN组，MCI和AD组成AD组。这导致了两类分类问题。他们使用注意力引导随机游走（AGRW）过程来提取鲁棒的图嵌入。他们的结果表明，所提出的模型检测到的AD特征与临床研究报告的特征一致。</p><h4 id="摘要-8"><a href="#摘要-8" class="headerlink" title="摘要"></a>摘要</h4><p>阿尔茨海默病 (AD) 是老年人痴呆症的主要原因。 由于 AD 不太可能可逆且尚无治愈方法，因此监测其进展对于调整患者的治疗计划以延缓其恶化至关重要。 计算机辅助纵向 AD 数据分析有助于此类任务，可用于评估疾病状态，识别有区别的大脑区域，并揭示疾病的进展。 然而，大多数现有方法存在两个主要问题：i）从整个图中全局提取图特征，这对噪声非常敏感； ii）他们在处理动态图方面有困难，而大脑网络是高度可变的，因为它们因人而异或随时间或疾病而变化。 为了解决这些问题，本文提出了一种新的注意力引导深度图神经网络 (AGDGN)，它利用注意力引导随机游走 (AGRW) 模块从大脑网络中提取结构图特征。 由于AGRW在随机游走的每一步只需要邻域节点周围的局部信息，因此它对图噪声具有鲁棒性并且在处理动态图时具有灵活性。 此外，全局注意力机制被集成到序列处理模块中。 两种attention机制联合训练从结构域和时间域揭示信息最丰富的大脑区域以进行 AD 分析。 对阿尔茨海默氏病神经影像学倡议 (ADNI) 数据集的实验结果和分析证明了所提出方法的有效性和效率。</p><p>主要贡献：</p><ol><li>提出了一种用于纵向阿尔茨海默病分析的新型 AGDGN 模型，该模型利用两种注意机制来揭示图形级别最相关的大脑区域和序列级别的基本时间点。 所提的 AGDGN 旨在尊重人口中的个体差异和网络随时间的变化。 此外，它可以灵活地改变序列长度。</li><li>提出了一种新颖的注意力引导随机游走（AGRW）过程来提取输入图中的结构信息。</li><li>全局注意力机制集成到所提出的模型中，可以突出显示与图序列诊断标签相关的重要时间点。</li><li>ADNI 数据集上的实验结果证明了所提出模型的有效性。</li></ol><h4 id="架构图-8"><a href="#架构图-8" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/rYqQZxf6KbJzqz2Ee2zPE3kAwkjXSIhrWW-OSDV_1Gc.png" alt="image"></p><p>AGDGN = AGRW + Sequence processing module</p><p>注意引导随机游走 (AGRW) 模块旨在主动突出大脑中信息量最大的区域，并指导随机游走过程的节点选择过程，以从图中提取结构信息。</p><p>序列处理模块遵循最新的具有全局注意力机制的序列处理模型。该模块旨在处理从同一主题收集的纵向AD数据，并揭示诊断序列中的基本时间点。 该模块的输入是 (AGRW) 模块的输出，被认为是从图结构和节点属性中学习到的图表示。 LSTM 还用于汇总从序列中看到的纵向数据。 注意力机制是跟随全局的。</p><p><img src="/2023/07/25/7-2-GNN-For-AD/xGVYHuKcuHNZ_0Dmzky8AOsT87BldPvL2QjavyA94d4.png" alt="image"></p><p>左图显示了每个节点上注意力的实际值。 右图显示了对大脑的关注。 节点大小代表注意力值。 节点颜色代表节点 ID。 （在线彩图）</p><p><img src="/2023/07/25/7-2-GNN-For-AD/MCLupr1QniGUTDSPx_wih56M7JGcRweTw9UoN__XuXM.png" alt="image"></p><p>最后 30 个步骤中每个步骤中前 10 个节点的节点频率。 左图显示实际频率值。 右图显示了这些节点在大脑中的位置。 节点大小表示频率值。 节点颜色代表节点 ID。 （在线彩图）</p><h4 id="总结-amp-讨论-8"><a href="#总结-amp-讨论-8" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p>在本文中，提出了一种用于纵向阿尔茨海默病分析的新型注意力引导深度图神经 (AGDGN) 网络模型。 两种注意机制被集成并联合训练以提取结构和时间图特征。 通过利用所提出的注意力引导随机游走 (AGRW) 过程，所提出的模型可以处理人群中大脑网络的个体差异，向诊断标签显示信息量最大的区域，并提取更多噪声鲁棒图嵌入。 对实验结果的分析表明，所提出的模型成功地识别了临床研究报告的 AD 特征。 尽管本文只关注“sequence to one label”问题，但值得一提的是，所提出的模型可以轻松扩展到“sequence to sequence”设置。 将来当相应的数据准备好时，我们将在此设置中测试所提出的模型。</p><h3 id="12-Multi-scale-enhanced-graph-convolutional-network-for-early-mild-cognitive-impairment-detection"><a href="#12-Multi-scale-enhanced-graph-convolutional-network-for-early-mild-cognitive-impairment-detection" class="headerlink" title="12. Multi-scale enhanced graph convolutional network for early mild cognitive impairment detection"></a>12. Multi-scale enhanced graph convolutional network for early mild cognitive impairment detection</h3><p>DOI: 10.1007/978-3-030-59728-3_38 （265页）</p><p>[147] S. Yu, S. Wang, X. Xiao, J. Cao, G. Yue, D. Liu, T. Wang, Y. Xu, andB. Lei, “Multi-scale enhanced graph convolutional network for early mild cognitive impairment detection,” inProc. Med. Image Comput.Comput.-Assist. Interv. (MICCAI), 2020, pp. 228–237.</p><p>Yu et al. [147] used a multi-scale enhanced GCN (MSE-GCN) and applied it to a population graph which was built bycombining imaging data(rs-fMRI and diffusion tensor imaging(DTI)) and demographic relationships (e.g.gender and age)to predict EMCI. This resulted in better performance incomparison to the prior methods of Zhao et al. [148] and Xinget al. [58].</p><p>Yu等人[147]使用了多尺度增强GCN（MSE-GCN），并将其应用于人口图，该图通过结合成像数据（rs fMRI和扩散张量成像（DTI））和人口关系（如性别和年龄）来预测EMCI。这与Zhao等人[148]和Xing等人[58]的现有方法相比，性能更好。</p><h4 id="摘要-9"><a href="#摘要-9" class="headerlink" title="摘要"></a>摘要</h4><p>早期轻度认知障碍 (EMCI) 是 MCI 的早期阶段，可以通过大脑连接网络检测到。 为了检测 EMCI，我们在本文中设计了一个基于多尺度增强 GCN (MSE-GCN) 的新框架，它融合了分别来自静息态功能磁共振成像和扩散张量成像的功能和结构信息。 然后，连接网络中的功能和结构信息都通过局部加权聚类系数（LWCC）进行整合，这些系数被连接成特征向量来表示人口图的顶点。 同时，将受试者的性别和年龄信息与多模态神经影像学特征相结合，构建稀疏图。 然后，我们通过随机游走嵌入设计了多个具有不同输入的并行 GCN 层，这可以从 GCN 中的嵌入中识别出内在的 MCI 图信息。 最后，我们将全连接层中所有 GCN 层的输出连接起来进行检测。 所提出的方法能够同时表示来自潜在患者的受试者之间的个体特征和信息关联。 在ADNI 数据集的实验结果表明，与所有竞争方法相比，我们提出的方法实现了令人印象深刻的 EMCI 识别性能。</p><p>多模态融合可以发现互补信息，有利于提高特征表示和模型检测性能。</p><p>在本文中，我们提出了一种 MSE-GCN 来探索受试者之间的个体差异和信息关联，以改进 EMCI 检测。 通过数据融合探索 FC 和 SC 的互补性，以提高单个模型的性能。 我们通过随机游走嵌入设计具有不同输入的多个并行 GCN 层，用于 MCI 图分析。 我们提出的 MSE-GCN 模型能够通过利用图像和种群表型信息来学习丰富的特征。 我们验证了模型在ADNI 数据集上的有效性。 我们提出的模型实现了非常有前途的 EMCI 检测性能并且优于相关算法。</p><h4 id="架构图-9"><a href="#架构图-9" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/FM-7nHyA-Tgo7XuvQgob8ioEOYtVyIqesTHBrilBdKc.png" alt="image"></p><p>我们首先使用非重叠滑动窗口将 R-fMRI 分成几个子系列，并通过计算对子系列的 Pearson 相关 (PC) 系数来获得动态 FC。 同时，每对脑区之间的白质纤维束连接被视为一个结构网络。 然后，我们提取 FC 和 SC 的 LWCC，并将其连接为一个特征向量来表示人口图的顶点。 图的边缘代表主题之间的相似性，并包含非图像信息。 最后，MSE-GCN 用于 MCI 检测。</p><p>处理软件：GRETNA+DARTEL(R-fMRI)，PANDA(DTI)</p><p>大脑的不同部分负责不同的任务，并非所有区域都与 EMCI 密切相关。 因此，我们尝试利用我们提出的方法来搜索这些相关的 ROI，以了解大脑异常。 我们依次屏蔽一个大脑区域，然后得到90个检测结果。 根据相应的检测性能，我们分析相应的ROI对疾病的影响。 图 3 显示了使用我们提出的方法的前 10 个大脑区域和不同任务的功能连接。 此外，我们可视化不同阶段患者大脑区域之间的联系。 图 4 显示了我们方法的结构连接，这表明大脑区域的结构连接在不同阶段的患者中是不同的。</p><p><img src="/2023/07/25/7-2-GNN-For-AD/OP7uU0ikd5NpvTDrPBx-S7UuDMXk-jj57rFbMPdY22Y.png" alt="image"></p><p><img src="/2023/07/25/7-2-GNN-For-AD/WorB7TRGhVVeHn81gNgQbxwlN2DoI9c8WLPUJzs3GW8.png" alt="image"></p><h4 id="总结-amp-讨论-9"><a href="#总结-amp-讨论-9" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p>在这项研究中，我们提出了一种基于 EMS-GCN 的新型 EMCI 诊断框架。 具体来说，我们从 FC 和 SC 中提取 LWCC。 通过随机游走嵌入增强的 MS-GCN 模型用于 EMCI 检测。 结果表明，增强感受野有利于提高检测性能。 我们的方法在 ADNI 数据集上取得了良好的结果，可以为 EMCI 的早期临床诊断提供有效的参考。 未来，我们将考虑更多样化的方法来构建大脑网络并设计更有效的网络模型（例如，图形生成对抗网络）。</p><h3 id="13-Identification-of-early-mild-cognitive-impairment-using-multi-modal-data-and-graph-convolutional-networks"><a href="#13-Identification-of-early-mild-cognitive-impairment-using-multi-modal-data-and-graph-convolutional-networks" class="headerlink" title="13. Identification of early mild cognitive impairment using multi-modal data and graph convolutional networks"></a>13. Identification of early mild cognitive impairment using multi-modal data and graph convolutional networks</h3><p><a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-020-3437-6" target="_blank" rel="noopener">https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-020-3437-6</a></p><p>[144] J. Liu, G. Tan, W. Lan, and J. Wang, “Identification of early mild cognitive impairment using multi-modal data and graph convolutional networks,”BMC Bioinform., vol. 21, no. 6, pp. 1–12, 2020.</p><p>Liu et al. [144] processed multi-modal data, MRIand rs-fMRI, to identify EMCI. First, feature representation and multi-task feature selection are applied to each input.Then, a graph was developed using imaging and non-imaging(phenotypic measures of each subject) data. Finally, a GCNwas used to perform the EMCI identification task from theADNI dataset [145].</p><p>Liu等人[144]处理了多模态数据MRI和RFMRI，以识别EMCI。首先，将特征表示和多任务特征选择应用于每个输入。然后，使用成像和非成像（每个受试者的表型测量）数据绘制图。最后，使用GCN从ADNI数据集执行EMCI识别任务[145]。</p><h4 id="摘要-10"><a href="#摘要-10" class="headerlink" title="摘要"></a>摘要</h4><p>早期轻度认知障碍 (EMCI) 是阿尔茨海默病 (AD) 的早期阶段，与大脑结构和功能变化有关，但其识别仍然是一项具有挑战性的任务。最近的研究表明，通过结合多种结构和功能特征（例如灰质体积和最短路径长度），有望提高 EMCI 识别的性能。然而，提取哪些特征以及如何组合多个特征来提高EMCI识别性能一直是一个具有挑战性的问题。为了解决这个问题，在本研究中，我们提出了一种使用多模态数据和图卷积网络 (GCN) 的新 EMCI 识别框架。首先，我们基于自动解剖标记 (AAL) 图集分别从每个受试者的 T1w MRI 和 rs-fMRI 数据中提取灰质体积和每个大脑区域的最短路径长度作为特征表示。然后，为了获得更有利于识别EMCI的特征，应用了一种通用的多任务特征选择方法。之后，我们使用每个受试者的成像和非成像表型测量构建一个未完全标记的受试者图。最后，采用 GCN 模型执行 EMCI 识别任务。</p><p>由于磁共振成像（MRI）可以在体内无创地测量与脑功能障碍发展相关的脑结构和功能变化，近年来被广泛应用于脑功能障碍的研究[3]，如AD/MCI[4, 5] ]、精神分裂症 [6、7] 和自闭症 [8]。因此，MRI 可以提供可用于诊断此类疾病的表型。 MRI 分为两大类：结构 MRI（例如 T1 MRI 和 T2 MRI）和功能 MRI（例如 rs-fMRI 和 ts-fMRI）。大脑结构通常使用结构 MRI 测量，它可以提供灰质和白质中相对高清的大脑结构。衡量大脑结构的指标有很多，其中大部分已广泛应用于MCI识别研究，如灰质体积、皮质厚度、纹理特性等[9-12]。大脑功能通常使用功能性 MRI 测量，它可以提供由神经元活动引起的血液动力学变化。大脑区域之间的功能连通性是衡量大脑功能的常用方法。此外，基于大脑区域和大脑区域之间功能连接的大脑网络已广泛用于各种大脑疾病研究中的特征表示。近年来，基于图论的脑功能分析在探索脑功能障碍的功能障碍方面显示出强大的作用，并被广泛用于MCI识别。</p><h4 id="架构图-10"><a href="#架构图-10" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/LqtRZsbWNXMAMgbXjyQHFGa3LfYU-M1rCtuxxTPUsTc.png" alt="image"></p><p>在本研究中，我们提出了一种使用多模态数据和图卷积网络的新 EMCI 识别框架，表示为 GCN-EMCI。首先，我们提取 GMV 和 SPL基于自动解剖标记 (AAL) 图集 [33] 的每个大脑区域分别作为每个受试者的 T1w MRI 和 rs-fMRI 数据的特征表示。然后，为了获得更有利于识别EMCI的特征，应用了一种通用的多任务特征选择方法。之后，我们使用每个受试者的成像和非成像表型测量构建一个未完全标记的受试者图。最后，采用最近的 GCN 模型来执行 EMCI 识别任务。</p><h4 id="总结-amp-讨论-10"><a href="#总结-amp-讨论-10" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p>在这项研究中，我们提出了一种使用多模态数据和图卷积网络的新 EMCI 识别方法。首先，我们对每个受试者的 T1w MRI 和 rs-fMRI 数据进行图像预处理和特征表示。然后，为了获得更有利于识别EMCI的特征，采用通用的多任务特征选择方法。之后，我们使用每个受试者的成像表型测量和非成像表型测量构建了一个受试者图。最后，应用 GCN 模型执行 EMCI 识别任务。来自 ADNI 数据库的 210 名受试者的实验结果表明，我们提出的框架对于 EMCI 识别是有效的。该方法为用于计算机辅助识别 EMCI 的判别成像标记铺平了道路。</p><h3 id="14-Edge-variational-graph-convolutional-networks-for-uncertainty-aware-disease-prediction"><a href="#14-Edge-variational-graph-convolutional-networks-for-uncertainty-aware-disease-prediction" class="headerlink" title="14. Edge-variational graph convolutional networks for uncertainty-aware disease prediction"></a>14. Edge-variational graph convolutional networks for uncertainty-aware disease prediction</h3><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445252862-60ae43b9-5c74-4a31-b507-c67b0d90456d.pdf" target="_blank" rel="noopener">📎Edge-variational Graph Convolutional Networks.pdf</a></p><p>[31] Y. Huang and A. C. Chung, “Edge-variational graph convolutional networks for uncertainty-aware disease prediction,” inProc. Med.Image Comput. Comput.-Assist. Interv. (MICCAI), 2020, pp. 562–572.</p><p>Huang et al. [31] applied their edge-variational GCN (EV-GCN) method to the ADNI dataset for AD classification (thedata was prepared in the same manner as Parisot [98]). Inaddition, they applied their method on TADPOLE [146] whichis a subset of ADNI for classifying subjects into cognitivenormal, MCI, and AD. For TADPOLE, the authors constructeda graph by using the segmentation features inferred fromMRI and PET data, phenotypic data, APOE and FDG-PETbiomarkers. Their results on both datasets showed a highperformance in comparison to Parisot [98] and InceptionGCN [93].</p><p>Huang等人[31]将其边缘变分GCN（EV-GCN）方法应用于AD分类的ADNI数据集（该数据以与Parisot[98]相同的方式制备）。此外，他们将他们的方法应用于TADPOLE[146]，TADPOLE是ADNI的一个子集，用于将受试者分类为认知正常、MCI和AD。对于TADPOLE，作者通过使用从MRI和PET数据、表型数据、APOE和FDG PET生物标志物推断的分割特征构建了图。与Parisot [98]和InceptionGCN [93]相比，他们在两个数据集上的结果都显示出较高的性能。</p><h4 id="摘要-11"><a href="#摘要-11" class="headerlink" title="摘要"></a>摘要</h4><p>人们越来越需要计算模型来补充利用不同模式的数据，同时研究受试者之间的关联，以进行基于人群的疾病分析。尽管卷积神经网络在图像数据的表征学习方面取得了成功，但这仍然是一项极具挑战性的任务。在本文中，我们提出了一个可推广的框架，该框架可以自动将人口中的图像数据与非图像数据集成起来，用于不确定性预警。其核心是具有变分边的可学习自适应种群图，我们在数学上证明了它与图卷积神经网络相结合是可操作的。为了估计与图拓扑相关的预测不确定性，我们提出了Monte-Carlo edge dropout的新概念。在四个数据库上的实验结果表明，我们的方法可以一致且显著地提高自闭症谱系障碍、阿尔茨海默病和眼部疾病的诊断准确性，表明其在计算机辅助诊断的多模态数据中的通用性。</p><p>基于多模式学习的方法通常通过疾病分类的深层神经网络总结所有模式的特征，这忽略了人群中受试者之间的相互作用和关联。图形提供了一种自然的方式来表示人口数据，并允许使用强大的工具，如用于疾病分析的聚类算法。</p><h4 id="架构图-11"><a href="#架构图-11" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/2023/07/25/7-2-GNN-For-AD/wo9-6p0nvW-cTuWNtsFNRiFl2tFvEq8yyJab3iWmqWw.png" alt="image"></p><p>PAE：成对关联编码器</p><p>ED：边缘脱落</p><p>GC：图形卷积</p><p>融合：顶点串联</p><p>ui：受试者的预测不确定性</p><p>图中的颜色：绿色和橙色标记的诊断值（例如，健康或患病），灰色：未标记</p><h4 id="总结-amp-讨论-11"><a href="#总结-amp-讨论-11" class="headerlink" title="总结&amp;讨论"></a>总结&amp;讨论</h4><p>在本文中，我们提出了一种可推广的图卷积框架，以解决从多模态数据中学习用于疾病预测的挑战。与以前的方法不同，所提出的方法不手动设计相似的人口图，而是学习构造图连通性，该图连通性在数学上被证明可以使用GCN进行优化。所提出的Monte-Carloedge Dropout是第一次对GCN的图不确定性估计进行研究，并通过实验证明是有益的，但我们承认，在未来的工作中，这需要进一步的理论证明。大量实验结果表明，所提出的方法在大脑分析和眼部疾病预测方面具有优异的性能。此外，估计的预测不确定性允许检测用于临床干预的不确定样本，有助于更安全的深度学习辅助诊断系统。我们相信，这样一种可扩展的方法可以对更好地利用人群中的多模态数据进行临床计算机辅助诊断产生巨大影响。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/07/25/7-2-GNN-For-AD/eoU98wMNr9k7Zd36NUkPlfXEbJotoTjFSFmZYL1eEAo.png&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="论文" scheme="http://JavaSsun.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="图神经网络" scheme="http://JavaSsun.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>7-1-GNN For Medical Diagnosis</title>
    <link href="http://javassun.github.io/2023/06/28/7-1-GNN-For-Medical-Diagnosis/"/>
    <id>http://javassun.github.io/2023/06/28/7-1-GNN-For-Medical-Diagnosis/</id>
    <published>2023-06-28T15:16:38.000Z</published>
    <updated>2024-05-09T07:22:15.617Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><h2 id="1-Graph-Neural-Network-Based-Diagnosis-Prediction-2020"><a href="#1-Graph-Neural-Network-Based-Diagnosis-Prediction-2020" class="headerlink" title="1. Graph Neural Network-Based Diagnosis Prediction-2020"></a>1. Graph Neural Network-Based Diagnosis Prediction-2020</h2><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445219100-bca0ae4c-8666-48a1-be50-69a3a16923c1.pdf" target="_blank" rel="noopener">📎Graph based for Diagnosis.pdf</a></p><p>本文提出了一种基于知识的预测方法，即基于图形神经网络的诊断预测（GNDP），以充分利用医学知识进行准确的诊断预测。与常规的RNN+Attention机制不同，其提出的GNDP是基于时空图卷积网络（ST-GCN）的框架开发的。GNDP可以同时利用EHR中的顺序信息和医学本体中的领域知识，以获得更稳健和准确的患者表示，并在诊断预测任务中执行更准确的预测。</p><a id="more"></a><p>ST-GCN主要用于骨骼的动作识别任务。它捕获了图形结构骨架数据的空间配置和时间动态下的特征，以生成对人类行文的鲁棒和准确预测。由于EHR和骨骼动作数据之间的显著差异，还需要对数据进行特殊的预处理。</p><p>EHR数据与医学本体结合转化为图结构。</p><h3 id="创新点1"><a href="#创新点1" class="headerlink" title="创新点1"></a>创新点1</h3><p>本文提出了GNDP，这是一种基于图卷积网络的端到端的鲁棒诊断预测方法，可以全面利用EHR数据的潜在时空相关性，提高诊断预测的准确性。</p><h3 id="创新点2"><a href="#创新点2" class="headerlink" title="创新点2"></a>创新点2</h3><p>我们介绍了一种时空患者图构建方法，通过将患者的EHR数据与医学知识图相结合，有助于深度学习模型提取更多有意义的特征。通过实验证明，所提的GNDP在诊断预测任务中优于SOTA(RNN+Attention)方法。</p><p>诊断预测是基于EHR数据的临床预测中最重要和最困难的任务之一。这项任务旨在根据患者的历史病历预测患者的未来诊断，关键在于对患者就诊进行有效建模。</p><p><strong>RETAIN</strong>利用RNN对反向时序EHR数据进行建模。这是受临床实践的启发，即患者的最新健康状况比以前更具有说服力。<strong>Dipole</strong>将双向LSTM应用于长序列，从而增强预测模型的建模能力。这些方法证明RNN对模拟患者的历史记录是有效的。然而，这两种方法仍然存在数据不足和噪声的问题。KAME和CAMP都采用了医学本体和增强记忆网络的知识引导方法，证明了利用领域知识可以有效提高基于RNN的深度模型在诊断约任务中的性能。</p><h2 id="2-Graph-Based-Deep-Learning-for-Medical-Diagnosis-and-Analysis-Past-Present-and-Future-2021"><a href="#2-Graph-Based-Deep-Learning-for-Medical-Diagnosis-and-Analysis-Past-Present-and-Future-2021" class="headerlink" title="2. Graph-Based Deep Learning for Medical Diagnosis and Analysis: Past, Present and Future-2021"></a>2. Graph-Based Deep Learning for Medical Diagnosis and Analysis: Past, Present and Future-2021</h2><p><a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445219093-d54fc9e2-6f7a-4245-9406-99cde9fc2980.pdf" target="_blank" rel="noopener">📎Graph Based for Medical.pdf</a></p><p><a href="https://baijiahao.baidu.com/s?id=1703327276502784593&wfr=spider&for=pc" target="_blank" rel="noopener">https://baijiahao.baidu.com/s?id=1703327276502784593&amp;wfr=spider&amp;for=pc</a></p><p>医疗诊断是指确定患者患哪一种疾病、何种程度的过程。疾病诊断所需的信息是从患者的病史和各种医学成像数据中获得，包括功能性磁共振成像（fMRI）、磁共振成像（MRI）、电子计算机断层扫描（CT）、超声波（US）成像和X射线（X-ray）成像，以及其他诊断工具如电切割图（EEG）。然而，诊断过程不仅耗时长久，还容易产生和患者真实情况有差异的主观解释。借助计算机辅助诊断系统，临床专家已经有所受益。另外，自动化在医疗卫生服务和医生有限的情况下也十分有益，可以提高医疗卫生系统的质量、降低成本。</p><p>GNN 是一种处理由顶点和边构成的图结构信息的神经网络，近几年已成为机器学习领域的热点。由于化学、生物学、医疗卫生等学科的大部分信息需要复杂的数据结构，并不适用于矢量表示。而图结构的本质是捕获实体之间的关系，可以对它们之间的关系进行编码，因此在这些应用中非常有用。在医疗卫生中，图相关的机器学习方法广泛应用于脑活动分析、脑表面表示、解剖结构的分割和标记、多模态医学数据分析等领域。因此，需要特别注意 GNN 在非结构（无序）和结构（有序）中的泛化。除此以外，此类方法仍然稀缺，而且它们尚且不能完全解决许多具有挑战性的医学问题。</p><p>文章主要贡献有以下几个方面：<br>1.我们确定了传统深度学习在应用于医学数据分析时面临的许多挑战，并强调了图神经网络在克服这些挑战方面的贡献。<br>2.我们介绍和讨论为医学诊断提出的各种图神经网络框架及其具体应用。我们涵盖了使用图网络结合深度学习技术进行生物医学成像应用的工作。<br>3.我们总结了基于图的深度学习当前面临的挑战，并根据当前观察到的趋势和局限性提出医疗卫生的未来方向。</p><h3 id="2-1-图神经网络在医疗诊断中的热门领域"><a href="#2-1-图神经网络在医疗诊断中的热门领域" class="headerlink" title="2.1 图神经网络在医疗诊断中的热门领域"></a>2.1 图神经网络在医疗诊断中的热门领域</h3><h4 id="脑活动分析"><a href="#脑活动分析" class="headerlink" title="脑活动分析"></a>脑活动分析</h4><p>大脑信号是图形信号的一个例子，图形表示可以编码大脑的复杂结构，以表示不同大脑区域的物理或功能连接。在结构层面，网络由脑组织区域之间的解剖联系定义。在功能层，图形节点表示感兴趣的脑区域（ROI），而边缘捕捉通过fMRI相关矩阵计算的其活动之间的相关性，并且它们不能单独使用电极的物理位置进行简单建模。GCN在处理离散空间域中的信号的辨别特征提取时具有优势，对于诸如EEG分析的应用，可以捕获来自不同信道的EEG信号之间的隐藏关系。GCN提供了一种有效的方法来发现和建模图或触点的不同节点之间的内在关系。当考虑需要开发深度学习评分模型时，GNN模型也提供了非欧几里得空间的解释。这种解释有助于识别和定位与特定任务的模型决策相关的区域。例如某些脑区如何与特定的神经疾病相关。</p><h4 id="脑表皮表示"><a href="#脑表皮表示" class="headerlink" title="脑表皮表示"></a>脑表皮表示</h4><p>医学图像中的结构具有球形拓扑结构（即大脑皮层或亚皮层表面），这些结构有时由三角形网格表示，在顶点数量和局部连通性方面，受试者之间和受试者内部存在较大变化。由于缺乏一致和规则的邻域定义，传统的CNN不能直接应用于这些曲面。GCN可以应用于具有不同节点数和连通性的图。球面CNN架构可以在球面空间中呈现有效的参数化，而不会在球面上引入空间扭曲（球面映射），并且可以通过使用表面配准方法来增强几何特征。GCN还可以通过在表面数据以不同方式排列的目标域数据集上提供更好的概括，提供更大的灵活性来分割大脑皮层（表面分割），而无需手动注释或对这些表面进行显式排列。</p><h4 id="解剖结构的分割和标记"><a href="#解剖结构的分割和标记" class="headerlink" title="解剖结构的分割和标记"></a>解剖结构的分割和标记</h4><p>由于解剖的复杂性，血管和器官的分割是医学图像处理管道中的一个关键但具有挑战性的阶段。传统的深度学习分割方法通过提取高级语义特征将图像的每个像素分类为一个类。由于图像中的区域很少是网格状的，并且需要非本地信息，因此CNN表现不理想。与这些逐像素方法相比，基于图的方法直接学习和回归血管和器官的位置，并允许模型学习局部空间结构。GCN还可以在整个图像中传播和交换局部信息，以学习对象之间的语义关系。</p><h4 id="多模态医学数据分析"><a href="#多模态医学数据分析" class="headerlink" title="多模态医学数据分析"></a>多模态医学数据分析</h4><p>由于单一模态的限制，多模态神经图像分析越来越流行，这导致数据集越来越大、越来越复杂。将人群中的成像数据和非成像数据组合成一个统一的模型可能很困难。对于疾病分类，传统的基于多模态学习的方法通常通过CNN总结所有模态的特征，这忽略了人群中受试者之间的相互作用和关联。实例（受试者）之间的关联很重要，例如，在学习脑功能网络嵌入时，应考虑图中的相邻患者。最近，研究人员利用图卷积网络的进展来解决这些问题。图提供了一种自然的方式来表示人口数据，并通过组合不同模态的特征来建模复杂交互作用。每个受试者都被建模为一个节点（患者或健康对照）以及一组特征，并根据受试者特征之间的相似性定义边。</p><h3 id="2-2-用于医学诊断分析的研究案例研究"><a href="#2-2-用于医学诊断分析的研究案例研究" class="headerlink" title="2.2 用于医学诊断分析的研究案例研究"></a>2.2 用于医学诊断分析的研究案例研究</h3><h4 id="2-2-1-大脑中的功能连接分析"><a href="#2-2-1-大脑中的功能连接分析" class="headerlink" title="2.2.1 大脑中的功能连接分析"></a>2.2.1 大脑中的功能连接分析</h4><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/TlTrMc_x_feHA7_j3W8tp1sscMbKY9-TAf90Lo7mxnI.png" alt="image"></p><p>功能性磁共振成像（fMRI）</p><p>静息态功能性磁共振成像（rs-fMRI）</p><p>任务态功能性磁共振成像（t-fMRI）</p><p>上述模态是将受试者分为患者或健康对照组的主要数据来源。具体包括：自闭症谱系障碍（ASD）、精神分裂症（SZ）、注意力缺陷多动障碍（ADHD）、重度抑郁症 (MDD)、双相情感障碍（BD）等精神疾病。</p><p>依据节点的不同，可以将用于分析 fMRI 成像的 GNN 模型大致分为两类：</p><p>（i）个体图(a)：节点是大脑的不同区域，边是随时间序列观察的这些区域之间的功能相关性；</p><p>  (ii) 群体图(b)：每个节点代表一个具有相应大脑功能连接数据的受试者，边为受试者表型特征（年龄、性别等）之间的相似性。</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/PQaZwAPlHJP47-0kXKOt9bekEJr8miu_4KXvkyXGPdE.png" alt="image"></p><p>基于图的fMRI建模方法（个体图&amp;群体图）</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/HQL0uf3AuONtMV9SkJh4KYyGa2Hz45hCp1Dzx6zGRlE.png" alt="image"></p><p>个体图用于分析 fMRI 成像的 GNN 模型</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/N-SalxyO1_OazWILbSAMy8BKKUyo2EwPukvJTV4htEo.png" alt="image"></p><p>群体图用于分析 fMRI 成像的 GNN 模型</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/XzKJ8YwpUHu4-oe1X99G9DSR6DRd5JTIBVTEyZaLKo0.png" alt="image"></p><p>图卷积解码大脑功能区域</p><p>GNN 还被用于确定与特定认知刺激相关的大脑区域之间的关系，以及生成捕捉大脑功能和结构变化的超高分辨率 MRI 图像。</p><h4 id="2-2-2-基于电波图的分析"><a href="#2-2-2-基于电波图的分析" class="headerlink" title="2.2.2 基于电波图的分析"></a>2.2.2 基于电波图的分析</h4><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/485wnbLYVdc47W_p32VeRaNsPxiX5hhrZZIhHJD3a20.png" alt="image"></p><p>脑电图（EEG）被广泛应用于情感心理状态、情感认同等情感分析，以及癫痫等神经系统疾病诊断；心电图（ECG）则被用于识别心脏异常。除此以外， GNN 还可以被用于睡眠阶段的分类和脑机交互研究中的监测。</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/WkRq2FBSf8ZtqjLuwdWdxN8lKsBPQPNgKhFaLJteerI.png" alt="image"></p><p>从 EEG 信号中提取特征以构建基于图的架构并对精神心理状态进行分类</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/hOjvzKUlN4x92YuTlvvV9ON8TD6_rFqNx8xOlDjqXLg.png" alt="image"></p><p>具有 Attention 机制的 GNN-LSTM 用于 EEG 信号的分析</p><h4 id="2-2-3-解剖结构分析（分类和预测）"><a href="#2-2-3-解剖结构分析（分类和预测）" class="headerlink" title="2.2.3 解剖结构分析（分类和预测）"></a>2.2.3 解剖结构分析（分类和预测）</h4><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/AbD9_JoXirVJC3rmKQvLPbpFD9yRu8ooE70lPEjuUDA.png" alt="image"></p><ul><li><strong>基于 MRI 数据， GNN 模型可以对阿兹海默和帕金森疾病进行分类；</strong></li><li>基于 CT 图片， GNN 模型可以对结核病、 COVID-19 进行分类；</li><li>基于 X 光片， GNN 模型可以对胸部疾病、乳腺癌、肾病进行分类；</li><li>基于扩散磁共振成像（DMRI）数据， GNN 模型可以对大脑数据做出预测。</li></ul><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/rExUXqA9U28SrYdo32rHim_jLZ2Ppf1wnl538LTKexA.png" alt="image"></p><p>基于GCN的标签共现学习框架在语义信息的指导下探索潜在的异常，包括病理共现和相互依赖</p><h4 id="2-2-4-解剖结构分析（分割）"><a href="#2-2-4-解剖结构分析（分割）" class="headerlink" title="2.2.4 解剖结构分析（分割）"></a>2.2.4 解剖结构分析（分割）</h4><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/z0peHaCELBrJ1EOSL3EoCIJs0d-pQn91gPYXFbK_944.png" alt="image"></p><p>在不同的医学图像分割和标记方法中，基于图网络的方法显示出有前景的临床应用结果。主要用于血管分割（冠状动脉、肺动脉和静脉、视网膜血管、颅内动脉、头部和颈部血管）和器官分割（脑皮质、呼吸道、脑组织、眼睛、胰腺和脾脏、前列腺、淋巴结）两大类。</p><p>大脑皮层图形被映射到光谱域。源域和目标域与参考模板对齐。GCN分割器学习预测每个域的一般皮质包裹标签。最后，判别器对分割器预测进行分类。</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/P83bHmvztjsskecRaE7HzACC9094HWzFMpEYYF3O_yA.png" alt="image"></p><p>分段的对抗图域自适应</p><p>球形U-Net架构。输出表面是皮质分割图或皮质属性图，蓝色框反映球面空间中的特征图。</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/OfldnXvX4OXdRfiizK87LSGNg4XrfTibPUdKBxqPCSQ.png" alt="image"></p><p>用于脑皮质分割的球形U-NET架构</p><p>超体素是由大脑MRI体积生成的。由这些具有KNN的超体素构建图。GCN用于将超体素分类为不同类型的组织。</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/FVbgBgai40ph34gm9-HwOxTmzQDxvEy1bTlRKwmleAU.png" alt="image"></p><p>基于超体素的脑组织分割</p><h3 id="3-研究挑战和未来方向"><a href="#3-研究挑战和未来方向" class="headerlink" title="3. 研究挑战和未来方向"></a>3. 研究挑战和未来方向</h3><h4 id="3-1-七个主要挑战"><a href="#3-1-七个主要挑战" class="headerlink" title="3.1 七个主要挑战"></a>3.1 七个主要挑战</h4><ol><li><strong>图表示和估计：</strong>大多数研究中的图结构都是手动设计的，缺乏统一的结构知识；不同的属性和任务需要不同的模型架构，图结构估计就是为了找到合适的图，以将数据表示为研究所需的输入形式。</li><li><strong>动态图和时序图：</strong>许多现实世界的医学应用是动态的，这意味着图的节点、边和权重可以随时间变化。因此，静态图在时间场景中工作表现不佳。</li><li><strong>图模型的复杂性和训练效率：</strong>GCN 与它的变体有着相当大的复杂性，这对于不太具有挑战的应用程序来说可能是苛刻且不必要的，需要更简单的图神经网络模型。</li><li><strong>可解释性和可解读性：</strong>缺乏透明度被认为是 AI 在临床实践中采用的主要障碍之一，迈向值得信赖的 AI 的一步是可解释 AI 的发展。</li><li><strong>图模型的泛化：</strong>难以使用异构数据构建准确和强大的学习模型，由于患者隐私和临床数据管理要求，真正集中的开源医疗大数据集团用于深度学习十分罕见，这就需要模型具有很强的泛化能力。</li><li><strong>数据标注效率和训练范式：</strong>由于深度学习利用高度数据驱动的分层特征表示，医疗应用有几个关键挑战，包括注释稀缺、复杂注释和弱注释，以及标签的稀疏性。</li><li><strong>不确定性的量化：</strong>在医学应用中，不确定性可以分为偶然不确定性和认知不确定性：偶然不确定性由数据中的噪声产生；认知不确定性则可能源于模型的不完整。</li></ol><h4 id="3-2-三个可能的方向"><a href="#3-2-三个可能的方向" class="headerlink" title="3.2 三个可能的方向"></a>3.2 三个可能的方向</h4><p>面部分析：临床专家依靠某些面部特征和症状进行辅助医学诊断，并且已引入计算机视觉来提供面部特征的自动和客观评估。然而， CNN 主要关注面部各区域，没有考虑面部运动之间隐藏的相互关系，这可以用 GCN 捕获。因此，在临床环境中使用 GNN 创建互补的图表示和关系推理方法还有待探索。<br>潜在应用：术后疼痛管理、血管脉搏监测、面瘫评估，以及几种神经和精神疾病，包括癫痫、多动症、自闭症、双相情感障碍和精神分裂症。</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/KF5wybJ1zBuA11ShRgpALDT0kaFELFZibz5lg2izIUI.png" alt="image"></p><p>通过 GCN 对面部动作单元进行建模</p><p>人体姿势定位：人体姿势捕捉重要的健康相关指标，在评估癫痫、睡眠监测和手术恢复等医疗状况方面具有潜在价值。由于人体姿势估计与图形结构有关，因此 GCN 可以以灵活的方式处理骨架数据。<br>潜在应用：病床上姿势估计，以跟踪手术和疾病恢复以及其他睡眠障碍（如呼吸暂停、压疮和腕管综合征）造成的损伤。</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/IpFyUpDutX4XQWAKaJDMw-qsGKfyaNJOM6lFMRzaBMg.png" alt="image"></p><p>采用图回归来学习用于变化的时空图作为 GCN 的输入，用于动作特征学习</p><p>基于姿势的动作识别和行为分析：运动评估和监测是临床观察过程中的有力工具，并有助于诊断运动和精神障碍。然而，如前所述，骨架本身是图的形式。基于图的人体骨骼表示有一个显着的特点：i）关节和骨骼信息是互补的，将它们结合起来可以进一步改进基于骨骼的动作识别；ii) 时间连续性不仅存在于关节之间，也存在于身体结构中；iii) 空间域和时间域之间存在共存关系；iv) 骨架序列的时间动态也包含识别任务的重要信息。<br>潜在应用：<br>运动障碍：癫痫、帕金森、阿尔茨海默病、中风、震颤、亨廷顿舞蹈症和神经发育障碍。<br>精神障碍：痴呆症、精神分裂症、重度抑郁症、躁郁症和自闭症谱系。<br>其他情况：呼吸障碍、住院患者跌倒预测、诸如躁动、抑郁、谵妄、异常活动或评估医院环境中的人际交往等健康状况。</p><p><img src="/2023/06/28/7-1-GNN-For-Medical-Diagnosis/wBGzyxX1u8d9QKnK7td3UQBDXVNMuiLgB3gPrQCvAnc.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;h2 id=&quot;1-Graph-Neural-Network-Based-Diagnosis-Prediction-2020&quot;&gt;&lt;a href=&quot;#1-Graph-Neural-Network-Based-Diagnosis-Prediction-2020&quot; class=&quot;headerlink&quot; title=&quot;1. Graph Neural Network-Based Diagnosis Prediction-2020&quot;&gt;&lt;/a&gt;1. Graph Neural Network-Based Diagnosis Prediction-2020&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445219100-bca0ae4c-8666-48a1-be50-69a3a16923c1.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;📎Graph based for Diagnosis.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文提出了一种基于知识的预测方法，即基于图形神经网络的诊断预测（GNDP），以充分利用医学知识进行准确的诊断预测。与常规的RNN+Attention机制不同，其提出的GNDP是基于时空图卷积网络（ST-GCN）的框架开发的。GNDP可以同时利用EHR中的顺序信息和医学本体中的领域知识，以获得更稳健和准确的患者表示，并在诊断预测任务中执行更准确的预测。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="论文" scheme="http://JavaSsun.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="图神经网络" scheme="http://JavaSsun.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>6-2-SCI一区论文精读</title>
    <link href="http://javassun.github.io/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"/>
    <id>http://javassun.github.io/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/</id>
    <published>2023-05-25T15:16:38.000Z</published>
    <updated>2024-05-09T07:22:09.612Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p>论文：<a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445164871-750ffa66-0171-4c77-b5c6-426bb99f1d42.pdf" target="_blank" rel="noopener">📎s41746-022-00577-x.pdf</a><br>补充材料：<a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445164882-e5e234d9-1ea9-409e-bbd6-56f9495ddf8b.pdf" target="_blank" rel="noopener">📎41746_2022_577_MOESM1_ESM.pdf</a><br>报告摘要：<a href="https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445164874-3eca6782-7b91-4eb9-8885-b6c872771408.pdf" target="_blank" rel="noopener">📎41746_2022_577_MOESM2_ESM.pdf</a><br>文章官方网址：<a href="https://www.nature.com/articles/s41746-022-00577-x#MOESM1" target="_blank" rel="noopener">https://www.nature.com/articles/s41746-022-00577-x#MOESM1</a><br>录用：NPJ | digital medicine SCI医学1区</p><h3 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1-摘要"></a>1-摘要</h3><p>现状：ADNI领域数据集有限。<br>问题：小数据集上的模型会过拟合，且未进行跨组评估。</p><a id="more"></a><p>解决思路：为了抑制有限数据导致的过拟合，作者提出一种混合机器学习框架，由多个CNN组成，引入大脑先验知识，从脑段角度自动提取图像特征（根据临床发现，这些特征确实与认知衰退有关）。<br>最终分类器：采用Linear-SVM，将上面提取到的图像特征与非图像信息进行结合做最终的预测。<br>模型性能：与其他最先进的方法相比，模型具有优越的性能，且模型具有高度的概括性（因为进行了跨组评估），可泛化于不用人种之间。</p><h3 id="2-模型架构"><a href="#2-模型架构" class="headerlink" title="2-模型架构"></a>2-模型架构</h3><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/KI0BG_PfvQ_ZNkTLaZA9CIELNfV2XPW8Z_iMJRSDedo.jpg" alt="image"></p><h3 id="3-数据集"><a href="#3-数据集" class="headerlink" title="3-数据集"></a>3-数据集</h3><p>尽管PET和脑脊液(CSF)检查对AD诊断更有用,但由于其成本高,未被选中.</p><p>使用的是相对容易获得的信息作为输入,如MRI和非图像信息。</p><p><strong>数据来源大部分都是北美白人队列，该数据集的样本数量相对较少，因此有必要使用完全不同的数据集评估训练后的模型(缺乏不同人种之间关于AD的横向对比)，为了使该模型泛化性能更强，作者采用了两套数据来做实验。因为有研究表明：高加索人与东亚人之间的大脑皮层结构存在差异**</strong>。**</p><p>NA-ADNI：北美白人ADNI人群作为训练/验证模型</p><p>J-ADNI： 东亚(日本)作为测试模型</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/E1J2dy9VQESJCe1Zn6-zlVAHpckrQXfZM8b8sOaKtjA.jpg" alt="image"></p><p>补充表7：NA-ADNI和J-ADNI具体数据</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/Hvrq541tbIJvoYZLN0slKmuoHNg4z3foCd04fpr4Pks.jpg" alt="image"></p><h3 id="4-工具"><a href="#4-工具" class="headerlink" title="4-工具"></a>4-工具</h3><p>SmoothGrad可视化：研究IFEP中CNN关注的领域。</p><p>A：整个大脑作为输入的可视化。</p><p>B：脑段作为输入的可视化。</p><p>B比A更关注于海马体和杏仁核。</p><p><strong>红色表明对AD研究贡献大，蓝色表明对AD研究贡献小。</strong></p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/_8GVD9K7BqCGtZ3XWF_8Ew94b7Ln6kU5potDUkid75o.jpg" alt="image"></p><p>UMAP：研究模型提取特征的有效性，将训练样本的图像特征和非图像特征投影到二维（2D）空间，图5如下。</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/baX3gMNNg5NewCLAdG2jGmPkRLo614TVq8upLY0BcHM.jpg" alt="image"></p><p>使用UMAP将训练样本的图像和非图像特征的尺寸减少到2后，绘制训练样本。</p><p>蓝色圆点表示我们的模型正确归类为sMCI的sMCI，</p><p>蓝色“xs”表示错误归类为pMCI的SMCI。</p><p>红点圆点表示我们的模型正确分类为pMCI的pMCI，</p><p>红色“xs”表示错误分类为sMCI的PMCI。</p><p><strong>结论：****尽管存在少量的误分类错误，但大多数训练样本都是适当分布的，这表明成功地提取了用于分类sMCI和pMCI的有效特征，并且线性SVM适合于分类任务。</strong></p><h3 id="5-挑战"><a href="#5-挑战" class="headerlink" title="5-挑战"></a>5-挑战</h3><h4 id="挑战1：如何通过使用有限数量的训练样本，有效的从图像中提取有意义的特征？"><a href="#挑战1：如何通过使用有限数量的训练样本，有效的从图像中提取有意义的特征？" class="headerlink" title="挑战1：如何通过使用有限数量的训练样本，有效的从图像中提取有意义的特征？"></a>挑战1：如何通过使用有限数量的训练样本，有效的从图像中提取有意义的特征？</h4><p><strong>使用CNN，但有可能会因为样本过少而过拟合陷入局部最优解中，导致对未知数据的泛化性能变差</strong>。</p><p><strong>引入脑成像先验知识，在IFEP中，不针对整个大脑做CNN，而是针对从全脑图像中裁剪的不同脑段训练多个CNN，最终选择了与AD高度相关的海马体和颞叶前部。通过采用脑段，每个样本的输入图像尺寸减少到不到整个大脑的十分之一，另外，每个CNN只能与AD进展高度相关的区域学习图像特征。</strong></p><h4 id="挑战2：采取哪种分类器作为最终预测？"><a href="#挑战2：采取哪种分类器作为最终预测？" class="headerlink" title="挑战2：采取哪种分类器作为最终预测？"></a>挑战2：采取哪种分类器作为最终预测？</h4><p><strong>既要兼顾IFEP中提取的图像特征，又要兼顾非图像信息，此论文选用了泛化性能更高的SVM。</strong></p><h3 id="6-消融实验"><a href="#6-消融实验" class="headerlink" title="6-消融实验"></a>6-消融实验</h3><p><strong>主干架构采用DenseNet，消融AE（Auto-Encoder）和SE（Self-Attention），论文表明，AE在NA-ADNI数据集中贡献大，SA在J-ADNI数据集中贡献大。两者都存在的DenseNet模型在这两个数据集上性能稳定。</strong></p><p>补充表4</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/3TYwJmeXIfRSrhPl39esuoe2ZoDIIQRlfG7sagPRbBc.jpg" alt="image"></p><p>补充表5：使用RBF SVM进行消融实验对比</p><p>SVM中的SVC()算法包含两种核函数</p><ol><li><strong>SVC(kernel = ‘ploy’)</strong>：表示算法使用多项式核函数，依靠升维使得原本线性不可分的数据线性可分。</li><li><strong>SVC(kernel = ‘rbf’)</strong>：表示算法使用高斯核函数，依靠降维度使得非线性可分的样本可分。</li></ol><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/yKiHv-FAFrI0aOxCAU-X00zROo_rzpOiTvszw3-qk-g.jpg" alt="image"></p><h3 id="7-对比实验"><a href="#7-对比实验" class="headerlink" title="7-对比实验"></a>7-对比实验</h3><p>表1：作者实验结果和以往其他人实验结果对比（突出作者模型优秀）</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/4Vrv8Zlqaz_P9skVKsqJtVaCWW7EYi9jplT6vfZib1g.jpg" alt="image"></p><p>补充表2：SVM和E2E在不同输入信号上的实验结果对比（证明为什么选用SVM而不选用E2E）</p><p>E2E：端到端指的是输入的是原始数据，输出是最后的结果。</p><p>原来输入端不是直接的原始数据，而是在原始数据中提取的特征，这一点在图像问题上尤为突出，因为图像像素数太多，数据维度高，会产生维度灾难，所以原来一个思路是手工提取图像的一些关键特征，这实际就是就一个降维的过程。</p><p>那么问题来了，特征怎么提？</p><blockquote><p>特征提取的好坏异常关键，甚至比学习算法还重要，举个例子，对一系列人的数据分类，分类结果是性别，如果你提取的特征是头发的颜色，无论分类算法如何，分类效果都不会好，如果你提取的特征是头发的长短，这个特征就会好很多，但是还是会有错误，如果你提取了一个超强特征，比如染色体的数据，那你的分类基本就不会错了。</p></blockquote><blockquote></blockquote><blockquote><p>这就意味着，特征需要足够的经验去设计，这在数据量越来越大的情况下也越来越困难。 &gt; 于是就出现了端到端网络，特征可以自己去学习，所以特征提取这一步也就融入到算法当中，不需要人来干预了</p></blockquote><blockquote></blockquote><blockquote><p>经典机器学习方式是以人类的先验知识将raw数据预处理成feature，然后对feature进行分类。分类结果十分取决于feature的好坏。所以过去的机器学习专家将大部分时间花费在设计feature上。那时的机器学习有个更合适的名字叫feature engineering 。  </p></blockquote><blockquote></blockquote><blockquote><p>后来人们发现，利用神经网络，让网络自己学习如何抓取feature效果更佳。于是兴起了representation learning。这种方式对数据的拟合更加灵活。  </p></blockquote><blockquote></blockquote><blockquote><p>网络进一步加深，多层次概念的representation learning将识别率达到了另一个新高度。于是你听到了是个搞机器学习的人都知道的名字：deep learning。实指多层次的特征提取器与识别器统一训练和预测的网络。  </p></blockquote><blockquote></blockquote><blockquote><p>end to end的好处：通过缩减人工预处理和后续处理，尽可能使模型从原始输入到最终输出，给模型更多可以根据数据自动调节的空间，增加模型的整体契合度。</p></blockquote><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/y5onDQvhuOj4IwVDrP_Px26-T89AmfSOPJaxZl4he7s.jpg" alt="image"></p><p>补充表3：模型在NA-ADNI和J-ADNI人种之间的实验结果对比（突出作者模型泛化能力强，可适配不同人种）</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/xB20SA3_N0rvQi_s5POqoEw3eWSaZKrJgSHV3OL2yBU.jpg" alt="image"></p><p>补充表6：最先进的方法仅通过验证数据集（而不是测试数据集）进行评估（作者模型的潜在优势应该更大）</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/qv4pIYrS_F7_43GCows0F8DEXDFzLAwIhG0lFIaXjzk.jpg" alt="image"></p><p>图3：不同人种之间的评估结果：AUC越高，模型检测真实率越高。</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/EvYsimHKjHZfiVhZ3e0DyAHGAQO0eULqGjawtXwn93A.jpg" alt="image"></p><h3 id="8-局限性"><a href="#8-局限性" class="headerlink" title="8-局限性"></a>8-局限性</h3><h4 id="局限1：数据集小"><a href="#局限1：数据集小" class="headerlink" title="局限1：数据集小"></a>局限1：数据集小</h4><p>尽管ADNI数据集是世界上关于AD最大的数据库，但其规模仍然相对较小，作者提出混合模型来抑制小数据上的过拟合。</p><h4 id="局限2：数据利用率不高"><a href="#局限2：数据利用率不高" class="headerlink" title="局限2：数据利用率不高"></a>局限2：数据利用率不高</h4><p>作者的目标是为临床试验做贡献，仅采用基线数据作为输入，为了将其推广到可以获得纵向数据的常见临床诊断，不仅使用基线数据，还要利用好整个纵向数据，有待改进。</p><h4 id="局限3：数据在动态发展，现有模型只是当前表现优越"><a href="#局限3：数据在动态发展，现有模型只是当前表现优越" class="headerlink" title="局限3：数据在动态发展，现有模型只是当前表现优越"></a>局限3：数据在动态发展，现有模型只是当前表现优越</h4><p>由于数据集过小，作者提出的混合模型比使用主流的DenseNet作为主干的端到端模型显得比较优越，但ADNI数据集在逐年增大中，最先进的架构（如视觉转换器）作为主干模型应当继续研究。</p><h3 id="9-ADNI简介"><a href="#9-ADNI简介" class="headerlink" title="9-ADNI简介"></a>9-ADNI简介</h3><p>官方网址：<a href="https://adni.loni.usc.edu/" target="_blank" rel="noopener">https://adni.loni.usc.edu/</a></p><p>作者用于训练、验证、测试的数据集来自于ADNI1/ADNI-GO/ADNI2。</p><p>NA-ADNI是一项队列研究，以公私合作的形式由首席研究员Michael W.Weiner M.D发起。</p><p>NA-ADNI研究招募了2000+认知正常的参与者和MCI或AD患者。</p><p>ADNI-1：200CN个体，400晚期MCI患者，200名轻度痴呆患者，总共800人。</p><p>ADNI-GO：约200+早期MCI患者。</p><p>ADNI-2：招募了更多处于AD不同阶段的参与者进行AD监测。</p><p>ADNI-3：由于正在收集更多患者数据中，目前没有可用的诊断信息，未被作者采纳。</p><h3 id="10-参与者筛选"><a href="#10-参与者筛选" class="headerlink" title="10-参与者筛选"></a>10-参与者筛选</h3><p>每个参与者都要进行纵向数据的筛查：首先确定参与者被诊断为MCI的候选基线点，并且T1加权MRI图像和该患者的其他非图像信息均可用。</p><p>非图像信息包括简易精神状态检查（MMSE）、功能活动问卷（FAQ）、临床痴呆症评分（CDR）盒子总和评分、阿尔茨海默病评估量表Cog-11（ADAS）、APOE类型（载脂蛋白E）和人口统计信息，如性别和年龄。</p><p>如果参与者在基线检查后的20年内发展为AD，我们将该参与者与基线检查时的T1加权MRI图像和非图像信息一起标记为pMCI样本；否则，作为sMCI样本。</p><p>实验提取了399个sMCI和430个pMCI样本，用于训练、验证和测试作者的预测模型。同样的程序应用于J-ADNI数据集，从J-ADNI数据集中提取了总计80个稳定的和118个进行性MCI样本，用于评估我们的训练模型。</p><h3 id="11-图像处理"><a href="#11-图像处理" class="headerlink" title="11-图像处理"></a>11-图像处理</h3><h4 id="图像形状规范化"><a href="#图像形状规范化" class="headerlink" title="图像形状规范化"></a>图像形状规范化</h4><p>研究中使用的3D T1加权MRI图像首先通过将T1加权MRI图像与在MNI空间创建的图谱图像（标准图像）对齐，转换为蒙特利尔神经研究所（MNI）空间。使用了MNI152 NLIN 2009a地图集的模板图像。</p><h4 id="图像强度归一化"><a href="#图像强度归一化" class="headerlink" title="图像强度归一化"></a>图像强度归一化</h4><p>由于使用不同设备在不同地点获取的T1加权MRI图像在强度分布方面可能有不同的偏差，因此图像强度归一是许多图像分析任务的重要预处理。为了确保用于强度归一化的形状归一化andatas模板图像中对应的斑块包含相同的组织，我们在形状归一化andatas模型图像和atlas模板图像之间进行了非线性图像配准。</p><p>最后基于<strong>ITK</strong>实现了非线性图像配准。</p><h4 id="脑段提取"><a href="#脑段提取" class="headerlink" title="脑段提取"></a>脑段提取</h4><p>在进行强度归一化后，对形状归一化图像执行颅骨剥离过程，以提取大脑区域。训练了一个四层V-net。V-net使用与地标检测相同的数据集进行训练。训练数据的大脑区域的是在放射技师的监督下通过手工编辑获得的。分割结果由图像配准方法自动生成，该方法还包括在ITK中实现的不同地貌图像配准。从标准化（形状和强度）和颅骨断层图像中，提取海马（左和右）和前颞叶（左和右侧）的脑段。这些片段的位置是在影像模板图像中手动确定的，它们的大小固定为64×64×64像素，足够大，可以包含标准化图像中每个感兴趣的片段，并有必要的边界。对于每个样本，分别从其归一化图像中提取出位于图谱模板图像中指定位置的四个脑段，其中包含海马和颞前叶，左右两侧。</p><h4 id="图像特征提取"><a href="#图像特征提取" class="headerlink" title="图像特征提取"></a>图像特征提取</h4><p>DenseNet作为提取图像特征的主干网络，引入SA和AE来增强提取效果。</p><h3 id="12-Linear-SVM-Classification"><a href="#12-Linear-SVM-Classification" class="headerlink" title="12-Linear SVM Classification"></a>12-Linear SVM Classification</h3><p>由于训练样本有限，作者采用线性SVM替代E2E deep学习作为最终预测，提高泛化能力。</p><p>通过CNN从每个脑段提取128维图像特征后，使用PCA将每个脑段维数降为1。然后将非图像信息，如认知得分（MMSE/FAQ/CDR/ADAS）年龄、APOE类型，与四个片段的简化图像特征结合，作为 SVM的输入。</p><h3 id="13-End-to-End-E2E-Classification"><a href="#13-End-to-End-E2E-Classification" class="headerlink" title="13-End-to-End(E2E) Classification"></a>13-End-to-End(E2E) Classification</h3><p>作为对比实验采用实现了两个E2E模型，一个仅使用图像进行预测，另一个同时使用图像和非图像信息。</p><p>对于同时使用图像和非图像信息，双线性融合（Bilinear fusion）用于组合从图像中提取的图像特征和从非图像中提取的非图像特征。作者配置了两个图像特征提取模块，并行的从海马和前颞图像中提取图像特征，并将图像特征连接在一起。</p><p>作者首先嵌入非图像特征，然后被扩展到与图像特征相同的维度。然后将双线性融合应用得到图像特征和扩展后的非图像特征，从而生成用于分类的多模态特征。</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/y5onDQvhuOj4IwVDrP_Px26-T89AmfSOPJaxZl4he7s.jpg" alt="image"></p><h3 id="14-DATA-AVAILABILITY"><a href="#14-DATA-AVAILABILITY" class="headerlink" title="14-DATA AVAILABILITY"></a>14-DATA AVAILABILITY</h3><h4 id="NA-ADNI-dataset：https-adni-loni-usc-edu"><a href="#NA-ADNI-dataset：https-adni-loni-usc-edu" class="headerlink" title="NA-ADNI dataset：https://adni.loni.usc.edu/"></a>NA-ADNI dataset：<a href="https://adni.loni.usc.edu/" target="_blank" rel="noopener">https://adni.loni.usc.edu/</a></h4><h4 id="J-ADNI-dataset：https-humandbs-biosciencedbc-jp-en-hum0043-v1）"><a href="#J-ADNI-dataset：https-humandbs-biosciencedbc-jp-en-hum0043-v1）" class="headerlink" title="J-ADNI dataset：https://humandbs.biosciencedbc.jp/en/hum0043-v1）"></a>J-ADNI dataset：<a href="https://humandbs.biosciencedbc.jp/en/hum0043-v1" target="_blank" rel="noopener">https://humandbs.biosciencedbc.jp/en/hum0043-v1</a>）</h4><h3 id="15-CODE-AVAILABILITY"><a href="#15-CODE-AVAILABILITY" class="headerlink" title="15-CODE AVAILABILITY"></a>15-CODE AVAILABILITY</h3><p>The DenseNet code, which was used as the backbone of our architecture, is available at</p><p><a href="https://github.com/liuzhuang13/DenseNet" target="_blank" rel="noopener">https://github.com/liuzhuang13/DenseNet</a></p><p>主干网络：提取图片特征</p><p>The Faster R-CNN code used for brain landmark detection is available at</p><p><a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="noopener">https://github.com/rbgirshick/py-faster-rcnn</a></p><p>目标检测模型：脑段抽取</p><p>The Insight Toolkit: ITK, on which our image registration algorithm was implemented, is available at</p><p><a href="https://itk.org/" target="_blank" rel="noopener">https://itk.org/</a></p><p>医学影像处理工具：图像配准</p><h3 id="16-文献参考及引用缘由"><a href="#16-文献参考及引用缘由" class="headerlink" title="16-文献参考及引用缘由"></a>16-文献参考及引用缘由</h3><p><strong>作者为什么研究这个课题-&gt;目前这个这个课题的研究现状-&gt;作者想解决什么问题-&gt;作者通过什么理论/模型解决这个问题-&gt;作者给出的实验结果如何-&gt;作者关于当前模型的不足与未来猜想</strong></p><ol><li>Alzheimer’s Association. Alzheimer’s disease facts and figure. <em>Alzheimer’s Dement.</em> <strong>15</strong>, 321–387 (2019). 2019.</li></ol><p>（在Introduction中，开篇阐述了AD的症状和给社会带来的负担，调研了北美AD患者在2019年的数量，预测了2050年的AD患者数量，AD患者数量剧增，研究AD发展很有意义）</p><ol start="2"><li>Cummings, J., Lee, G., Ritter, A., Sabbagh, M. &amp; Zhong, K. Alzheimer’s disease drug development pipeline: 2019. <em>Alzheimer’s Dement.</em> <strong>5</strong>, 272–293 (2019).</li><li>Cummings, J., Lee, G., Ritter, A., Sabbagh, M. &amp; Zhong, K. Alzheimer’s disease drug development pipeline: 2020. <em>Alzheimer’s Dement.</em> <strong>23</strong>, 1–24 (2021).</li></ol><p>（AD治疗方案有限且失败率高，AD药物研究发展缓慢，新药研发面临挑战，大部分药物研发的目的是减缓早期AD的病变速度）</p><ol start="4"><li>Manly, J. J. et al. Frequency and course of mild cognitive impairment in a multiethnic community. <em>Ann. Neurol.</em> <strong>63</strong>, 494–506 (2008).</li><li>Petersen, R. C. et al. Practice guideline update summary: mild cognitive impairment. <em>Neurology</em> <strong>16</strong>, 126–135 (2018).</li></ol><p>（MCI患者是临床诊断的主要对象，那些被招募的MCI患者中，重点关注会从MCI演变为AD的患者，因为有20%的MCI在1.5-2年后被确诊为AD，80%的MCI稳定或者返回CN）</p><ol start="6"><li>Mueller, S. G. et al. The Alzheimer’s disease neuroimaging initiative. <em>Neuroimaging Clin. North Am.</em> <strong>15</strong>, 869–877 (2005).</li></ol><p>（AD患者数据大部分来自于NA-ADNI）</p><ol start="7"><li>Lu, D., Popuri, K., Ding, G. W., Balachandar, R. &amp; Beg, M. F. Multimodal and multiscale deep neural networks for the early diagnosis of Alzheimer’s disease using structural MR and FDG-PET images. <em>Sci. Rep.</em> <strong>8</strong>, <a href="https://doi.org/10.1038/s41598-018-22871-z" target="_blank" rel="noopener">https://doi.org/10.1038/s41598-018-22871-z</a> (2018).</li><li>Basaia, S. et al. Automated classification of Alzheimer’s disease and mild cognitive impairment using a single MRI and deep neural networks. <em>NeuroImage: Clin.</em> <strong>21</strong>, <a href="https://doi.org/10.1016/j.nicl.2018.101645" target="_blank" rel="noopener">https://doi.org/10.1016/j.nicl.2018.101645</a> (2019).</li><li>Zhang, J. et al. A 3D densely connected convolution neural network with connection-wise attention mechanism for Alzheimer’s disease classification. <em>Magn. Reson. Imaging</em> <strong>78</strong>, 119–126 (2021).</li><li>Abrol, A. et al. Deep residual learning for neuroimaging: An application to predict progression to Alzheimer’s disease. <em>J. Neurosci. Methods</em> <strong>339</strong>, <a href="https://doi.org/10.1016/j.jneumeth.2020.108701" target="_blank" rel="noopener">https://doi.org/10.1016/j.jneumeth.2020.108701</a> (2020).</li></ol><p>（7-10模型仅使用脑图信息作为输入）</p><ol start="11"><li>Tam, A. et al. A highly predictive signature of cognition and brain atrophy for progression to Alzheimer’s dementia. <em>GigaScience</em> <strong>8</strong>, <a href="https://doi.org/10.1093/gigascience/giz055" target="_blank" rel="noopener">https://doi.org/10.1093/gigascience/giz055</a> (2019).</li><li>Ledig, C., Schuh, A., Guerrero, R., Heckemann, R. A. &amp; Rueckert, D. Structural brain imaging in Alzheimer’s disease and mild cognitive impairment: biomarker analysis and shared morphometry database. <em>Sci. Rep.</em> <strong>8</strong>, <a href="https://doi.org/10.1038/s41598-018-29295-9" target="_blank" rel="noopener">https://doi.org/10.1038/s41598-018-29295-9</a> (2018).</li><li>Syaifullah A. et al. Machine learning for diagnosis of AD and prediction of MCI progression from brain MRI using brain anatomical analysis using diffeomorphic deformation. <em>Front. Neurosci.</em> <strong>11</strong>, <a href="https://doi.org/10.3389/fneur.2020.576029" target="_blank" rel="noopener">https://doi.org/10.3389/fneur.2020.576029</a> (2021).</li><li>Nakagawa, T. et al. Prediction of conversion to Alzheimer’s disease using deep survival analysis of MRI images. <em>Brain Commun.</em> <strong>2</strong>, <a href="https://doi.org/10.1093/braincomms/fcaa057" target="_blank" rel="noopener">https://doi.org/10.1093/braincomms/fcaa057</a> (2020).</li><li>Lee, G., Nho, K., Kang, B., Sohn, K. A. &amp; Kim, D. Predicting Alzheimer’s disease progression using multi-modal deep learning approach. <em>Sci. Rep.</em> <strong>9</strong>, <a href="https://doi.org/10.1038/s41598-018-37769-z" target="_blank" rel="noopener">https://doi.org/10.1038/s41598-018-37769-z</a> (2019).</li><li>Goto, T., Wang, C., Li, Y. &amp; Tsuboshita, Y. Multi-modal deep learning for predicting progression of Alzheimer’s disease using bi-linear shake fusion. <em>Proc. SPIE (Med. Imaging)</em> <strong>11314</strong>, 452–457 (2020).</li><li>El-Sappagh, S. et al. A multilayer multimodal detection and prediction model based on explainable artificial intelligence for Alzheimer’s disease. <em>Sci. Rep.</em> <strong>11</strong>, <a href="https://doi.org/10.1038/s41598-021-82098-3" target="_blank" rel="noopener">https://doi.org/10.1038/s41598-021-82098-3</a> (2021).</li></ol><p>（11-17模型使用多模态信息：图像和认知分数等非图信息）</p><p>一些已提出的相关工作在补充表1中提出，如下图（补充表1）</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/sAzwM-n1KQpVZjWyI4BhY70nzZ3ZnINHWkaiXOForKQ.jpg" alt="image"></p><ol start="18"><li>Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. &amp; Salakhutdinov, R. Dropout: a simple way to prevent neural networks from overfitting. <em>J. Mach. Learn. Res.</em> <strong>15</strong>, 1929–1958 (2014).</li></ol><p>（大部分已知模型使用的是深度学习，这需要大量的训练样本和可调节的参数，引入Dropout来让模型达到一个好的泛化性能）  </p><ol start="19"><li>Wang, X. et al. ChestX-Ray8: Hospital-Scale Chest X-Ray Database and benchmarks on weakly-supervised classification and localization of common thorax diseases. <em>Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>, 3462-3471 (2017).</li><li>Deng, J. et al. ImageNet: A large-scale hierarchical image database. <em>Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>, 248-255 (2009).</li></ol><p>（尽管sMCI和pMCI分类准确率达到了75%-86%之间，但与上述两个数据集相比，仍然存在问题。第一个问题是ADNI数据量过小，只有成千上百个，容易导致过拟合）</p><ol start="21"><li>Iwatsubo, T. et al. Japanese and North American Alzheimer’s disease neuroimaging initiative studies: harmonization for international trials. <em>Alzheimer’s Dement.</em> <strong>14</strong>, 1077–1086 (2018).</li><li>Kang, D. W. et al. Differences in cortical structure between cognitively normal East Asian and Caucasian older adults: a surface-based morphometry study. <em>Sci. Rep.</em> <strong>10</strong>, <a href="https://doi.org/10.1038/s41598-020-77848-8" target="_blank" rel="noopener">https://doi.org/10.1038/s41598-020-77848-8</a> (2020).</li></ol><p>（第二个问题是由于患者数据的偏见，即AI模型仅在高加索人人种范围内进行训练和评估，模型的实际能力受到了制约，训练的AI模型有必要在其他人种队列中进行测试，以验证模型的泛化性能。据研究表明，北美白人和东亚人在大脑皮层结构中有差异，这类不同人种队列的方法还没有被使用，作者在这篇文章中提出了此方法 ，<strong>创新点</strong>）</p><ol start="23"><li>LeCun, Y., Bengio, Y. &amp; Hinton, G. Deep learning. <em>Nature</em> <strong>521</strong>, 436–444 (2015).</li><li>Yamaguchi, H. et al. Three-dimensional convolutional autoencoder extracts features of structural brain images with a “diagnostic label-free” approach: application to Schizophrenia Datasets. <em>Front. Neurosci.</em> <strong>07</strong>, <a href="https://doi.org/10.3389/fnins.2021.652987" target="_blank" rel="noopener">https://doi.org/10.3389/fnins.2021.652987</a> (2021).</li></ol><p>（在IFEP中，采用经典的CNN架构自动提取图像特征）</p><ol start="25"><li>Wang, L. et al. Alterations in cortical thickness and white matter integrity in mild cognitive impairment measured by whole-brain cortical thickness mapping and diffusion tensor imaging. <em>Am. J. Neuroradiol.</em> <strong>30</strong>, 893–899 (2009).</li><li>Misra, C., Fan, Y. &amp; Davatzikos, C. Baseline and longitudinal patterns of brain atrophy in MCI patients, and their use in prediction of short-term conversion to AD: Results from ADNI. <em>Neuroimage</em> <strong>44</strong>, 1415–1422 (2009).</li><li>Risacher, S. L. et al. Baseline MRI predictors of conversion from MCI to probable AD in the ADNI cohort. <em>Curr. Alzheimer Res.</em> <strong>6</strong>, 347–361 (2009).</li></ol><p>（在IFEP中，为了抑制深度学习所带来的过拟合，作者引入脑成像先验知识，请大脑领域研究员挑选与认知下降高度相关的脑段来进行研究，减少图像维度）</p><ol start="28"><li>Shorten, C. &amp; Khoshgoftaar, T. A survey on image data augmentation for deep learning, <em>J. Big Data</em>, <strong>6</strong>, 1–48, (2019).</li><li>Vaswani, A. et al. Attention is all you need. <em>Proc. Int’l Conf. on Neural Information Processing Systems</em>, 6000–6010 (2017).</li><li>Vincent, P., Larochelle, H., Bengio, Y. &amp; Manzagol, P. A. Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion. <em>J. Mach. Learn. Res.</em> <strong>11</strong>, 3371–3408 (2010).</li><li>Hinton, G. E., Krizhevsky, A. &amp; Wang, S. D. Transforming auto-encoders. <em>Proc. Int’l Conf. on Artificial Neural Netw.</em> 44-51 (2011).</li></ol><p>（为了提高CNN的性能和泛化能力，作者引入了数据增强、18-Dropout、SA、AE）</p><ol start="32"><li>Brereton, R. G. &amp; Lloyd, G. R. Support Vector Machines for classification and regression. <em>The Analyst Online</em> <strong>135</strong>, <a href="https://doi.org/10.1039/B918972F" target="_blank" rel="noopener">https://doi.org/10.1039/B918972F</a> (2010).</li><li>Girshick, R., Donahue J., Darrell, T. &amp; Malik, J. Rich feature hierarchies for accurate object detection and semantic segmentation. <em>Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>, 580-587 (2014).</li></ol><p>（线性SVM比非线性SVM有更高的泛化能力，使用它作为分类器对CNN提取的图像特征和非图像特征进行分类效果更佳）</p><ol start="34"><li>Iwatsubo, T. Japanese Alzheimer’s disease neuroimaging initiative: present status and future. <em>Alzheimer’s Dement.</em> <strong>6</strong>, 297–299 (2010).</li></ol><p>（J-ADNI数据集）</p><ol start="35"><li>Smilkov, D., Thorat, N., Kim, B., Viégas, F. &amp; Wattenberg, M. SmoothGrad: removing noise by adding noise, <em>Proc. Int’l Conf. on Machine Learning (ICML)</em>, <a href="https://doi.org/10.48550/arXiv.1706.03825" target="_blank" rel="noopener">https://doi.org/10.48550/arXiv.1706.03825</a> (2017).</li></ol><p>（SmoothGrad：有待进一步了解）</p><p>M2和M5表明脑段作为输入优于全脑输入M1和M4。</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/y5onDQvhuOj4IwVDrP_Px26-T89AmfSOPJaxZl4he7s.jpg" alt="image"></p><p>（为了可视化在IFEP部分CNN关注的区域，使用了SmoothGrad工具进行可视化）</p><p>上述脑段输入优于全脑输入的原因有下图给出，ROI区域被重点关注,模型精力不会被分散.</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/_8GVD9K7BqCGtZ3XWF_8Ew94b7Ln6kU5potDUkid75o.jpg" alt="image"></p><p>S1-S4样本的选择来自于补充图5（颞叶前部和海马体由有先验知识的脑专家手动指定）</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/UWjf4x5tXQ41bR5Hx2CXvEEULzdFICBKASnvnPe4u1A.jpg" alt="image"></p><ol start="36"><li>McInnes, L., Healy, J., Saul, N. &amp; Großberger, L. UMAP: Uniform Manifold Approximation and Projection. <em>J. Open Source Softw.</em> <strong>3</strong>, 861. <a href="https://doi.org/10.21105/joss.00861" target="_blank" rel="noopener">https://doi.org/10.21105/joss.00861</a> (2018).</li></ol><p>（UMAP工具，有待进一步了解）</p><ol start="37"><li>Rajkomar, A., Dean, J. &amp; Kohane, I. Machine learning in medicine. <em>N. Engl. J. Med.</em> <strong>380</strong>, 1347–1358 (2019).</li></ol><p>（深度学习模型的优点有时也会是其脆弱性之一，既数据量小时容易陷入局部最优解）</p><ol start="38"><li>Buolamwini, J. &amp; Gebru, T. Gender shades: intersectional accuracy disparities in commercial gender classification. <em>Proc. Mach. Learn. Res.</em> <strong>81</strong>, 1–15 (2018).</li></ol><p>（性别识别系统中报告了由队列（北美和东亚）和性别偏见造成的意外影响）</p><ol start="39"><li>Dosovitskiy, A. An image is worth 16x16 words: transformers for image recognition at scale. <em>Proc. Int’l Conf. on Learning Representations (ICLR)</em>, <a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noopener">https://arxiv.org/abs/2010.11929</a> (2021).</li></ol><p>（由于ADNI数据量有限,作者的模型表现优越，但随着ADNI的不断发展，先进的模型也会变的更加优越，比如这里引用的视觉转换模型）</p><ol start="40"><li>Palmqvist, S. et al. Prediction of future Alzheimer’s disease dementia using plasma phospho-tau combined with other accessible measures. <em>Nat. Med.</em> <strong>27</strong>, 1034–1042 (2021).</li></ol><p>（新的研究表明，血浆磷-τ，对预测也有效，有必要考虑在未来的模型中加入这些生物标记物）</p><ol start="41"><li>Brett, M., Johnsrude, I. S. &amp; Owen, A. M. The problem of functional localization in the human brain. <em>Nat. Rev. Neurosci.</em> <strong>3</strong>, 243–249 (2002).</li><li>Fonov, V. S., Evans, A. C., McKinstry, R. C., Almli, C. R. &amp; Collins, D. L. Unbiased nonlinear average age-appropriate brain templates from birth to adulthood. <em>NeuroImage</em> <strong>47</strong>, 539–541 (2009).</li></ol><p>（将T1加权MRI图像与在MNI空间创建的图谱图像（标准图像）对齐，首次将我们研究中使用的3D T1加权核磁共振图像转换为蒙特利尔神经研究所（MNI）空间。使用了MNI152 NLIN 2009a atlas的模板图像。为了将根据NA-ADNI或J-ADNI研究中T1加权MRI图像与在MNI空间中创建的atlas模板图像进行可靠、准确的对齐，开发了一种包含基于地标和基于图像配准的对齐步骤的粗到细方法）</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/ZpHWa8IRdgzfVOfLn8DYamwvs8bGIHUm-aGWZsI-YiA.jpg" alt="image"></p><ol start="43"><li>Ren, S., He, K., Girshick, R. &amp; Sun, J. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. <em>Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>, 1137-1149 (2016).</li><li>Marcus, D. S. et al. Open access series of imaging studies (OASIS): cross-sectional MRI data in young, middle aged, nondemented, and demented older adults. <em>J. Cogn. Neurosci.</em> <strong>19</strong>, 1498–1507 (2007).</li></ol><p>（基于区域的Fater R-CNN模型和OASIS数据集进行训练，训练图像的地标是在放射技师的监督下手动指定的，landmask为：左右眼，胼胝体(顶部)、穹窿体(前部)、中脑(中部)、第四脑室(中部)，整体用于基于Landmask进行对齐）</p><ol start="45"><li>Maes, F., Vandermeulen, D. &amp; Suetens, P. Medical image registration using mutual information. <em>Proc. IEEE</em> <strong>91</strong>, 1699–1722 (2003).</li><li>Oliveira, P. P. M. &amp; Tavares, M. R. R. Medical image registration: a review. <em>Computer Methods Biomech. Biomed. Eng.</em> <strong>17</strong>, 73–93 (2014).</li><li>Mattes, D., Haynor, D. R., Vesselle, H., Lewellen, T. K. &amp; Eubank, W. Nonrigid multimodality image registration. <em>Proc. SPIE 4322, Medical Imaging: Image Processing</em>, 1609-1620(2001).</li></ol><p>（基于图像配准的对齐步骤中，通过使用图像配准技术，利用之前的方法进行图像相似度度量）</p><ol start="48"><li>Avants, B. B. et al. The Insight ToolKit image registration framework. <em>Front. Neuroinformatics</em> <strong>8</strong>, 1–13 (2014).</li></ol><p>（使用了与图谱一起提供的图谱模板图像的大脑掩码，以确保图像注册仅在大脑区域进行。使用的图像注册技术是基于开源Insight Tool Kit（ITK）图像注册框架实现，ITK有待进一步了解）</p><ol start="49"><li>Reinhold, J.C., Dewey, B.E., Carass, A. &amp; Prince, J.L. Evaluating the impact of intensity normalization on MR image synthesis. <em>Proc. SPIE 10949, Medical Imaging: Image Processing</em>, <a href="https://doi.org/10.1117/12.2513089" target="_blank" rel="noopener">https://doi.org/10.1117/12.2513089</a> (2019).</li><li>Roy, S. &amp; Carass, A. Magnetic resonance image example-based contrast synthesis. <em>IEEE Trans. Med. Imaging</em> <strong>32</strong>, 2348–2363 (2013).</li><li>Shinohara, R. T. et al. Statistical normalization techniques for magnetic resonance imaging. <em>Neuroimage: Clin.</em> <strong>6</strong>, 9–19 (2014).</li><li>Sun, X. et al. Histogram-based normalization technique on human brain magnetic resonance images from different acquisitions. <em>BioMedical Eng. OnLine</em> 14, <a href="https://doi.org/10.1186/s12938-015-0064-y" target="_blank" rel="noopener">https://doi.org/10.1186/s12938-015-0064-y</a> (2015).</li></ol><p>（过去提出的图像强度归一化方法）</p><p>作者采用类似基于示例的强度归一化方法，该方法使用T1加权MRI图像和图谱模板图像中的斑块，其中包含所需的获得的斑块和组织对比度，但为了鲁棒性和计算简单性，作者以更简单的方式实现了它。</p><p>补充图3：显示了图像强度归一化算法的概要（有待进一步了解）</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/VDLWsfffIpqKfAbb9ADHfTG8cdqOtBz2Nm3Yu4ZeBCg.jpg" alt="image"></p><ol start="53"><li>Milletari, F., Navab, N. &amp; Ahmadi, S. V-Net: Fully convolutional neural networks for volumetric medical image segmentation. <em>Fourth Int’l Conf. on 3D Vision (3DV)</em>, 565-571 (2016).</li></ol><p>（在进行强度归一化后，对形状归一化图像进行颅骨剥离处理，以提取大脑区域。作者训练了一个四层V-net）</p><ol start="54"><li>Ashburner, J. A fast diffeomorphic image registration algorithm. <em>NeuroImage</em> <strong>38</strong>, 95–113 (2007).</li></ol><p>（V-net使用与地标检测相同的数据集进行训练。训练数据的大脑区域的基本真相是在放射技师的监督下通过手工编辑获得的。分割结果由图像配准方法自动生成，该方法还包括在<strong>ITK中实现的差异图像配准</strong>）</p><ol start="55"><li>Huang, G., Liu, Z. &amp; Maaten, L. Densely Connected Convolutional Networks. <em>Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>, 4700-4708 (2017).</li></ol><p>（作者采用的主干网络DenseNet模型）</p><ol start="56"><li>Islam, J. &amp; Zhang, Y. Brain MRI analysis for Alzheimer’s disease diagnosis using an ensemble system of deep convolutional neural networks. <em>Brain Informatics</em> <strong>5</strong>, <a href="https://doi.org/10.1186/s40708-018-0080-3" target="_blank" rel="noopener">https://doi.org/10.1186/s40708-018-0080-3</a> (2018).</li></ol><p>（DenseNet在不同数据集上完成相同任务时比其他网络架构具有优势）</p><p>补充表8：显示了作者的DenseNet主干网的详细架构，该架构与DenseNet-121（参考文献55）基本相同，其中2D卷积层和池层被修改为3D层。由于脑段图像的尺寸较小，第一个卷积层的尺寸也变小了。</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/cc0t0QyETLo8M6vlgzptwETKfpG328uR1jk3Iul7MfM.jpg" alt="image"></p><p>补充表9：除了将输入的脑段分类为sMCI或pMCI类的分类任务外，AE的另一个任务是从图像特征中恢复输入的脑片段图像，该任务被添加到DenseNet主干网中。通过引入AE任务，该任务被认为比使用少量样本的分类更健壮，预计整个体系结构的健壮性将得到提高。对于解码器，采用了一个简单的五层网络，由去卷积层和上采样层组成。</p><p><img src="/2023/05/25/6-2-SCI%E4%B8%80%E5%8C%BA%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/IF7Hk6vOmXWXdJTxKlWSfOaxmkkyE2pzI8k9zCod5Sg.webp" alt="image"></p><ol start="57"><li>Hsiunga, G-Y.R &amp; Sadovnick, A.D. Genetics and dementia: risk factors, diagnosis, and management. <em>Alzheimer’s Dement.</em> <strong>3</strong>, 418–427 (2007).</li></ol><p>（根据该参考文献将APOE类型转换为代表AD风险的值）</p><ol start="58"><li>Bolstad, B. M., Irizarry, R. A., Astrand, M. &amp; Speed, T. P. A comparison of normalization methods for high density oligonucleotide array data based on variance and bias. <em>Bioinformatics</em> <strong>19</strong>, 185–193 (2003).</li></ol><p>（由于这些多模态输入的分布差异很大，因此在应用SVM之前，使用<strong>四分位归一化</strong>组合特征进行归一化。为了进行验证和测试，将用于训练的相同四分位数标准化应用于组合特征）</p><h3 id="18-有待了解与学习"><a href="#18-有待了解与学习" class="headerlink" title="18-有待了解与学习"></a>18-有待了解与学习</h3><ol><li>ITK：图像配准工具</li></ol><p><a href="https://github.com/InsightSoftwareConsortium/ITK" target="_blank" rel="noopener">https://github.com/InsightSoftwareConsortium/ITK</a></p><ol start="2"><li>UMAP：降为算法，可视化证明模型提取特征的有效性</li></ol><p><a href="https://doi.org/10.21105/joss.00861" target="_blank" rel="noopener">https://doi.org/10.21105/joss.00861</a> (2018).</p><ol start="3"><li>SmoothGrad：证明脑段中与AD研究高度相关的区域（海马体、杏仁核、颞前叶）</li></ol><p><a href="https://doi.org/10.48550/arXiv.1706.03825" target="_blank" rel="noopener">https://doi.org/10.48550/arXiv.1706.03825</a> (2017).</p><ol start="4"><li>Faster R-CNN：基于区域的CNN，基于选取的六个Landmask进行图片对齐。</li></ol><p>目标检测算法发展：R-CNN——Fast R-CNN——Faster R-CNN——Mask R-CNN</p><p>R-CNN：CVPR2014 <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="noopener">https://arxiv.org/abs/1311.2524</a></p><p>Fast R-CNN：ICCV2015 <a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="noopener">https://arxiv.org/abs/1504.08083</a></p><p>Faster R-CNN：NIPS2015 <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">https://arxiv.org/abs/1506.01497</a></p><p>Mask R-CNN：CVPR2017 <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="noopener">https://arxiv.org/abs/1703.06870</a></p><ol start="5"><li>OASIS数据集：Open access series of imaging studies，训练Faster R-CNN</li></ol><p><a href="https://www.oasis-brains.org/" target="_blank" rel="noopener">https://www.oasis-brains.org/</a></p><ol start="6"><li>DenseNet：主干网络，用于IFEP部分的图片特征自动提取<a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.html" target="_blank" rel="noopener">https://openaccess.thecvf.com/content_cvpr_2017/html/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.html</a></li><li>APOE转为AD风险的算法</li><li>图像强度归一化算法：由于采集设备、采集环境的不同，需要对图像强度进行归一化</li><li>图像相似度度量算法：度量图像之间的相似度</li><li>V-Net算法：基于3D卷积神经网络的方法，快速，准确的方式执行MRI体积的分割</li></ol><p><a href="https://github.com/mattmacy/vnet.pytorch" target="_blank" rel="noopener">https://github.com/mattmacy/vnet.pytorch</a></p><ol start="11"><li>四分位归一化组合特征：特征工程归一化的方法之一</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;论文：&lt;a href=&quot;https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445164871-750ffa66-0171-4c77-b5c6-426bb99f1d42.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;📎s41746-022-00577-x.pdf&lt;/a&gt;&lt;br&gt;补充材料：&lt;a href=&quot;https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445164882-e5e234d9-1ea9-409e-bbd6-56f9495ddf8b.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;📎41746_2022_577_MOESM1_ESM.pdf&lt;/a&gt;&lt;br&gt;报告摘要：&lt;a href=&quot;https://www.yuque.com/attachments/yuque/0/2024/pdf/22829897/1711445164874-3eca6782-7b91-4eb9-8885-b6c872771408.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;📎41746_2022_577_MOESM2_ESM.pdf&lt;/a&gt;&lt;br&gt;文章官方网址：&lt;a href=&quot;https://www.nature.com/articles/s41746-022-00577-x#MOESM1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.nature.com/articles/s41746-022-00577-x#MOESM1&lt;/a&gt;&lt;br&gt;录用：NPJ | digital medicine SCI医学1区&lt;/p&gt;
&lt;h3 id=&quot;1-摘要&quot;&gt;&lt;a href=&quot;#1-摘要&quot; class=&quot;headerlink&quot; title=&quot;1-摘要&quot;&gt;&lt;/a&gt;1-摘要&lt;/h3&gt;&lt;p&gt;现状：ADNI领域数据集有限。&lt;br&gt;问题：小数据集上的模型会过拟合，且未进行跨组评估。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="论文" scheme="http://JavaSsun.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>6-1-MRI成像及ADNI简介</title>
    <link href="http://javassun.github.io/2023/05/10/6-1-MRI%E6%88%90%E5%83%8F%E5%8F%8AADNI%E7%AE%80%E4%BB%8B/"/>
    <id>http://javassun.github.io/2023/05/10/6-1-MRI%E6%88%90%E5%83%8F%E5%8F%8AADNI%E7%AE%80%E4%BB%8B/</id>
    <published>2023-05-10T15:16:38.000Z</published>
    <updated>2024-05-09T06:44:06.289Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p>知识来源：知网《基于卷积神经网络的阿尔茨海默病 MRI影像辅助诊断研究》</p><h2 id="MRI影像分析"><a href="#MRI影像分析" class="headerlink" title="MRI影像分析"></a>MRI影像分析</h2><p>医学影像成像的原理，是利用某些物理因子（如X线、电磁场、微波、红外线等）穿过人体，作为一种信息载体，这些含有能量的物理因子可以准确的反映出人体的内部组织或器官的结构、形态和功能等情况，并且通过影像成像的方式直观的呈现出来。</p><a id="more"></a><p>医学影像由于含有丰富的人体组织、器官等信息，医师可以根据医学图像所反映的人体内部组织和器官的形态密度等信息来判断患者的组织和器官是否产生了异常以及异常的程度，以此实现对阿尔茨海默病的早期诊断、研究与治疗。医学影像成像技术引领着临床诊断和治疗技术的发展。</p><p>在恒定磁场中的核子，在相应的射频脉冲激发后，其电磁能量的吸收和释放，称为磁共振（Magnetic Resonance，MR），磁共振成像（MRI）是一种利用磁共振原理的影像检测技术，它利用原子核自旋运动的特点，在外加磁场内，经过射频脉冲激励后产生信号，用探测器检测弛豫信号并将该信号输入计算机，经过数据处理转换后在可视化设备上显示图像。与其它医学影像成像技术相比，MRI影像中含有更加丰富的脑部组织、器官等信息，并且高分辨率的MRI影像，其参数较多，<strong>大脑结构显示清晰，可以从矢状面、冠状面、横断面等不同角度观察大脑病变组织，从而帮助医师及时发现早期病变</strong>。</p><p>MRI设备是一种非电离辐射医学影像设备，不会产生来自X光或放射性示踪剂的有害辐射，无损伤，对人体相对安全，目前已广泛应用于阿尔茨海默病等脑疾病的检查中。</p><h2 id="ADNI"><a href="#ADNI" class="headerlink" title="ADNI"></a>ADNI</h2><p><img src="/2023/05/10/6-1-MRI%E6%88%90%E5%83%8F%E5%8F%8AADNI%E7%AE%80%E4%BB%8B/6-Ef-pBlQehpmnYNpjHZJtxGObl8mJOh-MfKwhDs_ZE.png" alt="image"></p><p>从2004年开始，对ADNI的研究已经进行了约17年，经历了四个阶段：ADNI-1（5年）、ADNI-GO（2年）、ADNI-2（5年）和ADNI-3（5年）。</p><p>ADNI-1开始于2004年并持续了5年。它旨在寻找更精确的生物标志物，用于早期AD的检测和跟踪。<strong>ADNI-1包括200名CN、400名MCI和200名AD，并积累和研究了大量脑扫描、基因图谱以及血液和脑脊液等生物标志物。ADNI-1使用MRI、结构MRI和PET（包括FDG-PET和淀粉样蛋白PET）作为成像方式</strong>。</p><p>ADNI-2成立于2011年，历经5年。<strong>其目的是寻找生物标志物来预测和分析轻度认知障碍</strong>。除了现有的ADNI-1和ADNI-GO，该研究还包括150名CN、100名EMCI、150名MCI和150名AD。</p><p>在ADNI数据库中选择适用于实验的MRI影像时，应合理选择各技术参数，从而获得高质量的影像。</p><p><img src="/2023/05/10/6-1-MRI%E6%88%90%E5%83%8F%E5%8F%8AADNI%E7%AE%80%E4%BB%8B/b82DB5HhVY9kqo6GQVzTXOrk5S0_9tZOXGuMBKYRips.png" alt="image"></p><p><img src="/2023/05/10/6-1-MRI%E6%88%90%E5%83%8F%E5%8F%8AADNI%E7%AE%80%E4%BB%8B/xzQDW-8GqU_Ha6NV2mxRCxLyFnIZEFt8lWT16CHUYz0.png" alt="image"></p><h2 id="MRI影像预处理"><a href="#MRI影像预处理" class="headerlink" title="MRI影像预处理"></a>MRI影像预处理</h2><p><img src="/2023/05/10/6-1-MRI%E6%88%90%E5%83%8F%E5%8F%8AADNI%E7%AE%80%E4%BB%8B/pkg-IJTQMGDnhSTp3b37SGH9yd2I-PzmovzVNRYj5aY.png" alt="image"></p><p><img src="/2023/05/10/6-1-MRI%E6%88%90%E5%83%8F%E5%8F%8AADNI%E7%AE%80%E4%BB%8B/HQ-csRy7RtCuPk1VrsDkZ6xVt7kBc3JWHVpARmQB4yo.png" alt="image"></p><p><img src="/2023/05/10/6-1-MRI%E6%88%90%E5%83%8F%E5%8F%8AADNI%E7%AE%80%E4%BB%8B/xmsMRT48EppTpoBILMQ126njsFANZWOqPoJiTE_Xuxo.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;知识来源：知网《基于卷积神经网络的阿尔茨海默病 MRI影像辅助诊断研究》&lt;/p&gt;
&lt;h2 id=&quot;MRI影像分析&quot;&gt;&lt;a href=&quot;#MRI影像分析&quot; class=&quot;headerlink&quot; title=&quot;MRI影像分析&quot;&gt;&lt;/a&gt;MRI影像分析&lt;/h2&gt;&lt;p&gt;医学影像成像的原理，是利用某些物理因子（如X线、电磁场、微波、红外线等）穿过人体，作为一种信息载体，这些含有能量的物理因子可以准确的反映出人体的内部组织或器官的结构、形态和功能等情况，并且通过影像成像的方式直观的呈现出来。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>5-ADNI-实验数据筛选与下载</title>
    <link href="http://javassun.github.io/2023/04/25/5-ADNI-%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E4%B8%8E%E4%B8%8B%E8%BD%BD/"/>
    <id>http://javassun.github.io/2023/04/25/5-ADNI-%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E4%B8%8E%E4%B8%8B%E8%BD%BD/</id>
    <published>2023-04-25T15:16:38.000Z</published>
    <updated>2024-05-09T06:41:08.427Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><p><a href="https://ida.loni.usc.edu/pages/access/search.jsp" target="_blank" rel="noopener">https://ida.loni.usc.edu/pages/access/search.jsp</a></p><h3 id="1-实验数据集下载"><a href="#1-实验数据集下载" class="headerlink" title="1-实验数据集下载"></a>1-实验数据集下载</h3><p><strong>T1W1-3D-MP RAGE</strong>：T1加权三维磁化强度预备梯度回波序列属于快速容积扫描技术，具有较高的空间分辨率和时间分辨率，信噪比高，伪影小，对 脑内结构（如白质、灰质和脑脊液）对比度良好，能三维显示人脑内部精细解剖结构，有利于显示小病灶及其细节，对神经系统疾病的诊断具有重要价值；同时也是获取正常人脑的三维可视化图谱的重要方法。</p><a id="more"></a><p><strong>T1W1-3D-MP RAGE：T1W1 three dimensional magnetization prepared rapid acquisition gradient echo sequences.</strong></p><p><img src="/2023/04/25/5-ADNI-%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E4%B8%8E%E4%B8%8B%E8%BD%BD/5hhdjrFHDcYMHOi77cPbh6qKsvY66MK_AgotQzdzFfI.png" alt="image"></p><p><img src="/2023/04/25/5-ADNI-%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E4%B8%8E%E4%B8%8B%E8%BD%BD/GKPkW0oAoS1rvOO2TjwVvqu4HYRXCo39uYbqMHO61og.png" alt="image"></p><p>挑选自己想要的数据进行下载，此处对AD/MCI/CN只选取年龄在60-85之间的人，每个人只选择一个3D图像</p><p><img src="/2023/04/25/5-ADNI-%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E4%B8%8E%E4%B8%8B%E8%BD%BD/hkwFvBiZU7-Eh9dpEbgaBZf7mA8uaKf8ItVARJw5O3w.png" alt="image"></p><p>最后选出来3个数据集：</p><ul><li>My_Study_AD</li><li>My_Study_CN</li><li>My_Study_MCI</li></ul><p>由于下载的My_Study_MCI男女数量差别过大，重新进行下载My_Study_MCI_Male和My_Study_MCI_Female，到本地进行数据合并。</p><p>自己挂梯子开始下载可能比较快一点，下载CSV，NIFTI，MetaData，一健下载</p><p><img src="/2023/04/25/5-ADNI-%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E4%B8%8E%E4%B8%8B%E8%BD%BD/kY-KN-UP168ax_uEhBUIp87ZfsnftH5WKyq7IHlyfbo.png" alt="image"></p><h3 id="2-数据集性别-年龄分布"><a href="#2-数据集性别-年龄分布" class="headerlink" title="2-数据集性别/年龄分布"></a>2-数据集性别/年龄分布</h3><table><thead><tr><th>Dataset</th><th>Male</th><th>Female</th><th>Age_Round</th><th>Mean_Age</th><th>Count_Number</th></tr></thead><tbody><tr><td>AD</td><td>44</td><td>36</td><td>60 ~ 85</td><td>75.59 ± 5.86</td><td>80</td></tr><tr><td>MCI</td><td>40</td><td>40</td><td>60 ~ 84</td><td>74.15 ± 7.12</td><td>80</td></tr><tr><td>NC</td><td>52</td><td>48</td><td>70 ~ 85</td><td>75.83 ± 3.85</td><td>100</td></tr></tbody></table><p><img src="/2023/04/25/5-ADNI-%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E4%B8%8E%E4%B8%8B%E8%BD%BD/68v2OC0UH52ZxgMnUYmfUDHVGPFRHjamiB-KApT3iGw.png" alt="image"></p><p>由于上面下载的数据头动矫正一直报错，网上说不同患者的头动参数差距过大，此处还是使用other 分享的。</p><p>后来知道是format是DCOM格式的，需要自己手动转换为nii格式，但是自己明明下载的就是nii格式。。。</p><p>ADNI1_Baseline_3T因为每个人可能超过两张MRI图像，所以用代码随机删除csv文中的条目。确保一个人只有一个MRI图像。</p><p><img src="/2023/04/25/5-ADNI-%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E4%B8%8E%E4%B8%8B%E8%BD%BD/9PtfTj76Uw5Gic7X7KExdEvXufBW3XlAEmYV7GWYeX8.png" alt="image"></p><h3 id="3-ADNI挑选有意义的数据进行下载"><a href="#3-ADNI挑选有意义的数据进行下载" class="headerlink" title="3-ADNI挑选有意义的数据进行下载"></a>3-<strong>ADNI挑选有意义的数据进行下载</strong></h3><h4 id="ADNI数据集本身提供处理过的图片"><a href="#ADNI数据集本身提供处理过的图片" class="headerlink" title="ADNI数据集本身提供处理过的图片"></a>ADNI数据集本身提供处理过的图片</h4><p>有一篇论文“Non-White Matter Tissue Extraction and Deep Convolutional Neural Network for Alzheimer’s Disease Detection”中涉及到的预处理的数据如下：</p><p>“We use the FDG-PET and MRI data downloaded from ADNI1 dataset with each pair of FDG-PET and MRI for same subject and captured at the same time. The MRI and PET images have undergone several preprocessed steps of research groups belonged to the ADNI.”</p><p>In detail, the MRI images are pre-processed by steps: <strong>gradwarp, B1 non-uniformity and N3</strong>. Gradwarp means correction of image geometry distortion due to gradient model, B1 non-uniformity is a correction procedure that uses B1 calibration scans to correct image intensity nonuniformity. Finally, a N3 histogram peak sharpening algorithm was applied to reduce intensity non-uniformity of images.</p><p>其中，对MRI图像进行预处理的步骤有:<strong>梯度偏差、B1非均匀性和N3</strong>。梯度偏差是指梯度模型引起的图像几何畸变的校正，B1非均匀性是利用B1校正扫描对图像强度非均匀性进行校正的一种校正方法。最后，采用N3直方图峰值锐化算法来降低图像的强度不均匀性</p><p>For the FDG-PET images, a procedure involving <strong>dynamic co-registering frames</strong> and acquiring averaging from baseline PET scan was conducted. PET images were reoriented as <strong>AC-PC correction</strong> into a standard 160x160x96 voxel image grid, having 1.5mm cubic voxels. These images underwent continued ﬁltering with a scanner-speciﬁc ﬁlter function to procedure images of a uniform isotropic resolution of 8mm Full Width at Half Maximum (FWHM).</p><p>对FDG-PET图像，采用<strong>动态共配帧</strong>和<strong>基线PET扫描平均</strong>的方法。将<strong>PET图像重新定向为AC-PC校正</strong>，得到标准的160x160x96体素图像网格，体素为1.5mm立方。这些图像在半最大值(FWHM)条件下，通过一个特定于扫描器的滤波功能，对均匀各向同性分辨率为8mm的全宽图像进行连续滤波。</p><p>那么如何针对论文中提到的数据进行搜索呢？</p><p><img src="/2023/04/25/5-ADNI-%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E4%B8%8E%E4%B8%8B%E8%BD%BD/1u6Yv8htikRptPnp2YHF1yM1BoaN4WrouRT3epWl5TU.png" alt="image"></p><p>我们首先搜索AD类的数据，且同时搜索MRI和PET模态的数据，请见上图。单击搜索（SEARCH）后如下图所示。</p><p><img src="/2023/04/25/5-ADNI-%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E4%B8%8E%E4%B8%8B%E8%BD%BD/MhNTmFZVQwq6dJ5gWMV9_7d2cqIIbr4_tT7dhDqZRXg.png" alt="image"></p><p>可以发现，受试者002_S_0619的图片都是MRI模态的，没有PET模态的，所以放弃这是受试者，通过滚动条，继续查找下一个受试者，因为我们的目的是寻找同一年内既有MRI图像又有PET图像的受试者，最终把这两种模态的图片进行配准等多模态分析，可以详见论文。接下来继续：</p><p><img src="/2023/04/25/5-ADNI-%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E4%B8%8E%E4%B8%8B%E8%BD%BD/lSSvmBHWrEK-pLDlG4hynX3Fald625c88Smt7Wafq-w.png" alt="image"></p><p>这里84.6和84.7岁视为85岁，且存在满足条件的图像，所以，就勾选上，然后单击<strong>Add to Collection</strong>按钮</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://ida.loni.usc.edu/pages/access/search.jsp&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://ida.loni.usc.edu/pages/access/search.jsp&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;1-实验数据集下载&quot;&gt;&lt;a href=&quot;#1-实验数据集下载&quot; class=&quot;headerlink&quot; title=&quot;1-实验数据集下载&quot;&gt;&lt;/a&gt;1-实验数据集下载&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;T1W1-3D-MP RAGE&lt;/strong&gt;：T1加权三维磁化强度预备梯度回波序列属于快速容积扫描技术，具有较高的空间分辨率和时间分辨率，信噪比高，伪影小，对 脑内结构（如白质、灰质和脑脊液）对比度良好，能三维显示人脑内部精细解剖结构，有利于显示小病灶及其细节，对神经系统疾病的诊断具有重要价值；同时也是获取正常人脑的三维可视化图谱的重要方法。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>4-AD文献的阅读记录</title>
    <link href="http://javassun.github.io/2023/04/20/4-AD%E6%96%87%E7%8C%AE%E7%9A%84%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/"/>
    <id>http://javassun.github.io/2023/04/20/4-AD%E6%96%87%E7%8C%AE%E7%9A%84%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/</id>
    <published>2023-04-20T11:16:38.000Z</published>
    <updated>2024-05-09T07:22:36.383Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>Wechat: SHR—97</p><h3 id="1-AD的诊断标准（张伟娇，张巍：阿尔茨病的诊断进展）"><a href="#1-AD的诊断标准（张伟娇，张巍：阿尔茨病的诊断进展）" class="headerlink" title="1 AD的诊断标准（张伟娇，张巍：阿尔茨病的诊断进展）"></a><strong>1 AD的诊断标准（张伟娇，张巍：阿尔茨病的诊断进展）</strong></h3><p>AD生物学标志物的包括**(强调病程连续性)**：（1）核磁MRI萎缩；（2）脑脊液CSF中beta淀粉蛋白A-beta42下降；（3）总tau(T-tau)、磷酸化tau(P-tau)升高。</p><p>AD临床症状判断标准：（1）内侧颞叶萎缩；（2）延迟故事回忆DSR&lt;=10.5分；（3） 霍普金斯词语学习测试HVLT &lt;=15.5； （4）综合认知：简易精神状况检查表MMSE&lt;=26 (一说中国标准是&lt;=23)；（5）功能：日常生活能力ADL&gt;=16分；（6）语言：波士顿命名测试 BNT 30项&lt;=21.5分；（7）视空音：中国改良版连线测试A， TMF-A&gt;=98.5 ， TMT-B&gt;=188.5s。<br>几个诊断标准：NINCDS-ADRDA，IWG-1标准，NIA-AA标准，IWG-2标准。《中国认知障碍与痴呆指南》采用NINCDS-ADRDA与NIA-AA标准。</p><a id="more"></a><h3 id="2-18-F-FBB-PET-MRI-对阿尔茨海默病诊断价值研究-（刘家金-等），侧重影像学研究"><a href="#2-18-F-FBB-PET-MRI-对阿尔茨海默病诊断价值研究-（刘家金-等），侧重影像学研究" class="headerlink" title="2 18 F-FBB PET-MＲI 对阿尔茨海默病诊断价值研究 （刘家金 等），侧重影像学研究"></a><strong>2 18 F-FBB PET-MＲI 对阿尔茨海默病诊断价值研究 （刘家金 等），侧重影像学研究</strong></h3><p>对研究对象均完成18 F-FBB PET-MＲI 脑部检查， 分别测量左、 右侧大脑前扣带回、 额叶、 侧颞叶、 后扣带回、 枕叶、 上顶叶、 小脑皮层的感兴趣区( ＲOI) 及对应的标准摄取值比率( SUVＲ) ， 比较两组的18 F-FBB PET-MＲI 图像和18 F-FBB SUVＲ</p><p>结论：18 F-FBB PET-MＲI 显示: 健康对照组各叶皮层未见明显放射性浓聚， AD 组除小脑外各叶皮层放射性分布异常摄取; 健康对照组和 AD 组皮质下白质呈高度弥漫性放射性浓聚。AD 组前扣带回、 额叶、 侧颞叶、 后扣带回、 枕叶、 上顶叶、 全脑的18 F-FBB SUVＲ 均高于健康对照组 。</p><p><img src="/2023/04/20/4-AD%E6%96%87%E7%8C%AE%E7%9A%84%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/ZvrLZjAtlwx6eFOjWXkQGrdmk7KsfRz_MHLWE5Q4GM0.png" alt="image"></p><h3 id="3-阿尔茨海默病的症状、-诊断及其护理（刘畅等，基因组学与应用生物学）"><a href="#3-阿尔茨海默病的症状、-诊断及其护理（刘畅等，基因组学与应用生物学）" class="headerlink" title="3 阿尔茨海默病的症状、 诊断及其护理（刘畅等，基因组学与应用生物学）"></a><strong>3 阿尔茨海默病的症状、 诊断及其护理（刘畅等，基因组学与应用生物学）</strong></h3><p>前期症状：轻微认知障碍MCI是一种介于正常和失忆症之间的过渡状态。难以记住最近发生的事，无法吸收新资讯。其他包括：注意力管控、计划事情、弹性处理、抽象思考和语义记忆等方面的问题。</p><p>早期症状：失语症、书面表达变得困难。精细动作（如写作、画图和穿衣）动作不协调，失用症。</p><p>中期症状：游荡、易怒、情绪不稳，尿失症。</p><p>晚期症状：完全依赖护理，语言能力退化。</p><p>临床诊断：病人病史、行业评估、认知测验、脑部影像检查和血液采检来排除其他可能的因素。<strong>一些医学影像技术可以协助排除其他大脑病变或痴呆症亚型，医学影像也可以用于预测从MCI到AD的转变**</strong>。**  </p><p>影像学诊断： 电脑断层扫描(CT)、 核磁共振成像(MRI)、 单光子电脑断层摄影(SPECT)和正子电脑断层摄影(PET) 等高阶医学影像技术， 可以协助排除脑膜瘤、 硬膜下出血等其他脑部疾病或痴呆症亚型。此外，医学影像也可以用于预测从轻微认知失调到阿尔茨海默病的转变(Schroeter et al., 2009)。海马回计量(hippocampal volumetry)的诊断价值或许较高， 但大多数医院不易取得(Scheltens et al., 2016)。目前核磁共振已经有影像评分系统，可以协助识别皮质萎缩的区域。 目前用于阿尔茨海默病的放射性示踪剂中， 针对检测大脑中的类淀粉样斑块(可能是阿尔茨海默症的生物标记)， 美国(FDA)核准的药物有 florbetapir F18， flutemetamol F18 和 florbetaben F18。针对tau20，它们都用于检测大脑中的淀粉样 β 斑块(可能是阿尔茨海默症的生物标记)。</p><h3 id="4-阿尔茨海默病生物标志物的临床诊断应用-（张守字）"><a href="#4-阿尔茨海默病生物标志物的临床诊断应用-（张守字）" class="headerlink" title="4 阿尔茨海默病生物标志物的临床诊断应用 （张守字）"></a><strong>4 阿尔茨海默病生物标志物的临床诊断应用 （张守字）</strong></h3><p>AD的病理发病过程是由一系列级联反应组成的， 最开始的驱动因素从β-淀粉样蛋白（amyloid β-protein, Aβ）聚集开始， 导致了蛋白缠结的扩散、 神经元损伤和进行性认知功能下降。AD 生物标志物有望在痴呆早期进行病理性确诊， 一直被寄予厚望。目前研究最多的 AD诊断生物标志物主要包括体液生物标志物和影像学标志物 。</p><p>（1）体液生物标志物 </p><p>脑脊液标志物：Aβ42、 T-tau 和 P-tau 。一般推荐诊断 AD的脑脊液Aβ42为183～523 pg/ml， T⁃tau为145～759 pg/ml，P⁃tau 为 66～187 pg/ml； Aβ42 为 663 pg/ml， 诊断 AD的敏感度、 特异度分别为 94.8%和 66.0%； T⁃tau 为184 pg/ml， 诊断AD的敏感度和特异度分别为56.8%和92.6%； T⁃tau / Aβ42＞0.215 区别轻中度 AD 与认知正常的敏感度达94.8%， 特异度为77.7% 。</p><p>血浆生物标志物 ：使用IMR 技术检测血浆 Aβ42 和 tau， 采用分界值 Aβ42 ×tau＞382.68（pg/ml）2 </p><p>基因测序：早发家族性 AD病例中， 68%的患者与 APP、 早老素 1（PSEN1）或早老素 2（PSEN2）基因突变有关，携带者AD发病风险超过95%。 </p><p>（2）影像学标志物 </p><p>淀粉样蛋白 PET： 目前临床常用的淀粉样蛋白 PET 的配体 主 要 有 11C- PIB、florbetapir、florbetaben、flute⁃metamol和 AZD4694 。PiB⁃PET 诊断 AD 的敏感度为94%（83%～100%）， 特异度为 56%（46%～88%）</p><p>Tau 蛋白 PET（tau-PET）：tau⁃PET内侧颞叶区域示踪剂（18F⁃AV⁃1451）滞留增加与情景记忆损害、 总体认知下降以及神经纤维缠结的 tau 病理 Braak 分期相关。与 AD早期即出现明显的 Aβ沉积不同， tau示踪 剂对临床前或极早期AD并不敏感， 其诊断AD的敏感度和特异度分别为 96.8%和 87.9%</p><p>头颅 MRI检查已经成为诊断 AD必不可少的工具，尤其对海马、 内侧颞叶、 顶叶、 枕叶等脑区是否有萎缩 的判断， 是诊断和鉴别诊断各种类型痴呆的前提。脑FDG- PET 对诊断认知障碍类疾病也很有帮助， 如以AD病理诊断为对照， FDG⁃PET的敏感度为 93%， 但其特异度仅为63%</p><h3 id="5-阿尔茨海默病患者血清-miR-－-145表达水平及诊断价值研究-（党玉婷等）"><a href="#5-阿尔茨海默病患者血清-miR-－-145表达水平及诊断价值研究-（党玉婷等）" class="headerlink" title="5 阿尔茨海默病患者血清 miR － 145表达水平及诊断价值研究 （党玉婷等）"></a><strong>5 阿尔茨海默病患者血清 miR － 145表达水平及诊断价值研究 （党玉婷等）</strong></h3><p>血清 miR － 145 在阿尔茨海默病患者中的表达水平及临床诊断价值 ，AD 组在治疗前及盐酸多奈哌齐治疗 6 个月后、 对照组在入组时采用荧光定量 PCR 检测 miR － 145 表达水平 与 MMSE 和 MoCA 量表评分、 IGF － 1R 表达水平呈负相关 ，AD 患者血清 miR － 145 表达上调，对 AD 筛查具有一定的应用价值，有望成为临床辅助诊断 AD 的潜在生物学标志物 。</p><h3 id="6-阿尔茨海默病早期诊断的生物标志物研究进展-（谢文然等）"><a href="#6-阿尔茨海默病早期诊断的生物标志物研究进展-（谢文然等）" class="headerlink" title="6 阿尔茨海默病早期诊断的生物标志物研究进展 （谢文然等）"></a><strong>6 阿尔茨海默病早期诊断的生物标志物研究进展 （谢文然等）</strong></h3><p><img src="/2023/04/20/4-AD%E6%96%87%E7%8C%AE%E7%9A%84%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/R9o96wVrfPqqtFhlNumDMk4QVdI1stBCBvHAbe8jJuU.png" alt="image"></p><h3 id="7-磁共振成像在阿尔茨海默病诊断中的研究进展-（巴成慧-等）"><a href="#7-磁共振成像在阿尔茨海默病诊断中的研究进展-（巴成慧-等）" class="headerlink" title="7 磁共振成像在阿尔茨海默病诊断中的研究进展 （巴成慧 等）"></a><strong>7 磁共振成像在阿尔茨海默病诊断中的研究进展 （巴成慧 等）</strong></h3><p>从结构性磁共振成像( structural magnetic resonance imaging，sMＲI) 、 弥 散 张 量 成 像 ( diffusion tensor imaging，DTI) 、 磁共振波谱( magnetic resonance spectroscopy， MＲS) 及 动 脉 自 旋 标 记 磁 共 振 成 像 ( arterial spin labeling magnetic resonance imaging， ASL-MＲI)四个方面简述 MＲI 技术在 AD 早期诊断中的应用研究。</p><h3 id="8-MRI鉴别诊断阿尔茨海默病和血管性痴呆的价值研究（张钦等）"><a href="#8-MRI鉴别诊断阿尔茨海默病和血管性痴呆的价值研究（张钦等）" class="headerlink" title="8 MRI鉴别诊断阿尔茨海默病和血管性痴呆的价值研究（张钦等）"></a><strong>8 MRI鉴别诊断阿尔茨海默病和血管性痴呆的价值研究（张钦等）</strong></h3><p>MＲI 在影像学上区别 AD 和 VD 患者的主要表现 AD 患者以大脑皮层萎缩， 尤其是海马萎缩为主， 而 VD 患者以脑白质病变为主， 临床还可依据疾病史、 临床症状及各项问卷进行综合评估 。</p><h3 id="9-磁共振成像在我国阿尔茨海默病早期诊断中的研究发展历程-（倪良卉等）"><a href="#9-磁共振成像在我国阿尔茨海默病早期诊断中的研究发展历程-（倪良卉等）" class="headerlink" title=" 9 磁共振成像在我国阿尔茨海默病早期诊断中的研究发展历程 （倪良卉等）"></a> <strong>9 磁共振成像在我国阿尔茨海默病早期诊断中的研究发展历程 （倪良卉等）</strong></h3><p> (structural Magnetic Resonance Imaging, sMRI）也逐渐被应用到早期 ＡＤ 人群的研究中，以期发现这类患者的一些脑区结构变化。 ２０２０年南京医科大学和南京脑科医院合作开展的一项研究发现，轻度认知功能障碍 （ Mild Cognitive Impairment, MCI）患者在双侧海马、海马旁回、杏仁核、右侧苍白球、右侧岛叶和左侧颞中回出现结构性萎缩，而主观认知下降（Subjective Cognitive Decline， SCD） 患者的灰质萎缩部位主要集中在右侧舌回、右侧楔叶和左侧额叶内侧回 .</p><p>不同类型痴呆患者的海马亚区体积的萎缩程度有显著差异，并且与记忆力呈显著相关，由于海马亚区对 ＡＤ 病理损伤的易感性不同，在识别早期 ＡＤ 时，评估海马亚区的体积可能在一定程度上优于海马总体积 。</p><p>fMRI对 ＡＤ 和 ＭＣＩ患者在额叶、颞叶和顶叶的不同脑区表现出异常的低频振幅值（一项在静息态磁共振中广泛应用、可以对脑局部情况进行观测的指标）。 该研究还发现，扣带回后部的低频振幅值是这 ３ 组间差异最明显的脑区，呈现出 ＮＣ ＞ ＭＣＩ ＞ ＡＤ 的模式 .</p><p>表观弥散系数可用来评价单位时间内水分子位移运动的范围和速度 ：与健康对照组比较，遗忘型轻度认知功能障碍 （ａＭＣＩ）患者的 ＡＤＣ 值在左侧边缘叶也有显著升高，而 ＡＤ 患者出现显著改变的脑区主要集中在双侧海马、中扣带回、右侧海马旁回和额颞叶。</p><h3 id="10-磁共振后扣带回纹理特征分析在老年健康人群、轻度认知障碍与阿尔茨海默病患者鉴别诊断中的价值-（王波涛）"><a href="#10-磁共振后扣带回纹理特征分析在老年健康人群、轻度认知障碍与阿尔茨海默病患者鉴别诊断中的价值-（王波涛）" class="headerlink" title="10 磁共振后扣带回纹理特征分析在老年健康人群、轻度认知障碍与阿尔茨海默病患者鉴别诊断中的价值 （王波涛）"></a><strong>10 磁共振后扣带回纹理特征分析在老年健康人群、轻度认知障碍与阿尔茨海默病患者鉴别诊断中的价值 （王波涛）</strong></h3><p>图像纹理特征参数包括角二阶矩、对比度、自相关、逆差距、熵。</p><p><img src="/2023/04/20/4-AD%E6%96%87%E7%8C%AE%E7%9A%84%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/W7S6lrx37BUyarABjlAYWkaEaTPdaguH4SL2ryJBKs0.png" alt="image"></p><h3 id="11-合理应用神经影像技术提高对阿尔茨海默病的诊断效能-（陈敏）"><a href="#11-合理应用神经影像技术提高对阿尔茨海默病的诊断效能-（陈敏）" class="headerlink" title=" 11 合理应用神经影像技术提高对阿尔茨海默病的诊断效能 （陈敏）"></a> <strong>11 合理应用神经影像技术提高对阿尔茨海默病的诊断效能 （陈敏）</strong></h3><p>MRI: MRI包括结构 MRI和广义的功能 MRI，前者可以清晰显示脑解剖细节，后者可以评价脑代谢及脑功能，被广泛用于AD的科学研究和临床评估。 PET: 随着药物合成技术的不断进步，PET 示踪剂从标记脱氧葡萄糖发展到现在可标记 Aβ和 Tau蛋白，为 AD 早期，甚至是临床前期诊断提供了强有力的支持，不过 PET 因具有放射性、采集时间长及检查费用高等限制了其广泛应用。<br>Tau-PET: AD 患者的 Tau 蛋白示踪剂高摄取脑区与脑萎缩和 FDG代谢减低区有更好的一致性，提示 Tau-PET 更能从病理学层面揭示AD脑异常改变。</p><p>Aβ-PET: 老年斑的核心是 Aβ沉积，Aβ-PET已成为 AD的病理诊断标志物 ,但部分正常老年人脑内也可见相似的 Aβ沉积，仅仅依据 Aβ-PET 阳性并不能诊断 AD；由于 Aβ沉积与疾病严重程度相关性差， Aβ-PET不适合用于 AD的病情监测 。</p><p>18F-脱氧葡萄糖 （18-fluorine flurode oxyglucose，18F-FDG） PET ：FDG-PET 是 AD 早期诊断和鉴别诊断的重要检查手段。不过 FDG 代谢减低并非 AD 的特征表现，且代谢减低出现时神经元已严重损伤，患者难以从治疗中获益。</p><h3 id="12-基于-fMRI-和-sMRI-特征融合的阿尔茨海默病辅助诊断-刘茜等"><a href="#12-基于-fMRI-和-sMRI-特征融合的阿尔茨海默病辅助诊断-刘茜等" class="headerlink" title="12 基于 fMＲI 和 sMＲI 特征融合的阿尔茨海默病辅助诊断 (刘茜等)"></a><strong>12 基于 fMＲI 和 sMＲI 特征融合的阿尔茨海默病辅助诊断 (刘茜等)</strong></h3><p>使用数据集：ADNI，该数据集包括静息态fMRI以及对应的sMRI数据。</p><p>数据预处理：</p><p>fMRI包含大脑活动的时间信息和大脑内部的空间特征，通过功能连接矩阵可以有效区分疾病的进展情况。使用dpabi软件对fMRI进行预处理，获得时间序列，以此计算 功能连接矩阵。</p><p>提取脑灰质：AD患者的特定脑区灰质发生萎缩。使用SPM8软件对sMRIl图像做预处理，使用dpabi软件提取大脑90个脑区的灰质体积特征，分为分割、生成特异性模板，生成流动场、配准和提取各大脑区灰质体积，共5步。</p><p>研究方法：</p><h4 id="基于动态功能连接的-fMRI-特征提取"><a href="#基于动态功能连接的-fMRI-特征提取" class="headerlink" title="基于动态功能连接的 fMＲI 特征提取"></a>基于动态功能连接的 fMＲI 特征提取</h4><p><img src="/2023/04/20/4-AD%E6%96%87%E7%8C%AE%E7%9A%84%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/r2xP7XX0Dh0iQ2qSKNARTyJH1WeUR4XmWIVW8Kqksxk.png" alt="image"></p><h4 id="基于特征选择的-sMRI-特征提取"><a href="#基于特征选择的-sMRI-特征提取" class="headerlink" title="基于特征选择的 sMＲI 特征提取"></a>基于特征选择的 sMＲI 特征提取</h4><p><img src="/2023/04/20/4-AD%E6%96%87%E7%8C%AE%E7%9A%84%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/57_10LyUeWUJooB9ZFIot5lafhCbV-qP5MYQNsuCka8.png" alt="image"></p><h4 id="特征融合"><a href="#特征融合" class="headerlink" title="特征融合"></a>特征融合</h4><p>采取串行融合的方法，在 SVM 分类器前进行特征融合，如式( 7) 所示。 f =［ α’ β’］ ( 7) 对特征向量 α 和 β 做最大最小值标准化后获得α’和 β’，串行特征融合将上述特征向量直接合并为一个新的向量，特征维数变为 α’和 β’特征维数之和， 将 f作为融合特征输入 SVM 分类器 </p><h4 id="评价标准"><a href="#评价标准" class="headerlink" title="评价标准"></a>评价标准</h4><p>结果使用准确率 ( Accuracy) 、 精确率 ( Precision) 、 召回率( Ｒecall) 表示， 准确度评估判断正确占全体测试集的比例，精确率评估诊断为某类正确的概率，召回率评估某类样本中判断正确的概率</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;Wechat: SHR—97&lt;/p&gt;
&lt;h3 id=&quot;1-AD的诊断标准（张伟娇，张巍：阿尔茨病的诊断进展）&quot;&gt;&lt;a href=&quot;#1-AD的诊断标准（张伟娇，张巍：阿尔茨病的诊断进展）&quot; class=&quot;headerlink&quot; title=&quot;1 AD的诊断标准（张伟娇，张巍：阿尔茨病的诊断进展）&quot;&gt;&lt;/a&gt;&lt;strong&gt;1 AD的诊断标准（张伟娇，张巍：阿尔茨病的诊断进展）&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;AD生物学标志物的包括**(强调病程连续性)**：（1）核磁MRI萎缩；（2）脑脊液CSF中beta淀粉蛋白A-beta42下降；（3）总tau(T-tau)、磷酸化tau(P-tau)升高。&lt;/p&gt;
&lt;p&gt;AD临床症状判断标准：（1）内侧颞叶萎缩；（2）延迟故事回忆DSR&amp;lt;=10.5分；（3） 霍普金斯词语学习测试HVLT &amp;lt;=15.5； （4）综合认知：简易精神状况检查表MMSE&amp;lt;=26 (一说中国标准是&amp;lt;=23)；（5）功能：日常生活能力ADL&amp;gt;=16分；（6）语言：波士顿命名测试 BNT 30项&amp;lt;=21.5分；（7）视空音：中国改良版连线测试A， TMF-A&amp;gt;=98.5 ， TMT-B&amp;gt;=188.5s。&lt;br&gt;几个诊断标准：NINCDS-ADRDA，IWG-1标准，NIA-AA标准，IWG-2标准。《中国认知障碍与痴呆指南》采用NINCDS-ADRDA与NIA-AA标准。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="论文" scheme="http://JavaSsun.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>3-指标特征选择</title>
    <link href="http://javassun.github.io/2023/04/05/3-%E6%8C%87%E6%A0%87%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    <id>http://javassun.github.io/2023/04/05/3-%E6%8C%87%E6%A0%87%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/</id>
    <published>2023-04-05T09:16:38.000Z</published>
    <updated>2024-05-09T06:33:10.386Z</updated>
    
    <content type="html"><![CDATA[<p>Author: haoransun<br>WeChat: SHR—97</p><p>ADNI公开数据集中包含每个受试者的临床信息，包括人口统计学信息、神经心理学评估、生物学检测、神经病理学、基因检测等。本文通过CfsSubsetEval评估器和查阅医学相关论文，选择了其中11个指标作为临床特征。其中包括2个人口统计学指标，4个神经心理学指标，5个生物学检测指标。具体如下：</p><p>（1）简易智力状态检查量表（MMSE）。MMSE是目前临床上检查智力最常见的量表，能全面、准确、迅速地反应被试患者智力状态及认知功能缺损程度。通过量表总分值数反应患者的情况，其中与文化教育程度有关，进一步的测验包括记忆力、执行功能等各项认知功能的评估。</p><a id="more"></a><p>（2）临床痴呆评估量表（CDR）。CDR是通过与患者及其家属交谈中获得信息，加以提炼、完成对患者认知受损程度的评估，继而快速评定患者病情的严重程度。评定的领域包括记忆、定向力、判断与解决问题的能力、工作与社会交往能力、家庭生活和个人业余爱好、独立生活自理能力。</p><p>（3）莱氏听觉言语学习测试（RAVLT）。RAVLT即刻和延迟测试，该测试评估患者的语言记忆，是最敏感的记忆测试之一。测试通过给患者听读一定数量的内容，然后进行即刻和延时回忆，以此来判断患者的情况。研究表明，RAVLT对于AD的区分均高于其它的神经心理学评估。</p><p>（4）精神活动功能问卷（FAQ）。FAQ问卷包含一些生活常见问题，用于测量有关日常事务的详细信息。通过受试者对于这些信息的描述来判断其认知能力。</p><p>（5）β淀粉样蛋白。老年斑为AD神经病理学特征性表现，其主要成分是β 淀粉样蛋白（Amyloid β，Aβ）。生物体内的Aβ以多种形式存在，其中最主要的为Aβ40和Aβ42。研究发现，AD患者脑组织中β 淀粉樣蛋白明显增多，通过检测血浆中Aβ水平对于检出AD有一定的帮助。</p><p>（6）Tau蛋白和水溶性磷酸化Tau蛋白。Tau 蛋白是一种相对低分子质量的微管相关蛋白，在发生异常磷酸化、糖基化后易形成配对螺旋纤维 （paired helical filaments， PHFs），进一步组成神经原纤维缠结，后者为 AD 的特征性病理表现。 中重度AD患者脑脊液中 tau 蛋白水平较正常对照明显升高，且这一指标的升高早于临床痴呆症状的出现，提示其可用于 AD 的预测。</p><p>（7）ApoE-载脂蛋白E。ApoE是中枢神经系统最主要的载脂蛋白之一，参与胆固醇的动员和重分布，也是神经系统发育和损伤后维持髓鞘和神经元细胞膜完整性的必要成分，其在血浆中的蛋白水平受ApoE基因影响。相关研究表明携带ApoE 基因型者由MCI进展至AD的风险较高，因此ApoE对于AD的诊断有一定的参考价值。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Author: haoransun&lt;br&gt;WeChat: SHR—97&lt;/p&gt;
&lt;p&gt;ADNI公开数据集中包含每个受试者的临床信息，包括人口统计学信息、神经心理学评估、生物学检测、神经病理学、基因检测等。本文通过CfsSubsetEval评估器和查阅医学相关论文，选择了其中11个指标作为临床特征。其中包括2个人口统计学指标，4个神经心理学指标，5个生物学检测指标。具体如下：&lt;/p&gt;
&lt;p&gt;（1）简易智力状态检查量表（MMSE）。MMSE是目前临床上检查智力最常见的量表，能全面、准确、迅速地反应被试患者智力状态及认知功能缺损程度。通过量表总分值数反应患者的情况，其中与文化教育程度有关，进一步的测验包括记忆力、执行功能等各项认知功能的评估。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="人工智能" scheme="http://JavaSsun.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="研究生课题-AD检测" scheme="http://JavaSsun.github.io/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E9%A2%98-AD%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
</feed>
